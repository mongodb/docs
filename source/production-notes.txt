================
Production Notes
================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

Overview
--------

With |service-fullname| as your data platform, your operational focus
can shift away from the mundane operational tasks and workflows required
to build and maintain database infrastructure, allowing you to focus on
helping engineers add value to the business. Instead of maintaining
hardware and keeping up with operating system-level software patches,
engineers can devote their time and energy to developing data models
that meet the current and future requirements of your enterprise.

This document outlines some best practices for establishing and
maintaining a successful MongoDB production deployment using
|service-fullname| {+clusters+}.

.. seealso::

   - To learn about sizing considerations, see :ref:`sizing`.
   - To learn more about resilience, see :ref:`resilient-application`.
   - To learn more about {+PIT-Restore+}. see 
     :ref:`recover-pit-continuous-cloud-backup`.

Roles and Responsibilities
--------------------------

MongoDB manages and operates the infrastructure required to provide a
MongoDB Database Service to the customer. MongoDB's responsibilities
include the following:

- Manage the database {+clusters+} and underlying infrastructure, ensuring
  availability, stability, and performance of MongoDB, backed by a
  99.995%
  :website:`Uptime Service Level Agreement (SLA) </cloud/atlas/availability-sla>`
  for {+clusters+} of size ``M10`` and larger.

- Ensure the health of the underlying compute nodes. Make sure they are
  running, have network connectivity, and have all recommended OS-level
  patches to maintain the
  :website:`Uptime SLA </cloud/atlas/availability-sla>`.

- Manage the MongoDB database configuration based on the customer's
  specific design choices made via the Atlas user interface or
  :doc:`REST API </api>`.

- Apply all MongoDB maintenance upgrades automatically to ensure the
  latest bug fixes to the product are in use.

- Manage the security profile, including
  :doc:`Role-Based Access Control </security-add-mongodb-users>`,
  :doc:`adding IP addresses to an IP access list </security/ip-access-list>`, and
  :doc:`peering </security-vpc-peering>` to
  maximize {+cluster+} security per the customer's direction.

- Provide :doc:`backup and restore </backup-restore-cluster>` services.

The customer continues to develop and deploy applications which access
MongoDB, without having to directly manage the underlying database
resources and/or infrastructure.

.. _db-deployment-best-practices:

{+Database-Deployment+} Management
----------------------------------

.. important::

   |service| doesn't support moving {+database-deployments+} from one project to
   another. Instead, perform a :ref:`live migration <import-strategies>`.

|service-fullname| abstracts away database operations so that you can
focus on high-value, high-level management decisions. You can manage
access to your |service| {+database-deployments+} with :doc:`Atlas User
Roles </reference/user-roles/>`. You can apply these permissions
**only** on the :ref:`the organization level
<org-level-best-practices>` or :ref:`the project level
<project-level-best-practices>`. So, you should carefully plan the
hierarchy of your organizations and projects.

.. tip::

   If you need to create more than the |service| organization limit of 
   250 projects, create more organizations to store them. To learn
   more, see :ref:`Atlas Organization and Project Limits <org-project-limits>`.

To create a well-designed hierarchy of :doc:`organizations and
projects <organizations-projects>` within |service|, break your
{+database-deployments+} into projects that make sense for your use
cases. This allows for maximum enterprise efficiency with minimum
operational friction.

.. tip::

   Use :ref:`Cross-Organization Billing <cross-org-billing>` to link 
   multiple |service| organizations and receive a single invoice for 
   all of them. To learn more, see :ref:`Cross-Organization Billing Use
   Cases <cross-org-billing-use-cases>`.

.. _org-level-best-practices:

The Organization Level
~~~~~~~~~~~~~~~~~~~~~~

At the :doc:`Organization </tutorial/manage-organizations>` level, you
can implement security controls and create users which work across one
or more :doc:`Projects </tutorial/manage-projects>`. |service|
:doc:`billing </billing/>` occurs at the Organization level.

To efficiently control user access and privileges, you can group users
into :doc:`teams </access/manage-teams-in-orgs>` at the Organization
level.

.. important::

   Don't include :ref:`sensitive information <sensitive-info>` in your 
   :ref:`organization names <create-organization>`.

.. _project-level-best-practices:

The Project Level
~~~~~~~~~~~~~~~~~

Projects offer a security isolation and authorization boundary, so they
are typically allocated by application team and application
environment. For example, within two application teams there might be
six projects: one for each team in the Development, Staging, and
Production environments.

You can create project-level |service|
:doc:`users and roles </security-add-mongodb-users>` with appropriate
access to the different production and development application
environments.

- Users with the :authrole:`Project Read Only` role can access
  project-level monitoring and system health metadata without having
  access to any collection data or administrative operations.

- Users with the :authrole:`Project {+Cluster+} Manager` role can scale
  {+clusters+} and perform other administrative operations, but have no
  data-level access.

.. important:: Features Unavailable in {+Serverless-Instances+} (Deprecated)

   {+Serverless-instances+} don't support most of
   the following responsibilities. To learn more, see
   :doc:`{+Serverless-Instance+} Limitations
   </reference/serverless-instance-limitations/>`.

Other project-level responsibilities include:

- Configure :ref:`termination protection
  <create-cluster-termination-protection>` to prevent users from
  accidentally deleting your {+cluster+}.

- Implement optional enterprise security features, including:

  - :doc:`Encryption with customer key management </security-kms-encryption>`
  - :doc:`Database auditing </database-auditing>`
  - :doc:`LDAP </security-ldaps>`

- Set up network access configuration, including:

  - :doc:`VPC / VNet Peering </security-vpc-peering>`
  - :doc:`Adding IP addresses to an IP access list </security/ip-access-list>`

- Define appropriate :doc:`database alerts <monitoring-alerts>` via the
  |service| interface or API and respond to any which require
  attention.

- Integrate with external :doc:`monitoring/alerting systems
  </tutorial/manage-project-settings>`, such as DataDog and New Relic.

  .. include:: /includes/fact-new-relic-deprecated.rst

.. important::

   Don't include :ref:`sensitive information <sensitive-info>` in your 
   :ref:`project names <create-project>`.

{+Cluster+} Naming Conventions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Choosing the right naming convention for your |service| {+clusters+} is a good
first step towards running a successful production environment. Once you've
named a {+cluster+} you can't rename it, so it's important to get it right the
first time. The following suggestions can make it easier to parse logs and
differentiate {+clusters+}.

- Use descriptive, lowercase names.

- Avoid special characters.

- Join words with hyphens or underscores. Avoid blank spaces between words.

- Use a convention which makes it clear whether a {+cluster+} is for production,
  staging, or development purposes. 

- Don't include :ref:`sensitive information <sensitive-info>` in your 
  :ref:`{+cluster+} names <create-new-cluster-procedure>`.

Some examples of good {+cluster+} names:

- ``prod-aws-website``
- ``staging-gcp-internal``
- ``dev-azure-analytics``

Single Region and Multi-Region {+Clusters+} 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

High availability and {+cluster+} durability depend on a cluster's
geographical deployment configuration. {+Clusters+} which are deployed
within a single :doc:`region </cloud-providers-regions>` are spread
across availability zones within that region, so they can withstand
partial region outages without an interruption of read or write
availability.

You can optionally choose to spread your {+clusters+} across two or
more regions for greater resilience and
:doc:`workload isolation </cluster-config/multi-cloud-distribution>`.

The order of regions determines the priority order for the location of
the :manual:`primary node </core/replica-set-members#replica-set-primary-member>`.
Therefore, if you wish to direct database write operations to a
particular region when that region is available, you should list that
region first. The second region on the list should be the second
choice for where writes should go if the first region is unavailable.

The following example from the |service|
:doc:`Create a {+Cluster+} </tutorial/create-new-cluster/>` UI shows a
multi-region {+cluster+} with electable nodes in three different regions,
arranged by priority from highest to lowest:

.. figure:: /images/multi-region-cluster.png
   :alt: Screenshot of electable nodes across three regions
   :figwidth: 550px

If the :guilabel:`us-east-1` region becomes unavailable, a new primary
will be elected in the :guilabel:`us-west-1` region.

.. note::

   {+Clusters+} must have an odd number of nodes to ensure primary
   electability. To learn more, see
   :manual:`Replica Set Elections </core/replica-set-elections/>`.

Deployment in Two Regions
`````````````````````````

Deploying a {+cluster+} to two regions ensures that a copy of your data
will always be maintained in more than one region. However, a loss of
the region which contains a majority of the nodes in the {+cluster+} will
leave the second region in a read-only state until an administrator
intervenes or the original region becomes available.

Deployment in Three or More Regions
```````````````````````````````````

Deploying a {+cluster+} to three or more regions ensures that the {+cluster+}
can withstand a full region-level outage while maintaining read and
write availability, provided the application layer is fault-tolerant.

If maintaining write operations in your preferred region at all times
is a high priority, it is recommended to deploy the {+cluster+} so that at
least two :manual:`electable members
</core/replica-set-architecture-geographically-distributed#electability-of-members>`
are in at least two data centers within your preferred region.

Global {+Clusters+}
```````````````````

For the best database performance in a worldwide deployment, users can
configure a :doc:`global {+cluster+} </global-clusters>` which uses
location-aware sharding to minimize read and write latency. Users with
geographical storage requirements can also ensure that data is stored
in a particular geographical area.


.. _sensitive-info:

Sensitive Information
~~~~~~~~~~~~~~~~~~~~~

Don't provide sensitive information such as Personally Identifiable 
Information (PII) or Protected Health Information (PHI) for the 
following items:

- :ref:`organization names <create-organization>`
- :ref:`project names <create-project>`
- :ref:`{+cluster+} names <create-new-cluster-procedure>`
- :ref:`database names <atlas-ui-create-a-db>`
- :ref:`collection names <atlas-ui-create-a-collection>`
- :ref:`resource tags <configure-resource-tags>`

Application Management
----------------------

Application-level responsibilities include:

- :manual:`Schema design </core/data-modeling-introduction>`, including
  query and index optimization.

- {+Cluster+} tier and topology selection. Choosing the appropriate
  {+cluster+} :ref:`size <create-cluster-instance>` and topology 
  (:term:`replica set` or :term:`sharded {+cluster+}`), along with 
  :doc:`storage capacity and IOPS </customize-storage/>` is crucial for 
  optimal database performance.

- Provisioning of non-production {+clusters+}. Production backups can be
  restored into non-production {+clusters+} with the |service| UI or the
  API.

- Capacity planning. Determining when additional computational capacity
  is needed, typically using the
  :doc:`monitoring telemetry </monitor-cluster-metrics>` that |service|
  provides. Additional capacity can be added with no application
  downtime, and you can optionally enable
  :doc:`auto-scaling </cluster-autoscaling/>` to respond automatically
  to spikes in usage.

- Deciding when to implement a major database
  :doc:`version upgrade </tutorial/major-version-change/>`.

- Implementing and testing a
  :doc:`backup and restoration </backup-restore-cluster/>` plan.

- Ensuring that applications gracefully handle {+cluster+} failover through
  :doc:`testing </tutorial/test-resilience/test-primary-failover/>`.

- Configuring data analytics services with tools such as
  :bic:`BI Connector </>` and :charts:`Charts </>`.

Scale {+Clusters+}
~~~~~~~~~~~~~~~~~~

MongoDB Atlas offers two methods for scaling, vertical and horizontal.

*Vertical scaling* involves increasing a {+clusters+} storage capacity,
computing power, and/or |iops| rate. Vertical scaling can be
accomplished quickly and is useful for peak usage periods. Vertically
scaling from :term:`shared {+clusters+} <shared cluster>` (``M2`` and
``M5``) requires a few minutes of downtime whereas scaling between
:term:`dedicated {+clusters+} <dedicated cluster>` (``M10`` and greater)
happens without downtime.

When scaling vertically, ``M30`` and higher {+clusters+} are recommended for
production environments. You can use the following {+cluster+} tiers as
production environments for low-traffic applications, but these tiers
are recommended for development environments:

- ``M2`` and ``M5`` shared {+clusters+} (deprecated)
- {+Flex clusters+}
- ``M10`` and ``M20`` {+Dedicated clusters+}

*Horizontal scaling* involves implementing
:manual:`sharding </sharding/>` or adding shards in an
existing sharded {+cluster+}. Horizontal scaling requires careful planning
and execution, and is part of a long-term growth strategy for ``M30+``
{+clusters+}. You can also reduce the number of shards in a sharded {+cluster+}.

.. include:: /includes/fact-reduce-shards-warning.rst

Vertical and horizontal sharding can be combined in |service|. For example,
a sharded {+cluster+} can be vertically scaled up for a peak period,
increasing the storage capacity and computing power of the individual
sharded {+cluster+} members.

By default, |service| :doc:`vertically auto-scales {+cluster+} storage
</cluster-autoscaling/>` up to your configured {+cluster+} tier size limit.

You can configure |service| to
:doc:`automatically scale </cluster-autoscaling/>` your {+cluster+} tier
and {+cluster+} storage capacity in response to increased {+cluster+} usage,
allowing for a rapid, automated response to a need for greater storage
computing power.

.. _build-multi-tenancy-intro:

Multi-Tenancy
-------------

You can implement multi-tenancy with |service| so that a single instance 
of an application serves multiple tenants. Your initial design 
decisions for a multi-tenant architecture can have unintended effects 
over time as requirements evolve or scaling expectations change. To 
learn more, see :ref:`build-multi-tenant-arch`.

.. _archive-cold-data:

Offload and Query Archived Data
-------------------------------

As part of the data lifecycle, if you need to move cold data to a 
different storage tier, you can set up an |service| :ref:`Online Archive 
<online-archive-overview>` rule to move data based on a date or custom 
criteria. Once |service| archives your infrequently accessed data, you 
have a unified view of your |service| and Online Archive data through a 
read-only federated database instance. 

Query Federated Data
--------------------

You can use {+adf+} to query data-in-place across diverse 
infrastructure or to move data between various systems. You can use the 
aggregation pipeline on data from multiple sources to extract insights 
from your data or to transform it for other purposes. For example, you 
can use :ref:`$out <adf-out-stage>` to |s3| and :ref:`$out 
<adf-out-stage>` to |service| to move data between storage tiers. You 
can also use :ref:`$out <adf-out-stage>` to |s3| to easily transform 
data from your |service| {+cluster+} into |json|, |bson|, |csv|, TSV, 
Avro, Parquet, and ORC as well as land it in |aws| |s3| to feed 
downstream systems that need access. 

.. _audit-temp-db-users:

Audit Temporary Database Users
------------------------------

Enabling auditing for all database users, including application service 
users, might severely affect {+cluster+} performance. If you need to audit 
the actions of a temporary database user, you can create a custom role 
targeted for auditing, create a temporary user with elevated privileges, 
and grant this user the custom role to audit their actions.

To audit the actions of a temporary database user:

.. include:: /includes/steps/db-audit-temp-user.rst

Optional Monitoring & Logging Integrations
------------------------------------------

.. include:: /includes/fact-monitoring-logging-integrations.rst

Manage {+Cluster+} Data Volume
------------------------------

|service| offers the following built-in tools to help you manage your
{+cluster+} data volume:

- :ref:`{+Cluster+} auto-scaling <sizing-auto-scaling>` automatically
  reacts to your application load and adjusts the {+cluster+} tier.
- :ref:`Online Archive <archive-cold-data>` automates the
  archival of infrequently accessed data.
- :ref:`Search Nodes <what-is-search-node>` scale independently and
  offload :ref:`{+fts+}
  <fts-top-ref>` and :ref:`{+avs+} <fts-vector-search>` index storage
  from your {+cluster+}.
- :manual:`TTL indexes </core/index-ttl>` automatically remove documents
  from a time series collection to free up space.

In addition to these tools, see the :ref:`{+cluster+} sizing guide
<sizing>` to learn how to adjust your cluster's size up or down. You
can also :ref:`pause a {+cluster+} <pause-terminate-cluster>` to save
costs by temporarily shutting it down while preserving data for up to
30 days.

Support
-------

Different tiers of :doc:`support </support/>` are available, including
options for customers in development and for enterprise customers.

Possible support areas include:

- Issues and concerns with the MongoDB {+clusters+} under management.
- Performance-related inquiries.
- Application-side and :driver:`driver </>` consultation.

.. toctree::
   :titlesonly:

   Cluster Sizing and Tiers </sizing-tier-selection>
   Build a Resilient Application </resilient-application>
   Recover a Point in Time </recover-pit-continuous-cloud-backup>
   Multi-Tenant Architecture </build-multi-tenant-arch>
