.. _adl-add-pipeline:

==================================
Create an {+adl+} Pipeline 
==================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

You can create {+adl+} pipelines using the |service| |ui|, {+dl+} 
Pipelines |api|, and the {+atlas-cli+}. This page guides you through 
the steps for creating an {+adl+} pipeline.

.. _adl-add-pipeline-prereqs:

Prerequisites 
------------- 

Before you begin, you must have the following: 

- :ref:`Backup-enabled <backup-cloud-provider>` ``M10`` or higher 
  |service| cluster. 
- :authrole:`Project Owner` role for the project for which you want to 
  deploy a {+dl+}.
- :ref:`Sample data <sample-data>` loaded on your cluster (if you wish 
  to try the example in the following 
  :ref:`adl-add-pipeline-steps`).

.. _adl-add-pipeline-steps:

Procedure
---------

.. tabs::

   .. tab:: {+atlas-cli+}
      :tabid: atlascli

      .. include:: /includes/extracts/atlas-dataLakePipelines-create.rst

      Watch for a Pipeline to Complete 
      ```````````````````````````````````

      .. include:: /includes/extracts/atlas-dataLakePipelines-watch.rst

   .. tab:: {+atlas-admin-api+}
      :tabid: api

      .. _adl-add-pipeline-api:

      To create an {+adl+} pipeline through the |api|, send a ``POST`` 
      request to the :oas-atlas-tag:`{+dl+} </Data-Lake-Pipelines>` 
      ``pipelines`` endpoint. To learn more about the ``pipelines`` endpoint 
      syntax and parameters for creating a pipeline, see 
      :oas-atlas-op:`Create One Data Lake Pipeline 
      </createPipeline>`. 

      .. tip:: 

         You can send a ``GET`` request to the :oas-atlas-tag:`{+dl+} 
         </Data-Lake-Pipelines>` :oas-atlas-op:`availableSchedules 
         </listPipelineSchedules>` endpoint to retrieve the 
         list of backup schedule policy items that you can use to create your 
         {+dl+} pipeline of type ``PERIODIC_DPS``.

   .. tab:: {+atlas-ui+}
      :tabid: ui

      .. _adl-add-pipeline-ui:

      .. procedure:: 
         :style: normal

         .. step:: Navigate to {+adl+} in the |service| |ui|. 

            .. include:: /includes/extracts/ui-nav-adl.rst 
         
         .. step:: Click :guilabel:`Add Data Lake Pipeline`.
         
         .. step:: Define the data source for the pipeline.

            You can create a copy of data on your |service| cluster in 
            MongoDB-managed cloud object storage optimized for analytic 
            queries with workload isolation.
            
            To set up a pipeline, specify the following in the 
            :guilabel:`Setup Pipeline` page: 

            a. Select the |service| cluster from the dropdown.

               .. example:: 
                  
                  If you loaded the sample data on your cluster, select the 
                  |service| cluster where you loaded the sample data.

            #. Select the database on the specified cluster from the 
               dropdown, or type the database name in the field if the
               database isn't listed in the dropdown.

               {+adl+} won't display the database if it's unable to
               fetch the names of the databases for the specified cluster. 

               .. example:: 
                  
                  If you selected the cluster where the sample data is 
                  loaded, select ``sample_mflix``. 

            #. Select the collection in the specified database from the 
               dropdown, or type the collection name in the field if the
               collection isn't available.

               {+adl+} won't display the collection if it's unable to
               fetch the collection namespace for the specified cluster. 

               {+adl+} doesn't support :manual:`Views </core/views/>` as a
               data source for pipelines. You must select a collection from
               your cluster. 

               .. example:: 
                  
                  If you selected the ``sample_mflix`` database, select the 
                  ``movies`` collection in the ``sample_mflix`` database.

            #. Enter a name for the pipeline.

               {+adl+} pipeline names can't exceed 64 characters and can't contain: 
               
               - Forward slashes (``/``), 
               - Backward slashes (``\``)
               - Empty spaces
               - Dollar signs (``$``)

               .. example:: 
                  
                  If you are following the examples in this tutorial, enter 
                  ``sample_mflix.movies`` in the :guilabel:`Pipeline Name` 
                  field.

            #. Click :guilabel:`Continue`.

         .. step:: Specify an ingestion schedule for your cluster data.

            You can specify how frequently your cluster data is extracted 
            from your |service| Backup Snapshots and ingested into {+dl+} 
            Datasets. Each snapshot represents your data at that point in 
            time, which is stored in a workload isolated, analytic storage. 
            You can query any snapshot data in the {+dl+} datasets.

            You can choose :guilabel:`Basic Schedule` or :guilabel:`On 
            Demand`.

            .. tabs:: 

               .. tab:: Basic Schedule 
                  :tabid: basic

                  :guilabel:`Basic Schedule` lets you define the frequency 
                  for automatically ingesting data from available snapshots.
                  You must choose from the following schedules. Choose the 
                  :guilabel:`Snapshot Schedule` that is similar to your 
                  backup schedule:

                  - Every day 
                  - Every Saturday 
                  - Last day of the month

                  For example, if you select ``Every day``, you must have a 
                  ``Daily`` backup schedule configured in your policy. Or, if 
                  you want to select a schedule of once a week, you must have 
                  a ``Weekly`` backup schedule configured in your policy. To 
                  learn more, see :atlas:`Backup Scheduling </backup/cloud-backup/overview/#backup-scheduling--retention--and-on-demand-backup-snapshots>`. 
                  You can send a ``GET`` request to the 
                  :oas-atlas-tag:`{+dl+} </Data-Lake-Pipelines>` 
                  :oas-atlas-op:`availableSchedules 
                  </returnAvailableSchedulesForPipeline>` endpoint to 
                  retrieve the list of backup schedule policy items that you 
                  can use in your {+dl+} pipeline.

                  .. example:: 
               
                     For this tutorial, select :guilabel:`Daily` from the 
                     :guilabel:`Snapshot Schedule` dropdown if you don't have 
                     a backup schedule yet. If you have a backup schedule, 
                     the available options are based on the schedule you have 
                     set for your backup schedule.

               .. tab:: On Demand 
                  :tabid: ondemand

                  :guilabel:`On Demand` lets you manually trigger ingestion  
                  of data from available snapshots whenever you want. 

                  .. example:: 
               
                     For this tutorial, if you select :guilabel:`On Demand`,  
                     you must manually trigger the ingestion of data from 
                     the snapshot after creating the pipeline. To learn more, 
                     see :ref:`ingest-on-demand`.

         .. step:: Select the |aws| region for storing your extracted data.

            {+adl+} provides optimized storage in the following |aws| regions:

            .. include:: /includes/list-table-supported-aws-regions.rst

            By default, {+adl+} automatically selects the region closest to 
            your |service| cluster for storing extracted data. If
            {+adl+} is unable to determine the region, it defaults to
            ``us-east-1``. 

         .. step:: Specify fields in your collection to create partitions.

            Enter the most commonly queried fields from the collection in the 
            :guilabel:`Partition Attributes` section. To specify nested 
            fields, use the :manual:`dot notation 
            </core/document/#dot-notation>`. Do not include quotes (``""``) 
            around nested fields that you specify using :manual:`dot notation 
            </core/document/#dot-notation>`. You can't specify fields inside 
            an array. The specified fields are used to partition your data. 

            .. warning::

               You can't specify field names that contain periods (``.``) for
               partitioning.

            The most frequently queried fields should be listed towards the 
            top because they will have a larger impact on performance and 
            cost than fields listed lower down the list. The order of fields 
            is important in the same way as it is for :manual:`Compound 
            Indexes </core/index-compound/>`. Data is optimized for queries 
            by the first field, followed by the second field, and so on. 

            .. example:: 
               
               Enter ``year`` in the :guilabel:`Most commonly queried field` 
               field and ``title`` in the :guilabel:`Second most commonly 
               queried field` field. 

               {+adl+} optimizes performance for the ``year`` field, followed 
               by the ``title`` field. If you configure a {+fdi+} for your 
               {+dl+} dataset, {+adf+} optimizes performance for queries on 
               the following fields:

               - the ``year`` field, and 
               - the ``year`` field and the ``title`` field.

               {+adf+} can also support a query on the ``title`` field only. 
               However, in this case, {+adf+} wouldn't be as efficient in 
               supporting the query as it would be if the query were on the 
               ``title`` field only. Performance is optimized in order; if a 
               query omits a particular partition, {+adf+} is less efficient 
               in making use of any partitions that follow that.  
      
               You can run {+adf+} queries on fields not specified here, but 
               {+adl+} is less efficient in processing such queries.

         .. step:: (Optional) Specify fields inside your documents to exclude.

            By default, {+adl+} extracts and stores all fields inside the 
            documents in your collection. To specify fields to exclude: 

            a. Click :guilabel:`Add Field`.
            #. Enter field name in the :guilabel:`Add Transformation Field 
               Name` window.

               .. example:: 
                  
                  (Optional) Enter ``fullplot`` to exclude the field named 
                  ``fullplot`` in the ``movies`` collection. 

            #. Click :guilabel:`Done`.
            #. Repeat steps for each field you wish to exclude. To remove a 
               field from this list, click :icon:`trash-alt`.

         .. step:: Click :guilabel:`Finish` to create the {+dl+}.

Next steps 
----------

Now that you've created your {+dl+} pipeline, proceed to 
:ref:`adl-create-federated-db`.
