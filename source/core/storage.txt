=======
Storage
=======

.. default-domain:: mongodb

.. versionadded:: 3.0
   MongoDB adds support for additional storage engines. MongoDB's
   original storage engine, known as ``mmapv1`` remains the default in
   3.0, but the new ``wiredTiger`` engine is available and can offer
   additional flexibility and improved throughput for many workloads.

Data Model
----------

MongoDB stores data in the form of :term:`BSON` documents, which are
rich mappings of keys, or field names, to values. BSON supports a rich
collection of types, and fields in BSON documents may hold arrays of
values or embedded documents. All documents in MongoDB must be less
than 16MB, which is the :limit:`BSON document size <BSON Document Size>`.

All documents are part of a :term:`collection`, which are a logical
groupings of documents in a MongoDB database. The documents in a
collection share a set of indexes, and typically these documents share
common fields and structure.

In MongoDB the :term:`database` construct is a group of related
collections. Each database has a distinct set of data files and can
contain a large number of collections. A single MongoDB deployment may
have many databases.

.. _storage-wiredtiger:

WiredTiger Storage Engine
-------------------------

.. versionadded:: 3.0

WiredTiger is a storage engine that is optionally available in the
64-bit build of MongoDB 3.0. It excels at read and insert workloads as
well as more complex update workloads.

Document Level Locking
~~~~~~~~~~~~~~~~~~~~~~

With WiredTiger, all write operations happen within the context of a
*document* level lock. As a result, multiple clients can modify
more than one document in a single collection at the same
time. With this very granular concurrency control, MongoDB can more
effectively support workloads with read, write and updates as well as
high-throughput concurrent workloads.

Journal
~~~~~~~

WiredTiger uses a write-ahead transaction log in combination with
checkpoints to ensure data persistence. With
WiredTiger, by default MongoDB will commit a checkpoint to disk every
60 seconds, or when there are 2 gigabytes of data to write. The
checkpoint thresholds are configurable. Between and during checkpoints
the data files are *always* valid.

The WiredTiger journal persists all data modifications between
checkpoints. If MongoDB exits between checkpoints, it uses the journal
to replay all data modified since the last checkpoint. By default the
WiredTiger journal is compressed using the :term:`snappy` algorithm.

You can disable journaling by setting :setting:`storage.journal.enabled`
to ``false``, which can reduce the overhead of maintaining the
journal. For :term:`standalone` instances, not using the journal means
that you will lose some data modifications when MongoDB exits
unexpectedly between
checkpoints. For members of :term:`replica sets <replica set>`, the replication
process may provide sufficient durability guarantees.

.. _storage-wiredtiger-compression:

Compression
~~~~~~~~~~~

MongoDB supports compression for all collections and indexes using
both block and :term:`prefix compression`. Compression minimizes storage use at the
expense of additional CPU.

By default, all indexes with the WiredTiger engine use :term:`prefix compression`.
Also, by default all collections with WiredTiger use block
compression with the :term:`snappy` algorithm. Compression with :term:`zlib`
is also available.

You can modify the default compression settings for all collections
and indexes. Compression is also configurable on a per-collection and
per-index basis during collection and index creation.

For most workloads, the default compression settings balance storage
efficiency and processing requirements.

.. TODO add link to wiredTiger configuration

.. _storage-mmapv1:

MMAPv1 Storage Engine
---------------------

MMAPv1 is MongoDB's original storage engine based on memory mapped
files. It excels at workloads with high volume inserts, reads, and
in-place updates. MMAPv1 is the default storage engine in MongoDB
3.0 and all previous versions.

Journal
~~~~~~~

In order to ensure that all modifications to a MongoDB data set are
durably written to disk, MongoDB records all modifications to a
journal that it writes to disk more frequently than it writes the data
files. The journal allows MongoDB to successfully recover
data from data files after a :program:`mongod` instance exits without
flushing all changes.

See :doc:`/core/journaling` for more information about the journal in
MongoDB.

Record Storage Characteristics
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

All records are contiguously located on disk, and when a document
becomes larger than the allocated record, MongoDB must allocate a new
record. New allocations require MongoDB to move a document and update
all indexes that refer to the document, which takes more time than
in-place updates and leads to storage
fragmentation.

.. versionchanged:: 3.0.0

By default, MongoDB uses :ref:`power-of-2-allocation` so that every
document in MongoDB is stored in a *record* which contains the document
itself and extra space, or :term:`padding`. Padding allows the document
to grow as the result of updates while minimizing the likelihood of
reallocations.

.. _record-allocation-strategies:

Record Allocation Strategies
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB supports multiple record allocation strategies that determine
how :program:`mongod` adds padding to a document when creating a
record. Because documents in MongoDB may grow after insertion
and all records are contiguous on disk, the padding can reduce the
need to relocate documents on disk following updates. Relocations are
less efficient than in-place updates and can lead to storage
fragmentation. As a result, all padding strategies trade additional
space for increased efficiency and decreased fragmentation.

Different allocation strategies support different kinds of workloads:
the :ref:`power of 2 allocations <power-of-2-allocation>` are more
efficient for insert/update/delete workloads; while :ref:`exact fit
allocations <exact-fit-allocation>` is ideal for collections *without*
update and delete workloads.

.. _power-of-2-allocation:

Power of 2 Sized Allocations
````````````````````````````

.. versionchanged:: 3.0.0

MongoDB 3.0 uses the power of 2 sizes allocation as the default record
allocation strategy for MMAPv1. With the power of 2 sizes allocation
strategy, each record has a size in bytes that is a power of 2 (e.g.
32, 64, 128, 256, 512 ... 16777216). The smallest allocation for a
document is 32 bytes.

The power of 2 sizes allocation strategy has the following key
properties:

- Can efficiently reuse freed records to reduce fragmentation. The
  limited number of record allocation sizes help ensure that MongoDB
  can efficiently reuse free space created by document deletion or
  relocation.

- Can minimize the occurrence of re-allocation. In many cases, the
  record allocations are significantly larger than the documents they
  hold. This significantly larger size minimizes the chance that the
  :program:`mongod` will need to allocate a new record if the document
  grows. Although the power of 2 sizes strategy can minimize the
  occurrence of reallocation, it does not eliminate
  document re-allocation.

.. _exact-fit-allocation:

Exact Fit Allocation with No Padding
````````````````````````````````````

.. versionchanged:: 3.0.0

For collections whose workloads do not change the document sizes, such
as workloads that consist of insert-only operations, insert-and-remove
operations on documents of uniform size, or update operations that do
not increase document size, you can disable the :ref:`power of 2
allocation <power-of-2-allocation>` using the :dbcommand:`collMod`
command with the :collflag:`noPadding` flag or the
:method:`db.createCollection()` method with the ``noPadding`` option.

Prior to version 3.0.0, MongoDB used an exact fit allocation strategy
that included a dynamically calculated :data:`padding
<collStats.paddingFactor>` as a factor of the document size.

Capped Collections
------------------

:term:`Capped collections <capped collection>` are fixed-size
collections that support high-throughput operations that store records
in insertion order. Capped collections work like circular buffers:
once a collection fills its allocated space, it makes room for new
documents by overwriting the oldest documents in the collection.

See :doc:`/core/capped-collections` for more information.
