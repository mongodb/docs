====================
FAQ: MongoDB Storage
====================

.. default-domain:: mongodb

This document addresses common questions regarding MongoDB's storage
system.

If you don't find the answer you're looking for, check
the :doc:`complete list of FAQs </faq>` or post your question to the
`MongoDB User Mailing List <https://groups.google.com/forum/?fromgroups#!forum/mongodb-user>`_.

Storage Engine Fundamentals
---------------------------

What is a storage engine?
~~~~~~~~~~~~~~~~~~~~~~~~~

A storage engine is the part of a database that is responsible for
managing how data is stored on disk. Many databases support multiple
storage engines, where different engines perform better for specific
workloads. For example, one storage engine might offer better
performance for read-heavy workloads, and another might support
a higher-throughput for write operations.

What will be the default storage engine going forward?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MMAPv1 is the default storage engine in 3.0. With multiple storage
engines, you can decide which storage engine is
best for your application.

Can you mix storage engines in a replica set?
---------------------------------------------

Yes. You can have a replica set members that use different storage
engines.

When designing these multi-storage engine deployments consider the
following:

- the oplog on each member may need to be sized differently to account
  for differences in throughput between different storage engines.

- recovery from backups may become more complex if your backup
  captures data files from MongoDB: you may need to maintain backups
  for each storage engine.

WiredTiger Storage Engine
-------------------------

Can I upgrade an existing deployment to a WiredTiger?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Yes. You can upgrade an existing deployment to WiredTiger while the
deployment remains available by adding replica set
members with the new storage engine and then removing members with the
legacy storage engine. See the following sections of the
:doc:`/release-notes/3.0-upgrade` for the complete procedure that you
can use to upgrade an existing deployment:

- :ref:`3.0-upgrade-repl-set-wiredtiger`

- :ref:`3.0-upgrade-cluster-wiredtiger`

How much compression does WiredTiger provide?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The ratio of compressed data to uncompressed data depends on your data
and the compression library used. By default, collection data in
WiredTiger use :term:`Snappy block compression <snappy>`; :term:`zlib`
compression is also available. Index data use :term:`prefix
compression` by default.

.. _wt-cache-and-eviction:

To what size should I set the WiredTiger cache?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The size of the cache should be sufficient to hold the entire working
set for the :program:`mongod`. If the cache does not have enough space
to load additional data, WiredTiger evicts pages from the cache to free
up space.

To see statistics on the cache and eviction, use the
:dbcommand:`serverStatus` command. The
:data:`~serverStatus.wiredTiger.cache` field holds the information on
the cache and eviction:

.. code-block:: none

   ...
   "wiredTiger" : {
      ...
      "cache" : {
         "tracked dirty bytes in the cache" : <num>,
         "bytes currently in the cache" : <num>,
         "maximum bytes configured" : <num>,
         "bytes read into cache" :<num>,
         "bytes written from cache" : <num>,
         "pages evicted by application threads" : <num>,
         "checkpoint blocked page eviction" : <num>,
         "unmodified pages evicted" : <num>,
         "page split during eviction deepened the tree" : <num>,
         "modified pages evicted" : <num>,
         "pages selected for eviction unable to be evicted" : <num>,
         "pages evicted because they exceeded the in-memory maximum" : <num>,,
         "pages evicted because they had chains of deleted items" : <num>,
         "failed eviction of pages that exceeded the in-memory maximum" : <num>,
         "hazard pointer blocked page eviction" : <num>,
         "internal pages evicted" : <num>,
         "maximum page size at eviction" : <num>,
         "eviction server candidate queue empty when topping up" : <num>,
         "eviction server candidate queue not empty when topping up" : <num>,
         "eviction server evicting pages" : <num>,
         "eviction server populating queue, but not evicting pages" : <num>,
         "eviction server unable to reach eviction goal" : <num>,
         "pages split during eviction" : <num>,
         "pages walked for eviction" : <num>,
         "eviction worker thread evicting pages" : <num>,
         "in-memory page splits" : <num>,
         "percentage overhead" : <num>,
         "tracked dirty pages in the cache" : <num>,
         "pages currently held in the cache" : <num>,
         "pages read into cache" : <num>,
         "pages written from cache" : <num>,
      },
      ...

To adjust the size of the WiredTiger cache, see
:setting:`storage.wiredTiger.engineConfig.cacheSizeGB` and
:option:`--wiredTigerCacheSizeGB`.

MMAPv1 Storage Engine
---------------------

.. _faq-storage-memory-mapped-files:

What are memory mapped files?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A memory-mapped file is a file with data that the operating system
places in memory by way of the ``mmap()`` system call. ``mmap()`` thus
*maps* the file to a region of virtual memory. Memory-mapped files are
the critical piece of the MMAPv1 storage engine in MongoDB. By using memory
mapped files, MongoDB can treat the contents of its data files as if
they were in memory. This provides MongoDB with an extremely fast and
simple method for accessing and manipulating data.

How do memory mapped files work?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB uses memory mapped files for managing and interacting with all
data.

Memory mapping assigns files to a block of virtual memory with a direct
byte-for-byte correlation. MongoDB memory maps data files to memory as
it accesses documents. Unaccessed data is *not* mapped to memory.

Once mapped, the relationship between file and memory allows MongoDB to
interact with the data in the file as if it were memory.

.. _faq-disk-size:

Why are the files in my data directory larger than the data in my database?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The data files in your data directory, which is the :file:`/data/db`
directory in default configurations, might be larger than the data set
inserted into the database. Consider the following possible causes:

- Preallocated data files.

  In the data directory, MongoDB preallocates data files to a
  particular size, in part to prevent file system
  fragmentation. MongoDB names the first data file ``<databasename>.0``,
  the next ``<databasename>.1``, etc. The first file :program:`mongod`
  allocates is 64 megabytes, the next 128 megabytes, and so on, up to
  2 gigabytes, at which point all subsequent files are 2
  gigabytes. The data files include files with allocated space but
  that hold no data. :program:`mongod` may allocate a 1 gigabyte data
  file that may be 90% empty. For most larger databases, unused
  allocated space is small compared to the database.

- The :term:`oplog`.

  If this :program:`mongod` is a member of a replica set, the data
  directory includes the :term:`oplog.rs <oplog>` file, which is a
  preallocated :term:`capped collection` in the ``local``
  database. The default allocation is approximately 5% of disk space
  on 64-bit installations, see :ref:`Oplog Sizing
  <replica-set-oplog-sizing>` for more information. In most cases, you
  should not need to resize the oplog. However, if you do, see
  :doc:`/tutorial/change-oplog-size`.

- The :term:`journal`.

  The data directory contains the journal files, which store write
  operations on disk prior to MongoDB applying them to databases. See
  :doc:`/core/journaling`.

- Empty records.

  MongoDB maintains lists of empty records in data files when
  deleting documents and collections. MongoDB can reuse this space,
  but will never return this space to the operating system.

  To de-fragment allocated storage, use :dbcommand:`compact`, which
  de-fragments allocated space. By de-fragmenting storage, MongoDB
  can effectively use the allocated space. :dbcommand:`compact`
  requires up to 2 gigabytes of extra disk space to run. Do not
  use :dbcommand:`compact` if you are critically low on disk space.

  .. important:: :dbcommand:`compact` only removes fragmentation
     from MongoDB data files and does not return any disk space to
     the operating system.

  To reclaim deleted space, use :dbcommand:`repairDatabase`, which
  rebuilds the database which de-fragments the storage and may release
  space to the operating system. :dbcommand:`repairDatabase` requires
  up to 2 gigabytes of extra disk space to run. Do not use
  :dbcommand:`repairDatabase` if you are critically low on disk space.

  .. warning::
     :dbcommand:`repairDatabase` requires enough free disk space to
     hold both the old and new database files while the repair is
     running. Be aware that :dbcommand:`repairDatabase` will block
     all other operations and may take a long time to complete.

.. _faq-working-set:

What is the working set?
~~~~~~~~~~~~~~~~~~~~~~~~

Working set represents the total body of data that the application
uses in the course of normal operation. Often this is a subset of the
total data size, but the specific size of the working set depends on
actual moment-to-moment use of the database.

If you run a query that requires MongoDB to scan every document in a
collection, the working set will expand to include every
document. Depending on physical memory size, this may cause documents
in the working set to "page out," or to be removed from physical memory by
the operating system. The next time MongoDB needs to access these
documents, MongoDB may incur a hard page fault.

For best performance, the majority of your *active* set should fit in
RAM.

.. _faq-storage-page-faults:

What are page faults?
~~~~~~~~~~~~~~~~~~~~~

.. include:: /includes/fact-page-fault.rst

If there is free memory, then the operating system can find the page
on disk and load it to memory directly. However, if there is no free
memory, the operating system must:

- find a page in memory that is stale or no longer needed, and write
  the page to disk.

- read the requested page from disk and load it into memory.

This process, on an active system, can take a long time,
particularly in comparison to reading a page that is already in
memory.

See :ref:`administration-monitoring-page-faults` for more information.

What is the difference between soft and hard page faults?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

:term:`Page faults <page fault>` occur when MongoDB, with the MMAP
storage engine, needs access to data that isn't currently in active
memory. A "hard" page fault refers to situations when MongoDB must
access a disk to access the data. A "soft" page fault, by contrast,
merely moves memory pages from one list to another, such as from an
operating system file cache.

See :ref:`administration-monitoring-page-faults` for more information.

Data Storage Diagnostics
------------------------

How can I check the size of a collection?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To view the statistics for a collection, including the data size, use
the :method:`db.collection.stats()` method from the :program:`mongo`
shell. The following example issues :method:`db.collection.stats()` for
the ``orders`` collection:

.. code-block:: javascript

   db.orders.stats();

MongoDB also provides the following methods to return specific sizes
for the collection:

- :method:`db.collection.dataSize()` to return data size in bytes for
  the collection.

- :method:`db.collection.storageSize()` to return allocation size in
  bytes, including unused space.

- :method:`db.collection.totalSize()` to return the data size plus the
  index size in bytes.

- :method:`db.collection.totalIndexSize()` to return the index size in
  bytes.

The following script prints the statistics for each database:

.. code-block:: javascript

   db._adminCommand("listDatabases").databases.forEach(function (d) {
      mdb = db.getSiblingDB(d.name);
      printjson(mdb.stats());
   })

The following script prints the statistics for each collection in each
database:

.. code-block:: javascript

   db._adminCommand("listDatabases").databases.forEach(function (d) {
      mdb = db.getSiblingDB(d.name);
      mdb.getCollectionNames().forEach(function(c) { 
         s = mdb[c].stats();
         printjson(s);
      })
   })

How can I check the size of indexes for a collection?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To view the size of the data allocated for an index, use the
:method:`db.collection.stats()` method and check the
:data:`~collStats.indexSizes` field in the returned document.

.. _faq-tools-for-measuring-storage-use:

How can I get information on the storage use of a database?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :method:`db.stats()` method in the :program:`mongo` shell returns
the current state of the "active" database. For the description of the
returned fields, see :ref:`dbStats Output <dbstats-output>`.
