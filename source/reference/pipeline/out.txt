.. _adl-out-stage:

====
$out
====

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. |out| replace:: :pipeline:`~pipe.$out`
.. |convert| replace:: :pipeline:`~pipe.$convert`


|out| takes documents returned by the aggregation pipeline and writes
them to a specified collection. The |out| operator must be the last
stage in the
:manual:`aggregation pipeline </reference/operator/aggregation-pipeline/>`.
In {+adl+}, |out| can be used to write to |s3| buckets with read and
write permissions or to an |service| cluster
:manual:`namespace </reference/limits/#faq-dev-namespace>`.

.. seealso::

   |out|

.. tabs::

   .. tab:: S3
      :tabid: s3

   .. tab:: Atlas Cluster
      :tabid: atlas


.. _adl-out-stage-perms:

Permissions Required
--------------------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      You must have:

      - A {+dl+} configured for |s3| bucket with read and write
        permissions or
        :aws:`s3::PutObject </AmazonS3/latest/dev/using-with-s3-actions.html#using-with-s3-actions-related-to-objects>`
        permissions.
      - A MongoDB user with :authrole:`readWriteAnyDatabase` role.

   .. tab:: Atlas Cluster
      :tabid: atlas

      You must be a database user with one of the following roles:

      - :authrole:`readWriteAnyDatabase`
      - :authrole:`readAnyDatabase`
      - :atlasrole:`atlasAdmin`
      - A custom role with the following privileges:

        - :manual:`insert </reference/privilege-actions/#insert>` and
        - :manual:`remove </reference/privilege-actions/#remove>`

.. _adl-out-stage-syntax:

Syntax
------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      .. code-block:: json
         :linenos:

         {
           "$out": {
             "s3": {
               "bucket": "<bucket-name>",
               "region": "<aws-region>",
               "filename": "<file-name>",
               "format": {
                 "name": "json|json.gz|bson|bson.gz",
                 "maxFileSize": "<file-size>"
               }
             }
           }
         }

   .. tab:: Atlas Cluster
      :tabid: atlas

      .. code-block:: json
         :linenos:

         {
           "$out": {
             "atlas": {
               "projectId": "<atlas-project-ID>",
               "clusterName": "<atlas-cluster-name>",
               "db": "<atlas-database-name>",
               "coll": "<atlas-collection-name>"
             }
           }
         }

.. _adl-out-stage-fields:

Fields
------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      .. list-table::
         :header-rows: 1
         :widths: 10 10 70 10

         * - Field
           - Type
           - Description
           - Necessity

         * - ``s3``
           - object
           - Location to write the documents from the aggregation
             pipeline.
           - Required

         * - ``s3.bucket``
           - string
           - Name of the |s3| bucket to write the documents from
             the aggregation pipeline to.

             .. important::

                The generated call to |s3| inserts a ``/`` between
                ``s3.bucket`` and ``s3.filename``. Don't append a
                ``/`` after the ``s3.bucket``.

                .. example::

                   If you set ``s3.bucket`` to ``myBucket`` and
                   ``s3.filename`` to ``myPath/myData``, {+adl+} writes
                   this out as ``s3://myBucket/myPath/myFile``

           - Required

         * - ``s3.region``
           - string
           - Name of the |aws| region in which the bucket is hosted.
           - Required

         * - ``s3.filename``
           - string
           - Name of the file to write the documents from the
             aggregation pipeline to. Filename can be constant or
             :ref:`created dynamically <adl-out-stage-egs>` from the
             fields in the documents that reach the |out| stage.

             .. important::

                The generated call to |s3| inserts a ``/`` between
                ``s3.bucket`` and ``s3.filename``. Don't prepend a
                ``/`` before the ``s3.filename``.

                .. example::

                   If you set ``s3.bucket`` to ``myBucket`` and
                   ``s3.filename`` to ``myPath/myData``, {+adl+} writes
                   this out as ``s3://myBucket/myPath/myFile``

           - Required

         * - ``s3.format``
           - object
           - Details of the file in |s3|.
           - Required

         * - | ``s3``
             | ``.format``
             | ``.name``
           - enum
           - Format of the file in |s3|. Value can be one of the
             following:

             - ``json``
             - ``json.gz``
             - ``bson``
             - ``bson.gz``

           - Required

         * - | ``s3``
             | ``.format``
             | ``.maxFileSize``
           - bytes
           - Maximum size of the file in |s3|. When the file size limit
             for the current file is reached, a new file is created in
             |s3|. For each additional file, an incremental number is
             appended to the filename.

             .. example::

                ``<filename>.1.<fileformat>``

                ``<filename>.2.<fileformat>``

             If a document is larger than the ``maxFileSize``, {+dl+}
             writes the document to its own file. The following
             suffixes are supported:

             .. list-table::
                :widths: 30 70

                * - Base 10: scaling in multiples of 1000
                  - - ``B``
                    - ``KB``
                    - ``MB``
                    - ``GB``
                    - ``TB``
                    - ``PB``
                * - Base 2: scaling in multiples of 1024
                  - - ``KiB``
                    - ``MiB``
                    - ``GiB``
                    - ``TiB``
                    - ``PiB``

             If omitted, defaults to ``200MiB``.

           - Optional

   .. tab:: Atlas Cluster
      :tabid: atlas

      .. list-table::
         :header-rows: 1
         :widths: 10 10 70 10

         * - Field
           - Type
           - Description
           - Necessity

         * - ``atlas``
           - object
           - Location to write the documents from the aggregation
             pipeline.
           - Required

         * - ``clusterName``
           - string
           - Name of the |service| cluster.
           - Required

         * - ``coll``
           - string
           - Name of the collection on the |service| cluster.
           - Required

         * - ``db``
           - string
           - Name of the database on the |service| cluster that contains
             the collection.
           - Required

         * - ``projectId``
           - string
           - Unique identifier of the project that contains the
             |service| cluster. The project ID must be the ID of the
             project that contains your {+dl+}. If omitted, defaults to
             the ID of the project that contains your {+dl+}.
           - Optional

.. _adl-out-stage-egs:

Examples
--------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      The following examples show |out| syntaxes for dynamically
      creating a filename from a constant string or from the fields of
      the same or different data types in the documents that reach the
      |out| stage.

      **Simple String Example**

      .. example::

         Consider the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": "big_box_store/",
                  "format": {
                    "name": "bson.gz"
                  }
                }
              }
            }

         |out| operation writes up to 200 MiB of data, which is the
         default file size, to a compressed |bson| file named
         ``big_box_store.bson.gz`` in the bucket named ``my-s3-bucket``.
         Once the maximum file size of 200 MiB is reached, the |out|
         operation creates a new file by appending an incremental number
         to the constant filename. That is, ``big_box_store.1.bson.gz``,
         ``big_box_store.2.bson.gz``, and so on.

      **Single Field from Documents**

      .. example::

         Consider the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {"$toString": "$sale-date"},
                  "format": {
                    "name": "json",
                    "maxFileSize": "100MiB"
                  }
                }
              }
            }

         |out| writes up to 100 MiB of data to a |json| file in the root
         of the bucket named ``my-s3-bucket``. The filename is the value
         of the date type field named ``sale-date`` from the documents
         and is converted to a string.

      **Multiple Fields from Documents**

      .. example::

         Consider the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {
                    "$concat": [
                      "persons/",
                      "$name", "/",
                      "$unique-id"
                    ]
                  },
                  "format": {
                    "name": "bson",
                    "maxFileSize": "200MiB"
                  }
                }
              }
            }

         |out| operation writes up to 200 MiB of data to a |bson| file
         in the bucket named ``my-s3-bucket``. The filename is a
         combination of a constant string named ``persons`` and the
         value of the fields named ``name`` and ``unique-id`` of type
         string from the documents.

      **Multiple Types of Fields from Documents**

      .. example::

         Consider the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {
                    "$concat": [
                      "big-box-store/",
                      {
                        "$toString": "$store_number"
                      }, "/",
                      {
                        "$toString": "$sale-date"
                      }, "/",
                      "$part-id"
                    ]
                  },
                  "format": {
                    "name": "json.gz",
                    "maxFileSize": "200MiB"
                  }
                }
              }
            }

         The |out| operation writes up to 200 MiB of data to a
         compressed |json| file in the bucket named ``my-s3-bucket``.
         The filename is a combination of the following:

         - A constant string named ``big-box-store``
         - A unique store number in the field named ``store-number``
           that is converted to a string
         - Value of the date type field named ``sale-date`` that is
           converted to a string
         - A part ID in the field named ``part-id`` that is already a
           string

   .. tab:: Atlas Cluster
      :tabid: atlas

      The following example shows the |out| syntax for sending the
      aggregated data to a ``sampleDB.mySampleData`` collection in the
      |service| cluster named ``myTestCluster``. In the following
      syntax, the project ID is not specified and therefore |out|
      uses the ID of the project that contains your {+dl+}.

      .. code-block:: json
         :linenos:

         {
           "$out": {
             "atlas": {
               "clusterName": "myTestCluster",
               "db": "sampleDB",
               "coll": "mySampleData"
             }
           }
         }

.. _adl-out-stage-limitations:

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      **Limitations**

      {+dl+} interprets empty strings (``""``) as null values when
      parsing filenames. If you want {+dl+} to generate filenames that
      it can parse correctly, you must wrap the field references that
      could have null values using |convert| with an empty
      string ``onNull`` value.

      .. example::

         This example shows how to handle null values in the ``year``
         field when creating a filename from the field value.

         .. code-block:: json
            :copyable: false
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {
                    "$concat": [
                      "big-box-store/",
                      {
                        "$convert": {
                          "input": "year",
                          "to": "string",
                          "onNull": ""
                        }
                      }
                    ]
                  },
                  "format": {
                    "name": "json.gz",
                    "maxFileSize": "200MiB"
                  }
                }
              }
            }

      **Errors**

      - If the filename is not of type string, {+dl+} writes documents
        to a special error file in your bucket.

      - If the documents cannot be written to a file with the specified
        filename, {+dl+} writes documents to ordinally-named files in
        the specified format and specified size.

        .. example::

          - ``s3://<bucket-name>/atlas-data-lake-{<CORRELATION_ID>}/$out-error-docs/1.json``
          - ``s3://<bucket-name>/atlas-data-lake-{<CORRELATION_ID>}/$out-error-docs/2.json``

        {+dl+} returns an error message that specifies the number of
        documents that had invalid filenames and the directory where
        these documents were written.

   .. tab:: Atlas Cluster
      :tabid: atlas
