{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Vector Search - Vector Quantization - New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion for the [Vector Quantization](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-quantization/#how-to-ingest-pre-quantized-vectors) page. Refer to this page for set up steps and explanation details.\n",
    "\n",
    "This notebook takes you through how to pre-quantize and ingest your vectors for vector search from **new data** by using [Cohere's](https://cohere.com/) `embed-english-v3.0` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade pymongo cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "data = [\n",
    "   \"The Great Wall of China is visible from space.\",\n",
    "   \"The Eiffel Tower was completed in Paris in 1889.\",\n",
    "   \"Mount Everest is the highest peak on Earth at 8,848m.\",\n",
    "   \"Shakespeare wrote 37 plays and 154 sonnets during his lifetime.\",\n",
    "   \"The Mona Lisa was painted by Leonardo da Vinci.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cohere\n",
    "\n",
    "# Specify your Cohere API key\n",
    "os.environ[\"COHERE_API_KEY\"] = \"<COHERE-API-KEY>\"\n",
    "cohere_client = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
    "\n",
    "# Generate embeddings using the embed-english-v3.0 model\n",
    "generated_embeddings = cohere_client.embed(\n",
    "   texts=data,\n",
    "   model=\"embed-english-v3.0\",\n",
    "   input_type=\"search_document\",\n",
    "   embedding_types=[\"float\", \"int8\", \"ubinary\"] \n",
    ").embeddings\n",
    "\n",
    "float32_embeddings = generated_embeddings.float\n",
    "int8_embeddings = generated_embeddings.int8\n",
    "int1_embeddings = generated_embeddings.ubinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.binary import Binary, BinaryVectorDtype\n",
    "\n",
    "# Define function to generate BSON vectors\n",
    "def generate_bson_vector(vector, vector_dtype):\n",
    "   return Binary.from_vector(vector, vector_dtype)\n",
    "\n",
    "# For all vectors in your collection, generate BSON vectors of float32, int8, and int1 embeddings\n",
    "bson_float32_embeddings = []\n",
    "bson_int8_embeddings = []\n",
    "bson_int1_embeddings = []\n",
    "for i, (f32_emb, int8_emb, int1_emb) in enumerate(zip(float32_embeddings, int8_embeddings, int1_embeddings)):\n",
    "   bson_float32_embeddings.append(generate_bson_vector(f32_emb, BinaryVectorDtype.FLOAT32))\n",
    "   bson_int8_embeddings.append(generate_bson_vector(int8_emb, BinaryVectorDtype.INT8))\n",
    "   bson_int1_embeddings.append(generate_bson_vector(int1_emb, BinaryVectorDtype.PACKED_BIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the field names for the float32, int8, and int1 embeddings\n",
    "float32_field = \"<FIELD-NAME-FOR-FLOAT32-TYPE>\"\n",
    "int8_field = \"<FIELD-NAME-FOR-INT8-TYPE>\"\n",
    "int1_field = \"<FIELD-NAME-FOR-INT1-TYPE>\"\n",
    "\n",
    "# Define function to create documents with BSON vector embeddings\n",
    "def create_docs_with_bson_vector_embeddings(bson_float32_embeddings, bson_int8_embeddings, bson_int1_embeddings, data):\n",
    "  docs = []\n",
    "  for i, (bson_f32_emb, bson_int8_emb, bson_int1_emb, text) in enumerate(zip(bson_float32_embeddings, bson_int8_embeddings, bson_int1_embeddings, data)):\n",
    "\n",
    "     doc = {\n",
    "          \"_id\": i,\n",
    "          \"data\": text,\n",
    "          float32_field: bson_f32_emb,\n",
    "          int8_field: bson_int8_emb,\n",
    "          int1_field: bson_int1_emb\n",
    "     }\n",
    "     docs.append(doc)\n",
    "  return docs\n",
    "\n",
    "# Create the documents\n",
    "documents = create_docs_with_bson_vector_embeddings(bson_float32_embeddings, bson_int8_embeddings, bson_int1_embeddings, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connect to your Atlas cluster\n",
    "mongo_client = pymongo.MongoClient(\"<ATLAS-CONNECTION-STRING>\")\n",
    "\n",
    "# Insert documents into a new database and collection\n",
    "db = mongo_client[\"<DB-NAME>\"]\n",
    "db.create_collection(\"<COLLECTION-NAME>\")\n",
    "collection = db[\"<COLLECTION-NAME>\"]\n",
    "\n",
    "collection.insert_many(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.operations import SearchIndexModel\n",
    "import time\n",
    "\n",
    "# Define and create the vector search index\n",
    "index_name = \"<INDEX-NAME>\"\n",
    "search_index_model = SearchIndexModel(\n",
    "  definition={\n",
    "    \"fields\": [\n",
    "      {\n",
    "        \"type\": \"vector\",\n",
    "        \"path\": float32_field,\n",
    "        \"similarity\": \"dotProduct\",\n",
    "        \"numDimensions\": 1024\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"vector\",\n",
    "        \"path\": int8_field,\n",
    "        \"similarity\": \"dotProduct\",\n",
    "        \"numDimensions\": 1024\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"vector\",\n",
    "        \"path\": int1_field,\n",
    "        \"similarity\": \"euclidean\",\n",
    "        \"numDimensions\": 1024\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  name=index_name,\n",
    "  type=\"vectorSearch\"\n",
    ")\n",
    "result = collection.create_search_index(model=search_index_model)\n",
    "print(\"New search index named \" + result + \" is building.\")\n",
    "\n",
    "# Wait for initial sync to complete\n",
    "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
    "predicate=None\n",
    "if predicate is None:\n",
    "  predicate = lambda index: index.get(\"queryable\") is True\n",
    "while True:\n",
    "  indices = list(collection.list_search_indexes(index_name))\n",
    "  if len(indices) and predicate(indices[0]):\n",
    "    break\n",
    "  time.sleep(5)\n",
    "print(result + \" is ready for querying.\")\n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to run a vector search query\n",
    "def run_vector_search(query_text, collection, path):\n",
    "  query_text_embeddings = cohere_client.embed(\n",
    "    texts=[query_text],\n",
    "    model=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\",\n",
    "    embedding_types=[\"float\", \"int8\", \"ubinary\"]\n",
    "  ).embeddings\n",
    "\n",
    "  if path == float32_field:\n",
    "    query_vector = query_text_embeddings.float[0]\n",
    "    vector_dtype = BinaryVectorDtype.FLOAT32\n",
    "  elif path == int8_field:\n",
    "    query_vector = query_text_embeddings.int8[0]\n",
    "    vector_dtype = BinaryVectorDtype.INT8\n",
    "  elif path == int1_field:\n",
    "    query_vector = query_text_embeddings.ubinary[0]\n",
    "    vector_dtype = BinaryVectorDtype.PACKED_BIT\n",
    "  bson_query_vector = generate_bson_vector(query_vector, vector_dtype)\n",
    "\n",
    "  pipeline = [\n",
    "    {\n",
    "      '$vectorSearch': {\n",
    "        'index': index_name,\n",
    "        'path': path,\n",
    "        'queryVector': bson_query_vector,\n",
    "        'numCandidates': 5,\n",
    "        'limit': 2\n",
    "       }\n",
    "     },\n",
    "     {\n",
    "       '$project': {\n",
    "         '_id': 0,\n",
    "         'data': 1,\n",
    "         'score': { '$meta': 'vectorSearchScore' }\n",
    "        }\n",
    "     }\n",
    "  ]\n",
    "\n",
    "  return collection.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run the vector search query on the float32, int8, and int1 embeddings\n",
    "query_text = \"tell me a science fact\"\n",
    "float32_results = run_vector_search(query_text, collection, float32_field)\n",
    "int8_results = run_vector_search(query_text, collection, int8_field)\n",
    "int1_results = run_vector_search(query_text, collection, int1_field)\n",
    "\n",
    "print(\"results from float32 embeddings\")\n",
    "pprint(list(float32_results))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"results from int8 embeddings\")\n",
    "pprint(list(int8_results))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"results from int1 embeddings\")\n",
    "pprint(list(int1_results))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
