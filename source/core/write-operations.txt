.. index:: write operations
.. index:: crud; write operations

================
Write Operations
================

.. default-domain:: mongodb

All operations that create or modify data in the MongoDB instance are
write operations. MongoDB represents data as :term:`BSON documents
<document>` stored in :term:`collections <collection>`. Write
operations target one collection and are atomic on the level of a
single document: no single write operation can atomically affect more
than one document or more than one collection.

This document introduces the write operators available in MongoDB as
well as presents strategies to increase the efficiency of writes in
applications.

.. index:: write operators
.. _write-operations-operators:

Write Operators
---------------

For information on write operators and how to write data to a MongoDB
database, see the following pages:

- :doc:`/core/create`
- :doc:`/core/update`
- :doc:`/core/delete`

For information on specific methods used to perform write operations in the
:program:`mongo` shell, see the following:

- :method:`db.collection.insert()`
- :method:`db.collection.update()`
- :method:`db.collection.save()`
- :method:`db.collection.findAndModify()`
- :method:`db.collection.remove()`

For information on how to perform write operations from within an
application, see the :doc:`/applications/drivers` documentation or the
documentation for your client library.

.. _write-operations-write-concern:

Write Concern
-------------

.. include:: /includes/introduction-write-concern.rst

.. note:: The :doc:`driver write concern </release-notes/drivers-write-concern>`
   change created a new connection class in all of the MongoDB
   drivers, called ``MongoClient`` with a different default write
   concern. See the :doc:`release notes </release-notes/drivers-write-concern>`
   for this change, and the release notes for the driver you're using
   for more information about your driver's release.

.. seealso:: :doc:`/core/write-concern` and
   :doc:`/reference/write-concern`.

.. _write-operations-bulk-insert:

Bulk Inserts
------------

In some situations you may need to insert or ingest a large amount of
data into a MongoDB database. These *bulk inserts* have some
special considerations that are different from other write
operations.

The :method:`insert() <db.collection.insert()>` method, when passed an
array of documents, will perform a bulk insert, and inserts each
document atomically. :doc:`Drivers </applications/drivers>`
provide their own interface for this kind of operation.

.. versionadded:: 2.2
   :method:`insert() <db.collection.insert()>` in the :program:`mongo`
   shell gained support for bulk inserts in version 2.2.

Bulk insert can significantly increase performance by amortizing
:ref:`write concern <write-operations-write-concern>` costs. In the
drivers, you can configure write concern for batches rather than on a
per-document level.

Drivers also have a ``ContinueOnError`` option in their insert
operation, so that the bulk operation will continue to insert
remaining documents in a batch even if an insert fails.

.. note::

   .. versionadded::  2.0
      Support for ``ContinueOnError`` depends on version 2.0 of the
      core :program:`mongod` and :program:`mongos` components.

If the bulk insert process generates more than one error in a batch
job, the client will only receive the most recent error. All bulk
operations to a :term:`sharded collection <sharded cluster>` run with
``ContinueOnError``, which applications cannot disable. See
:ref:`sharding-bulk-inserts` section for more information on
consideration for bulk inserts in sharded clusters.

For more information see your :doc:`driver documentation
</applications/drivers>` for details on performing bulk inserts in
your application. Also consider the following resources:
:ref:`write-operations-sharded-clusters`,
:ref:`sharding-bulk-inserts`, and
:doc:`/core/import-export`.

.. _write-operations-indexing:

Indexing
--------

After every insert, update, or delete operation, MongoDB must update
*every* index associated with the collection in addition to the data
itself. Therefore, every index on a collection adds some amount of
overhead for the performance of write operations. [#exceptions]_

In general, the performance gains that indexes provide for *read
operations* are worth the insertion penalty; however, when optimizing
write performance, be careful when creating new indexes and always
evaluate the indexes on the collection and ensure that your queries are
actually using these indexes.

For more information on indexes in MongoDB consider :doc:`/indexes`
and :doc:`/applications/indexes`.

.. [#exceptions] The overhead for :ref:`sparse indexes
   <index-type-sparse>` inserts and updates to un-indexed fields
   is less than for non-sparse indexes. Also for non-sparse indexes,
   updates that don't change the record size have less indexing
   overhead.

.. _write-operations-isolation:

Isolation
---------

When a single write operation modifies multiple documents, the
operation as a whole is not atomic, and other operations may
interleave. The modification of a single document, or record, is always
atomic, even if the write operation modifies multiple sub-document
*within* the single record.

No other operations are atomic; however, you can attempt to isolate a
write operation that affects multiple documents using the
:doc:`isolation operator </reference/operator/isolated>`.

To isolate a sequence of write operations from other read and write
operations, see :doc:`/tutorial/perform-two-phase-commits`.

Updates
-------

Each document in a MongoDB collection has allocated *record* space
which includes the entire document *and* a small amount of
padding. This padding makes it possible for update operations to
increase the size of a document slightly without causing the document
to outgrow the allocated record size.

Documents in MongoDB can grow up to the full maximum :limit:`BSON
document size <BSON Document Size>`. However, when documents outgrow
their allocated record size MongoDB must allocate a new record and
move the document to the new record. Update operations that do not
cause a document to grow, (i.e. *in-place* updates,) are significantly
more efficient than those updates that cause document growth. Use
:doc:`data models </core/data-modeling>` that minimize the need for
document growth when possible.

For complete examples of update operations, see
:doc:`/core/update`.

.. _write-operations-padding-factor:

Padding Factor
--------------

If an update operation does not cause the document to increase in
size, MongoDB can apply the update in-place. Some updates
change the size of the document, for example using the
:operator:`$push` operator to append a sub-document to an array can
cause the top level document to grow beyond its allocated space.

When documents grow, MongoDB relocates the document on disk with
enough contiguous space to hold the document. These relocations
take longer than in-place updates, particularly if the collection has
indexes that MongoDB must update all index entries. If
collection has many indexes, the move will impact write throughput.

To minimize document movements, MongoDB employs padding. MongoDB
adaptively learns if documents in a collection tend to grow, and if
they do, adds a :data:`~collStats.paddingFactor` so that the documents
have room to grow on subsequent writes. The
:data:`~collStats.paddingFactor` indicates the padding for new inserts
and moves.

.. versionadded:: 2.2
   You can use the :dbcommand:`collMod` command
   with the :collflag:`usePowerOf2Sizes` flag so that MongoDB
   allocates document space in sizes that are powers of 2. This helps
   ensure that MongoDB can efficiently reuse the space freed as a
   result of deletions or document relocations. As with all padding,
   using document space allocations with power of 2 sizes minimizes,
   but does not eliminate, document movements.

To check the current :data:`~collStats.paddingFactor` on a collection, you can
run the :method:`db.collection.stats()` operation in the
:program:`mongo` shell, as in the following example:

.. code-block:: javascript

   db.myCollection.stats()

Since MongoDB writes each document at a different point in time, the
padding for each document will not be the same. You can calculate the
padding size by subtracting 1 from the :data:`~collStats.paddingFactor`, for
example:

.. code-block:: none

   padding size = (paddingFactor - 1) * <document size>.

For example, a :data:`~collStats.paddingFactor` of ``1.0`` specifies no padding
whereas a paddingFactor of ``1.5`` specifies a padding size of ``0.5`` or 50
percent (50%) of the document size.

Because the :data:`~collStats.paddingFactor` is relative to the size of each
document, you cannot calculate the exact amount of padding for a
collection based on the average document size and padding factor.

If an update operation causes the document to *decrease* in size, for
instance if you perform an :operator:`$unset` or a :operator:`$pop`
update, the document remains in place and effectively has more
padding. If the document remains this size, the space is not reclaimed
until you perform a :dbcommand:`compact` or a
:dbcommand:`repairDatabase` operation.

.. note::

   The following operations remove padding:

   - :dbcommand:`compact`,
   - :dbcommand:`repairDatabase`, and
   - initial replica sync operations.

   However, with the :dbcommand:`compact` command, you can run the
   command with a ``paddingFactor`` or a ``paddingBytes`` parameter.

   Padding is also removed if you use :program:`mongoexport` from a
   collection. If you use :program:`mongoimport` into a new
   collection, :program:`mongoimport` will not add padding.  If you
   use :program:`mongoimport` with an existing collection with
   padding, :program:`mongoimport` will not affect the existing
   padding.

   When a database operation removes padding, subsequent update that
   require changes in record sizes will have reduced throughput until
   the collection's padding factor grows. Padding does not affect
   in-place, and after :dbcommand:`compact`,
   :dbcommand:`repairDatabase`, and replica set initial sync
   the collection will require less storage.

.. COMMENT -- not sure if we really need this manual padding info or if
   it belongs here, but ...

.. seealso::

   - :ref:`faq-developers-manual-padding`

   - The :operator:`$inc` for in-place updates.

Architecture
------------

.. _write-operations-replica-sets:

Replica Sets
~~~~~~~~~~~~

In :term:`replica sets <replica set>`, all write operations go to the
set's :term:`primary`, which applies the write operation then records
the operations on the primary's operation log or :term:`oplog`. The
oplog is a reproducible sequence of operations to the data
set. :term:`Secondary` members of the set are continuously replicating the
oplog and applying the operations to themselves in an asynchronous
process.

Large volumes of write operations, particularly bulk operations, may
create situations where the secondary members have difficulty applying
the replicating operations from the primary at a sufficient rate: this
can cause the secondary's state to fall behind that of the primary. Secondaries
that are significantly behind the primary present problems for normal
operation of the replica set, particularly :ref:`failover
<replica-set-failover-administration>` in the form of :ref:`rollbacks
<replica-set-rollback>` as well as general :doc:`read consistency
</applications/replication>`.

To help avoid this issue, you can customize the :ref:`write concern
<write-operations-write-concern>` to return confirmation of the write
operation to another member [#write-concern-throttling]_ of the replica
set every 100 or 1,000 operations. This provides an opportunity for
secondaries to catch up with the primary. Write concern can slow the
overall progress of write operations but ensure that the secondaries
can maintain a largely current state with respect to the primary.

For more information on replica sets and write operations, see
:ref:`replica-set-write-concern`, :ref:`replica-set-oplog-sizing`, and
:doc:`/tutorial/change-oplog-size`.

.. [#write-concern-throttling] Calling :dbcommand:`getLastError`
   intermittently with a ``w`` value of ``2`` or ``majority`` will
   slow the throughput of write traffic; however, this practice will
   allow the secondaries to remain current with the state of the
   primary.

.. _write-operations-sharded-clusters:

Sharded Clusters
~~~~~~~~~~~~~~~~

In a :term:`sharded cluster`, MongoDB directs a given write operation to
a :term:`shard` and then performs the write on a particular
:term:`chunk` on that shard. Shards and chunks are range-based.
:term:`Shard keys <shard key>` affect how MongoDB distributes documents
among shards. Choosing the correct shard key can have a great impact on
the performance, capability, and functioning of your database and
cluster.

For more information, see :doc:`/administration/sharded-clusters` and
:ref:`write-operations-bulk-insert`.
