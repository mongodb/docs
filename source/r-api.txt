=======================
Spark Connector R Guide
=======================

.. default-domain:: mongodb

.. note:: Source Code

   For the source code that contains the examples below, see
   :mongo-spark:`introduction.R
   </blob/master/examples/src/test/R/introduction.R>`.

Prerequisites
-------------

.. include:: /includes/list-prerequisites.rst

Getting Started
---------------

.. _sparkR-shell:

``sparkR`` Shell
~~~~~~~~~~~~~~~~

This tutorial uses the ``sparkR`` shell, but the code examples work
just as well with self-contained R applications.

When starting the ``sparkR`` shell, you can specify:

.. include:: /includes/extracts/command-line-start-sparkR.rst

.. _r-basics:

Create a ``SparkSession`` Object
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. note:: 

   When you start ``sparkR`` you get a ``SparkSession`` object called
   ``spark`` by default. In a standalone R application, you need
   to create your ``SparkSession`` object explicitly, as show below.
   
If you specified the ``spark.mongodb.input.uri``
and ``spark.mongodb.output.uri`` configuration options when you
started ``sparkR``, the default ``SparkSession`` object uses them.
If you'd rather create your own ``SparkSession`` object from within
``sparkR``, you can use ``sparkr.session()`` and specify different
configuration options.

.. code-block:: none

   my_spark <- sparkR.session(
    master="local[*]",
    sparkConfig=list(),
    appName="my_app"
   )

You can use a ``SparkSession`` object to write data to MongoDB, read
data from MongoDB, create DataFrames, and perform SQL operations.

Tutorials
---------

- :doc:`/r/write-to-mongodb`
- :doc:`/r/read-from-mongodb`
- :doc:`/r/aggregation`
- :doc:`/r/filters-and-sql`

.. toctree::
   :titlesonly:

   /r/write-to-mongodb
   /r/read-from-mongodb
   /r/aggregation
   /r/filters-and-sql
