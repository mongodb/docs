.. _performance-issues-psa:

===============================================================
Mitigate Performance Issues with a Self-Managed PSA Replica Set
===============================================================

.. meta::
   :keywords: on-prem

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Overview
--------

In a three-member replica set with a primary-secondary-arbiter (PSA)
architecture or a sharded cluster with three-member PSA shards, a
data-bearing node that is down or lagged can lead to performance issues.

If one data-bearing node goes down, the other node becomes the primary.
Writes with :writeconcern:`w:1 <\<number\>>` continue to succeed in this
state but writes with write concern :writeconcern:`"majority"` cannot
succeed and the commit point starts to lag. If your PSA replica set
contains a lagged secondary and your replica set requires two nodes to
majority commit a change, your commit point also lags.

With a lagged commit point, two things can affect your cluster
performance:

- The storage engine keeps **all** changes that happen after the commit
  point on disk to retain a :term:`durable` history. The extra I/O from
  these writes tends to increase over time. This can greatly impact
  write performance and increase cache pressure.
- MongoDB allows the :ref:`oplog <replica-set-oplog>` to grow past its
  configured size limit to avoid deleting the :data:`majority commit
  point <replSetGetStatus.optimes.lastCommittedOpTime>`.

To reduce the cache pressure and increased write traffic, set
:rsconf:`votes: 0 <members[n].votes>` and :rsconf:`priority: 0
<members[n].priority>` for the node that is unavailable or lagging. For
write operations issued with "majority", only voting members are
considered to determine the number of nodes needed to perform a majority
commit. Setting the configuration of the node to :rsconf:`votes: 0
<members[n].votes>` reduces the number of nodes required to commit a
write with write concern :writeconcern:`"majority"` from two to one and
allows these writes to succeed.

Once the secondary is caught up, you can use the
:method:`rs.reconfigForPSASet()` method to set :rsconf:`votes
<members[n].votes>` back to ``1``.

.. note::

   In earlier versions of MongoDB,
   :setting:`~replication.enableMajorityReadConcern` and
   :option:`--enableMajorityReadConcern` were configurable allowing you
   to disable the default read concern :readconcern:`"majority"` which
   had a similar effect.

Procedure
---------

To reduce the cache pressure and increased write traffic for a
deployment with a three-member primary-secondary-arbiter (PSA)
architecture, set ``{ votes: 0, priority: 0 }`` for the secondary that
is unavailable or lagging:

.. code-block:: javascript

   cfg = rs.conf();
   cfg["members"][<array_index>]["votes"] = 0;
   cfg["members"][<array_index>]["priority"] = 0;
   rs.reconfig(cfg);


If you want to change the configuration of the secondary later, use the
:method:`rs.reconfigForPSASet()` method.
