.. _arch-center-dr:

==========================================
Guidance for {+service+} Disaster Recovery
==========================================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: tutorial

.. meta::
   :description: Learn how to prepare for and respond to disasters with this disaster recovery page for MongoDB Atlas.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: onecol

It is critical for enterprises to plan for disaster recovery. We strongly recommend that you prepare a comprehensive disaster recovery (DR) plan 
that includes elements such as: 

- Your designated recovery point objective (RPO)
- Your designated recovery time objective (RTO)
- Automated processes that facilitate alignment with these objectives

Use the recommendations on this page to prepare for and respond to
disasters.

To learn more about proactive high availability configurations that
can help with disaster recovery, see :ref:`arch-center-ha-configurations`.

Features for {+service+} Disaster Recovery
------------------------------------------

To learn about {+service+} features that support disaster recovery, see
the following pages in the {+atlas-arch-center+}:

- :ref:`arch-center-high-availability`
- :ref:`arch-center-resiliency`
- :ref:`arch-center-backups`

.. _arch-center-dr-recs:

Recommendations for {+service+} Disaster Recovery
-------------------------------------------------

Use the following disaster recovery recommendations to create a {+DR+}
plan for your organization. These recommendations provide information
on steps to take in the event of a disaster.

It is imperative that you test the plans in this section regularly (ideally quarterly, but at least semi-annually). Testing often helps prepare the Enterprise Database Management (EDM) team to respond to disasters while also helping to keep the instructions up to date. 

Some disaster recovery testing might require actions that cannot be performed by EDM users. In these cases, open a support case for the purpose of performing artificial outages at least a week in advance of when you plan on running a test exercise.

This section covers the following disaster recovery procedures:

- :ref:`arch-center-single-node-outage`
- :ref:`arch-center-regional-outage`
- :ref:`arch-center-provider-outage`
- :ref:`arch-center-atlas-outage`
- :ref:`arch-center-resource-capacity`
- :ref:`arch-center-resource-failure`
- :ref:`arch-center-data-deletion`
- :ref:`arch-center-driver-failure`
- :ref:`arch-center-data-corruption`

.. _arch-center-single-node-outage:

Single Node Outage
~~~~~~~~~~~~~~~~~~

If a single node in your replica set fails due to a regional outage, your deployment should still be available, assuming you have followed best practices. If you are reading from secondaries, you might experience degraded performance because you have one less node to read from.

You can test a primary node outage in {+service+} using the 
{+atlas-ui+}\'s
:atlas:`Test Primary Failover </tutorial/test-resilience/test-primary-failover/>` feature or the :oas-atlas-op:`Test Failover </testFailover>` {+atlas-admin-api+} endpoint.

.. _arch-center-regional-outage:

Regional Outage
~~~~~~~~~~~~~~~

If a single region outage or multi-region outage degrades the state of your {+cluster+}, follow these steps:

.. procedure::
   :style: normal

   .. step:: Identify the region experiencing issues

   .. step:: Identify how many nodes are still online

      You can find information about {+cluster+} health in the {+cluster+}\'s :guilabel:`Overview` tab of the
      {+atlas-ui+}.

   .. step:: Determine how many nodes you require
    
      Based on how many nodes are left online, determine how many new nodes you require to restore the replica set to a normal state.
    
      A normal state is a state in which the majority of nodes
      are available.

   .. step:: Determine which regions are unlikely to be affected by the current outage
    
      Depending on the cause of the outage, there may be additional regions in the near future that will also experience unscheduled outages. For example, if the outages were caused by a natural disaster on the east coast of the United States, you should avoid regions on the east coast of the United States in case there are additional issues.

   .. step:: Add nodes to the regions you identified
    
      Add the required number of nodes for a normal state across
      regions that are unlikely to be affected by the cause of the
      outage.

      To reconfigure a replica set during an outage by adding regions
      or nodes, see 
      :atlas:`Reconfigure a Replica Set During a Regional Outage </reconfigure-replica-set-during-regional-outage/>`.

   .. step:: (Optional) Add additional nodes
    
      In addition to adding nodes to restore your replica set to a
      normal state, you can add additional nodes to match the topology of your replica set before the disaster.

You can test a region outage in {+service+} using the 
{+atlas-ui+}\'s
:atlas:`Simulate Outage </tutorial/test-resilience/simulate-regional-outage/>` feature or the :oas-atlas-op:`Start an Outage Simulation </startOutageSimulation>` {+atlas-admin-api+} endpoint.

.. _arch-center-provider-outage:

Cloud Provider Outage
~~~~~~~~~~~~~~~~~~~~~

In the highly unlikely event that an entire cloud provider is
unavailable, follow these steps to bring your deployment back online:

.. procedure::
   :style: normal
   
   .. step:: Determine when the cloud provider outage began. 
      
      You need this information later in this procedure to restore your deployment.

   .. step:: Identify the alternative cloud provider you would like to deploy your new {+cluster+} on

      For a list of cloud providers and information, see 
      :atlas:`Cloud Providers </reference/cloud-providers>`.

   .. step:: Find the most recent available snapshot taken of the {+cluster+} before the outage began

      To learn how to view your backup snapshots, see 
      :atlas:`View M10+ Backup Snapshots </backup/cloud-backup/dedicated-cluster-backup/#view-m10--backup-snapshots>`.

   .. step:: Create a new {+cluster+} with the alternative cloud provider

      Your new {+cluster+} must have an identical topology of the original cluster.

      Alternatively, instead of creating a full new cluster, you can also add new
      nodes hosted by an alternative cloud provider to the existing cluster.

   .. step:: Restore the most recent snapshot from the previous step into the new {+cluster+}

      To learn how to restore your snapshot, see :atlas:`Restore Your Cluster </backup/cloud-backup/restore-overview/>`.

   .. step:: Switch any applications that connect to the old {+cluster+} to the newly-created {+cluster+}

      To find the new connection string, see :atlas:`Connect via Drivers </driver-connection>`.
      Review your application stack as you likely need to redeploy it onto the new cloud provider.

.. _arch-center-atlas-outage:

{+service+} Outage
~~~~~~~~~~~~~~~~~~

In the highly unlikely event that the {+service+} Control Plane and
the {+atlas-ui+} are unavailable, your {+cluster+} is still available and accessible.
To learn more, see `Platform Reliability <https://www.mongodb.com/products/platform/trust#reliability>`__.
Open a high-priority :atlas:`support ticket </support/#request-support>`
to investigate this further.

.. _arch-center-resource-capacity:

Resource Capacity Issues
~~~~~~~~~~~~~~~~~~~~~~~~

Computational resource (such as disk space, RAM, or CPU) capacity
issues can result from poor planning or unexpected database traffic.
This behavior might not be a result of a disaster. 

If a computational resource reaches the maximum allocated
amount and causes a disaster, follow these steps:

.. procedure::
   :style: normal

   .. step:: Identify which computational resource is maxed out by using the Real Time Performance Panel or {+service+} metrics

      To view your resource utilization in the {+atlas-ui+}, see :atlas:`Monitor Real-Time Performance </real-time-performance-panel>`.

      To view metrics with the {+atlas-admin-api+},
      see :oas-atlas-tag:`Monitoring and Logs </Monitoring-and-Logs>`.

   .. step:: Determine how much more of the maxed-out resource you need to alleviate performance issues

   .. step:: Allocate the necessary resources
      
      Note that Atlas will perform this change in a rolling manner, so
      it should not have any major impact on your applications.

      To learn how to allocate more resources, see :atlas:`Edit a Cluster </scale-cluster/#edit-a-cluster>`.

   .. step:: Monitor your {+cluster+} to determine whether any other issues exist after the change

.. _arch-center-resource-failure:

Resource Failure
~~~~~~~~~~~~~~~~

.. include:: /includes/temporary-cluster-fix.rst

If a computational resource fails and causes your cluster to become
unavailable, follow these steps:

.. procedure::
   :style: normal

   .. step:: Open a high-priority :atlas:`support ticket </support/#request-support>`

   .. step:: Create a new {+cluster+} with the same topology as the failing {+cluster+}

   .. step:: Restore the most recent backup into the newly-created {+cluster+}

      To learn how to restore your snapshot, see :atlas:`Restore Your Cluster </backup/cloud-backup/restore-overview/>`.

   .. step:: Point all applications using the failing {+cluster+} to the newly-created {+cluster+}

.. _arch-center-data-deletion:

Deletion of Production Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Production data might be accidentally deleted due to human error or a bug
in the application built on top of the database.
If the cluster itself was accidentally deleted, Atlas might retain
the volume temporarily.

If the contents of a collection or database have been deleted, follow these steps to restore your data:

.. procedure::
   :style: normal

   .. step:: Determine the date and time or oplog timestamp when the data was deleted

   .. step:: Create a copy of the current state of the collection or database, if it contains any data

      You can use `mongoexport <https://www.mongodb.com/docs/database-tools/mongoexport/>`__ to create a copy.

   .. step:: Restore your data
   
      If the deletion occurred within the last 72 hours, and you configured continuous backup,
      use Point in Time (PIT) restore to restore from the point in time right before the deletion occurred.
      
      If the deletion did not occur in the past 72 hours, restore the most recent backup from before the deletion occurred into the cluster.

      To learn more, see :atlas:`Restore Your Cluster </backup/cloud-backup/restore-overview/>`.

   .. step:: If you created a copy of your data, import the new data you exported

      You can use `mongoimport <https://www.mongodb.com/docs/database-tools/mongoimport/>`__ with `upsert mode <https://www.mongodb.com/docs/database-tools/mongoimport/#std-option-mongoimport.--mode>`__ to import your data and ensure that any data that was modified or added is reflected properly in the collection or database.

.. _arch-center-driver-failure:

Driver Failure
~~~~~~~~~~~~~~

If a driver fails, follow these steps:

.. procedure::
   :style: normal

   .. step:: Determine the issue

      You can work with the technical support team during this step.

      If you determine that reverting to an earlier driver version will
      fix the issue, continue to the next step.

   .. step:: Determine when the issue was introduced and the latest working driver version

   .. step:: Evaluate if any other changes are required to move to an earlier driver version
      
      This might include application code or query changes. For example,
      there might be a breaking change if you are moving between
      major and minor versions.

   .. step:: Test the changes in a non-production environment

   .. step:: If you don't encounter issues while testing, downgrade to the new driver version
      
      Ensure that any other changes from the previous step are
      reflected in the production environment.

.. _arch-center-data-corruption:

Data Corruption
~~~~~~~~~~~~~~~

.. include:: /includes/temporary-cluster-fix.rst

If your underlying data becomes corrupted, follow these steps:

.. procedure::
   :style: normal

   .. step:: Open a high-priority :atlas:`support ticket </support/#request-support>`

   .. step:: Create a new {+cluster+} with the same topology as the failing {+cluster+}

   .. step:: Restore the most recent backup into the newly-created {+cluster+}

      To learn how to restore your snapshot, see :atlas:`Restore Your Cluster </backup/cloud-backup/restore-overview/>`.

   .. step:: Check the restored data to confirm that the corruption does not exist

   .. step:: Point all applications using the failing {+cluster+} to the newly-created {+cluster+}









