=====================
Aggregation Mechanics
=====================

.. versionadded:: 2.1

.. default-domain:: mongodb

This section describes behaviors and limitations specific to the
:ref:`aggregation pipeline <aggregation-pipeline>`.

Sharded Operation
-----------------

.. note::

   .. versionchanged:: 2.1

   Some aggregation operations using :dbcommand:`aggregate` will
   cause :program:`mongos` instances to require more CPU resources
   than in previous versions. This modified performance profile may
   dictate alternate architectural decisions if you use the
   :ref:`aggregation pipeline <aggregation-pipeline>` extensively
   in a sharded environment.

The aggregation pipeline is compatible with sharded collections.

When operating on a sharded collection, the aggregation pipeline
is split into two parts. The aggregation pipeline pushes
all of the operators up to the first
:pipeline:`$group` or :pipeline:`$sort` operation to each shard.
[#match-sharding]_ Then, a second pipeline on the :program:`mongos`
runs. This pipeline consists of the first :pipeline:`$group` or
:pipeline:`$sort` and any remaining pipeline operators, and runs
on the results received from the shards.

The :pipeline:`$group` operator brings in any "sub-totals" from
the shards and combines them: in some cases these may be
structures. For example, the :group:`$avg` expression
maintains a total and count for each shard; :program:`mongos` combines
these values and then divides.

.. [#match-sharding] If an early :pipeline:`$match` can exclude
   shards through the use of the shard key in the predicate, then
   these operators are only pushed to the relevant shards.

Limitations
-----------

Aggregation operations with the :dbcommand:`aggregate` command have
the following limitations:

- The :ref:`aggregation pipeline <aggregation-pipeline>`
  cannot operate on values of the following types:
  ``Symbol``, ``MinKey``, ``MaxKey``, ``DBRef``, ``Code``,
  ``CodeWScope``.

  .. versionchanged:: 2.4
     Removed restriction on ``Binary`` type data. In 2.2, the pipeline
     could not operate on ``Binary`` type data.

- Output from the pipeline can only contain 16 megabytes. If
  your result set exceeds this limit, the :dbcommand:`aggregate`
  command produces an error.

- If any single aggregation operation consumes more than 10 percent of
  system RAM the operation will produce an error.
