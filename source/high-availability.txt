.. _arch-center-high-availability:

=================
High Availability
=================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: onecol

Consult this page to plan the appropriate cluster configuration that optimizes 
your availability and performance while aligning with your enterprise's 
cost controls and access needs.

{+service+} Features and Recommendations for High Availability
---------------------------------------------------------------

Features
~~~~~~~~

When you launch a new cluster in |service|, {+service+} automatically configures a 
minimum three-node replica set and distributes it in the region you deploy to. If a 
primary member experiences an outage, the MongoDB database automatically detects this failure 
and elects a secondary member as a replacement, and promotes this secondary member 
to become the new primary. |service| then restores or replaces the failing member 
to ensure that the cluster is returned to its target configuration as soon as possible. 
The MongoDB client driver also automatically switches all client connections. The 
entire selection and failover process happens within seconds, without manual 
intervention. MongoDB optimizes the algorithms used to detect failure and elect a 
new primary, reducing the failover interval. 

Clusters that you deploy within a single region are spread across availability 
zones within that region, so that they can withstand partial region outages without 
an interruption of read or write availability. You can optionally choose to spread 
your clusters across two or more regions for greater resilience and 
:ref:`workload isolation <create-cluster-multi-region>`.

Deploying a cluster to three or more regions ensures that the cluster can withstand 
a full region-level outage while maintaining read and write availability, provided 
the application layer is fault-tolerant. If maintaining write operations in your 
preferred region at all times is a high priority, MongoDB recommends deploying the 
cluster so that at least two electable members are in at least two data centers within 
your preferred region.

For the best database performance in a worldwide deployment, users can configure a 
:ref:`global cluster <global-clusters>` which uses location-aware sharding to minimize 
read and write latency. If you have geographical storage requirements, you can also 
ensure that {+service+} stores data in a particular geographical area.

.. _arch-center-deployment-topologies:

Recommended Deployment Topologies
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Single Region, 3 Node Replica Set / Shard (Primary Secondary Secondary)
```````````````````````````````````````````````````````````````````````

.. figure:: /includes/images/highavailabilityPSS.svg
   :figwidth: 750px
   :alt: A topology with a single region with 3 nodes: one primary and two secondaries.

This topology is appropriate if low latency is required but high availability requirements 
are limited to a single region. This topology can tolerate any 1 node failure and easily satisfy majority write 
concern within region secondaries. This will maintain a primary in the preferred region upon any node 
failure, limits cost, and is the least complicated from an application architecture perspective. 
The reads and writes from secondaries in this topology encounter low latency in your preferred region.

This topology, however, can't tolerate a regional outage.

3-Region, 3 Node Replica Set / Shard (Primary - Secondary - Secondary)
``````````````````````````````````````````````````````````````````````

.. figure:: /includes/images/highavailabilityP-S-S.svg
   :figwidth: 750px
   :alt: A topology with a three regions. There is one primary node in the first region, one secondary node in the second region, and one secondary node in the third region.

This topology is the standard multi-regional topology where high availability can be provided to tolerate a regional outage. 
This topology can tolerate any 1 node failure, any 1 region outage, and is the least expensive multi-region topology. 

If the application requires high durability and the app server code has the write majority option set 
in the driver, this topology will experience higher latency for writes as they need to replicate to a second region. 
Additionally, any reads off the secondary always exist in a different region than the preferred primary region
and will require a different app server architecture. Furthermore, any failover event will occur to a different region, and your 
application architecture must adjust as a result.

3-Region, 5 Node Replica Set / Shard (Primary Secondary - Secondary Secondary - Secondary)
``````````````````````````````````````````````````````````````````````````````````````````

.. figure:: /includes/images/highavailabilityPS-SS-S.svg
   :figwidth: 750px
   :alt: A topology with a three regions. There is one primary node and one secondary node in the first region, two secondary nodes in the second region, and one secondary node in the third region.

This topology is the preferred topology that balances high availability, performance, and cost across multiple regions. 
This topology can tolerate any 2 nodes' failure, tolerate primary node failure 
while keeping the new primary in the preferred region, and tolerate any 1 region outage. 

If the application requires high durability and the app server code has the write majority option set 
in the driver, this topology will experience higher latency for writes as they need to replicate to a second region. 
In order to accommodate a regional outage, the application tier must be configured to also fail over and shift work to 
the elected primary.

Examples
--------

The following examples configure the Single Region, 3 Node Replica Set / Shard 
deployment topology using |service| :ref:`tools for automation <arch-center-automation>`.

These examples also apply other recommended configurations, including:

.. tabs::

   .. tab:: Dev and Test Environments
      :tabid: devtest

      .. include:: /includes/shared-settings-clusters-devtest.rst

   .. tab:: Staging and Prod Environments
      :tabid: stagingprod

      .. include:: /includes/shared-settings-clusters-stagingprod.rst

.. tabs::

   .. tab:: CLI
      :tabid: cli

      .. note::

         Before you
         can create resources with the {+atlas-cli+}, you must:

         - :atlas:`Create your paying organization 
           </billing/#configure-a-paying-organization>` and :atlas:`create an API key </configure-api-access/>` for the
           paying organization.
         - :atlascli:`Install the {+atlas-cli+} </install-atlas-cli/>` 
         - :atlascli:`Connect from the {+atlas-cli+} 
           </connect-atlas-cli/>` using the steps for :guilabel:`Programmatic Use`.

      Create One Deployment Per Project
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      .. tabs::

         .. tab:: Dev and Test Environments
            :tabid: devtest

            For your development and testing environments, run the following command for each project. Change
            the IDs and names to use your values:

            .. include:: /includes/examples/cli-example-create-clusters-devtest.rst

         .. tab:: Staging and Prod Environments
            :tabid: stagingprod

            For your staging and production environments, create the following ``cluster.json`` file for each project. 
            Change the IDs and names to use your values:

            .. include:: /includes/examples/cli-json-example-create-clusters.rst

            After you create the ``cluster.json`` file, run the
            following command for each project. The
            command uses the ``cluster.json`` file to create a cluster.

            .. include:: /includes/examples/cli-example-create-clusters-stagingprod.rst 

      For more configuration options and info about this example, 
      see :ref:`atlas-clusters-create`.

   .. tab:: Terraform
      :tabid: Terraform

      .. note::

         Before you
         can create resources with Terraform, you must:

         - :atlas:`Create your paying organization 
           </billing/#configure-a-paying-organization>` and :atlas:`create an API key </configure-api-access/>` for the
           paying organization. Store your API key as environment
           variables by running the following command in the terminal:

           .. code-block::

              export MONGODB_ATLAS_PUBLIC_KEY="<insert your public key here>"
              export MONGODB_ATLAS_PRIVATE_KEY="<insert your private key here>"

         - `Install Terraform 
           <https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli>`__ 

      Create the Projects and Deployments
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      .. tabs::

         .. tab:: Dev and Test Environments
            :tabid: devtest

            For your development and testing environments, create the
            following files for each application and environment 
            pair. Place the files for each application and environment
            pair in their own directory. Change the IDs and names to use your values:

            main.tf
            ```````

            .. include:: /includes/examples/tf-example-main-devtest.rst 

            variables.tf
            ````````````

            .. include:: /includes/examples/tf-example-variables.rst

            terraform.tfvars
            ````````````````

            .. include:: /includes/examples/tf-example-tfvars-devtest.rst

            provider.tf
            ```````````

            .. include:: /includes/examples/tf-example-provider.rst

            After you create the files, navigate to each application and environment pair's directory and run the following
            command to initialize Terraform:

            .. code-block::

               terraform init

            Run the following command to view the Terraform plan:

            .. code-block::

               terraform plan
            
            Run the following command to create one project and one deployment for the application and environment pair. The command uses the files and the |service-terraform| to
            create the projects and clusters:

            .. code-block::

               terraform apply

            When prompted, type ``yes`` and press :kbd:`Enter` to apply
            the configuration.

         .. tab:: Staging and Prod Environments
            :tabid: stagingprod

            For your staging and production environments, create the
            following files for each application and environment 
            pair. Place the files for each application and environment
            pair in their own directory. Change the IDs and names to use your values:

            main.tf
            ```````

            .. include:: /includes/examples/tf-example-main-stagingprod.rst 

            variables.tf
            ````````````

            .. include:: /includes/examples/tf-example-variables.rst

            terraform.tfvars
            ````````````````

            .. include:: /includes/examples/tf-example-tfvars-stagingprod.rst

            provider.tf
            ```````````

            .. include:: /includes/examples/tf-example-provider.rst

            After you create the files, navigate to each application and environment pair's directory and run the following
            command to initialize Terraform:

            .. code-block::

               terraform init

            Run the following command to view the Terraform plan:

            .. code-block::

               terraform plan
            
            Run the following command to create one project and one deployment for the application and environment pair. The command uses the files and the |service-terraform| to
            create the projects and clusters:

            .. code-block::

               terraform apply

            When prompted, type ``yes`` and press :kbd:`Enter` to apply
            the configuration. 
      
      For more configuration options and info about this example, 
      see |service-terraform| and the `MongoDB Terraform Blog Post
      <https://www.mongodb.com/developer/products/atlas/deploy-mongodb-atlas-terraform-aws/>`__.

