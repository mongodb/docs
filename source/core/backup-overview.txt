==============
Backup Process
==============

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

|mms| backups, once started, are an ongoing and continuous process.
Data is continually backed up as long as the backup remains
synchronized with the database. This process works like 
:manual:`replica set data synchronization </core/replica-set-sync>`

The backup process:

1. Performs an :term:`initial sync` to back up all of your existing data in
   its current state. In sharded clusters, this occurs on each shard and on
   the config servers.

2. Takes snapshots of the ``data`` directory in a deployment as often
   as your
   :ref:`snapshot schedule <snapshot-frequency-and-retention>`
   specifies and then transfers the snapshots to a storage system.

   Sharded Clusters also can :ref:`enable checkpoints 
   <enable-cluster-checkpoints>` to permit restores at moments between 
   snapshots. To learn how sharded clusters use checkpoints, see 
   :ref:`checkpoints <checkpoint>`.

3. Monitors the :term:`oplog` constantly and adds new database
   operations to the latest backup to keep the local |onprem| copy of
   the data current.

The backup process works in this manner regardless of how snapshots are
stored.

.. _backup-stages:

Backup Definition and Operational States
----------------------------------------

Each backup is defined as a :term:`job <backup job>`. Each job defines
how much and how often data is backed up. Backup jobs are defined on a
per-group basis.

Operational States
~~~~~~~~~~~~~~~~~~

The following table lists the states of a backup job:

.. list-table::
   :widths: 20 27 27 26
   :header-rows: 1

   * - State
     - Retain Old Snapshots
     - Create New Snapshots
     - Apply Oplogs
  
   * - ``Active``
     - Yes
     - Yes
     - Yes

   * - ``Stopped`` 
     - Yes
     - No
     - No

   * - ``Inactive``
     - No
     - No
     - No

Change Operational States
~~~~~~~~~~~~~~~~~~~~~~~~~

Once backup jobs are active for a :term:`group`, they run without
further intervention until they are stopped or terminated. The operator
can change the state of a backup in the following ways:

.. list-table::
   :widths: 20 40 40
   :header-rows: 1

   * - Initial State

     - Desired State

     - Method

   * - ``Active``

     - :guilabel:`Active` after ``Initial Sync``

     - Click :guilabel:`Start`.

   * - ``Active``

     - :guilabel:`Stopped`

     - Click :guilabel:`Stop`.

   * - ``Stopped``

     - :guilabel:`Active` after ``Initial Sync``

     - Click :guilabel:`Restart`.

   * - ``Stopped``

     - :guilabel:`Inactive`

     - Click :guilabel:`Terminate`.
      
       .. warning::
          :guilabel:`Terminate` deletes all retained backups.

.. important::
   You may receive a :alert:`Backup requires a resync` alert
   for your backup jobs. This may require you to :doc:`/tutorial/resync-backup`. 
   This is not a different state, but a triggering of
   a new :ref:`backup-initial-sync`. The backup job, once ``Initial
   Sync`` completes, becomes :guilabel:`Active` again.

.. _backup-initial-sync:

Backup Process Flows
--------------------

Initial Backup
~~~~~~~~~~~~~~

Once created, a backup job goes through the following process flow:

.. include:: /images/backup-flow.rst

#. The Backup Agent connects to, and authenticates with, the databases
   associated with the backup job.

#. The :term:`initial sync` begins and enters its ``starting`` phase.
   Initial Sync is a transition state between :guilabel:`Inactive` and
   :guilabel:`Active`. Initial Sync goes through a series of phases 
   that are displayed in the :guilabel:`Backup` page to show progress.
   The Backup Agent streams the existing data to |onprem| in 10 MB batches of
   documents called slices. The Backup Agent creates slices at the point in
   time when the backup was created. Data inserted to the cluster after that
   point in time is captured separately.

#. The ``transferring`` phase begins as the slices are stored in the
   :term:`oplog store <Oplog Store Database>` temporarily for later
   processing. The Oplog Store is created when the first
   :term:`Snapshot Store` is created.

#. While the Backup Agent is streaming the data, it tails the
   :term:`oplog`. This tailing collects any differences between the
   state of the deployment database when the backup began and the
   deployment database's current state. The oplog entries are sent in
   compressed bundles of 10 MB each called 
   :term:`oplog slices <oplog slice>`. These two streams of slices are
   collected in parallel to reduce the time needed to construct a
   complete backup.
   
#. The ``building`` phase begins once |onprem| has received all of the
   slices. In this phase, |onprem| creates a local version of the
   backed up database called a :term:`head database`.

#. |onprem| inserts the documents stored in the Oplog Store into the head
   database.

#. The ``applying oplogs`` phase begins as |onprem| applies the 
   tailed oplog entries into the head database.

#. During the ``fetching missing documents`` phase, |onprem| queries
   the deployment database for missing documents to validate the data.
   |onprem| inserts the missing documents found in the deployment
   database into the head database.

#. After the head database is validated, the ``creating indexes`` phase begins
   as |onprem| creates all of the indexes in the deployment databases. When
   the indexes finish, the initial sync ends and the phase changes to
   ``complete``.

#. Depending upon which snapshot store you chose to store your backup,
   a snapshot can be written out:

   a. As blocks to a :term:`blockstore <Backup Blockstore Database>`.
   #. As blocks to an AWS S3 bucket. The metadata for those blocks is
      written to a MongoDB database on the |onprem| host.
   #. As snapshot files to a file system store.

.. note::
   The characteristics of each storage method is covered in 
   :ref:`backup-configuration-options`.

Subsequent Backups
~~~~~~~~~~~~~~~~~~

The head database works as a full copy of the deployment database. It
needs oplogs applied to it on a regular basis to keep its data
synchronized with the deployment database. Snapshots are generated from
the data stored in the head database according to your 
:ref:`snapshot schedule <snapshot-frequency-and-retention>`.

Once the first full backup is completed, each active backup job follows
this process:

1. The Backup Agent tails the deployment's oplog.
2. The Backup Agent routinely batches new oplog entries in :term:`oplog
   slices` and transfers them to |onprem|.
3. |onprem| stores the oplog entries in the Oplog Store.
4. |onprem| applies the new oplog entries from the oplog slices to the
   head database that stores the deployment backup.
5. |onprem| creates a new snapshot and stores it in the snapshot store
   as specified in your :ref:`snapshot schedule <snapshot-frequency-and-retention>`.
