=================================
Known Issues in the |k8s-op-full|
=================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. _k8s-private-cluster-on-gke:

Update Google Firewall Rules to Fix WebHook Issues
--------------------------------------------------

When you deploy |k8s-op-short| to |gke| private clusters, the
|k8s-mdbrscs| or MongoDBOpsManager resource creation could time out.
The following message might appear in the logs:

  Error setting state to reconciling: Timeout: request did not
  complete within requested timeout 30s".

Google configures its firewalls to restrict access to your |k8s|
|k8s-pods|. To use the webhook service,
:gcp:`add a new firewall rule </kubernetes-engine/docs/how-to/private-clusters#add_firewall_rules>`
to grant |gke| control plane access to your webhook service.

The |k8s-op-short| webhook service runs on port 443.

.. _s3-snapshot-stores-om-4.2:

Enable |s3| Snapshot Stores in |onprem| 4.2.10 and 4.2.12
---------------------------------------------------------

To enable S3 Snapshot stores in |onprem| 4.2.10 and 4.2.12, you must
set ``brs.s3.validation.testing: disabled`` in
the :opsmgrkube:`spec.configuration` property of your |onprem|
resource specification.

Configure Persistent Storage Correctly
--------------------------------------

If there are no
:k8sdocs:`persistent volumes </concepts/storage/persistent-volumes/>`
available when you create a resource, the resulting |k8s-pod| stays in
transient state and the Operator fails  (after 20 retries) with the
following error:

.. code-block:: sh

   Failed to update Ops Manager automation config: Some agents failed to register

To prevent this error, either:

- Provide |k8s-pvs| or
- Set ``persistent : false`` for the resource

For testing only, you may also set ``persistent : false``. This
*must not be used in production*, as data is not preserved between
restarts.

Remove Resources before Removing |k8s|
--------------------------------------

Sometimes |onprem| can diverge from |k8s|. This mostly occurs when
|k8s| resources are removed manually. |onprem| can keep displaying an
Automation Agent which has been shut down.

If you want to remove deployments of MongoDB on |k8s|, use the
resource specification to delete resources first so no dead Automation
Agents remain.

Create Separate Namespaces for |k8s-op-short| and MongoDB Resources
-------------------------------------------------------------------

The best strategy is to create |k8s-op-short| and its resources in
different namespaces so that the following operations would work
correctly:

.. code-block:: sh

   kubectl delete pods --all

or

.. code-block:: sh

   kubectl delete namespace mongodb

If the |k8s-op-short| and resources sit in the same ``mongodb``
|k8s-ns|, then operator would also be removed in the same operation.
This would mean that it could not clean the configurations, which
would have to be done in the |application|.

.. _https-enablement-issues:

HTTPS Enabled After Deployment
------------------------------

We recommend that you enable |https| *before* deploying your |onprem| resources.
However, if you enable |https| after deployment,
your managed resources can no longer communicate with |onprem| and 
the |k8s-op-short| reports your resources' status as ``Failed``.

To resolve this issue, you must delete your |k8s-pods| by
running the following command for each Pod:

.. code-block:: sh

   kubectl delete pod <replicaset-pod-name>
      
After deletion, |k8s| automatically restarts the deleted Pods. 
During this period, the resource is unreachable and incurs 
downtime.

.. seealso::
   
   - :ref:`config-https`
   - :ref:`k8s-troubleshooting`

Difficulties with Updates
-------------------------

In some cases, the |k8s-op-short| can stop receiving change events. As
this problem is hard to reproduce, the recommended workaround is to
delete the operator pod. |k8s| starts the new |k8s-op-short|
automatically and starts working correctly:

.. code-block:: sh

   kubectl get pods;
   kubectl delete pod mongodb-enterprise-operator-<podId>`

.. cond:: onprem

   .. seealso::

      :doc:`Kubernetes Operator installation </tutorial/install-k8s-operator>`

.. _unable-to-upgrade-appdb-agent-in-om:

Unable to Update the {+mdbagent+} on Application Database Pods
-----------------------------------------------------------------

You can't use |onprem| to upgrade the {+mdbagent+}\s that run on the
Application Database Pods. The {+mdbagent+} version that runs on these
Pods is embedded in the Application Database Docker image.

You can use the |k8s-op-short| to upgrade the {+mdbagent+} version on
Application Database Pods as MongoDB publishes new images.

.. seealso::

   - :ref:`meko-appdb-agent-version`
   - :ref:`registry-appdb-version`

Machine Memory vs. Container Memory
-----------------------------------

MongoDB versions older than 3.6.13, 4.0.9, and 4.1.9 report host system 
RAM, not container RAM.
