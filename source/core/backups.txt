==========================
Backing up MongoDB Systems
==========================

.. default-domain:: mongodb

.. contents::
   :backlinks: none
   :local:

A good backup is an important part of any disaster recovery
plan. Depending on the specifics of the deployment, infrastructure,
and application requirements, MongoDB supports several backup options.

Backup Options
--------------

MMS Backups
~~~~~~~~~~~

The `MongoDB Management Service
<https://mms.10gen.com/?pk_campaign=MongoDB-Org&pk_kwd=Backup-Docs>`_
supports `backup and restore for MongoDB deployments
<https://mms.mongodb.com/help/backup/>`_.

MMS Replica Set Backups
```````````````````````

MMS backups rely on a `Backup Agent
<http://mms.mongodb.com/help/backup/tutorial/install-and-start-backup-agent/>`_
that runs as a local client of a MongoDB deployment. MMS sends you
an alert if the backup agent goes down or if the remote backups fall
too far behind the deployment.

The backup agent initially synchronizes your data from a single
member of your replica set to a secure remote server that is managed
by MMS. This process is similar to synchronizing a new replica set
member. A significant difference is that you may configure the MMS
backup to synchronize from a secondary member, which places less load
on the running deployment than synchronizing from the primary.

During the initial synchronization, the MMS backup tracks the replica
set :term:`oplog` in much the same way that the secondary members
track the primary. This updates the backup at roughly the same speed
as secondary members, and produces a continuous backup that is always
up-to-date.

In addition to retaining periodic snapshots, MMS backups also retain
24 hours of oplog data. This allows you to restore the replica set
to any given snapshot, or to any single moment within the past day.

To restore from an MMS backup, you can download a ``.tar.gz`` file
from the remote MMS servers, or have MMS copy a restored set of
ready-to-use data files into a local directory.

MMS Sharded Cluster Backups
```````````````````````````

Sharded clusters run multiple independent replica sets, each of which
is a single shard of the cluster. New documents are apportioned among
the shards, and the MongoDB balancer periodically migrates data from
one shard to another to ensure a balanced application load across
all shards.

MMS offers shapshots of sharded systems, producing one snapshot per
shard. To ensure consistency between the snapshots, the MMS backup
agent momentarily stops the balancer to insert a special document
into each shard.

The MMS service watches for the special document while processing
oplog data for each shard. When it detects one, it snapshots the
shard up to that point.

The result is a set of consistent snapshots that may not represent an
exact moment in time but do reflect a consistent state of the cluster
that can be restored and used by applications.

Filesystem Snapshots
~~~~~~~~~~~~~~~~~~~~

:doc:`Filesystem snapshots
</tutorial/backup-and-restore-with-filesystem-snapshots>` are a
relatively low-resource approach to point-in-time backups. Snapshots
use a copy-on-write approach that is slower than a simple copy, and
makes the backup operation appear to be no more resource-intensive
than the ordinary level of application queries. An expanded form
of filesystem snapshots can be used to :doc:`back up a full sharded
cluster </tutorial/backup-sharded-cluster-with-filesystem-snapshots>`

``mongodump``
~~~~~~~~~~~~~

MongoDB provides a versatile :program:`mongodump` tool
that reads database collections and dumps them to an
efficiently packed file. :program:`mongodump` can connect
directly to a running :program:`mongod` instance. Or if
no :program:`mongod` is running, :program:`mongodump`
can read the data files directly. :program:`mongodump`
can also :doc:`back up each component of a sharded cluster
</tutorial/backup-sharded-cluster-with-database-dumps>`, or connect
directly to a running :program:`mongos` instance in order to
:doc:`back up an entire sharded cluster to a single output file
</tutorial/backup-small-sharded-cluster-with-mongodump>`. In
some cases, :program:`mongodump` can also
:doc:`replay any data writes that entered the oplog
</tutorial/backup-and-restore-with-binary-database-dumps>` during
:program:`mongodump`'s execution, thus creating a point-in-time
backup that corresponds to the moment :program:`mongodump` completes
its execution.

One drawback of :program:`mongodump` is that it queries every document
in each collection it backs up, and so can be more resource-intensive
than other forms of backups. A way to mitigate this is to back up
only the collections that contain crucial data.

Another drawback is that :program:`mongodump` does not back up any
local collections by default. Local collections must be backed up
explicitly on each replica set member.

To create a consistent snapshot, mongodump requires access to the
:term:`oplog`, which is only available when running MongoDB as a
:term:`replica set`. Standalone :program:`mongod` instances lack
an oplog.

Simple Backups
~~~~~~~~~~~~~~

From a Standalone mongod Instance
`````````````````````````````````

At the simplest level, you can back up a MongoDB system by disabling
application writes and copying the data files from ``/data/db``
to a backup medium. The benefit of this approach is that it is
straightforward and uses common tools available by default on any
operating system.

This approach has several drawbacks. One is that it requires making the
database unavailable for application writes during the backup. Data
files that are written to while being copied may result in one part
of the copied file conflicting with another part. This type of error
renders the data files invalid. To avoid that, you must disable
application writes for the full duration of the backup.

A second drawback is that the backup files will be larger than
they need to be. To speed up queries, MongoDB data files pad BSON
documents to allow queries to quickly find relevant entries. MongoDB
also stores indexes in data files, which add unnecessarily to the
size of the backup.

If size and write availability are not issues for you, then this simple
approach may be best. If you need better up-time and space efficiency,
or if you want to ensure a lighter overall load on the system, MongoDB
supports several alternative approaches, each with their own strengths.

From a Replica Set Secondary
````````````````````````````

Another simple approach, when backing up a replica set, is to shut
down a secondary member and copy the data files from ``/data/db``
to a backup medium. As in the case of disabling application writes
in order to copy data files from a standalone :program:`mongod`
instance, this approach is also straightforward and uses commonly
available tools. In addition, the replica set continues to accept
application writes during the backup.

This method shares the drawback that the backup files will be larger
than they need to be, because of padding and indexes. Another drawback
is that the secondary member will fall behind the primary during
the backup. When you add the secondary back into the replica set,
the syncing operation will add to the load on the primary.

Considerations for Sharded Clusters
-----------------------------------

In sharded clusters, data moves around in ways that complicate any
backup operation. During normal operation, application writes may
occur on different shards at different times, and are not necessarily
immediately available to queries. In addition, the balancer migrates
chunks of data from one shard to another, leaving a window of time
when migrated data is on both shards simultaneously.

Any approach to sharded cluster backups must ensure data validity
and consistency between shards. This may require :doc:`turning off
the balancer </tutorial/schedule-backup-window-for-sharded-clusters>`
or stopping application writes.

When backing up any sharded cluster, it is also
necessary to :doc:`back up the config server metadata
</tutorial/backup-sharded-cluster-metadata>`.

Testing and Restoring Backups
-----------------------------

Regardless of whether you ever need to invoke a disaster recovery
plan, you should test your backups using whatever disaster recovery
procedure you develop. This could involve :doc:`restoring a single
replica set </tutorial/restore-replica-set-from-backup>`,
:doc:`restoring just a single shard of a cluster
</tutorial/restore-single-shard>`, or :doc:`restoring a complete
sharded cluster </tutorial/restore-sharded-cluster>`.
