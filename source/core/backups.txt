==========================
Backing up MongoDB Systems
==========================

.. default-domain:: mongodb

.. contents::
   :backlinks: none
   :local:

A good backup is an important part of any disaster recovery
plan. Depending on the specifics of the deployment, infrastructure,
and application requirements, MongoDB supports several backup options,
each with their own advantages and considerations.

.. include:: /includes/table/backup-approaches.rst

Backup Options
--------------

MMS Backups
~~~~~~~~~~~

The `MongoDB Management Service
<https://mms.10gen.com/?pk_campaign=MongoDB-Org&pk_kwd=Backup-Docs>`_
supports `backup and restore for MongoDB deployments
<https://mms.mongodb.com/help/backup/>`_.

MMS Replica Set Backups
```````````````````````

MMS backups rely on the user `installing a Backup Agent
<http://mms.mongodb.com/help/backup/tutorial/install-and-start-backup-agent/>`_
that runs as a local client of a MongoDB deployment. MMS sends you
an alert if the backup agent goes down or if the remote backups fall
too far behind the deployment.

The backup agent initially synchronizes your data from a single
member of your replica set to a secure remote server that is managed
by MMS. This process is similar to synchronizing a new replica set
member. A significant difference is that you may configure the MMS
backup to synchronize from a secondary member, which places less load
on the running deployment than synchronizing from the primary.

During the initial synchronization, the MMS backup tracks the replica
set :term:`oplog` in much the same way that the secondary members
track the primary. This updates the backup at roughly the same speed
as secondary members, and produces a continuous backup that is always
up-to-date.

In addition to retaining periodic snapshots, MMS backups also retain
24 hours of oplog data. This allows you to restore the replica set
to any given snapshot, or to any single moment within the past day.

To restore from an MMS backup, you can download a ``.tar.gz`` file
from the remote MMS servers, or have MMS push a restored set of
ready-to-use data files into a local directory on your server.

MMS Sharded Cluster Backups
```````````````````````````

Sharded clusters run multiple independent replica sets, each of which
is a single shard of the cluster. MongoDB apportions new documents
among the shards, and the MongoDB balancer periodically migrates data
from one shard to another to ensure a balanced application load across
all shards.

MMS offers shapshots of sharded systems, producing one snapshot per
shard. To ensure consistency between the snapshots, the MMS backup
agent momentarily stops the balancer to insert a special document
into each shard.

The MMS service watches for the special document while processing
oplog data for each shard. When it detects one, it snapshots the
shard up to that point.

The result is a set of consistent snapshots that may not represent an
exact moment in time but do reflect a consistent state of the cluster
that can be restored and used by applications.

Filesystem Snapshots
~~~~~~~~~~~~~~~~~~~~

Implementation
``````````````

:doc:`Filesystem snapshots
</tutorial/backup-and-restore-with-filesystem-snapshots>` use
copy-on-write to create a point-in-time :term:`replica set` backup
as of the time you initiate the snapshot.

Snapshots can also :doc:`back up a full sharded cluster
</tutorial/backup-sharded-cluster-with-filesystem-snapshots>`.

Advantages
``````````

Snapshots back up the state of the database at a known point in time,
the moment when you initiated the snapshot. This makes it possible to
predict exactly what data will be in the restored replica set. Other
forms of backup may not provide exact point-in-time resolution, but
provide a valid, consistent backup of the state of the database at
some point during the backup.

Snapshots can be incremental, so that each incremental snapshot uses
a small fraction of the computing resources needed for a full backup.

Even making a full snapshot is a relatively low-resource operation.
Copy-on-write ensures that the snapshot operation appears to be no more
resource-intensive than the ordinary level of application queries.

Considerations
``````````````

Snapshots impose additional constraints on the type of filesystem
and block devices used in a MongoDB deployment. Not all filesystems
and block devices support snapshotting.

MongoDB data files include indexes and padding that ensure fast
run-time operations, but that are larger than needed for an
efficient backup. Because of this, snapshots produce a relatively
space-inefficient backup.

``mongodump``
~~~~~~~~~~~~~

Implementation
``````````````

MongoDB provides a versatile :program:`mongodump` tool that uses
MongoDB's native querying operations to read database collections
and dump them to a file.

Advantages
``````````

:program:`mongodump` stores only documents. It discards the
indexes and padding associated with MongoDB data files. This makes
:program:`mongodump` backups highly space-efficient.

:program:`mongodump` provides per-collection granularity. This allows
you to back up only the collections you need, or to schedule different
frequencies of backups for different collections.

:program:`mongodump` reads data files in whatever way
they are available. :program:`mongodump` can connect
directly to a running :program:`mongod` instance. Or if
no :program:`mongod` is running, :program:`mongodump`
can read the data files directly. :program:`mongodump` can
connect to a running :program:`mongos` instance in order to
:doc:`back up an entire sharded cluster to a single output file
</tutorial/backup-small-sharded-cluster-with-mongodump>`. However,
the more common case is for :program:`mongodump`
to :doc:`back up each component of a sharded cluster
</tutorial/backup-sharded-cluster-with-database-dumps>` individually.

:program:`mongodump` provides the option to
:doc:`replay any data writes that entered the oplog
</tutorial/backup-and-restore-with-binary-database-dumps>` during
:program:`mongodump`'s execution. This creates a point-in-time backup
that corresponds to the moment :program:`mongodump` finishes building
the backup.

Considerations
``````````````

:program:`mongodump` queries every document in each collection it
backs up, and so can be more resource-intensive than other forms of
backups.

:program:`mongodump` does not back up any local collections by
default. Local collections must be backed up explicitly on each
replica set member.

To create a point-in-time backup, mongodump requires access to the
:term:`oplog`, which is only available when running MongoDB as a
:term:`replica set`. Standalone :program:`mongod` instances lack
an oplog.

Simple Backups
~~~~~~~~~~~~~~

Implementation
``````````````

MongoDB data files may be copied directly to a backup medium. For a
single :program:`mongod` instance, you must disable application writes,
and copy the data files from ``/data/db``. For a :term:`replica set`,
you may shut down a secondary member and copy the data files from its
``/data/db`` directory while still allowing application writes to
the primary member.

Advantages
``````````

Copying data files is a straightforward operation that uses common tools
available by default on any operating system.

Considerations
``````````````

Disabling writes on a standalone :program:`mongod` instance may
interfere with application availability.

As in the case of filesystem snapshots, a simple file copy includes
indexes and padding that ensure fast run-time operations, but that
are larger than needed for an efficient backup.

After shutting down a secondary member and copying its data files,
when you add the secondary back into the replica set the syncing
operation will add to the load on the primary.

Replica Set Considerations
--------------------------

If you decide not to use MMS Backups, there are some best practices that all
replica sets should follow in order to support more robust backups.

Always run with journaling enabled. This is MongoDB's default, and
you should not change it.

Create backups from secondary nodes instead of primaries where
feasible.

Use a volume manager that supports making incremental
snapshots. Include periodic incremental snapshots as part of your
overall backup plan.

Sharded Cluster Considerations
------------------------------

In sharded clusters, data moves around in ways that complicate
making backups. During normal operation, application writes may
occur on different shards at different times, and are not necessarily
immediately available to queries. In addition, the balancer migrates
chunks of data from one shard to another, leaving a window of time
when migrated data is on both shards simultaneously.

Any approach to sharded cluster backups must ensure data validity
and consistency between shards. This may require :doc:`turning off
the balancer </tutorial/schedule-backup-window-for-sharded-clusters>`
or stopping application writes.

When backing up any sharded cluster, it is also
necessary to :doc:`back up the config server metadata
</tutorial/backup-sharded-cluster-metadata>`.

Testing and Restoring Backups
-----------------------------

Regardless of whether you ever need to invoke a disaster recovery
plan, you should test your backups using whatever disaster recovery
procedure you develop. This could involve :doc:`restoring a single
replica set </tutorial/restore-replica-set-from-backup>`,
:doc:`restoring just a single shard of a cluster
</tutorial/restore-single-shard>`, or :doc:`restoring a complete
sharded cluster </tutorial/restore-sharded-cluster>`.

