============
Backup Flows
============

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Introduction
------------

|mms| Backup's process for keeping a backup in sync with your
deployment is analogous to the process used by a secondary to replicate
data in a :term:`replica set`. Backup first performs an :term:`initial sync` to catch up
with your deployment and then tails the :term:`oplog` to stay caught up. Backup
takes scheduled snapshots to keep a history of the data.

Blockstore Storage
~~~~~~~~~~~~~~~~~~

.. include:: /images/backup-flow-blockstore.rst

Filesystem Storage
~~~~~~~~~~~~~~~~~~

.. include:: /images/backup-flow-filesystem-storage.rst

Filesystem storage gives you full control over your data, allowing you
to reduce the number of MongoDB instances you need to run and enabling
you to take advantage of existing storage infrastructure. With
filesystem storage, you can access the backed-up data files using
standard filesystem utilities, rather than having to retrieve them
through the |mms| interface.

With filesystem storage, you can select any mountable filesystem to
which |mms| will write the snapshots. In addition, an :term:`oplog store
<Oplog Store Database>` database stores your :term:`oplog` for
processing. When you add a filesystem store |mms| prompts you to specify
the database for your oplogs.

If you use file system snapshot storage and use multiple |onprem| instances
(including those activated as Backup Daemons), all |onprem| instances
must have the same view of the file system snapshot storage. You can achieve
this through a Network File System (NFS) application or something similar.

.. include:: /includes/important-multiple-instances-share-view-filesystem-snapshots.rst

.. TODO: link to the installation tutorial where it talks about
   picking the snapshot store.

.. _backup-initial-sync:

Initial Sync
------------

Transfer of Data and Oplog Entries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When you start a backup, the Backup Agent streams your deployment's
existing data to the |http-service| in batches of documents
totaling roughly 10MB. The batches are called "slices" and contain
only the data as it existed when you started the backup. 

While transferring the data, the Backup Agent tails the
:term:`oplog` and streams the oplog updates to the |http-service|.
|mms| then stores the oplog entries in the oplog database
for later processing offline.

Building the Backup
~~~~~~~~~~~~~~~~~~~

When the |http-service| has received all of the slices, a Backup
Daemon creates a local database on its server and inserts the documents
that were captured as slices during the initial sync. The Daemon then
applies the oplog entries from the oplog store.

The Backup Daemon then validates the data. If there are missing
documents, |mms| queries the deployment for the documents and the Backup
Daemon inserts them. A missing document could occur because of an update
that caused a document to move during the initial sync.

Once the Backup Daemon validates the accuracy of the data directory, it
has completed the initial sync process and proceeds to routine operation.

Routine Operation
-----------------

The Backup Agent tails the deployment's oplog and routinely batches and
transfers new oplog entries to the |http-service|, which stores them in
the oplog store. The Backup Daemon applies all
newly-received oplog entries in batches to its local replica of the
backed-up deployment.

Snapshots
---------

The Backup Daemon takes a snapshot of the data directory for the
backed-up deployment regularly, as specified by the :ref:`snapshot
schedule <snapshot-frequency-and-retention>`. The Backup daemon takes
the snapshot and transfers it to the snapshot storage.
For a sharded cluster, the daemon takes a snapshot of
each shard and of the config servers. The daemon can also use
:ref:`checkpoints <checkpoint>` to synchronize the shards and config
servers for custom snapshots. You must first :ref:`enable checkpoints
<enable-cluster-checkpoints>`.

When a user requests a snapshot, a Backup Daemon retrieves the data from
the snapshot storage and delivers it to the
requested destination. For an overview of the restore process, see
:doc:`/core/restore-overview`.

Grooms
------

Groom jobs perform periodic "garbage collection" on the snapshot storage
to reclaim space from deleted snapshots. A scheduling
process determines when grooms are necessary.
