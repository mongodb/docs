:noprevnext:

.. _fts-vector-search:
.. _avs-overview:

============================
{+avs+} Overview
============================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: reference

.. meta::
   :keywords: vector search, semantic search, hybrid search, generative search, AI, search meaning, RAG, vector database, use cases
   :description: Use MongoDB Atlas Vector Search to create vector indexes and perform vector search, including semantic search and hybrid search, on your vector embeddings.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

You can use {+avs+} to perform vector search on your data stored 
in |service|. Vector search allows you to query your data based on 
semantic meaning rather than just keyword matches, which helps you 
retrieve more relevant search results. It enables your 
AI-powered applications to support 
:ref:`use cases <avs-use-cases>` such as semantic search,
hybrid search, and generative search, including |rag|.

By using |service| as a vector database, you can seamlessly index 
vector data along with your other data in |service|.
This allows you to filter on fields in your collection and perform 
vector search queries against vector data. You can also combine 
vector search with full-text search queries to return the most relevant 
results for your use case. You can :ref:`integrate <avs-integrations>` 
{+avs+} with popular AI frameworks and services to easily implement
vector search in your applications.

.. button:: Get Started with {+avs+}
   :uri: https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/

.. note::
      
   .. include:: /includes/avs/shared/avs-requirements-cluster-version-ann-enn.rst

.. _avs-about-vector-search:

What is Vector Search?
----------------------

Vector search is a search method that returns results based on
your data's semantic, or underlying, meaning. Unlike traditional 
full-text search which finds text matches, vector search finds 
:term:`vectors <vector>` that are close to your search query 
in multi-dimensional space. The closer the vectors are to your query, 
the more similar they are in meaning.

By interpreting the meaning of your search query and data,
vector search allows you to consider the searcher's intent
and search context to retrieve more relevant results.

For example, if you searched for the term "red fruit," full-text search 
returns only data that explicitly contains these keywords. However, 
semantic search might return data that is similar in meaning,
such as fruits that are red in color like apples or strawberries.

.. _avs-use-cases: 

Use Cases
---------

{+avs+} supports the following vector search use cases:

- **Semantic Search**: Query your vector embeddings based on semantic similarity
  by using the |ann| or |enn| search algorithm.

  To learn more, see :ref:`How to Perform Semantic Search 
  <vector-search-tutorial>` and :ref:`return-vector-search-results`.

- **Hybrid Search**: Combine results from both semantic search and 
  full-text search queries. To learn more, see :ref:`avs-reciprocal-rank-fusion`.

- **Generative Search**: By using |service| as a vector database, you can use {+avs+}
  to power your natural language processing (NLP), machine learning (ML), 
  and generative AI applications. Specifically, you can implement 
  **retrieval-augmented generation (RAG)** 
  by doing the following:
  
  #. Ingest data into |service|.
  #. Retrieve relevant documents with {+avs+}.
  #. Generate responses on your data by using an |llm|.
  
  To learn more, see :ref:`RAG with {+avs+} <avs-rag>`.

.. _avs-integrations:

AI Integrations
~~~~~~~~~~~~~~~

You can use {+avs+} with popular embedding and chat models 
from AI providers such as OpenAI, |aws|, and Google.
MongoDB and partners also provide specific product integrations to 
help you leverage {+avs+} in your AI-powered applications. 
These integrations include built-in tools and libraries 
that enable you to implement |rag| from start to finish. 

To learn more, see :ref:`vector-search-integrations`.

.. _avs-key-concepts:

Key Concepts
------------

.. glossary::

   vector
      A vector is an array of numbers that represents your data 
      in multiple dimensions. Vectors can represent any kind of data, 
      from text, image, and audio data to unstructured data. Semantic 
      similarity is determined by measuring the distance between
      vectors. 
      
      Vector dimensions refer to the number of elements
      in the array, and therefore the number of dimensions 
      in vector space where the vectors are plotted. 

      Specifically, {+avs+} uses dense vectors,
      which are a type of high-dimensional vector that favors 
      smaller storage and semantic richness. As opposed to sparse vectors, 
      dense vectors can be packed with more data,
      which enables {+avs+} to capture more complex relationships.

   vector embeddings
      Vector embeddings are vectors you use to
      represent your data. These embeddings capture 
      meaningful relationships in your data and enable tasks like 
      semantic search and retrieval. You create
      vector embeddings by passing your data through an 
      :term:`embedding model`, and you can store these embeddings 
      in |service| as a field in a document.
      
      {+avs+} determines semantic similarity by identifying the
      vector embeddings that are closest in distance to
      your :ref:`query vector <avs-queries>`.

      To learn more, see :ref:`create-vector-embeddings`.

   embedding model
      Embedding models are algorithms that 
      you use to convert your data into vector embeddings.
      To do this, embedding models use |llm|\s, machine 
      learning models trained on a large corpus of data, to generate 
      vector embeddings that capture the semantic meaning of your data.

      The embedding model that you choose determines the
      dimensions of your vector embeddings. You must specify
      these dimensions as a field in your :ref:`{+avs+} index 
      <avs-indexes>`.
      
      Embedding models vary depending on how 
      the model was trained. Therefore, 
      different models offer different advantages depending 
      on your data and use case. 
      To learn more, see :ref:`choose-embedding-model`.

.. _avs-indexes:

{+avs+} Indexes 
---------------------------

To perform vector search on your data in |service|, you must create 
an {+avs+} index. {+avs+} indexes are separate from your other database 
indexes and are used to efficiently retrieve documents that contain 
vector embeddings at query-time. In your {+avs+} index definition, 
you index the fields in your collection that contain your embeddings 
to enable vector search against those fields. {+avs+} supports embeddings 
that are less than and equal to 4096 dimensions in length.

You can also pre-filter your data by indexing any 
boolean, date, numeric, objectId, string, and UUID fields in your collection 
that you want to run your {+avs+} queries against. 
Filtering your data narrows the scope of your
search and ensures that certain vector embeddings
aren't considered for comparison.

To learn how to index fields for {+avs+}, see :ref:`avs-types-vector-search`. 

.. _avs-queries:

{+avs+} Queries 
---------------------------

{+avs+} supports approximate nearest neighbor (|ann|) search 
with the |hnsw| algorithm and exact nearest neighbor (|enn|) search.

To find the most similar vectors, {+avs+} performs |ann| search without
scanning every vector embedding and |enn| search exhaustively on all
the indexed vector embeddings. To learn more, see :ref:`vectorSearch
Definition <vectorSearch-agg-pipeline>`. 

{+avs+} queries consist of :manual:`aggregation pipeline stages 
</aggregation>` where the :pipeline:`$vectorSearch` stage is the
first stage in the pipeline. The process for a basic {+avs+} query 
is as follows:

#. You select either |ann| or |enn| search and specify the :ref:`query
   vector <vectorSearch-agg-pipeline-options>`, which is the vector
   embedding that represents your search query. 

#. {+avs+} finds vector embeddings in your data that are closest to the
   query vector. 

#. {+avs+} returns the documents that contain the most similar vectors.

To customize your vector search query, you can pre-filter your data on 
fields that you've indexed by using an :abbr:`MQL (MongoDB Query Language)` 
match expression with supported :manual:`query </reference/operator/query/>` 
or :manual:`aggregation operators </reference/operator/aggregation/>`,
or you can add additional :manual:`aggregation stages </reference/operator/aggregation-pipeline/>` 
to further process and organize your results.

To learn how to create and run {+avs+} queries,
see :ref:`return-vector-search-results`. 

Next Steps
-----------

For a hands-on experience creating {+avs+} indexes and running {+avs+} 
queries against sample data, try the :mdbu-course:`{+avs+} Course on MongoDB University 
</courses/using-vector-search-for-semantic-search>` and the tutorials in the following pages:

- :ref:`vector-search-quick-start`
- :ref:`avs-tutorials`

For optimal performance, we recommend deploying :ref:`separate search
nodes for workload isolation <configure-search-nodes>`. Search Nodes
support concurrent query execution to improve individual query
latency. To learn more, see :ref:`avs-deployment-options`.

.. toctree::
   :titlesonly:

   Quick Start </atlas-vector-search/tutorials/vector-search-quick-start/>
   Create Embeddings </atlas-vector-search/create-embeddings/>
   Create and Manage Indexes </atlas-vector-search/vector-search-type>
   Create and Run Queries </atlas-vector-search/vector-search-stage>
   Transform Documents & Filter Collections </atlas-vector-search/transform-documents-collections>
   Vector Quantization </atlas-vector-search/vector-quantization>
   Retrieval-Augmented Generation (RAG) </atlas-vector-search/rag>
   Review Deployment Options </atlas-vector-search/deployment-options>
   Tutorials </atlas-vector-search/tutorials>
   AI Integrations </atlas-vector-search/ai-integrations>
   Evaluate Results </atlas-vector-search/evaluate-results>
   Improve Performance </atlas-vector-search/tune-vector-search>
   Multi-Tenant Architecture </atlas-vector-search/multi-tenant-architecture>
   Troubleshooting </atlas-vector-search/troubleshooting>
   Changelog </atlas-vector-search/changelog>
