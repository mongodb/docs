.. _intro-converters:

==========
Converters
==========

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

Overview
--------

This guide describes how to use **converters** with the {+connector+}.
Converters are programs that translate between bytes and
{+kafka-connect+}'s runtime data format.

Converters pass data between {+kafka-connect+} and Apache Kafka. The connector passes data
between MongoDB and {+kafka-connect+}. The following diagram shows these relationships:

.. figure:: /includes/figures/converters.png
   :alt: Diagram illustrating converters' role in Kafka Connect  

To learn more about converters, see the following resources:

- `Article from Confluent <https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#configuring-converters>`__.
- `Confluent Article on Kafka Connect Concepts <https://docs.confluent.io/platform/current/connect/concepts.html#converters>`__
- `Converter Interface API Documentation <{+kafka_api_docs_base+}javadoc/org/apache/kafka/connect/storage/Converter.html>`__

Available Converters
--------------------

As the connector converts your MongoDB data into {+kafka-connect+}'s runtime data
format, the connector works with all available converters.

.. important:: Use the Same Converter for your Source and Sink Connectors

   You must use the same converter in your {+source-connector+} and {+sink-connector+}.
   For example, if your source connector writes to a topic using Protobuf, your
   sink connector must use Protobuf to read from the topic.

To learn what converter to use, `see this page from Confluent <https://docs.confluent.io/platform/current/schema-registry/connect.html>`__.

Converters with Schemas
~~~~~~~~~~~~~~~~~~~~~~~

If you use a schema-based converter such as the {+avro-converter+},
{+protobuf-converter+}, or {+json-schema-converter+}, you should define a schema
in your source connector. 

To learn how to specify a schema, see the 
:ref:`<kafka-source-apply-schemas>` guide.

Connector Configuration
-----------------------

This section provides templates for properties files to configure the following
converters in a connector pipeline:

- :ref:`Avro Converter <avro-converter-sample-properties>`
- :ref:`Protobuf Converter <protobuf-converter-sample-properties>`
- :ref:`JSON Schema Converter <json-schema-converter-sample-properties>`
- :ref:`JSON Converter <json-converter-sample-properties>`
- :ref:`String Converter <string-converter-sample-properties>`

.. _avro-converter-sample-properties:

Avro Converter
~~~~~~~~~~~~~~

Click the following tabs to view properties files that work with the Avro converter:

.. tabs::

    .. tab:: Source
       :tabid: source-avro
 
       The following properties file defines a source connector. This connector
       uses the default schema and an Avro converter to write to an {+kafka+} topic:

       .. literalinclude:: /includes/properties-files/converters/avro-source.properties
          :language: java
          :dedent:

       .. important:: Avro Converter with a MongoDB Data Source

          Avro converters are a great fit for data with a static structure but are not
          a good fit for dynamic or changing data. MongoDB's schemaless document
          model supports dynamic data, so ensure your MongoDB data source has a static
          structure before specifying an Avro converter.

    .. tab:: Sink
       :tabid: sink-avro

       The following properties file defines a sink connector. This connector
       uses an Avro converter to read from an {+kafka+} topic:

       .. literalinclude:: /includes/properties-files/converters/avro-sink.properties
          :language: java
          :dedent:

To use the preceding properties file, replace the placeholder text in angle
brackets with your information.

.. _protobuf-converter-sample-properties:

Protobuf Converter
~~~~~~~~~~~~~~~~~~

Click the following tabs to view properties files that work with the Protobuf converter:

.. tabs::

   .. tab:: Source
      :tabid: source-proto

      The following properties file defines a source connector. This connector
      uses the default schema and a Protobuf converter to write to an {+kafka+} topic:

      .. literalinclude:: /includes/properties-files/converters/protobuf-source.properties
         :language: java
         :dedent:

   .. tab:: Sink
      :tabid: sink-proto

      The following properties file defines a sink connector. This connector
      uses a Protobuf converter to read from an {+kafka+} topic:

      .. literalinclude:: /includes/properties-files/converters/protobuf-sink.properties
         :language: java
         :dedent:

To use the preceding properties file, replace the placeholder text in angle
brackets with your information.

.. _json-schema-converter-sample-properties:

JSON Schema Converter
~~~~~~~~~~~~~~~~~~~~~

Click the following tabs to view properties files that work with the JSON Schema converter:

.. tabs::

   .. tab::
      :tabid: Schema registry

      The following properties files configure your connector to manage JSON Schemas
      using Confluent Schema Registry:

      .. tabs::

         .. tab:: Source
            :tabid: source-json-schema

            The following properties file defines a source connector. This connector
            uses the default schema and a JSON Schema converter to write to an {+kafka+} topic:

            .. literalinclude:: /includes/properties-files/converters/json-schema-source.properties
               :language: java
               :dedent:

         .. tab:: Sink
            :tabid: sink-json-schema

            The following properties file defines a sink connector. This connector
            uses a JSON Schema converter to read from an {+kafka+} topic:

            .. literalinclude:: /includes/properties-files/converters/json-schema-sink.properties
               :language: java
               :dedent:

   .. tab::
      :tabid: Embedded Schema

      The following properties files configure your connector to embed JSON Schemas
      in messages:
      
      .. important:: Increased Message Size

         Embedding a JSON Schema in your message increases the size of your
         message. To decrease the size of your messages while using JSON
         Schema, use Schema Registry.
      
      .. tabs::

         .. tab:: Source
            :tabid: source-json-schema

            The following properties file defines a source connector. This connector
            uses the default schema and a JSON Schema converter to write to an {+kafka+} topic:

            .. literalinclude:: /includes/properties-files/converters/json-schema-source-mixed.properties
               :language: java
               :dedent:

         .. tab:: Sink
            :tabid: sink-json-schema

            The following properties file defines a sink connector. This connector
            uses a JSON Schema converter to read from an {+kafka+} topic:

            .. literalinclude:: /includes/properties-files/converters/json-schema-sink-mixed.properties
               :language: java
               :dedent:

To use the preceding properties file, replace the placeholder text in angle
brackets with your information.

.. _json-converter-sample-properties:

JSON Converter
~~~~~~~~~~~~~~

Click the following tabs to view properties files that work with the JSON converter:

.. tabs::

   .. tab:: Source
      :tabid: source-json

      The following properties file defines a source connector. This connector
      uses a JSON converter to write to an {+kafka+} topic:

      .. literalinclude:: /includes/properties-files/converters/json-source.properties
         :language: java
         :dedent:

   .. tab:: Sink
      :tabid: sink-json

      The following properties file defines a sink connector. This connector
      uses a JSON converter to read from an {+kafka+} topic: 

      .. literalinclude:: /includes/properties-files/converters/json-sink.properties
         :language: java
         :dedent:

To use the preceding properties file, replace the placeholder text in angle
brackets with your information.

.. _string-converter-sample-properties:

String Converter (Raw JSON)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Click the following tabs to view properties files that work with the String converter:

.. tabs::

   .. tab:: Source
      :tabid: source-string

      The following properties file defines a source connector. This connector
      uses a String converter to write to an {+kafka+} topic:

      .. literalinclude:: /includes/properties-files/converters/string-source.properties
         :language: java
         :dedent:

   .. tab:: Sink
      :tabid: sink-string

      The following properties file defines a sink connector. This connector
      uses a String converter to read from an {+kafka+} topic:

      .. literalinclude:: /includes/properties-files/converters/string-sink.properties
         :language: java
         :dedent:

      .. important:: Received Strings Must be Valid JSON

         Your sink connector must receive valid JSON strings from your
         {+kafka+} topic even when using a String converter.

To use the preceding properties file, replace the placeholder text in angle
brackets with your information.
