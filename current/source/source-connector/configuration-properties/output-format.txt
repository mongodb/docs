.. _source-configuration-output-format:

========================
Output Format Properties
========================

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

Overview
--------

.. _source-configuration-output-format-description-start:

Use the following configuration settings to specify the format of data the
{+source-connector+} publishes to Kafka topics.

.. _source-configuration-output-format-description-end:

.. include:: /includes/source-config-link.rst

Settings
--------

.. _source-configuration-output-format-table-start:

.. list-table::
   :header-rows: 1
   :widths: 30 70

   * - Name
     - Description

   * - | **output.format.key**
     - | **Type:** string
       |
       | **Description:**
       | Specifies which data format the source connector outputs the key
         document.
       |
       | **Default**: ``json``
       | **Accepted Values**: ``bson``, ``json``, ``schema``

   * - | **output.format.value**
     - | **Type:** string
       |
       | **Description:**
       | Specifies which data format the source connector outputs the value
         document.
       |
       | The connector supports Protobuf as an
         output data format. You can enable this format by specifying the
         ``schema`` value and installing and :ref:`configuring
         <protobuf-converter-sample-properties>` the `Kafka Connect Protobuf
         Converter <https://www.confluent.io/hub/confluentinc/kafka-connect-protobuf-converter>`__.
       |
       | **Default**: ``json``
       | **Accepted Values**: ``bson``, ``json``, ``schema``

   * - | **output.json.formatter**
     - | **Type:** string
       |
       | **Description:**
       | Class name of the JSON formatter the connector should use to
         output data.
       |
       | **Default**:

       .. code-block::

          com.mongodb.kafka.connect.source.json.formatter.DefaultJson

       | **Accepted Values**:
       | Your custom JSON formatter full class name or one of the
         following built-in formatter class names:

       .. code-block:: none

          com.mongodb.kafka.connect.source.json.formatter.DefaultJson
          com.mongodb.kafka.connect.source.json.formatter.ExtendedJson
          com.mongodb.kafka.connect.source.json.formatter.SimplifiedJson

       | To learn more about these output formats, see :ref:`kafka-source-json-formatters`.

   * - | **output.schema.key**
     - | **Type:** string
       |
       | **Description:**
       | Specifies an Avro schema definition for the key document of the
         `SourceRecord <{+kafka_api_docs_base+}javadoc/org/apache/kafka/connect/source/SourceRecord.html>`__.
       |
       | To learn more about Avro schema, see :ref:`Avro <data-formats-avro>` in the 
         :ref:`Data Formats guide <kafka-data-formats>`.
       |
       | **Default**:

       .. code-block:: json

          {
            "type": "record",
            "name": "keySchema",
            "fields" : [ { "name": "_id", "type": "string" } ]"
          }

       | **Accepted Values**: A valid Avro schema

   * - | **output.schema.value**
     - | **Type:** string
       |
       | **Description:**
       | Specifies an Avro schema definition for the value document of the
         `SourceRecord <{+kafka_api_docs_base+}javadoc/org/apache/kafka/connect/source/SourceRecord.html>`__.
       |
       | To learn more about Avro schema, see :ref:`Avro <data-formats-avro>` in the 
         :ref:`Data Formats guide <kafka-data-formats>`.
       |
       | **Default**:

       .. code-block:: json

          {
            "name": "ChangeStream",
            "type": "record",
            "fields": [
              { "name": "_id", "type": "string" },
              { "name": "operationType", "type": ["string", "null"] },
              { "name": "fullDocument", "type": ["string", "null"] },
              { "name": "ns",
                "type": [{"name": "ns", "type": "record", "fields": [
                          {"name": "db", "type": "string"},
                          {"name": "coll", "type": ["string", "null"] } ]
                         }, "null" ] },
              { "name": "to",
                "type": [{"name": "to", "type": "record",  "fields": [
                          {"name": "db", "type": "string"},
                          {"name": "coll", "type": ["string", "null"] } ]
                         }, "null" ] },
              { "name": "documentKey", "type": ["string", "null"] },
              { "name": "updateDescription",
                "type": [{"name": "updateDescription",  "type": "record", "fields": [
                           {"name": "updatedFields", "type": ["string", "null"]},
                           {"name": "removedFields",
                            "type": [{"type": "array", "items": "string"}, "null"]
                            }] }, "null"] },
              { "name": "clusterTime", "type": ["string", "null"] },
              { "name": "txnNumber", "type": ["long", "null"]},
              { "name": "lsid", "type": [{"name": "lsid", "type": "record",
                         "fields": [ {"name": "id", "type": "string"},
                                       {"name": "uid", "type": "string"}] }, "null"] }
            ]
          }

       | **Accepted Values**: A valid JSON schema

   * - | **output.schema.infer.value**
     - | **Type:** boolean
       |
       | **Description:**
       | Whether the connector should infer the schema for the value
         document of the `SourceRecord <{+kafka_api_docs_base+}javadoc/org/apache/kafka/connect/source/SourceRecord.html>`__.
         Since the connector processes each document in isolation, the
         connector may generate many schemas.
       |
       | :gold:`IMPORTANT:` The connector only reads this setting when you set your
         ``output.format.value`` setting to ``schema``.
       |
       | **Default**: ``false``
       | **Accepted Values**: ``true`` or ``false``

.. _source-configuration-output-format-table-end:
