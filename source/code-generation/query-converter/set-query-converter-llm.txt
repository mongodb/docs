.. _rm-query-converter-set-llm:

============================================================
Set the Query Converter AI Provider and Large Language Model
============================================================

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

:ref:`Query Converter <rm-query-converter>` generates application code as a
starting point for migrating an application from its original database
into MongoDB. Query Converter uses Generative AI (GenAI). For more information 
on how MongoDB uses GenAI, see :ref:`rm-ai-and-data-usage` and the 
`Generative AI FAQ <https://dochub.mongodb.org/core/faq-ai-features>`__ 

Changing the LLM
----------------

You can configure Query Converter to use a customer-hosted Large Language Model
(LLM) instead of using the default GPT-4o model on the `Azure OpenAI 
service <https://azure.microsoft.com/en-us/products/ai-services/openai-service>`__. 
When configured to use a locally-hosted LLM service, Relational Migrator 
doesn't require internet access for query conversion.

Before You Begin
----------------

- Review the list of :ref:`supported providers and models <rm-supported-llms>`.
- Configure your AI provider.
  This can include configuring access to the service, creating an API key or
  access credentials for Query Converter, or provisioning other resources.
  See your AI provider's documentation for details.

Steps
-----

.. procedure::
   :style: normal

   .. step:: Stop the Relational Migrator executable or service.

   .. step:: Open the configuration file.

      This file is located at:

      .. include:: /includes/fact-user-properties-location.rst

   .. step:: Configure Relational Migrator for your LLM.

      Add or set the following ``migrator.queryconversion.llm.options``. If 
      you're changing your LLM configuration, remove any that aren't used for 
      the new LLM.

      .. tabs::

         .. tab:: Azure OpenAI
            :tabid: llm-settings-azure-openai

            With `Azure OpenAI
            <https://azure.microsoft.com/en-us/products/ai-services/openai-service>`__,
            Query Converter supports the `GPT-4o
            <https://platform.openai.com/docs/models#gpt-4o>`__ and `GPT-4
            <https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4>`__
            models.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: AzureOpenAI
               migrator.queryconversion.llm.options.apiKey: <API key>
               migrator.queryconversion.llm.options.apiVersion: 2024-10-21
               migrator.queryconversion.llm.options.deployment: myDeployment
               migrator.queryconversion.llm.options.baseUrl: https://my-test-endpoint.openai.azure.com/
               migrator.queryconversion.llm.options.model: gpt-4o

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``AzureOpenAI``

               * - ``migrator.queryconversion.llm.options.apiKey``
                 - Your Azure OpenAI API key.

               * - ``migrator.queryconversion.llm.options.apiVersion``
                 - The Azure OpenAI API version, in the format ``YYYY-MM-DD``.

               * - ``migrator.queryconversion.llm.options.deployment``
                 - The Azure OpenAI deployment name, found in the **Model
                   Deployments** page of the Azure portal.

               * - ``migrator.queryconversion.llm.options.baseUrl``
                 - The Azure OpenAI endpoint, found in the **Keys and
                   Endpoint** section in the Azure portal.

               * - ``migrator.queryconversion.llm.options.model``
                 - ``gpt-4`` or ``gpt-4o``

            For more information, see the `Azure OpenAI documentation <https://learn.microsoft.com/en-us/azure/ai-services/openai/>`__.



         .. tab:: OpenAI
            :tabid: llm-settings-openai

            With `OpenAI <https://platform.openai.com/docs/overview>`__, Query
            Converter supports the `GPT-4o
            <https://platform.openai.com/docs/models#gpt-4o>`__ and `GPT-4
            <https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4>`__
            models.

            **Example** 

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: OpenAI
               migrator.queryconversion.llm.options.apiKey: <API key>
               migrator.queryconversion.llm.options.baseUrl: https://api.openai.com/v1
               migrator.queryconversion.llm.options.model: gpt-4

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``OpenAI``

               * - ``migrator.queryconversion.llm.options.apiKey``
                 - Your OpenAI API key, generated in the `OpenAI dashboard <https://platform.openai.com/api-keys>`__.

               * - ``migrator.queryconversion.llm.options.baseUrl``
                 - ``https://api.openai.com/v1``

               * - ``migrator.queryconversion.llm.options.model``
                 - ``gpt-4`` or ``gpt-4o``

            For more information, see the `OpenAI documentation
            <https://platform.openai.com/docs/overview>`__.



         .. tab:: Amazon Bedrock
            :tabid: llm-settings-aws-bedrock

            With `Amazon Bedrock <https://aws.amazon.com/bedrock/>`__, Query Converter supports the `Claude 3.5 (Sonnet)
            <https://docs.anthropic.com/en/api/claude-on-amazon-bedrock>`__ and
            `Mistral Large <https://docs.mistral.ai/deployment/cloud/aws/>`__
            models.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: AWSBedrock
               migrator.queryconversion.llm.options.awsAccessKeyId: <Access key>
               migrator.queryconversion.llm.options.awsSecretAccessKey: <Secret key>
               migrator.queryconversion.llm.options.regionName: us-east-1
               migrator.queryconversion.llm.options.modelId: anthropic.claude-3-5-sonnet-20241022-v2:0

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``AWSBedrock``

               * - ``migrator.queryconversion.llm.options.awsAccessKeyId``
                 - The ID for an `AWS access key <https://docs.aws.amazon.com/kms/latest/developerguide/overview.html>`__
                   associated with an IAM account.

               * - ``migrator.queryconversion.llm.options.awsSecretAccessKey``
                 - The AWS access key for the account.

               * - ``migrator.queryconversion.llm.options.regionName``
                 - The `regional endpoint <https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints>`__ 
                   where the model is deployed.

               * - ``migrator.queryconversion.llm.options.modelId``
                 - ``anthropic.claude-3-5-sonnet-20241022-v2:0`` or ``mistral.mistral-large-2407-v1:0``

            For more information, see the `Amazon Bedrock documentation
            <https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html>`__,
            or the model-specific documentation from `Anthropic
            <https://docs.anthropic.com/en/api/claude-on-amazon-bedrock>`__ or
            `Mistral <https://docs.mistral.ai/deployment/cloud/aws/>`__. 


         .. tab:: GCP Vertex AI
            :tabid: llm-settings-gcp-vertex

            With `GCP Vertex AI <https://cloud.google.com/vertex-ai>`__, Query Converter supports the `Gemini 1.5 Pro
            <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`__
            model.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.llm.options.provider: GCPVertex
               migrator.queryconversion.llm.options.apiKey: <API key>
               migrator.queryconversion.llm.options.model: gemini-1.5-pro-001

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.llm.options.provider``
                 - ``GCPVertex``

               * - ``migrator.queryconversion.llm.options.apiKey``
                 - Leave unset. Instead, set your `Application Default
                   Credentials
                   <https://cloud.google.com/docs/authentication/provide-credentials-adc>`__
                   with GCP through one of the other provided mechanisms.

               * - ``migrator.queryconversion.llm.options.model``
                 - ``gemini-1.5-pro-001`` or ``gemini-1.5-pro-002``

            For more information, see the `Google Vertex AI documentation
            <https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal>`__.



         .. tab:: Self-Managed
            :tabid: llm-settings-self-managed

            With self-managed local or Cloud deployments, Query Converter supports the `Llama 3.1 405B <https://www.llama.com/docs/getting_the_models>`__
            model.

            **Example**

            .. code-block:: javascript
               :copyable: true

               migrator.queryconversion.server.address: http://127.0.0.1:6081
               migrator.queryconversion.llm.options.model: Llama-3.1-405B

            **Configuration**

            .. list-table::
               header-rows: 1

               * - Field
                 - Value

               * - ``migrator.queryconversion.server.address``
                 - For local deployments, the IP address of the Query Converter endpoint.

               * - ``migrator.queryconversion.llm.options.model``
                 - ``Llama-3.1-405B``

   
   .. step:: Save and close the file, and restart Relational Migrator.

.. important::

   Test Query Converter output to verify that code quality meets your
   expectations. LLM Output varies widely between models. Code quality can
   further vary within the same model depending on the language, design
   patterns, and other factors.

Next Steps
----------

* If you haven't already, :ref:`enable Query Converter
  <rm-enable-query-converter>`.