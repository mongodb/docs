.. _adl-out-stage:

========
``$out``
========

.. default-domain:: mongodb

.. include:: /includes/fact-data-lake-beta.rst

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

``$out`` takes documents returned by the aggregation pipeline and writes them 
to a specified collection. The :manual:`$out 
</reference/operator/aggregation/out/#pipe._S_out>` operator must be the last 
stage in the :manual:`aggregation pipeline 
</reference/operator/aggregation-pipeline/>`. For more information, see 
:manual:`$out </reference/operator/aggregation/out/>`. In {+adl+}, ``$out`` can 
be used to write to |s3| buckets with read and write permissions.

.. _adl-out-stage-perms:

Permissions Required 
--------------------

You must have: 

- A {+dl+} configured for |s3| bucket with read and write permissions or 
  `s3::PutObject 
  <https://docs.aws.amazon.com/AmazonS3/latest/dev/using-with-s3-actions.html#using-with-s3-actions-related-to-objects>`__ permissions.
- A MongoDB user with :atlas:`readWriteAnyDatabase 
  </security-add-mongodb-users/#readWriteAnyDatabase>` role. 

.. _adl-out-stage-syntax:

Syntax 
------

.. code-block:: json 

   {
     $out: { 			
       s3: { 
         bucket: "<bucket-name>",
         region: "<aws-region>",
         filename: "<file-name>",
         format: { 
           name: "json|json.gz|bson|bson.gz", 
           maxFileSize: "<file-size>"
         } 
       } 
     }
   }

.. _adl-out-stage-fields:

Fields 
------

.. list-table::
   :header-rows: 1
   :widths: 10 10 70 10

   * - Field 
     - Type 
     - Description 
     - Necessity

   * - ``s3``
     - object
     - The location to write the documents from the aggregation pipeline.
     - Required

   * - ``s3.bucket``
     - string
     - The name of the |s3| bucket to write the documents from the 
       aggregation pipeline to.
     - Required

   * - ``s3.region``
     - string 
     - The name of the |aws| region in which the bucket is hosted.
     - Required

   * - ``s3.filename``
     - string
     - The name of the file to write the documents from the aggregation 
       pipeline to. Filename can be constant or created dynamically from 
       the fields in the documents that reach the ``$out`` stage. Filename 
       must be of type string.
     - Required

   * - ``s3.format``
     - object 
     - The details of the file in |s3|.
     - Required

   * - ``s3.format.name``
     - enum
     - The format of the file in |s3|. Value can be one of the following: 

       - ``json`` 
       - ``json.gz``
       - ``bson`` 
       - ``bson.gz``

     - Required

   * - ``s3.format.maxFileSize``
     - bytes
     - The maximum size of the file in |s3|. When the file size limit is 
       reached, a new file is created in |s3|. For each additional file, 
       an incremental number is appended to the filename. For example: 
       ``<filename>.1.<fileformat>``, ``<filename>.2.<fileformat>``. If a 
       document is larger than the ``maxFileSize``, {+dl+} writes the 
       document to its own file. The following suffixes are supported: 

       - ``B``, ``KB``, ``MB``, ``GB``, ``TB``, ``PB`` - suffixes that use 
         1000 bytes
       - ``KiB``, ``MiB``, ``GiB``, ``TiB``, ``PiB`` - suffixes that use 
         1024 bytes

       If omitted, defaults to ``200MiB``.

     - Optional

.. _adl-out-stage-egs:

Examples 
--------

The following examples show ``$out`` syntaxes for creating a filename from 
a constant string or from the fields of the same or different data types in 
the documents that reach the ``$out`` stage.

Simple String Example 
~~~~~~~~~~~~~~~~~~~~~

Consider the following ``$out`` syntax: 

.. code-block:: json 

   { 
     $out: { 
       s3: { 
         bucket: "my-s3-bucket",
         region: "us-east-1",
         filename: "big_box_store/",  
         format: { 
           name: "bson.gz" 
         } 
       } 
     }
   }

For the above example, ``$out`` operation writes up to 200 MiB of data, 
which is the default file size, to a compressed |bson| file named 
``big_box_store.bson.gz`` in the bucket named ``my-s3-bucket``. Once 
the maximum file size of 200 MiB is reached, the ``$out`` operation 
creates a new file by appending an incremental number to the constant 
filename. That is, ``big_box_store.1.bson.gz``, 
``big_box_store.2.bson.gz``, and so on.

Single Field from Documents 
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Consider the following ``$out`` syntax: 

.. code-block:: json 

   { 
     $out: { 
       s3: { 
         bucket: "my-s3-bucket",
         region: "us-east-1",
         filename: {$toString($sale-date)},  
         format: { 
           name: "json", 
           maxFileSize: "100MiB"
         } 
       } 
     }
   } 

For the above example, ``$out`` writes up to 100 MiB of data to a |json| 
file in the root of the bucket named ``my-s3-bucket``. The filename is the 
value of the date type field named ``sale-date`` from the documents and is 
converted to a string.

Multiple Fields from Documents 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Consider the following ``$out`` syntax: 

.. code-block:: json 

   { 
     $out: { 
       s3: { 
         bucket: "my-s3-bucket",
         region: "us-east-1",
         filename: {
           $concat: [  
             "persons/", 
             $name, ‘/’, 
             $unique-id  
           ]
         }, 
         format: { 
           name: "bson", 
           maxFileSize: "200MiB"
         } 
       } 
     }
   } 

For the above example, ``$out`` operation writes up to 200 MiB of data to 
a |bson| file in the bucket named ``my-s3-bucket``. The filename is a 
combination of a constant string named ``persons`` and the value of the 
fields named ``name`` and ``unique-id`` of type string from the documents.

Multiple Types of Fields from Documents 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Consider the following ``$out`` syntax: 

.. code-block:: json 

   { 
     $out: { 
       s3: { 
         bucket: "my-s3-bucket",
         region: "us-east-1",
         filename: {
           $concat: [  
             "big-box-store/", 
             {$toString($store_number)}, '/', 
             {$toString($sale-date)}, '/', 
             $part-id
           ]
         }, 
         format: { 
           name: "json.gz", 
           maxFileSize: "200MiB"
         } 
       } 
     }
   } 

For the above example, ``$out`` operation writes up to 200 MiB of data to 
a compressed |json| file in the bucket named ``my-s3-bucket``. The filename 
is a combination of the following: 

- A constant string named ``big-box-store``
- A unique store number in the field named ``store-number`` that is converted 
  to a string
- The value of the date type field named ``sale-date`` that is converted to a 
  string
- A part ID in the field named ``part-id`` that is already a string 

.. _adl-out-stage-limitations:

Limitations 
-----------

{+dl+} interprets empty strings (``""``) as null values when parsing 
filenames. If you want {+dl+} to generate filenames that it can parse 
correctly, you must wrap the field references that could have null values 
using :manual:`$convert </reference/operator/aggregation/convert>` with 
an empty string ``onNull`` value. The following example shows how to handle 
null values in the ``year`` field when creating a filename from the field 
value.

.. code-block:: json 
   :copyable: false 

   { 
     $out: { 
       s3: { 
         bucket: "my-s3-bucket",
         region: "us-east-1",
         filename: {
           $concat: [  
             "big-box-store/", 
             {$convert: {input: "year", to: "string", onNull: ""}}
           ]
         }, 
         format: { 
           name: "json.gz", 
           maxFileSize: "200MiB"
         } 
       } 
     }
   }

.. _adl-out-stage-errors:

Errors 
------

- If the filename is not of type string, {+dl+} writes documents to a special 
  error file in your bucket.
- If the documents cannot be written to a file with the specified filename, 
  {+dl+} writes documents to ordinally-named files in the specified format and 
  specified size. For example:

  - ``s3://<bucket-name>/atlas-data-lake-{<CORRELATION_ID>}/$out-error-docs/1.json``
  - ``s3://<bucket-name>/atlas-data-lake-{<CORRELATION_ID>}/$out-error-docs/2.json``

  {+dl+} returns an error message that specifies the number of documents that 
  had invalid filenames and the directory where these documents were written.
