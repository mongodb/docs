.. _langchain:

==========================================
Get Started with the LangChain Integration
==========================================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: tutorial

.. facet::
   :name: programming_language
   :values: python

.. meta::
   :description: Integrate Atlas Vector Search with LangChain to build LLM and RAG applications.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. note::

   This tutorial uses LangChain's `Python library 
   <https://python.langchain.com/docs/get_started/introduction>`__. 
   For a tutorial that uses the JavaScript library, see :ref:`langchain-js`.

You can integrate {+avs+} with `LangChain <https://langchain.com/>`__
to build |llm| applications and implement 
retrieval-augmented generation (RAG). This tutorial demonstrates
how to start using {+avs+} with LangChain to perform
semantic search on your data and build a |rag| implementation. 
Specifically, you perform the following actions:

#. Set up the environment.
#. Store custom data on |service|.
#. Create an {+avs+} index on your data.
#. Run the following vector search queries:

   - Semantic search.
   - Semantic search with score.
   - Semantic search with metadata pre-filtering.

#. Implement |rag| by using {+avs+} to answer questions on your data.

Background
----------

.. include:: /includes/ai-integrations/langchain/langchain-background.rst

Prerequisites
-------------

To complete this tutorial, you must have the following:

- An |service| {+cluster+} running MongoDB version 6.0.11, 7.0.2, or later
  (including :abbr:`RCs (Release Candidates)`).

- An OpenAI API Key. You must have a paid OpenAI account with credits
  available for API requests.

- A notebook to run your Python project such as `Colab <https://colab.research.google.com>`__.

Set Up the Environment
----------------------

First, set up the environment for this tutorial by copying 
and pasting the following code snippets into your notebook.

.. include:: /includes/ai-integrations/langchain/langchain-set-up-environment.rst

Use |service| as a Vector Store
-------------------------------

Then, load custom data into |service| and instantiate |service| as 
a vector database, also called a `vector store 
<https://python.langchain.com/docs/modules/data_connection/vectorstores/>`__.
Copy and paste the following code snippets into your notebook.

.. include:: /includes/ai-integrations/langchain/langchain-create-vector-store.rst

.. _langchain-create-index:

Create the {+avs+} Index
------------------------------------

To enable vector search queries on your vector store,
create an {+avs+} index on the ``langchain_db.test`` collection.

Required Access
~~~~~~~~~~~~~~~

To create an {+avs+} index, you must have :authrole:`Project Data Access 
Admin` or higher access to the |service| project.

Procedure 
~~~~~~~~~

.. include:: /includes/ai-integrations/langchain/langchain-create-index.rst

Run Vector Search Queries
-------------------------

Once |service| builds your index, return 
to your notebook and run vector search queries on your data. 
The following examples demonstrate various queries that you can 
run on your vectorized data.

.. include:: /includes/ai-integrations/langchain/langchain-query-examples.rst

.. seealso::

   For a full list of semantic search methods, refer to 
   the `API reference 
   <https://api.python.langchain.com/en/latest/vectorstores/langchain_mongodb.vectorstores.MongoDBAtlasVectorSearch.html>`__.

Answer Questions on Your Data
-----------------------------

This section demonstrates how to implement |rag| in your 
application with {+avs+} and LangChain. Now that you've used {+avs+} 
to retrieve semantically similar documents, run the following code examples 
to prompt the |llm| to answer questions based on those documents.

.. include:: /includes/ai-integrations/langchain/langchain-perform-qa.rst
  
Next Steps
----------

To learn about additional |rag| use-cases with {+avs+}, 
see the following templates provided by LangChain to help you build applications:

- :github:`Basic RAG with MongoDB and OpenAI </langchain-ai/langchain/tree/master/templates/rag-mongo>`
- :github:`Advanced RAG: Parent-Document Retrieval </langchain-ai/langchain/tree/master/templates/mongo-parent-document-retrieval>`

MongoDB also provides the following developer resources:

- `Introduction to LangChain and MongoDB Atlas Vector Search 
  <https://www.mongodb.com/developer/products/mongodb/langchain-vector-search/>`__
- `RAG with Atlas Vector Search, LangChain, and OpenAI 
  <https://www.mongodb.com/developer/products/atlas/rag-atlas-vector-search-langchain-openai>`__
- `Leveraging MongoDB Atlas Vector Search with LangChain 
  <https://www.mongodb.com/developer/products/atlas/leveraging-mongodb-atlas-vector-search-langchain/>`__
- :github:`MongoDB Developer GitHub Repository </mongodb-developer>`

.. seealso:: 

   - `LangChain Documentation <https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas>`__
   - `LangChain API Reference <https://api.python.langchain.com/en/latest/mongodb_api_reference.html>`__
