.. _streaming-mode:

==============
Streaming Mode
==============

.. meta::
   :description: Explore how to use the Spark Connector for reading and writing data in streaming mode with Spark Structured Streaming.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. toctree::

   Read </streaming-mode/streaming-read>
   Write </streaming-mode/streaming-write>

Overview
--------

The {+connector-short+} supports streaming mode, which uses Spark Structured Streaming
to process data as soon as it's available instead of waiting for a time interval to pass.
Spark Structured Streaming is a data-stream-processing engine that you can access by using
the Dataset or DataFrame API. 

.. include:: includes/streaming-distinction.rst

The following sections show you how to use the {+connector-short+} to read data from
MongoDB and write data to MongoDB in streaming mode:

- :ref:`streaming-read-from-mongodb`
- :ref:`streaming-write-to-mongodb`

.. tip:: Apache Spark Documentation

   To learn more about using Spark to process streams of data, see the 
   `Spark Programming Guide
   <https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html>`__.
