========================================
Getting Started with the {+connector-short+}
========================================

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. facet::
   :name: genre
   :values: tutorial

.. meta::
   :keywords: quick start, tutorial, code example
   :description: Get started with the Spark Connector by setting up dependencies, configuring connections, and integrating with platforms like Amazon EMR, Databricks, Docker, and Kubernetes.

Prerequisites
-------------

.. include:: /includes/list-prerequisites.rst

.. _pyspark-shell:
.. _scala-getting-started:
.. _python-basics:

Getting Started
---------------

.. tabs-drivers::

   tabs:
     - id: java-sync
       content: |

         .. include:: /java/api.rst

     - id: python
       content: |

         .. include:: /python/api.rst

     - id: scala
       content: |

         .. include:: /scala/api.rst

Integrations
------------

The following sections describe some popular third-party platforms that you can
integrate Spark and the {+connector-long+} with.

Amazon EMR
~~~~~~~~~~

Amazon EMR is a managed cluster platform that you can use to run big data frameworks like Spark. To install Spark on an EMR cluster, see
`Getting Started with Amazon EMR <https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html>`__ in the AWS documentation.

Databricks
~~~~~~~~~~

Databricks is an analytics platform for building, deploying, and sharing enterprise-level data. To integrate the {+connector-long+} with Databricks,
see `MongoDB <https://docs.databricks.com/aws/en/connect/external-systems/mongodb>`__ in the Databricks documentation.

Docker
~~~~~~

Docker is an open-source platform that helps developers build, share, and run applications in containers. 

- To start Spark in a Docker container, see `Apache Spark <https://hub.docker.com/r/apache/spark#!>`__ in the Docker documentation and follow the steps provided. 
- To learn how to deploy Atlas on Docker, see `Create a Local Atlas Deployment with Docker <https://www.mongodb.com/docs/atlas/cli/current/atlas-cli-deploy-docker/>`__.

Kubernetes
~~~~~~~~~~

Kubernetes is an open-source platform for automating containerization management. To run Spark on Kubernetes,
see `Running Spark on Kubernetes <https://spark.apache.org/docs/3.5.4/running-on-kubernetes.html>`__ in the Spark documentation.

Tutorials
---------

- :ref:`batch-write-to-mongodb`
- :ref:`batch-read-from-mongodb`
- :ref:`streaming-write-to-mongodb`
- :ref:`streaming-read-from-mongodb`

