# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008-2019
# This file is distributed under the same license as the mongodb-manual package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: mongodb-manual 3.6\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-03-19 11:30-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/faq/diagnostics.txt:5
msgid "FAQ: MongoDB Diagnostics"
msgstr ""

#: ../source/faq/diagnostics.txt:15
msgid "This document provides answers to common diagnostic questions and issues."
msgstr ""

#: ../source/faq/diagnostics.txt:18
msgid "If you don't find the answer you're looking for, check the :doc:`complete list of FAQs </faq>` or post your question to the `MongoDB User Mailing List <https://groups.google.com/forum/?fromgroups#!forum/mongodb-user>`_."
msgstr ""

#: ../source/faq/diagnostics.txt:23
msgid "Where can I find information about a ``mongod`` process that stopped running unexpectedly?"
msgstr ""

#: ../source/faq/diagnostics.txt:25
msgid "If :binary:`~bin.mongod` shuts down unexpectedly on a UNIX or UNIX-based platform, and if :binary:`~bin.mongod` fails to log a shutdown or error message, then check your system logs for messages pertaining to MongoDB. For example, for logs located in ``/var/log/messages``, use the following commands:"
msgstr ""

#: ../source/faq/diagnostics.txt:39
msgid "Does TCP ``keepalive`` time affect MongoDB Deployments?"
msgstr ""

#: ../source/faq/diagnostics.txt:41
msgid "If you experience socket errors between clients and servers or between members of a sharded cluster or replica set that do not have other reasonable causes, check the TCP keepalive value (for example, the ``tcp_keepalive_time`` value on Linux systems). A common keepalive period is ``7200`` seconds (2 hours); however, different distributions and macOS may have different settings."
msgstr ""

#: ../source/faq/diagnostics.txt:48
msgid "For MongoDB, you will have better results with shorter keepalive periods, on the order of ``120`` seconds (two minutes)."
msgstr ""

#: ../source/faq/diagnostics.txt:51
msgid "If your MongoDB deployment experiences keepalive-related issues, you must alter the keep alive value on *all* machines hosting MongoDB processes. This includes all machines hosting :binary:`~bin.mongos` or :binary:`~bin.mongod` processes and all machines hosting client processes that connect to MongoDB."
msgstr ""

#: ../source/faq/diagnostics.txt:59
msgid "For non-Linux systems, values greater than or equal to 600 seconds (10 minutes) will be ignored by :binary:`~bin.mongod` and :binary:`~bin.mongos`. For Linux, values greater than 300 seconds (5 minutes) will be overridden on the :binary:`~bin.mongod` and :binary:`~bin.mongos` sockets with a maximum of 300 seconds."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:1
msgid "**On Linux systems**:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:3
msgid "To view the keep alive setting, you can use one of the following commands:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:10
#: ../source/includes/fact-tcp-keepalive-linux.rst:30
msgid "Or:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:16
msgid "The value is measured in seconds."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:20
msgid "Although the path includes ``ipv4``, the ``tcp_keepalive_time`` value applies to both IPv4 and IPv6."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:23
msgid "To change the ``tcp_keepalive_time`` value, you can use one of the following command:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:36
msgid "These operations do not persist across system reboots. To persist the setting, add the following line to ``/etc/sysctl.conf``:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:43
msgid "On Linux, :binary:`~bin.mongod` and :binary:`~bin.mongos` processes limit the keepalive to a maximum of 300 seconds (5 minutes) on their own sockets by overriding keepalive values greater than 5 minutes."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:1
msgid "**For macOS systems**:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:3
#: ../source/includes/fact-tcp-keepalive-windows.rst:3
msgid "To view the keep alive setting, issue the following command:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:9
msgid "To change the ``net.inet.tcp.keepinit`` value, you can use the following command:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:16
msgid "The above method for setting the TCP keepalive is not persistent; you will need to reset the value each time you reboot or restart a system. See your operating systemâ€™s documentation for instructions on setting the TCP keepalive value persistently."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:1
msgid "**For Windows systems**:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:9
msgid "The registry value is not present by default. The system default, used if the value is absent, is 7200000 *milliseconds* or ``0x6ddd00`` in hexadecimal."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:13
msgid "To change the ``KeepAliveTime`` value, use the following command in an Administrator :guilabel:`Command Prompt`, where ``<value>`` is expressed in hexadecimal (e.g. 120000 is ``0x1d4c0``):"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:21
msgid "Windows users should consider the `Windows Server Technet Article on KeepAliveTime <https://technet.microsoft.com/en-us/library/cc957549.aspx>`_ for more information on setting keep alive for MongoDB deployments on Windows systems."
msgstr ""

#: ../source/faq/diagnostics.txt:71
msgid "You will need to restart :binary:`~bin.mongod` and :binary:`~bin.mongos` processes for new system-wide keepalive settings to take effect."
msgstr ""

#: ../source/faq/diagnostics.txt:75
msgid "Why does MongoDB log so many \"Connection Accepted\" events?"
msgstr ""

#: ../source/faq/diagnostics.txt:77
msgid "If you see a very large number connection and re-connection messages in your MongoDB log, then clients are frequently connecting and disconnecting to the MongoDB server. This is normal behavior for applications that do not use request pooling, such as CGI. Consider using FastCGI, an Apache Module, or some other kind of persistent application server to decrease the connection overhead."
msgstr ""

#: ../source/faq/diagnostics.txt:84
msgid "If these connections do not impact your performance you can use the run-time :setting:`~systemLog.quiet` option or the command-line option :option:`--quiet <mongod --quiet>` to suppress these messages from the log."
msgstr ""

#: ../source/faq/diagnostics.txt:90
msgid "What tools are available for monitoring MongoDB?"
msgstr ""

#: ../source/faq/diagnostics.txt:92
msgid "The |mms-home| and :products:`Ops Manager, an on-premise solution available in MongoDB Enterprise Advanced </mongodb-enterprise-advanced?jmp=docs>` include monitoring functionality, which collects data from running MongoDB deployments and provides visualization and alerts based on that data."
msgstr ""

#: ../source/faq/diagnostics.txt:98
msgid "For more information, see also the |mms-docs| and :opsmgr:`Ops Manager documentation </application>`."
msgstr ""

#: ../source/faq/diagnostics.txt:101
msgid "A full list of third-party tools is available as part of the :doc:`/administration/monitoring/` documentation."
msgstr ""

#: ../source/faq/diagnostics.txt:109
msgid "Memory Diagnostics for the MMAPv1 Storage Engine"
msgstr ""

#: ../source/faq/diagnostics.txt:112
msgid "Do I need to configure swap space?"
msgstr ""

#: ../source/faq/diagnostics.txt:114
msgid "Always configure systems to have swap space. Without swap, your system may not be reliant in some situations with extreme memory constraints, memory leaks, or multiple programs using the same memory.  Think of the swap space as something like a steam release valve that allows the system to release extra pressure without affecting the overall functioning of the system."
msgstr ""

#: ../source/faq/diagnostics.txt:121
msgid "Nevertheless, systems running MongoDB *do not* need swap for routine operation. Database files are :ref:`memory-mapped <faq-storage-memory-mapped-files>` and should constitute most of your MongoDB memory use. Therefore, it is unlikely that :binary:`~bin.mongod` will ever use any swap space in normal operation. The operating system will release memory from the memory mapped files without needing swap and MongoDB can write data to the data files without needing the swap system."
msgstr ""

#: ../source/faq/diagnostics.txt:133
msgid "What is a \"working set\"?"
msgstr ""

#: ../source/faq/diagnostics.txt:135
msgid "The *working set* is the portion of your data that clients access most often."
msgstr ""

#: ../source/faq/diagnostics.txt:139
#: ../source/faq/diagnostics.txt:214
msgid "Must my working set size fit RAM?"
msgstr ""

#: ../source/faq/diagnostics.txt:141
msgid "Your working set should stay in memory to achieve good performance. Otherwise many random disk IO's will occur, and unless you are using SSD, this can be quite slow."
msgstr ""

#: ../source/faq/diagnostics.txt:145
msgid "One area to watch specifically in managing the size of your working set is index access patterns. If you are inserting into indexes at random locations (as would happen with id's that are randomly generated by hashes), you will continually be updating the whole index. If instead you are able to create your id's in approximately ascending order (for example, day concatenated with a random id), all the updates will occur at the right side of the b-tree and the working set size for index pages will be much smaller."
msgstr ""

#: ../source/faq/diagnostics.txt:154
msgid "It is fine if databases and thus virtual size are much larger than RAM."
msgstr ""

#: ../source/faq/diagnostics.txt:157
#: ../source/faq/diagnostics.txt:221
msgid "How do I calculate how much RAM I need for my application?"
msgstr ""

#: ../source/faq/diagnostics.txt:161
msgid "The amount of RAM you need depends on several factors, including but not limited to:"
msgstr ""

#: ../source/faq/diagnostics.txt:164
msgid "The relationship between :doc:`database storage </faq/storage>` and working set."
msgstr ""

#: ../source/faq/diagnostics.txt:166
msgid "The operating system's cache strategy for LRU (Least Recently Used)"
msgstr ""

#: ../source/faq/diagnostics.txt:168
msgid "The impact of :doc:`journaling </core/journaling>`"
msgstr ""

#: ../source/faq/diagnostics.txt:170
msgid "The number or rate of page faults and other |MMS| gauges to detect when you need more RAM"
msgstr ""

#: ../source/faq/diagnostics.txt:173
msgid "Each database connection thread will need up to 1 MB of RAM."
msgstr ""

#: ../source/faq/diagnostics.txt:175
msgid "MongoDB defers to the operating system when loading data into memory from disk. It simply :ref:`memory maps <faq-storage-memory-mapped-files>` all its data files and relies on the operating system to cache data. The OS typically evicts the least-recently-used data from RAM when it runs low on memory. For example if clients access  indexes more frequently than documents, then indexes will more likely stay in RAM, but it depends on your particular usage."
msgstr ""

#: ../source/faq/diagnostics.txt:183
msgid "To calculate how much RAM you need, you must calculate your working set size, or the portion of your data that clients use most often. This depends on your access patterns, what indexes you have, and the size of your documents. Because MongoDB uses a thread per connection model, each database connection also will need up to 1 MB of RAM, whether active or idle."
msgstr ""

#: ../source/faq/diagnostics.txt:189
msgid "If page faults are infrequent, your working set fits in RAM. If fault rates rise higher than that, you risk performance degradation. This is less critical with SSD drives than with spinning disks."
msgstr ""

#: ../source/faq/diagnostics.txt:195
msgid "How do I read memory statistics in the UNIX ``top`` command"
msgstr ""

#: ../source/faq/diagnostics.txt:197
msgid "Because :binary:`~bin.mongod` uses :ref:`memory-mapped files <faq-storage-memory-mapped-files>`, the memory statistics in ``top`` require interpretation in a special way. On a large database, ``VSIZE`` (virtual bytes) tends to be the size of the entire database. If the :binary:`~bin.mongod` doesn't have other processes running, ``RSIZE`` (resident bytes) is the total memory of the machine, as this counts file system cache contents."
msgstr ""

#: ../source/faq/diagnostics.txt:205
msgid "For Linux systems, use the ``vmstat`` command to help determine how the system uses memory. On macOS systems use ``vm_stat``."
msgstr ""

#: ../source/faq/diagnostics.txt:211
msgid "Memory Diagnostics for the WiredTiger Storage Engine"
msgstr ""

#: ../source/faq/diagnostics.txt:216
msgid "No."
msgstr ""

#: ../source/includes/extracts/wt-cache-eviction.rst:1
msgid "If the cache does not have enough space to load additional data, WiredTiger evicts pages from the cache to free up space."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:3
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:3
msgid "The :setting:`storage.wiredTiger.engineConfig.cacheSizeGB` limits the size of the WiredTiger internal cache. The operating system will use the available free memory for filesystem cache, which allows the compressed MongoDB data files to stay in memory. In addition, the operating system will use any free RAM to buffer file system blocks and file system cache."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:10
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:10
msgid "To accommodate the additional consumers of RAM, you may have to decrease WiredTiger internal cache size."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:13
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:13
msgid "The default WiredTiger internal cache size value assumes that there is a single :binary:`~bin.mongod` instance per machine. If a single machine contains multiple MongoDB instances, then you should decrease the setting to accommodate the other :binary:`~bin.mongod` instances."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:19
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:19
msgid "If you run :binary:`~bin.mongod` in a container (e.g. ``lxc``, ``cgroups``, Docker, etc.) that does *not* have access to all of the RAM available in a system, you must set :setting:`storage.wiredTiger.engineConfig.cacheSizeGB` to a value less than the amount of RAM available in the container. The exact amount depends on the other processes running in the container."
msgstr ""

#: ../source/includes/extracts/wt-cache-size.rst:4
msgid "To see statistics on the cache and eviction, use the :dbcommand:`serverStatus` command. The :serverstatus:`wiredTiger.cache` field holds the information on the cache and eviction."
msgstr ""

#: ../source/includes/extracts/wt-cache-size.rst:49
msgid "For an explanation of some key cache and eviction statistics, such as :serverstatus:`wiredTiger.cache.bytes currently in the cache` and :serverstatus:`wiredTiger.cache.tracked dirty bytes in the cache`, see :serverstatus:`wiredTiger.cache`."
msgstr ""

#: ../source/includes/extracts/wt-cache-setting.rst:1
#: ../source/includes/extracts/wt-cache-setting.rst:1
msgid "To adjust the size of the WiredTiger internal cache, see :setting:`storage.wiredTiger.engineConfig.cacheSizeGB` and :option:`--wiredTigerCacheSizeGB <mongod --wiredTigerCacheSizeGB>`. Avoid increasing the WiredTiger internal cache size above its default value."
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:1
msgid "With WiredTiger, MongoDB utilizes both the WiredTiger internal cache and the filesystem cache."
msgstr ""

#: ../source/includes/extracts/wt-cache-default-setting.rst:2
msgid "Starting in 3.4, the WiredTiger internal cache, by default, will use the larger of either:"
msgstr ""

#: ../source/includes/extracts/wt-cache-default-setting.rst:5
msgid "50% of (RAM - 1 GB), or"
msgstr ""

#: ../source/includes/extracts/wt-cache-default-setting.rst:7
msgid "256 MB."
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:6
msgid "By default, WiredTiger uses Snappy block compression for all collections and prefix compression for all indexes. Compression defaults are configurable at a global level and can also be set on a per-collection and per-index basis during collection and index creation."
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:11
msgid "Different representations are used for data in the WiredTiger internal cache versus the on-disk format:"
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:14
msgid "Data in the filesystem cache is the same as the on-disk format, including benefits of any compression for data files. The filesystem cache is used by the operating system to reduce disk I/O."
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:17
msgid "Indexes loaded in the WiredTiger internal cache have a different data representation to the on-disk format, but can still take advantage of index prefix compression to reduce RAM usage. Index prefix compression deduplicates common prefixes from indexed fields."
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:21
msgid "Collection data in the WiredTiger internal cache is uncompressed and uses a different representation from the on-disk format. Block compression can provide significant on-disk storage savings, but data must be uncompressed to be manipulated by the server."
msgstr ""

#: ../source/includes/extracts/wt-filesystem-cache.rst:1
msgid "Via the filesystem cache, MongoDB automatically uses all free memory that is not used by the WiredTiger cache or by other processes."
msgstr ""

#: ../source/includes/extracts/wt-configure-cache.rst:7
msgid "To view statistics on the cache and eviction rate, see the :serverstatus:`wiredTiger.cache` field returned from the :dbcommand:`serverStatus` command."
msgstr ""

#: ../source/faq/diagnostics.txt:226
msgid "Sharded Cluster Diagnostics"
msgstr ""

#: ../source/faq/diagnostics.txt:228
msgid "The two most important factors in maintaining a successful sharded cluster are:"
msgstr ""

#: ../source/faq/diagnostics.txt:230
msgid ":ref:`choosing an appropriate shard key <sharding-internals-shard-keys>` and"
msgstr ""

#: ../source/faq/diagnostics.txt:232
msgid ":ref:`sufficient capacity to support current and future operations <sharding-capacity-planning>`."
msgstr ""

#: ../source/faq/diagnostics.txt:235
msgid "You can prevent most issues encountered with sharding by ensuring that you choose the best possible :term:`shard key` for your deployment and ensure that you are always adding additional capacity to your cluster well before the current resources become saturated. Continue reading for specific issues you may encounter in a production environment."
msgstr ""

#: ../source/faq/diagnostics.txt:244
msgid "In a new sharded cluster, why does all data remains on one shard?"
msgstr ""

#: ../source/faq/diagnostics.txt:246
msgid "Your cluster must have sufficient data for sharding to make sense. Sharding works by migrating chunks between the shards until each shard has roughly the same number of chunks."
msgstr ""

#: ../source/faq/diagnostics.txt:250
msgid "The default chunk size is 64 megabytes. MongoDB will not begin migrations until the imbalance of chunks in the cluster exceeds the :ref:`migration threshold <sharding-migration-thresholds>`. This behavior helps prevent unnecessary chunk migrations, which can degrade the performance of your cluster as a whole."
msgstr ""

#: ../source/faq/diagnostics.txt:256
msgid "If you have just deployed a sharded cluster, make sure that you have enough data to make sharding effective. If you do not have sufficient data to create more than eight 64 megabyte chunks, then all data will remain on one shard. Either lower the :ref:`chunk size <sharding-chunk-size>` setting, or add more data to the cluster."
msgstr ""

#: ../source/faq/diagnostics.txt:262
msgid "As a related problem, the system will split chunks only on inserts or updates, which means that if you configure sharding and do not continue to issue insert and update operations, the database will not create any chunks. You can either wait until your application inserts data *or* :doc:`split chunks manually </tutorial/split-chunks-in-sharded-cluster>`."
msgstr ""

#: ../source/faq/diagnostics.txt:268
msgid "Finally, if your shard key has a low :ref:`cardinality <sharding-shard-key-cardinality>`, MongoDB may not be able to create sufficient splits among the data."
msgstr ""

#: ../source/faq/diagnostics.txt:273
msgid "Why would one shard receive a disproportion amount of traffic in a sharded cluster?"
msgstr ""

#: ../source/faq/diagnostics.txt:275
msgid "In some situations, a single shard or a subset of the cluster will receive a disproportionate portion of the traffic and workload. In almost all cases this is the result of a shard key that does not effectively allow :ref:`write scaling <sharding-shard-key-write-scaling>`."
msgstr ""

#: ../source/faq/diagnostics.txt:280
msgid "It's also possible that you have \"hot chunks.\" In this case, you may be able to solve the problem by splitting and then migrating parts of these chunks."
msgstr ""

#: ../source/faq/diagnostics.txt:284
msgid "In the worst case, you may have to consider re-sharding your data and :ref:`choosing a different shard key <sharding-internals-choose-shard-key>` to correct this pattern."
msgstr ""

#: ../source/faq/diagnostics.txt:289
msgid "What can prevent a sharded cluster from balancing?"
msgstr ""

#: ../source/faq/diagnostics.txt:291
msgid "If you have just deployed your sharded cluster, you may want to consider the :ref:`troubleshooting suggestions for a new cluster where data remains on a single shard <sharding-troubleshooting-not-splitting>`."
msgstr ""

#: ../source/faq/diagnostics.txt:295
msgid "If the cluster was initially balanced, but later developed an uneven distribution of data, consider the following possible causes:"
msgstr ""

#: ../source/faq/diagnostics.txt:298
msgid "You have deleted or removed a significant amount of data from the cluster. If you have added additional data, it may have a different distribution with regards to its shard key."
msgstr ""

#: ../source/faq/diagnostics.txt:302
msgid "Your :term:`shard key` has low :ref:`cardinality <sharding-shard-key-cardinality>` and MongoDB cannot split the chunks any further."
msgstr ""

#: ../source/faq/diagnostics.txt:305
msgid "Your data set is growing faster than the balancer can distribute data around the cluster. This is uncommon and typically is the result of:"
msgstr ""

#: ../source/faq/diagnostics.txt:309
msgid "a :ref:`balancing window <sharding-schedule-balancing-window>` that is too short, given the rate of data growth."
msgstr ""

#: ../source/faq/diagnostics.txt:312
msgid "an uneven distribution of :ref:`write operations <sharding-shard-key-write-scaling>` that requires more data migration. You may have to choose a different shard key to resolve this issue."
msgstr ""

#: ../source/faq/diagnostics.txt:317
msgid "poor network connectivity between shards, which may lead to chunk migrations that take too long to complete. Investigate your network configuration and interconnections between shards."
msgstr ""

#: ../source/faq/diagnostics.txt:322
msgid "Why do chunk migrations affect sharded cluster performance?"
msgstr ""

#: ../source/faq/diagnostics.txt:324
msgid "If migrations impact your cluster or application's performance, consider the following options, depending on the nature of the impact:"
msgstr ""

#: ../source/faq/diagnostics.txt:327
msgid "If migrations only interrupt your clusters sporadically, you can limit the :ref:`balancing window <sharding-schedule-balancing-window>` to prevent balancing activity during peak hours. Ensure that there is enough time remaining to keep the data from becoming out of balance again."
msgstr ""

#: ../source/faq/diagnostics.txt:333
msgid "If the balancer is always migrating chunks to the detriment of overall cluster performance:"
msgstr ""

#: ../source/faq/diagnostics.txt:336
msgid "You may want to attempt :doc:`decreasing the chunk size </tutorial/modify-chunk-size-in-sharded-cluster>` to limit the size of the migration."
msgstr ""

#: ../source/faq/diagnostics.txt:339
msgid "Your cluster may be over capacity, and you may want to attempt to :ref:`add one or two shards <sharding-procedure-add-shard>` to the cluster to distribute load."
msgstr ""

#: ../source/faq/diagnostics.txt:343
msgid "It's also possible that your shard key causes your application to direct all writes to a single shard. This kind of activity pattern can require the balancer to migrate most data soon after writing it. Consider redeploying your cluster  with a shard key that provides better :ref:`write scaling <sharding-shard-key-write-scaling>`."
msgstr ""

