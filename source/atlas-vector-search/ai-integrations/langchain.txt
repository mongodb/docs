.. _langchain:

==========================================
Get Started with the LangChain Integration
==========================================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: tutorial

.. facet::
   :name: programming_language
   :values: python

.. meta::
   :description: Integrate Atlas Vector Search with LangChain to build LLM and RAG applications.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. note::

   This tutorial uses LangChain's `Python library 
   <https://python.langchain.com/docs/get_started/introduction>`__. 
   For a tutorial that uses the JavaScript library, see :ref:`langchain-js`.

You can integrate {+avs+} with `LangChain <https://langchain.com/>`__
to build |llm| applications and implement 
retrieval-augmented generation (RAG). This tutorial demonstrates
how to start using {+avs+} with LangChain to perform
semantic search on your data and build a |rag| implementation. 
Specifically, you perform the following actions:

#. Set up the environment.
#. Store custom data on |service|.
#. Create an {+avs+} index on your data.
#. Run the following vector search queries:

   - Semantic search.
   - Semantic search with score.
   - Semantic search with metadata pre-filtering.

#. Implement |rag| by using {+avs+} to answer questions on your data.

Background
----------

.. include:: /includes/ai-integrations/langchain/langchain-background.rst

Prerequisites
-------------

To complete this tutorial, you must have the following:

- An |service| {+cluster+} running MongoDB version 6.0.11, 7.0.2, or later
  (including :abbr:`RCs (Release Candidates)`). Ensure that your 
  :abbr:`IP address (Internet Protocal address)` is included
  in your |service| project's :ref:`access list <access-list>`.

- An OpenAI API Key. You must have a paid OpenAI account with credits
  available for API requests.

- An environment to run interactive Python notebooks 
  such as `Colab <https://colab.research.google.com>`__.

Set Up the Environment
----------------------

You must first set up the environment for this tutorial. 
Create an interactive Python notebook by saving a file 
with the ``.ipynb`` extension, and then run the 
following code snippets in the notebook.

.. include:: /includes/ai-integrations/langchain/langchain-set-up-environment.rst

Use |service| as a Vector Store
-------------------------------

Then, load custom data into |service| and instantiate |service| as 
a vector database, also called a `vector store 
<https://python.langchain.com/docs/modules/data_connection/vectorstores/>`__.
Copy and paste the following code snippets into your notebook.

.. include:: /includes/ai-integrations/langchain/langchain-create-vector-store.rst

.. _langchain-create-index:

Create the {+avs+} Index
------------------------------------

.. note:: 

   To create an {+avs+} index, you must have :authrole:`Project Data Access Admin` 
   or higher access to the |service| project.

.. include:: /includes/ai-integrations/langchain/langchain-create-index.rst

.. _langchain-run-queries:

Run Vector Search Queries
-------------------------

Once |service| builds your index, run vector search queries on your data. 
The following examples demonstrate various queries that you can 
run on your vectorized data.

.. include:: /includes/ai-integrations/langchain/langchain-query-examples.rst

.. seealso::

   For a full list of semantic search methods, refer to 
   the `API reference 
   <https://api.python.langchain.com/en/latest/vectorstores/langchain_mongodb.vectorstores.MongoDBAtlasVectorSearch.html>`__.

.. _langchain-rag:

Answer Questions on Your Data
-----------------------------

This section demonstrates how to implement |rag| in your 
application with {+avs+} and LangChain. Now that you've used {+avs+} 
to retrieve semantically similar documents, run the following code examples 
to prompt the |llm| to answer questions based on those documents.

.. include:: /includes/ai-integrations/langchain/langchain-perform-qa.rst
  
Next Steps
----------

To learn about additional |rag| use-cases with {+avs+}, 
see the following templates provided by LangChain to help you build applications:

- :github:`Basic RAG with MongoDB and OpenAI </langchain-ai/langchain/tree/master/templates/rag-mongo>`
- :github:`Advanced RAG: Parent-Document Retrieval </langchain-ai/langchain/tree/master/templates/mongo-parent-document-retrieval>`

MongoDB also provides the following developer resources:

- `Introduction to LangChain and MongoDB Atlas Vector Search 
  <https://www.mongodb.com/developer/products/mongodb/langchain-vector-search/>`__
- `RAG with Atlas Vector Search, LangChain, and OpenAI 
  <https://www.mongodb.com/developer/products/atlas/rag-atlas-vector-search-langchain-openai>`__
- `Leveraging MongoDB Atlas Vector Search with LangChain 
  <https://www.mongodb.com/developer/products/atlas/leveraging-mongodb-atlas-vector-search-langchain/>`__
- :github:`MongoDB Developer GitHub Repository </mongodb-developer>`

.. seealso:: 

   - `LangChain Documentation <https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas>`__
   - `LangChain API Reference <https://api.python.langchain.com/en/latest/mongodb_api_reference.html>`__
