.. _recover-om-yes-k8sop-cluster:

=================================================================
Recover |onprem| and AppDB if the Operator Cluster is Operational
=================================================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

If |k8s| clusters running the |application| instances or Application Database nodes
fail, but the operator cluster is available, you can use the |k8s-op-short|
to reconfigure deployments of the Application Database's replica set and the
|application| instances based on the following scenarios:

- If some or all |application| instances fail, no data is lost because the
  |application| is stateless. To increase the availability of the |application|,
  add new |application| instances to already configured and available |k8s| member
  clusters, or add new |k8s| clusters for running the |application| instances.

- If only a minority of replica set's nodes fail and the majority of nodes
  in a replica set are available, during the reconciliation process, the
  |k8s-op-short| ignores the failed |k8s| clusters and the Application Database
  remains in a writable state.

  Use the :opsmgrkube:`spec.applicationDatabase.clusterSpecList` settings
  to add Application Database's replica set nodes to already configured and
  available member |k8s| clusters, or add new |k8s| clusters on which
  you deploy Application Database's failed replica set members.
  You can also scale down the replica set's nodes on a failed |k8s| cluster
  to reconfigure the replica set to not contain these nodes anymore.

- If a majority of replica set's nodes fail, the replica set can't form
  a voting majority to elect a primary node. To learn more, see
  :manual:`Replica Set Deployment Architectures </core/replica-set-architectures/>`.
  In this case, if at least one node in an Application Database's replica set
  remains available, then no data is lost. Because there is no primary node
  in a replica set, you must
  :ref:`forcibly reconfigure the replica set <recover-appdb-forced-reconfig>`
  to add new replica set nodes. The nodes will form a voting majority allowing
  the replica set to elect a primary. New Application Database instances will sync with
  the healthy nodes to receive the data.

- If all |k8s| member clusters hosting the Application Database's replica set
  nodes fail, this causes an irreversible data loss (|onprem| doesn't back
  up the Application Database). If possible, use an odd number of member
  |k8s| clusters and distribute your Application Database nodes across
  data centers, zones, or |k8s| clusters. To learn more, see :manual:`Replica Sets Distributed Across Two or More Data Centers </core/replica-set-architecture-geographically-distributed/>`.
