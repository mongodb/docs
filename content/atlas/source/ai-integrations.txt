.. _vector-search-integrations:
.. _ai-integrations:

============================================
Integrate MongoDB Atlas with AI Technologies
============================================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: reference

.. meta::
   :description: Learn how to integrate MongoDB with our partner AI integrations.
   :keywords: RAG, OpenAI, LangChain, LlamaIndex, LangGraph, CrewAI, Amazon Bedrock, Vertex AI, integrations, chatbot, vector database, vector search, code example, java, python, node.js, C#, MCP

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

MongoDB and partners have developed specific product integrations to 
help you leverage |service-fullname| in your AI-powered applications 
and AI agents.

This page highlights notable AI integrations 
that MongoDB and partners have developed. 
You can use |service-fullname| with popular AI providers 
and |llm|\s through their standard connection methods and 
|api|\s. For a complete list of integrations and partner 
services, see :ref:`explore-ecosystem`.

.. _ai-frameworks:

Frameworks
----------

You can use the following open-source frameworks to store custom data 
in |service| and implement features such as |rag| with {+avs+}.

LangChain
~~~~~~~~~

`LangChain <https://python.langchain.com/docs/introduction/>`__ is a framework
that simplifies the creation of LLM applications
through the use of "chains," which are LangChain-specific
components that can be combined together for a variety of use 
cases, including |rag|.

To get started, see the following resources:

- :ref:`langchain`.
- :ref:`langchain-js`.

LangChainGo
~~~~~~~~~~~

`LangChainGo <https://pkg.go.dev/github.com/tmc/langchaingo>`__ is a framework
that simplifies the creation of LLM applications in Go. LangChainGo
incorporates the capabilities of LangChain into the Go ecosystem. You can use
LangChainGo for a variety of use cases, including semantic search and |rag|.

To get started, see :ref:`langchaingo`.

LangChain4j
~~~~~~~~~~~

`LangChain4j <https://docs.langchain4j.dev/>`__ is a framework 
that simplifies the creation of LLM applications in Java. LangChain4j
combines concepts and functionality from LangChain, Haystack,
LlamaIndex, and other sources. You can use LangChain4j for a variety of
use cases, including semantic search and |rag|.

To get started, see :ref:`langchain4j`.

LlamaIndex
~~~~~~~~~~

`LlamaIndex <https://docs.llamaindex.ai/en/stable/>`__ is a framework 
that simplifies how you connect custom data sources to |llm|\s. 
It provides several tools to help you load and prepare vector embeddings 
for |rag| applications.

To get started, see :ref:`llamaindex`.

Semantic Kernel
~~~~~~~~~~~~~~~

Microsoft `Semantic Kernel 
<https://learn.microsoft.com/en-us/semantic-kernel/overview/>`__
is an SDK that allows you to combine various AI services
with your applications. You can use Semantic Kernel for a variety 
of use cases, including |rag|.

To get started, see the following tutorials:

- :ref:`semantic-kernel-csharp`.
- :ref:`semantic-kernel`.

Haystack
~~~~~~~~

`Haystack <https://haystack.deepset.ai/integrations/mongodb>`__ is a framework 
for building custom applications with |llm|\s, embedding models, 
vector search, and more. It enables use cases
such as question-answering and |rag|.

To get started, see :ref:`haystack`.

Spring AI
~~~~~~~~~

`Spring AI <https://spring.io/projects/spring-ai>`__
is an application framework that allows you to apply Spring
design principles to your AI application. You can use Spring AI for a
variety of use cases, including semantic search and |rag|.

To get started, see :ref:`spring-ai`.

Agent Frameworks
----------------

You can use the following open-source frameworks to build AI agents
and multi-agent applications that use |service| to implement features 
such as agentic RAG and agent memory.

LangGraph
~~~~~~~~~

`LangGraph <https://www.langchain.com/langgraph/>`__ is a specialized framework
within the LangChain ecosystem designed for building AI agents and
complex multi-agent workflows. LangGraph's graph-based approach allows 
you to dynamically determine the execution path of your application,
enabling advanced agentic applications and use cases. It also supports 
features like persistence, streaming, and memory.

To get started, see the following resources:

- :ref:`langgraph`
- :ref:`langgraph-js`

CrewAI
~~~~~~

`CrewAI <https://docs.crewai.com/en/introduction>`__ is a
Python framework that enables you to build autonomous AI agents with 
specialized roles, tools, and tasks. These agents can be organized together
into "crews," which work together to complete complex tasks
by leveraging LLMs and delegating work amongst themselves.

To get started, see :ref:`crewai`.

Platforms
---------

You can also integrate {+avs+} with the following enterprise platforms
to build generative AI applications. These platforms provide
pre-trained models and other tools to help you build AI 
applications and agents in production.

{+aws-bedrock+}
~~~~~~~~~~~~~~

`{+aws-bedrock+} <https://aws.amazon.com/bedrock/>`__ is a fully-managed 
platform for building generative AI applications. You can integrate 
{+avs+} as a `knowledge base <https://aws.amazon.com/bedrock/knowledge-bases/>`__
for {+aws-bedrock+} to store custom data in |service|, implement |rag|, and 
deploy agents.

To get started, see :ref:`amazon-bedrock`.

Google Vertex AI
~~~~~~~~~~~~~~~~

`Vertex AI <https://cloud.google.com/vertex-ai>`__ is a platform
from |gcp| for building and deploying AI applications and agents. 
The Vertex AI platform includes several tools and pre-trained 
models from Google that you can use with |service| for |rag| 
and other uses cases such as natural language querying.

To get started, see :ref:`google-vertex-ai`.

Tools
-----

You can also integrate |service| with the following
AI tools.

MongoDB MCP Server
~~~~~~~~~~~~~~~~~~

Model Context Protocol (MCP) is an open standard 
for how LLMs connect to and interact 
with external resources and services. Use our official MCP Server
implementation to interact with your |service| data and deployments
from your agentic AI tools, assistants, and platforms.

To learn more, see `MongoDB MCP Server <https://www.mongodb.com/docs/mcp-server/>`__.

.. collapsible:: 
   :heading: API Resources
   :sub_heading: Refer to the following resources as you develop with our integrations.
   :expanded: false

   .. include:: /includes/avs/ai-integrations/api-resources.rst
    
.. toctree::
   :titlesonly:

   Frameworks </ai-integrations/frameworks>
   Agent Frameworks </ai-integrations/agent-frameworks>
   Platforms </ai-integrations/platforms>
   Tools </ai-integrations/tools>
   API Resources </ai-integrations/ai-api-resources>
   