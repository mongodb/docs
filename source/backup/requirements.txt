=====================
|backup| Requirements
=====================

.. default-domain:: mongodb

Hardware Requirements
---------------------

Sizing By Component
~~~~~~~~~~~~~~~~~~~

MMS Package (Front-end)
```````````````````````

This package requires a minimum of 4 x 2ghz+ CPU cores and 16GB of RAM to get
started. This setup has enough capacity to monitor and backup approximately 200
servers, including all replica set members, config servers, and
:program:`mongos` instances.

There are no specific hard disk requirements as all data used by this package
persists in the configured MongoDB databases. Additional servers increases the
number of backed up front-end instances.

Backup Daemon Package (Back-end)
````````````````````````````````

A server running the Daemon package will act as a hidden secondary for every
replica set assigned to it. 4 x 2ghz+ CPU cores and 16GB of RAM will be
adequate for most loads generated by this activity.

Since it will not deal with
read traffic, a server running a Backup Daemon will typically be able to handle
more replica sets then a server with production traffic.

Disk size limits the number of backups assigned to a daemon. The server running
this package needs enough disk to hold a full copy of every databases it backs
up. It also needs enough write I/O throughput to apply oplogs to each backup.

For example, imagine a sharded cluster with four 200GB shards. 
Looking at a secondary for each one of the shards it appears
the disk averages 15MB/sec of write traffic. A Backup Daemon assigned
these four shards would need at least 800GB of disk space (in reality
more to handle growth) and that disk partition would need to be able
to write more than 60MB/sec.

Point in time restore capability requires enough space to reconstruct
a snapshot of a backup on the daemon. In the example above, a
point in time restore of this cluster would required another 800GB of
temporary space on the daemon during the restore. Snapshot restores do
not require additional disk space.

MMS Metadata Database
`````````````````````

Each replica set member should have 4 x 2ghz+ CPU cores and 16GB of
RAM. 200GB of disk space will be adequate for the first 200
servers.

Because this data updates frequently, we recommend use of a 
high-end disk, preferably SSDs. If the system reaches the capacity of
this server, upgrade memory or bring additional replica sets online
and reconfigure the MMS application to split different types of MMS
data between these replica sets.

Snapshot Storage / Blockstore Database
``````````````````````````````````````

To calculate the amount of storage needed to store a replica set backup in the
Blockstore database, look at the file size of the replica set to back up,
gigabytes of oplog per hour generated by the replica set, compression ratio of
the data, and the configured snapshot retention schedule.

Using the four shard, 200GB per shard cluster example from above, also
add 2GB/day of oplogs generated per shard or 8GB/day total across the
cluster.

If the longest stored snapshot has a one year retention
period, the approximate amount of data in the blockstore will be 
800GB + (8GB * 365 days) or 3720GB. If the data gets a 4:1 compression
ratio, which is an average seen in the hosted MMS, the blockstore
space required will actually be 930GB.

930GB is a conservative estimate because it assumes 8GB of
oplog in one day changes 8GB of data on disk. The other extreme is
that 8GB of oplog could all be ``$inc`` operations on the same
document. In that case, 8GB of oplog could only change 4 bytes on
disk.

In practice the number will be somewhere in between depending on
the replica sets insert/update/delete patterns.

Based on looking at the MMS hosted service, a good rule of thumb is a replica
set will take up 2x - 3x its size in the Blockstore.

Medium grade HDDs will have enough I/O throughput to handle the load
of the Blockstore. Each replica set member should have 4 x 2ghz+ CPU
cores. We recommend 8GB of RAM for every 1TB disk of Blockstore to
provide good snapshot and restore speed.

Combining Components
~~~~~~~~~~~~~~~~~~~~

Each component does not require a dedicated server. Combine CPU and
RAM requirements based on your environment. Each component should 
still have its own disk partition with the recommended amount of
storage space and I/O throughput.

One possible configuration used in the MMS hosted environment has multiple
RAIDs attached to each high-end physical server. Each server may 
run a combination of a Blockstore primary/secondary, a Backup
Daemon, and a MMS Metadata primary/secondary. The front-end package
can run on a much smaller server as it only has modest CPU and RAM
requirements.

High Availability Setup
-----------------------

MMS Package (Front-end)
~~~~~~~~~~~~~~~~~~~~~~~

Use this stateless component with a load balancer (either layer 4 or 
layer 7) in front of the instances of this package to distribute requests.

To handle N servers for the desired capacity, more than N servers should be 
behind the load balancer to ensure a certain number of losses does not 
degrade performance. N+1 or N+2 are common configurations.

Backup Daemon Package (Back-end)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

While the system protects the daemon against data loss, a lost daemon 
requires manaual intervention.

A daemon exclusively owns a set of backups. 
If it is down, those backups do not continue. Built-in MMS alerts notify 
the system administrator backups have fallen behind. If the daemon is 
repairable, backups will continue where they left off. If the daemon is not 
repairable, assign the backups manually to a different daemon with the Admin 
section of the MMS service.

Moving a backup from one daemon to another involves
a self restore of the previous snapshot from the 
Blockstore. This makes the daemon is somewhat ephemeral and the
durability of the backup data lives in the Blockstore replica set.

MMS Metadata Database / Blockstore Database
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

These should be standard MongoDB replica sets. Follow all MongoDB best 
practices to make these replica sets highly available and durable.

Software Requirements
---------------------

MMS requires 64-bit Linux. MMS supports the following distributions:

- CentOS 5 or later

- Red Hat Enterprise Linux 5 or later

- Amazon Linux (latest version only)

- SLES 11 or later

- Ubuntu 12.04 or later

The MongoDB databases backing MMS best be MongoDB 2.4.6 or later.

The MongoDB replica sets and sharded clusters tobe backed up must be
running MongoDB 2.4.3 or later.

OS Configuration
----------------

Ulimit
~~~~~~

Configure ulimits correctly. The
MMS/Backup HTTP server under load, with the Backup Daemon launching 
``mongod`` instances, will quickly hit most linux distributions default ulimits.

We recommend these settings for the ``/etc/security/limits.conf``
file on all servers running the front-end or back-end package.

.. code-block:: none

   mongodb-mms        soft   nofile           64000
   mongodb-mms        hard   nofile           64000
   mongodb-mms        soft   nproc            32000
   mongodb-mms        hard   nproc            32000

   mongod           soft   nofile           64000
   mongod           hard   nofile           64000
   mongod           soft   nproc            32000
   mongod           hard   nproc            32000

Be sure to check for a ``/etc/security/limits.d/90-nproc.conf`` file
that may override the configured limits.

For any servers running a MMS Metadata Database or a Blockstore
Database, see the :manual:`production notes
</administration/production-notes/>` page for more specific
recommendations.

Firewall
~~~~~~~~

The front-end package will default to running web servers on ports
8080 and 8081.

Additional Information
----------------------

To learn more about |backup| requirements and |backup|, see
:doc:`/backup/faq` and the main :doc:`main Backup documentation page
</backup/>`.
