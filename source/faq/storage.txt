====================
FAQ: MongoDB Storage
====================

.. default-domain:: mongodb

This document addresses common questions regarding MongoDB's storage
system.

If you don't find the answer you're looking for, check
the :doc:`complete list of FAQs </faq>` or post your question to the
`MongoDB User Mailing List <https://groups.google.com/forum/?fromgroups#!forum/mongodb-user>`_.

.. contents:: Frequently Asked Questions:
   :backlinks: none
   :local:

.. _faq-storage-memory-mapped-files:

What are memory mapped files?
-----------------------------

A memory-mapped file is a file with data that the operating system
places in memory by way of the ``mmap()`` system call. ``mmap()`` thus
*maps* the file to a region of virtual memory. Memory-mapped files are
the critical piece of the storage engine in MongoDB. By using memory
mapped files MongoDB can treat the content of its data files as if
they were in memory. This provides MongoDB with an extremely fast and
simple method for accessing and manipulating data.

How do memory mapped files work?
--------------------------------

Memory mapping assigns files to a block of virtual memory with a
direct byte-for-byte correlation. Once mapped, the relationship
between file and memory allows MongoDB to interact with the data in
the file as if it were memory.

How does MongoDB work with memory mapped files?
-----------------------------------------------

MongoDB uses memory mapped files for managing and interacting with all
data. MongoDB memory maps data files to memory as it accesses
documents. Data that isn't accessed is *not* mapped to memory.

.. _faq-storage-page-faults:

What are page faults?
---------------------

Page faults will occur if you're attempting to access part of a
memory-mapped file that *isn't* in memory.

If there is free memory, then the operating system can find the page
on disk and load it to memory directly. However, if there is no free
memory, the operating system must:

- find a page in memory that is stale or no longer needed, and write
  the page to disk.

- read the requested page from disk and load it into memory.

This process, particularly on an active system can take a long time,
particularly in comparison to reading a page that is already in
memory.

What is the difference between soft and hard page faults?
---------------------------------------------------------

:term:`Page faults <page fault>` occur when MongoDB needs access to
data that isn't currently in active memory. A "hard" page fault
refers to situations when MongoDB must access a disk to access the
data. A "soft" page fault, by contrast, merely moves memory pages from
one list to another, such as from an operating system file
cache. In production, MongoDB will rarely encounter soft page faults.

What tools can I use to investigate storage use in MongoDB?
-----------------------------------------------------------

The :method:`db.stats()` method in the :program:`mongo` shell,
returns the current state of the "active" database. The
:doc:`/reference/database-statistics` document outlines the meaning of
the fields in the :method:`db.stats()` output.

What is the working set?
------------------------

Working set represents the total body of data that the application
uses in the course of normal operation. Often this is a subset of the
total data size, but the specific size of the working set depends on
actual moment-to-moment use of the database.

If you run a query that requires MongoDB to scan every document in a
collection, the working set will expand to include every
document. Depending on physical memory size, this may cause documents
in the working set to "page out," or removed from physical memory by
the operating system. The next time MongoDB needs to access these
documents, MongoDB may incur a hard page fault.

If you run a query that requires MongoDB to scan every
:term:`document` in a collection, the working set includes every
active document in memory.

For best performance, the majority of your *active* set should fit in
RAM.

.. todo The following "journal FAQ" content is from the wiki and must be added
   to the manual, perhaps on this page.

   If I am using replication, can some members use journaling and others not?
   --------------------------------------------------------------------------

   Yes. It is OK to use journaling on some replica set members and not
   others.

   Can I use the journaling feature to perform safe hot backups?
   -------------------------------------------------------------

   Yes, see :doc:`/administration/backups`.

   32 bit nuances?
   ---------------

   There is extra memory mapped file activity with journaling. This will
   further constrain the limited db size of 32 bit builds. Thus, for now
   journaling by default is disabled on 32 bit systems.

   When did the --journal option change from --dur?
   ------------------------------------------------

   In 1.8 the option was renamed to --journal, but the old name is still
   accepted for backwards compatibility; please change to --journal if
   you are using the old option.

   Will the journal replay have problems if entries are incomplete (like the failure happened in the middle of one)?
   -----------------------------------------------------------------------------------------------------------------

   Each journal (group) write is consistent and won't be replayed during
   recovery unless it is complete.

   How many times is data written to disk when replication and journaling are both on?
   -----------------------------------------------------------------------------------

   In v1.8, for an insert, four times. The object is written to the main
   collection and also the oplog collection. Both of those writes are
   also journaled as a single mini-transaction in the journal files in
   /data/db/journal.

   The above applies to collection data and inserts which is the worst
   case scenario. Index updates are written to the index and the
   journal, but not the oplog, so they should be 2X today not 4X.
   Likewise updates with things like $set, $addToSet, $inc, etc. are
   compactly logged all around so those are generally small.
