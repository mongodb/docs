:orphan:

========================================================
Release Notes for MongoDB 2.6 (Development Series 2.5.x)
========================================================

.. default-domain:: mongodb

MongoDB 2.6 is currently in development, as part of the 2.5
development release series. While 2.5-series releases are currently
available, these versions of MongoDB, including the 2.6 release
candidate builds, are for **testing only and
not for production use**.

This document will eventually contain the full release notes for
MongoDB 2.6; before its release this document covers the 2.5
development series as a work-in-progress.

.. contents:: See the :doc:`full index of this page <2.6-changes>` for
              a complete list of changes included in 2.6 (Development
              Series 2.5.x).
   :backlinks: none
   :local:
   :depth: 2

Downloading
-----------

You can download the 2.6 release candidate on the `downloads page`_ in the
:guilabel:`Development Release (Unstable)` section. There are no
distribution packages for development releases, but you can use the
binaries provided for testing purposes. See
:doc:`/tutorial/install-mongodb-on-linux`,
:doc:`/tutorial/install-mongodb-on-windows`, or
:doc:`/tutorial/install-mongodb-on-os-x` for the basic installation
process.

.. _`downloads page`: http://www.mongodb.org/downloads

Compatibility Changes
---------------------

.. important:: The MongoDB 2.5-series, which will become MongoDB 2.6,
   is for testing and development **only**. All identifiers, names,
   interfaces are subject to change. Do **not** use a MongoDB 2.5
   release in production situations.

SNMP Enterprise Identifier Changed
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. DOCS-1696

In 2.5.1, the IANA enterprise identifier for MongoDB changed from
37601 to 34601. Users of SNMP monitoring must modify their SNMP
configuration (i.e. MIB) accordingly.

Default ``bind_ip`` for RPM and DEB Packages
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the packages provided by 10gen for MongoDB in RPM (Red Hat, CentOS,
Fedora Linux, and derivatives) and DEB (Debian, Ubuntu, and
derivatives,) the default :setting:`bind_ip` value attaches MongoDB
components to the localhost interface *only*. These packages set this
default in the default configuration file
(i.e. ``/etc/mongodb.conf``.)

If you use one of these packages and have *not* modified the default
``/etc/mongodb.conf`` file, you will need to set :setting:`bind_ip`
before or during the upgrade.

There is no default ``bind_ip`` setting in any other 10gen distributions
of MongoDB.

``isMaster`` Comand includes Wire Protocol Versions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.2

In order to support changes to the wire protocol both now and in the
future, the output of :dbcommand:`isMaster` now contains two new
fields that report the earliest version of the wire protocol that this
:program:`mongod` instance supports and the highest version of the
wire protocol that this :program:`mongo` instance supports.

.. data:: isMaster.maxWireVersion

   The latest version of the wire protocol that this :program:`mongod`
   or :program:`mongos` instance is capable of using to communicate
   with clients.

.. data:: isMaster.minWireVersion

   The earliest version of the wire protocol that this
   :program:`mongod` or :program:`mongos` instance is capable of using
   to communicate with clients.

Replica Set Vote Configuration Validation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded: 2.5.3

MongoDB now deprecates giving any :term:`replica set` member more than
a single vote. During configuration,
:data:`local.system.replset.members[n].votes` should only have a value
of 1 for voting members and 0 for non-voting members. MongoDB treats
values other than 1 or 0 as a value of 1 and produces a warning message.

.. TODO DOCS-1948 Uncomment when this feature is complete 

   MongoDB Refuses to Insert Documents that Cannot be Indexed
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   In 2.5.3, MongoDB will *not* insert documents into collections if
   the content of an indexed field exceeds the :limit:`Maximum Index
   Key Length <Index Key>` and return an error. In previous versions of
   MongoDB, such documents were inserted but not indexed.

Changes
-------

.. important:: The MongoDB 2.5-series, which will become MongoDB 2.6,
   is for testing and development **only**. All identifiers, names,
   interfaces are subject to change. Do **not** use a MongoDB 2.5
   release in production situations.

Aggregation Pipeline Changes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

``$out`` Stage to Write Data to a Collection
````````````````````````````````````````````

.. pipeline:: $out

   In an aggregation pipeline you may specify the name of a collection
   to a :pipeline:`$out` stage, which will write all documents in the
   aggregation pipeline to that collection.

   .. important:: The input collection for the aggregation may be
      sharded; however, you may not specify a sharded collection to
      :pipeline:`$out`.

   :pipeline:`$out` will create a new collection if one does not
   already exist in the current database. This collection is not
   visible until the aggregation completes. If the aggregation fails,
   MongoDB will not create any collection.

   If the output collection already exists, when the aggregation
   completes *successfully*, the :pipeline:`$out` atomically replaces
   the output collection with the new results
   collection. :pipeline:`$out` does not change any indexes that
   existed on the previous collection.

   .. important:: The pipeline will fail to complete if the documents
      produced by the pipeline would violate any unique indexes,
      including the index on the ``_id`` field, that existed on the
      original output collection.

   You may *only* specify :pipeline:`$out` at the end of a pipeline.

With :pipeline:`$out`, the aggregation framework can return result
sets of any size.

.. example::

   The following operation will insert all documents in ``records``
   collection into a collection named ``users``. The inserted
   documents will *only* have the ``_id``, ``uid``, and ``email``
   fields from the source documents:

   .. code-block:: javascript

      db.records.aggregate( { $project: { uid: 1, email: 1 } },
                            { $out: "users" } )

.. [#same-as-replace] When the :pipeline:`$out` operation specifies
   a collection that already exists in the current database,
   :pipeline:`$out` behaves like the replace mode of
   :dbcommand:`mapReduce`.

Aggregation Operation Can Return a Cursor
`````````````````````````````````````````

.. re the above title change - We often use "may" for "can". I think that's fine in the text but
   it's easy to misread in a title, which I actually did.
   May means permission to.
   Can means ability to.
   In general, "can" is the stronger word. "May" has a softness, and I think we want to be bold
   in describing what we can do.

.. There's a few other edits in the content below to make our statements stronger.

.. DOCS-1835

The :dbcommand:`aggregate` may now return a cursor rather than a
result document. To return a cursor object, specify the ``cursor``
operation and an initial batch size as options to the
:dbcommand:`aggregate` command.
In 2.5.2, the *temporary* :program:`mongo` shell helper
``db.collection.aggregateCursor()`` provides access to this
capability.

By returning a cursor, aggregation pipelines can return result sets of
any size. In previous versions, the result of an aggregation operation
could be no larger than 16 megabytes.
Cursors returned from the aggregation command are equivalent to
cursors returned from :method:`~db.collection.find()` queries in every
way.

The following command returns a document that can be used to instantiate
an object. The command sets the ``batchSize`` to ``10`` documents:

.. code-block:: javascript

   db.runCommand(
      { aggregate: "records",
        pipeline: [
           { $project: { name: 1, email: 1, _id: 0 } },
           { $sort: { name: 1 } }
        ],
        cursor: { batchSize: 10 }
      }
   )

The ``{batchSize: 10 }`` document specifies the size of the *initial*
batch size only. Specify subsequent batch sizes to :ref:`OP_GET_MORE
<wire-op-get-more>` operations as with other MongoDB cursors.

The :program:`mongo` shell provides the helper method
``aggregateCursor()``:

.. code-block:: javascript

   db.records.aggregateCursor(
     [
        { $project : { name: 1, email: 1, _id: 0 } },
        { $sort : { name: 1 } }
     ]
   )

A ``batchSize`` of ``0`` means an empty first batch and is useful if you
want to quickly get back a cursor or failure message, without doing
significant server-side work. To specify a ``batchSize`` of ``0``, use
an empty document:

.. code-block:: javascript

   db.runCommand(
      { aggregate: "records",
        pipeline: [
           { $project : { name: 1, email: 1, _id: 0 } },
           { $sort : { name : 1 } }
        ],
        cursor: {}
      }
   )

Improved Sorting
````````````````

.. versionadded:: 2.5.2

The :pipeline:`$sort` and :pipeline:`$group` stages now use a more
efficient sorting system within the :program:`mongod` process. This
improves performance for sorting operations that cannot rely on an
index or that exceed the maximum memory use limit, see
:limit:`Aggregation Sort Operation` for more information.

For large sort operations these "external sort" operations can write
data to the ``_tmp`` directory in the :setting:`dbpath` directory. To
enable external sort use the new ``allowDiskUsage`` argument to the
:dbcommand:`aggregate`, as in the following prototype:

.. code-block:: javascript

   {
     aggregate: "<collection>",
     pipeline: [<pipeline>],
     allowDiskUsage: <boolean>
   }

You can run this pipeline operation, using the following command:

.. code-block:: javascript

   db.runCommand(
      { aggregate: "records",
        pipeline: [
           { $project : { name: 1, email: 1, _id: 0 } },
           { $sort : { name : 1 } }
        ],
        cursor: { batchSize: 10 },
        allowDiskUsage: true
      }
   )

``$redact`` Stage to Provide Filtering for Field-Level Access Control
`````````````````````````````````````````````````````````````````````

.. pipeline:: $redact

   .. versionadded:: 2.5.2

   Provides a method to restrict the content of a returned document on
   a per-field level.

   .. example::

      Given a collection with the following document in a ``test``
      collection:

      .. code-block:: javascript

         { a: {
             level: 1,
             b: {
                 level: 5,
                 c: {
                     level: 1,
                     message: "Hello"
                 }
             },
             d: "World."
         }

     Consider the following aggregation operation:

     .. code-block:: javascript

        db.test.aggregate(
           { $match: {} },
           { $redact: { $cond: [ { $lt: [ '$level', 3 ] },
                                 "$$CONTINUE",
                                 "$$PRUNE" ]
                      }
           }
        )

     This operation evaluates every field at every level for all
     documents in the ``test`` collection, and uses the
     :expression:`$cond` expression and the variables ``$$CONTINUE``
     and ``$$PRUNE`` to specify the redaction of document parts in the
     aggregation pipeline.

     .. important:: ``$$CONTINUE`` will become ``$$DESCEND`` in
        2.5.3.

     Specifically, if the field ``level`` is less than 3,
     (i.e. ``{ $lt: [ '$level', 3' ] }``) :pipeline:`$redact`
     continues (i.e. ``$$CONTINUE``) evaluating the fields and
     sub-documents at this level of the input document. If the value
     of ``level`` is greater than ``3``, then :pipeline:`$redact`
     removes all data at this level of the document.

     The result of this aggregation operation is as follows:

      .. code-block:: javascript

         { a: {
             level: 1,
             d: "World."
         }

     You may also specify ``$$KEEP`` as a variable to
     :expression:`$cond`, which returns the entire sub-document
     without transversing, as ``$$CONTINUE``.

     .. START-COMMENT

        In 2.5.3, :expression:`$cond` will accept a document with
        named parameters in addition to the current ordered array of
        parameters.

        In 2.5.3, ``$$CONTINUE`` will become ``$$DESCEND``.

     .. END-COMMENT

     .. see:: :expression:`$cond`.

Set Expression Operations in ``$project``
`````````````````````````````````````````

In 2.5.2, the :pipeline:`$project` aggregation pipeline stage now
supports the following set expressions:

.. important:: Set operators take arrays as their arguments and treat
   these arrays as sets. Except for :expression:`$setDifference`, the
   set operators ignore duplicate entries in an input array and
   produce arrays containing unique entries.

.. expression:: $setIsSubset

   Takes two arrays and returns ``true`` when the first array is a
   subset of the second and ``false`` otherwise.

.. expression:: $setEquals

   Takes two arrays and returns ``true`` when they contain the same
   elements, and ``false`` otherwise.

.. expression:: $setDifference

   Takes two arrays and returns an array containing the elements that
   only exist in the first array. :expression:`$setDifference` may
   produce arrays containing duplicate items in 2.5.2 if the input
   array contains duplicate items.

.. expression:: $setIntersection

   Takes any number of arrays and returns an array that contains the
   elements that appear in every input array.

.. expression:: $setUnion

   Takes any number of arrays and returns an array that containing the
   elements that appear in any input array.

.. expression:: $all

   Takes a single array and returns ``true`` if all its values are
   ``true`` and ``false`` otherwise.

   :expression:`$all` will become ``$allElementsTrue`` in 2.5.3.

.. expression:: $any

   Takes a single expression that returns an array and returns
   ``true`` if any of its values are ``true`` and ``false`` otherwise.

   :expression:`$any` will become ``$anyElementTrue`` in 2.5.3.

``$map`` and ``$let`` Expressions in Aggregation Pipeline Stages
````````````````````````````````````````````````````````````````

.. tip:: For :expression:`$let` and :expression:`$map`, the
   aggregation framework introduces variables. To specify a variable,
   use the name of the variable prefixed by **2** dollar signs
   (i.e. ``$$``) as in: ``$$<name>``.

.. expression:: $let

   :expression:`$let` binds variables for use in sub-expressions. For
   example:

   .. code-block:: javascript

      { $project: { $let: { vars: { tally: 75, count: 50 } },
                            in: { remaining: { $subtract: [ "$$tally", "$$count" ] } } } }

   Would return a document with the following:

   .. code-block:: javascript

      { remaining: 25 }

   :expression:`$let` is available the in :pipeline:`$project`,
   :pipeline:`$group`, and :pipeline:`$redact` pipeline stages.

.. expression:: $map

   :expression:`$map` applies a sub-expression to each item in an
   array and returns an array with the result of the sub-expression

   :expression:`$map` is available the in :pipeline:`$project`,
   :pipeline:`$group`, and :pipeline:`$redact` pipeline stages.

   Given an input document that resembles the following:

   .. code-block:: javascript

      { skews: [ 1, 1, 2, 3, 5, 8 ] }

   And the following :pipeline:`$project` statement:

   .. code-block:: javascript

      { $project: { adjustments: { $map: { input: "$skews",
                                           as: "adj",
                                           in: { $add: [ "$$adj", 12 ] } } } } }

   The :expression:`$map` would transform the input document into the
   following output document:

   .. code-block:: javascript

      { adjustments: [ 13, 13, 14, 15, 17, 20 ] }

``$literal`` Expression for Aggregation Pipeline Stages
```````````````````````````````````````````````````````

The new :expression:`$literal` operator allows users to explicitly
specify documents in aggregation operations that the pipeline stage
would otherwise interpret directly. For example, use
:expression:`$literal` to project fields with dollar signs
(e.g. ``$``) in their values.

.. expression:: $literal

   Wraps an expression to prevent the aggregation pipeline from
   interpreting an object directly.

Consider the following example:

.. code-block:: javascript

   db.runCommand( { aggregate: "records",
                    pipeline: [  { $project: { costsOneDollar:
                                      { $eq: [ "$price", { $literal: "$1.00" } ] } }
                                 } ] } )

This projects documents with a field named ``costsOneDollar`` that
holds a boolean value if the value of the field is the string
``$1.00``.

``explain`` Option for the Aggregation Pipeline
```````````````````````````````````````````````

The new ``explain`` option to the :dbcommand:`aggregate` command
provides information about how the command processes the pipeline. The
returned document contains information on each stage of the pipeline.

To use ``explain``, set the ``explain`` field to ``true`` as shown here:

.. code-block:: javascript

   db.runCommand( { aggregate: "<collection>",
                    explain: true,
                    pipeline: [ <pipeline operations> ] } )

.. example::

   Given the following aggregation command with ``explain`` field set to ``true``:

   .. code-block:: javascript

      db.runCommand( {
                       aggregate: "records",
                       explain: true,
                       pipeline: [ { $sort: { name : -1 } },
                                   { $skip: 10 },
                                   { $limit: 5 } ]
                     }

   The returned document provides information on how
   :dbcommand:`aggregate` processed the pipeline. In this example, the
   returned document would show, among other details, that:

   - a :ref:`sequence optimization
     <aggregation-pipeline-sequence-optimization>` occurs where the
     :pipeline:`$limit` moves before the :pipeline:`$skip` and the
     :pipeline:`$limit` amount has increased to the sum of its initial
     value and the :pipeline:`$skip` value, and

   - with the :pipeline:`$sort` now immediately preceding a
     :pipeline:`$limit`, :pipeline:`$sort` operation would only
     maintain the top 15 results (i.e. the new limit amount) as it
     progresses.

The format of the ``explain`` output document is not final for
version 2.6.

Update Improvements
~~~~~~~~~~~~~~~~~~~

MongoDB 2.5.2 includes a new subsystem which provides more reliable
and extensible update operations. 2.5.2 introduces two new changes to
the update language:

``$mul`` Update Operator
````````````````````````

.. operator:: $mul

   The new :operator:`$mul` allows you to multiply the value of a field
   by the specified amount. If the field does not exist in a document,
   :operator:`$mul` sets the field to zero of the same numeric type as
   the multiplier. Consider the following prototype:

   .. example::

      Given a collection named ``records`` with the following
      documents:

      .. code-block:: javascript

         { _id: 1, a: 1, b: 4 }
         { _id: 2, a: 1, b: 3 }
         { _id: 3, a: 1 }

      Consider the following update operation:

      .. code-block:: javascript

         db.records.update( { a: 1 },
                            { $mul: { b: 5 } },
                            { multi: true } )

      Following this operation, the collection would resemble the
      following:

      .. code-block:: javascript

         { _id: 1, a: 1, b: 20 }
         { _id: 2, a: 1, b: 15 }
         { _id: 3, a: 1, b: 0 }

``xor`` operation for ``$bit`` Operator
````````````````````````````````````````

The :operator:`$bit` now supports bitwise updates using a logical
``xor`` operation. See the documentation of :operator:`$bit` for more
information on bitwise updates. Consider the following operation:

.. code-block:: javascript

   db.collection.update( { field: NumberInt(1) }, { $bit: { field: { xor: NumberInt(5) } } } );

Sharding Improvements
~~~~~~~~~~~~~~~~~~~~~

Support for Removing Orphan Data From Shards
````````````````````````````````````````````

.. versionadded:: 2.5.2

The new :dbcommand:`cleanupOrphaned` is available to remove orphaned
data from a sharded cluster. Orphaned data are those documents in a
collection that exist on shards that belong to another shard in the
cluster. Orphaned data are the result of failed migrations or incomplete
migration cleanup due to abnormal shutdown.

.. dbcommand:: cleanupOrphaned

   :dbcommand:`cleanupOrphaned` removes documents from *one* orphaned
   chunk range on shard and runs directly on the shard's
   :program:`mongod` instance, and requires the
   :authrole:`clusterAdmin` for systems running with :setting:`auth`.
   You do **not** need to disable the :term:`balancer` to run
   :dbcommand:`cleanupOrphaned`.

   In the common case, :dbcommand:`cleanupOrphaned` takes the
   following form:

   .. code-block:: javascript

      { cleanupOrphaned: <namespace>, startingFromKey: { } }

   The ``startingFromKey`` field specifies the lowest value of the
   :term:`shard key` to begin searching for orphaned data. The empty
   document (i.e. ``{ }``) is equivalent to the minimum value for the
   shard key (i.e. ``$minValue``).

   The :dbcommand:`cleanupOrphaned` command returns a document that
   contains a field named ``stoppedAtKey`` that you can use to
   construct a loop, as in the following example in the
   :program:`mongo` shell:

   .. code-block:: javascript

      use admin

      var nextKey = {};

      while (
         nextKey = db.runCommand( { cleanupOrphaned : "test.user", startingFromKey : nextKey } ).stoppedAtKey
         ) { printjson(nextKey); }

   This loop removes all orphaned data on the shard.

Ability to Merge Co-located Contiguous Chunks
`````````````````````````````````````````````

.. versionadded:: 2.5.2

The :dbcommand:`mergeChunks` provides the ability for users to combine
contiguous chunks located on a single shard. This makes it possible to
combine chunks in situations where document removal leaves a sharded
collection with too many empty chunks.

.. dbcommand:: mergeChunks

   Combines two contiguous chunks located on the same shard. The
   :dbcommand:`mergeChunks` takes the following form:

   .. code-block:: javascript

      { mergeChunks: <namespace>, bounds: [ <minKey>, <maxKey> ] }

   The ``bounds`` option specified to :dbcommand:`mergeChunks` *must*
   be the boundaries of existing chunks in the collections. See the
   output of :method:`sh.status()` to see the current shard
   boundaries.

   .. important:: Both chunks **must** reside on the same shard.

   .. tip:: In 2.5.2, :dbcommand:`mergeChunks` has the following
      restrictions, which are subject to change in future releases:

      - :dbcommand:`mergeChunks` will only merge two chunks.

      - one chunk **must** not hold any documents (i.e. an "empty
        chunk").

User-Defined Roles
~~~~~~~~~~~~~~~~~~

MongoDB provides new commands for managing users and roles and
additionally lets you create custom roles. MongoDB also provides new
privileges for flexibility in role assignments.

New Schema for User and Role Data
````````````````````````````````````

.. DOCS-1934, DOCS-1935

To manage a user's roles, you no longer perform updates on the
:doc:`system.users </reference/privilege-documents>` collection but
instead make changes using MongoDB's new user-role management commands.
Role and user information for all databases is now be stored in system
collections in the ``admin`` database and manipulated exclusively via
the new commands.

The :doc:`system.users </reference/privilege-documents>` collection is
deprecated. You migrate data from the 2.4 schema to the 2.6 schema
during the MongoDB upgrade process.

.. Where will we publish how to do this ???
   The procedure is on this page in the wiki:
   https://wiki.mongodb.com/display/10GEN/Access+Control+Upgrade+Path+for+2.6

Users Can Define Roles and Grant Privileges
````````````````````````````````````````````

You can now define custom :ref:`user roles <user-roles>` in addition to
the nine MongoDB built-in roles. You can assign privileges and other
roles to the new roles.

To create a role scoped to a given database you must have the new
:authrole:`createRole` privilege on that database. The creator of a role
has ``canDelegate`` privilege on that role. If you can delegate a role,
you can also grant other users the ability to delegate that role.

When granting privileges to a role, you can grant any privilege on any
resource contained in any role for which you have ``canDelegate``
privilege. This allows a global ``admin`` to control what privileges a
database-level ``admin`` can grant.

If you have ``canDelegate`` privilege on a parent role but not on a
child role of that parent, you cannot grant the child role.

Role Management Commands
````````````````````````

.. DOCS-1980, SERVER-9515

MongoDB provides the following new commands for creating and managing
roles:

.. dbcommand:: createRole

   Creates a new role in the database on which you run the command. The
   :dbcommand:`createRole` command assigns privileges to the role. The
   user who runs the command must be authorized to grant the privileges.
   The user who runs the command is automatically given the
   ``canDelegate`` privilege on the new role. The command takes the
   following form:

   .. code-block:: javascript

      { createRole: "<new role>", privileges: [ <privilege document1>,  <privilege document2> ...] }

   The ``privileges`` array can contain only existing privileges. A
   given privileges document specifies a resource and the privileges on
   that resource. If you do not include the ``privileges`` array, the
   role starts with no privileges.

   The following is an example :dbcommand:`createRole` command:

   .. code-block:: javascript

      { createRole: "myClusterwideAdmin",
        privileges:
           [ {resource: {cluster: true}, actions : ["addShard"]},
             {resource: {db: "test", collection: "" }, actions : ["shardCollection", "moveChunk"]},
             {resource: {db:"users", collection:"usersCollection"}, actions: ["update", "insert", "remove"]},
             {resource: {db:"", collection:""}, actions : ["find"]}
           ],
        roles: [{name: "profile", source: "admin"}]
      }

.. dbcommand:: removeRole

   Removes a role from the database on which you run the command. The
   :dbcommand:`removeRole` command takes the following form:

   .. code-block:: javascript

      { removeRole: "myReadOnlyRole"}

.. dbcommand:: grantPrivilegesToRole

   Grants privileges to a role on the database on which you run the
   :dbcommand:`grantPrivilegesToRole` command.

   .. This is from the spec and still to be added to this doc. This
      applies both to granting and revoking: Resource is either the
      object {cluster: true} for cluster-wide operations, or an object
      with a "db" and "collection" component. Either or both of "db" and
      "collection" can be the empty string "" as a wildcard, though that
      is the only kind of wildcarding allowed. There is no restriction
      based on the roleâ€™s scope db as to what the resource can be.
      Privileges revoked from a role must be an exact match for a
      privilege the role contains. For example, if the role "myRole" has
      the "find" action on every collection in the database "A" (i.e.
      the collection field is ""), and you try to revoke find on A.foo,
      this returns an error. This is because even though the role does
      have the privilege being revoked (as a subset of the wildcard on
      "collection"), there's no way to express what the resulting
      privileges should be.

   .. code-block:: javascript

      { grantPrivilegesToRole: "myRole",
        privileges: [
         {resource: {db: "A"}, actions:["find"]},
         {resource: {db: "*", collection: "system.indexes"}, actions: ["find"] } ]
      }

.. dbcommand:: revokePrivilegesFromRole

   Removes privileges from a role on the database on which you run the
   :dbcommand:`revokePrivilegesFromRole` command.

   .. code-block:: javascript

      { revokePrivilegesFromRole: "myRole",
        privileges: [
         {resource: {db: "A"}, actions:["find"]},
         {resource: {db: "*", collection: "system.indexes"}, actions: ["find"] } ]
      }

.. dbcommand:: grantRolesToRole

   .. code-block:: javascript

      { grantRolesToRole: "AreaderWriter",
        grantedRoles: [ { name: "Areader", source: "test"} ]
      }

.. dbcommand:: revokeRolesFromRole

   .. code-block:: javascript

      { revokeRolesFromRole: "AreaderWriter",
        revokedRoles: [ { name: "Areader", source: "test"} ]
      }

.. dbcommand:: rolesInfo

   Lists the privileges and other roles that a role contains. You can
   specify a string, in which case the command returns an exact match,
   or a regular expression. The :dbcommand:`rolesInfo` command applies
   to the current database. The command takes the following form:

   .. code-block:: javascript

      { rolesInfo: <role> }

   To match the role on all databases, run :dbcommand:`rolesInfo` on the
   ``admin`` database and set the optional ``anyDB`` argument to
   ``true``. The ``anyDB`` argument is available only on ``admin``. To
   return all roles on all databases, issue the following from the
   ``admin`` database:

   .. code-block:: javascript

      { rolesInfo: /.*/, anyDB: true}

   The command returns a document similar to the following:

   .. code-block:: javascript

      { ok:1,
        roles:
         [ { name: "superUser", source: "admin", privileges:
              [ { resource: {db: "", collection: ""}, actions: ["read", "write", "clusterAdmin", ...]} ] },
           { name: "ABadmin", source: "admin", privileges:
              [ { resource: {db: "A", collection: ""}, actions: ["read", "write", "dbAdmin", ...] },
                { resource: {db: "B", collection: ""}, actions: ["read", "write", "dbAdmin", ...] } ] }
      ]}

User Management Commands
````````````````````````

.. DOCS-1936

MongoDB provides the following new commands for managing users and user
roles. You no longer manipulate users and roles directly through the
:doc:`system.users </reference/privilege-documents>` collection but
instead with the following commands.

All changes apply to the database on which you run the command. All
commands include the ``writeConcern`` field:

.. code-block:: javascript

   writeConcern: { w: "majority" , wtimeout: 5000 }

The following are the user-management commands:

.. dbcommand:: createUser

   Creates a new user. The :dbcommand:`createUser` command returns a
   duplicate user error if a user with the username and database scope
   already exists. The following is an example of the
   :dbcommand:`createUser` command:

   .. code-block:: javascript

      { createUser: "Carlos",
        pwd: "displayed password",
        customData: {employeeId:12345},
        roles: [ {name : "clusterAdmin", source: "admin", hasRole: true, canDelegate: false},
                 {name : "ABreader", source: "admin", hasRole: true, canDelegate: false},
                 "readWrite"
               ],
        writeConcern: { w: "majority" , wtimeout: 5000 }
      }

   The ``pwd`` field value is displayed. The ``pwd`` field is required,
   *unless* you run :dbcommand:`createUser` on ``$external``. The field
   value is not displayed on ``$external``.

   The ``customData`` field is optional and contains any arbitrary
   information.

   The ``roles`` array can contain only existing roles. If you do not
   provide the ``roles`` array, the user starts with no roles.

   The ``roles`` array can contain role documents and role strings. A
   role document has a ``name`` field for the name of the role, a
   ``source`` field specifying the database that the role is scoped to,
   a ``hasRole`` Boolean, and a ``canDelegate`` Boolean. If ``hasRole``
   is ``false`` but ``canDelegate`` is true, the user has delegation
   privilege on the role without actually having the role's privileges
   directly. At least one of ``canDelegate`` and ``hasRole`` must be
   true for every role.

   A role string applies to the database on which you run the command.
   ``hasRole`` is automatically ``true``, and ``canDelegate`` is
   automatically ``false``.

.. dbcommand:: updateUser

   Updates the user's information on the database on which the command
   is run. All fields are optional, but at least one must be provided.
   The :dbcommand:`updateUser` command can update ``pwd``, ``roles``,
   and ``customData``. The following is an example
   :dbcommand:`updateUser` command:

   .. code-block:: javascript

      { updateUser: "Carlos",
        pwd: "displayed password"
        customData: { employeeId:54321 },
        roles: [ {name:"Areader", source: "A", hasRole: true, canDelegate: true} ],
        writeConcern: { w: "majority" , wtimeout: 5000 }
      }

.. dbcommand:: removeUser

   Removes the user from the database on which you run the command. The
   command takes the following form:

   .. code-block:: javascript

      { removeUser: "Carlos" }

.. dbcommand:: removeUsersFromDatabase

   Removes *all* users from the database on which you run the command.
   The command returns the number of users removed. The command takes
   the following form:

   .. code-block:: javascript

      { removeUsersFromDatabase: 1 }

   Returns:

   .. code-block:: javascript

       { ok: 1, numUsersRemoved: 5 }

.. dbcommand:: grantRolesToUser

   Grants roles to a user. Specify roles as documents or strings. For a
   document, the ``name`` field specifies the role; the ``source`` field
   specifies the database. For a string, the role applies to the
   database on which you run the command. The command takes the
   following form:

   .. code-block:: javascript

      { grantRolesToUser: <username>, roles: <array of role/source pairs> }

   For example:

   .. code-block:: javascript

      { grantRolesToUser: "Erin",
        roles: [ {name: "Areader", source: "A"}, "Breader" ] }

.. dbcommand:: revokeRolesFromUser

   Revokes roles from a user. Specify roles as documents or strings. For
   a document, the ``name`` field specifies the role; the ``source``
   field specifies the database. For a string, the role applies to the
   database on which you run the command. The command takes the
   following form:

   .. code-block:: javascript

      { grantRolesToUser: <username>, roles: <array of role/source pairs> }

   For example:

   .. code-block:: javascript

      { grantRolesToUser: "Dan",
        roles: [ {name: "Areader", source: "A"}, "Breader" ] }

.. dbcommand:: grantDelegateRolesToUser

   Gives a user permission to delegate the specified roles to other
   users. Specify roles as documents or strings. For a document, the
   ``name`` field specifies the role; the ``source`` field specifies the
   database. For a string, the role applies to the database on which you
   run the command. The command takes the following form:

   .. code-block:: javascript

      { grantDelegateRolesToUser: <username>, roles: <array of role/source pairs> }

   For example:

   .. code-block:: javascript

      { grantDelegateRolesToUser: "Alice",
        roles: [ {name: "Areader", source: "A"}, "Breader" ] }

.. dbcommand:: revokeDelegateRolesFromUser

   Removes the user's permission to delegate the specified roles to
   other users. Specify roles as documents or strings. For a document,
   the ``name`` field specifies the role; the ``source`` field specifies
   the database. For a string, the role applies to the database on which
   you run the command. The command takes the following form:

   .. code-block:: javascript

      { revokeDelegateRolesFromUser: <username>, roles: <array of role/source pairs> }

   For example:

   .. code-block:: javascript

      { revokeDelegateRolesFromUser: "Bob",
        roles: [ {name: "Areader", source: "A"}, "Breader" ] }

.. dbcommand:: usersInfo

   Returns role information about the specified users. You can specify a
   string, in which case the command returns an exact match, or a
   regular expression. The command takes the following form:

   .. code-block:: javascript

      { usersInfo: <username> }

   The command applies to the database on which it is run. To match
   users on all databases, run :dbcommand:`usersInfo` on the ``admin``
   database and set the optional ``anyDB`` argument to ``true``. The
   ``anyDB`` argument is available only on ``admin``. To return all
   users on all databases, issue the following:

   .. code-block:: javascript

      { usersInfo: /.*/, anyDB: true } // run on admin DB

   The command returns a document similar to the following:

   .. code-block:: javascript

      { ok:1,
        users:
         [ { name: "administrator", source: "admin", pwd: "<password hash>", customData: {},
             roles: [ { name: "superUser", source: "admin", hasRole: true, canDelegate: true } ]},
           { name: "Carlos", source: "A", pwd: "<password hash>", customData: {},
             roles: [ { name: "Areader", source: "A", hasRole: true, canDelegate:false } ]},
           { name: "Alice", source: "admin", pwd: "<password hash>", customData: {},
             roles: [ { name: "ABreader", source: "admin", hasRole: true, canDelegate: false } ]}
      ]}

New User Privileges
````````````````````

MongoDB adds the following privileges:

.. authrole:: changeOwnPassword

   User can change own password.

.. authrole:: changeAnyPassword

   User can change the password of any user in the database.

.. authrole:: changeOwnCustomData

   User can change own ``customData`` field.

.. authrole:: changeAnyCustomData

   User can change the ``customData`` field of any user in the database.

.. authrole:: createUser

   User can create new users in the database.

.. authrole:: createRole

   User can create new roles in the database.

.. authrole:: grantAnyRole

   User can grant roles to other users within the database.

.. authrole:: revokeAnyRole

   User can revoke roles from other users within the database.

.. authrole:: directlyModifyUsers

   User can direct write operations to the new ``admin.system.users``
   and ``admin.system.roles`` collections.

SSL Improvements
~~~~~~~~~~~~~~~~

MongoDB Allows Only Strong SSL Ciphers
``````````````````````````````````````

.. DOCS-1921

MongoDB's SSL encryption only allows use of strong SSL ciphers, with a minimum
of 128-bit key length for all connections.

The strong-cipher requirement prevents an old or malicious client from forcing
use of a weak cipher.

Support for SSL and non-SSL Connections on the Same Port
````````````````````````````````````````````````````````

.. merge this under the new ~~~ header created by DOCS-1921

.. DOCS-1941

.. draft, waiting for feature complete before sending to technical review

MongoDB supports mixed SSL and non-SSL connections on the same port to
allow rolling upgrades to SSL without forcing downtime. MongoDB provides
a new command-line option and server command that configure a server
port to allow unencrypted internal connections while maintaining
encrypted external connections.

To use such mixed SSL modes on a port, you must retrict access at the
network level. You cannot at this time restrict encryption based on
MongoDB user or role. Outgoing connections from the MongoDB server
cannot choose encryption based on connection target.

To upgrade with both SSL and non-SSL connections on a port, first
perform a rolling restart of all servers in a cluster and second switch
clients to use SSL. Once all internal connections and clients use SSL,
configure the servers to accept only SSL connections.

MongoDB provides the following new server command-line option to handle
mixed SSL modes:

.. code-block:: sh

   --sslMode < option >

The value of ``<option>`` is one of the following:

- ``noSSL``. The server does not use SSL.

- ``onlySSL``. The server only uses SSL.

- ``acceptSSL``. Outgoing connections do not use SSL. For incoming
  connections, the server accepts both SSL and non-SSL.

- ``sendAcceptSSL``. Outgoing connections use SSL. For incoming
  connections, the server accepts both SSL and non-SSL.

MongoDB also provides the new server command ``setSSLMode``. The command
takes the above options.

You can only increase security level on a server. Changing a server's
listening behavior does not require a restart of the server.

x.509 Authentication
````````````````````

MongoDB introduces x.509 certificate authentication for use with a
secure :doc:`SSL connection </tutorial/configure-ssl>`.

.. important:: To use SSL, you must either use MongoDB Enterprise or
   build MongoDB locally using ``scons`` with the ``--ssl`` option.

The x.509 authentication allows clients to authenticate to servers with
certificates instead of with username and password.

The x.509 authentication also allows sharded cluster members and
replica set members to use x.509 certificates to verify their
membership to the cluster or the replica set instead of using key
files. The membership authentication is an internal process.

.. _`default distribution of MongoDB`: http://www.mongodb.org/downloads
.. _`MongoDB Enterprise`: http://www.mongodb.com/products/mongodb-enterprise

x.509 Certificate
^^^^^^^^^^^^^^^^^

The x.509 certificate for client authentication and the x.509
certificate for internal authentication have different properties.

The client certificate must have the following
properties:

- A single Certificate Authority (CA) must issue the certificates
  for both the client and the server.

- Client certificates must contain the following fields:

  .. code-block:: none

     keyUsage = digitalSignature
     extendedKeyUsage = clientAuth

The member certificate, used for internal authentication to verify
membership to the sharded cluster or a replica set, must have the
following properties:

- A single Certificate Authority (CA) must issue all the x.509
  certificates for the members of a sharded cluster or a replica set.

- The member certificate's ``subject``, which contains the
  Distinguished Name (``DN``), must match the ``subject`` of the
  certificate on the server, *starting from and including* the
  Organizational Unit (``OU``) of the certificate on the server.

New Protocol and Parameters
^^^^^^^^^^^^^^^^^^^^^^^^^^^

The change for x.509 authentication introduces a new ``MONGODB-X509``
protocol. For internal authentication for membership, the change also
introduces the ``--clusterAuthMode``, ``--sslClusterFile`` and the
``--sslClusterPassword`` options.

Use the ``--clusterAuthMode`` option to enable internal x.509
authentication for membership. The ``--clusterAuthMode`` option can
have one of the following values:

.. list-table::
   :header-rows: 1
   :widths: 20 40

   * - Value

     - Description

   * - ``keyfile``

     - Default value. Use keyfile for authentication.

   * - ``sendKeyfile``

     - For rolling upgrade purposes. Send the keyfile for
       authentication but can accept either keyfile or x.509
       certificate.

   * - ``sendX509``

     - For rolling upgrade purposes. Send the x.509 certificate for
       authentication but can accept either keyfile or x.509
       certificate.

   * - ``x509``

     - Recommended. Send the x.509 certificate for authentication and
       accept **only** x.509 certificate.

For the ``--sslClusterFile`` option, specify the full path to the x.509
certificate and key PEM file for the cluster or set member. If the key
is encrypted, specify the password with the ``--sslClusterPassword``
option.

Configure MongoDB Server to Use x.509
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Configure the MongoDB server from the command line, as in the following
[#additionalOptions]_:

.. code-block:: sh

   mongod --sslOnNormalPorts --sslPEMKeyFile <path to sslCertificate and key PEM file> --sslCAFile <path to root CA PEM file>

You may also specify these options in the :doc:`configuration file
</reference/configuration-options>`:

.. code-block:: none

   sslOnNormalPorts = true
   sslPEMKeyFile = <path to sslCertificate and key PEM file>
   sslCAFile = <path to the root CA PEM file>

To specify the x.509 certificate for internal cluster member
authentication, append the additional SSL options ``--clusterAuthMode``
and ``--sslClusterFile``, as in the following example for a member of a
replica set [#additionalOptions]_:

.. code-block:: sh

   mongod --replSet <name> --sslOnNormalPorts --sslPEMKeyFile <path to sslCertificate and key PEM file>  --sslCAFile <path to root CA PEM file>  --clusterAuthMode x509 --sslClusterFile <path to membership certificate and key PEM file>

.. [#additionalOptions] Include any additional options, SSL
   or otherwise, that are required for your specific configuration.

Authenticate with a x.509 Certificate
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To authenticate with a client certificate, you must first add a MongoDB
user that corresponds to the client certificate. See
:ref:`addX509SubjectUser`.

To authenticate, use the :method:`db.auth()` method in the
``$external`` database. For the ``mechanism`` field, specify
``"MONGODB-X509"``, and for the ``user`` field, specify the user, or
the ``subject``, that corresponds to the client certificate.

For example, if using the :program:`mongo` shell,

1. Connect :program:`mongo` shell to the :program:`mongod` set up for
   SSL:

   .. code-block:: sh

      mongo --ssl --sslPEMKeyFile <path to CA signed client PEM file>

#. To perform the authentication, use the :method:`db.auth()` method in the
   ``$external`` database.

   .. code-block:: javascript

      db.getSiblingDB("$external").auth(
                                         {
                                           mechanism: "MONGODB-X509",
                                           user: "CN=myName,OU=myOrgUnit,O=myOrg,L=myLocality,ST=myState,C=myCountry"
                                         }
                                       )

.. _addX509SubjectUser:

Add x.509 Certificate ``subject`` as a User
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To authenticate with a client certificate, you must first add the value
of the ``subject`` from the client certificate as a MongoDB user.

#. You can retrieve the ``subject`` from the client certificate with
   the following command:

   .. code-block:: sh

      openssl x509 -in <pathToClient PEM> -inform PEM -subject -nameopt RFC2253

   The command returns the ``subject`` string as well as certificate:

   .. code-block:: sh

      subject= CN=myName,OU=myOrgUnit,O=myOrg,L=myLocality,ST=myState,C=myCountry
      -----BEGIN CERTIFICATE-----
      # ...
      -----END CERTIFICATE-----

#. Add the value of the ``subject``, omitting the spaces, from the
   certificate as a user. 
   
   For example, in the :program:`mongo` shell, to add the user with
   both the ``readWrite`` role in the ``test`` database and the
   ``userAdminAnyDatabase`` role which is defined only in the ``admin``
   database:

   .. code-block:: javascript

      use $external
      db.addUser(
                  {
                    name: 'CN=myName,OU=myOrgUnit,O=myOrg,L=myLocality,ST=myState,C=myCountry',
                    roles: [
                             { name: 'readWrite', source: 'test', hasRole: true, canDelegate: false },
                             { name: 'userAdminAnyDatabase',source: 'admin', hasRole: true, canDelegate: false }
                           ]
                  }
                )

   In the above example, to add the user with the ``readWrite`` role in
   the ``test`` database, the role specification document specified
   ``'test'`` in the ``source`` field. To add ``userAdminAnyDatabase``
   role for the user, the above example specified ``'admin'`` in the
   ``source`` field.

   .. note:: 
      The following roles are defined only in the ``admin`` database:
      ``clusterAdmin``, ``readAnyDatabase``, ``readWriteAnyDatabase``,
      ``dbAdminAnyDatabase``, and ``userAdminAnyDatabase``. To add the
      user with these privileges, specify ``'admin'`` in the ``source``.

See :doc:`/tutorial/add-user-to-database` for details on adding a user
with roles using :doc:`privilege documents
</reference/privilege-documents>`.

Upgrade Clusters to x.509 Authentication
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To upgrade clusters that are currently using keyfile authentication to
x.509 authentication, use a rolling upgrade process:

1. For each node of a cluster, set ``--clusterAuthMode`` to
   ``sendKeyFile``. With this setting, each node continues to use its
   keyfile to authenticate itself as a member. However, each node can now
   accept either a keyfile or the x.509 certificate from other members to
   authenticate those members. Upgrade all nodes of the cluster to this
   setting.

2. Then, for each node of a cluster, set ``--clusterAuthMode`` to
   ``sendX509`` and set ``--sslClusterFile`` to the appropriate path of
   the node's certificate. [#encryptedKey]_ With this setting, each
   node uses its x.509 certificate to authenticate itself as a member.
   However, each node continues to accept either a keyfile or the x.509
   certificate from other members to authenticate those members.
   Upgrade all nodes of the cluster to this setting.

3. Optional but recommended. Finally, for each node of the cluster, set
   ``--clusterAuthMode`` to ``x509`` to only use the x.509 certificate
   for authentication.

.. [#encryptedKey] If the key is encrypted, set the
   ``--sslClusterPassword`` to the password to decrypt the key.

Index Building Improvements
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Background Index Builds Replicate to Secondaries
````````````````````````````````````````````````

Starting in MongoDB 2.5.0, if you initiate a :ref:`background index
build <index-creation-background>` on a :term:`primary`, the
secondaries will replicate the index build in the background.
In previous versions of MongoDB, secondaries built all indexes in the
foreground, even if the primary built an index in the background.

For all index builds, secondaries will not begin building indexes
until the primary has successfully completed the index build.

``mongod`` Automatically Continues in Progress Index Builds Following Restart
`````````````````````````````````````````````````````````````````````````````

If your :program:`mongod` instance was building an index when it
shutdown or terminated, :program:`mongod` will now continue building
the index when the :program:`mongod` restarts. Previously, the index
build *had* to finish building before :program:`mongod` shutdown.

To disable this behavior the 2.5 series adds a new run time option,
:setting:`noIndexBuildRetry` (or via, ``--noIndexBuildRetry`` on the
command line,) for :program:`mongod`. :setting:`noIndexBuildRetry`
prevents :program:`mongod` from continuing rebuilding indexes that did
not finished building when the :program:`mongod` last shut down.

.. setting:: noIndexBuildRetry

   By default, :program:`mongod` will attempt to rebuild indexes upon
   start-up *if* :program:`mongod` shuts down or stops in the middle
   of an index build. When enabled, this option prevents this
   behavior.

Tool Improvements
~~~~~~~~~~~~~~~~~

Global ``mongorc.js`` File
``````````````````````````

If the file :file:`mongorc.js` exists in the :file:`/etc` directory (or
:file:`%ProgramData%\\MongoDB` directory on Windows), the
:program:`mongo` shell evaluates the contents of this file on start-up.
Then, the :program:`mongo` shell evaluates the user's
:file:`.mongorc.js` file if the file exists in the user's :envvar:`HOME
directory`.

The :option:`--norc` option for :program:`mongo` suppresses only the
user's :file:`.mongorc.js` file.

.. important::
   The :file:`mongorc.js` in :file:`/etc` directory must have read
   permission for the user running the shell.

Support for ``--quiet`` Option for all Tools
````````````````````````````````````````````

.. versionadded:: 2.5.0

All MongoDB :doc:`executable files </reference/program>` now support
the ``--quiet`` option. This option suppresses all logging output
except for error messages.

``mongoimport`` Uses Filename If Collection Name Is Not Specified
`````````````````````````````````````````````````````````````````

.. versionadded:: 2.5.3

When invoked without the ``-c`` or ``--collection`` command-line argument,
the :program:`mongoimport` tool uses the input filename as the name
of the collection. MongoDB omits the extension of the file from the
collection name if the input file has an extension.

.. example::

   The following command imports data from the ``contacts.csv`` file
   into the ``contacts`` collection:

   .. code-block:: none

      mongoimport --db users --type csv --file /opt/backups/contacts.csv

   To specify the collection to import, use the ``-c`` or
   ``--collection`` option:

   .. code-block:: none

      mongoimport --db users --collection contacts --type csv --file /opt/backups/contacts.csv

Limit for ``maxConns`` Removed
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Starting in MongoDB 2.5.0, there is no longer any upward limit for the
:setting:`maxConns`, or :program:`mongod --maxConns` and
:program:`mongos --maxConns` options. Previous versions capped the
maximum possible :setting:`maxConns` setting at ``20,000``
connections.

Geospatial Enhancements
~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.2

MongoDB added support for the following `GeoJSON
<http://geojson.org/geojson-spec.html>`_ object types for use with
:doc:`2dsphere indexes </core/2dsphere>`:

- `MultiPoint <http://geojson.org/geojson-spec.html#id5>`_

- `MultiLineString <http://geojson.org/geojson-spec.html#id6>`_

- `MultiPolygon <http://geojson.org/geojson-spec.html#id7>`_

- `GeometryCollection <http://geojson.org/geojson-spec.html#geometrycollection>`_

C++ Driver Enhancement
~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.0

The C++ driver has been updated to monitor :term:`replica set` health with the
:dbcommand:`isMaster` command instead of :dbcommand:`replSetGetStatus`.
This allows the C++ driver to support systems that have access control enabled.

MSI Package for MongoDB Available for Windows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

MongoDB now distributes MSI packages for Microsoft Windows. This is the
recommended method for MongoDB installation under Windows.

New Replica Set Status Methods
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB provides two additional methods to provide information
regarding the status of a :term:`replica set`:
:method:`rs.printReplicationInfo()` and
:method:`rs.printSlaveReplicationInfo()`.

The :method:`rs.printReplicationInfo()` method provides a formatted
report of the status of a :term:`replica set` from the perspective of
the primary set member. The output is identical to that of the
:method:`db.printReplicationInfo()` method.

The :method:`rs.printSlaveReplicationInfo()` method provides a
formatted report of the status of a :term:`replica set` from the
perspective of a secondary set member. The output is identical to that
of the :method:`db.printSlaveReplicationInfo()` method.

MongoDB Enterprise Features
---------------------------

Support for Auditing
~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.2

MongoDB Enterprise adds features to audit server and client activity
for :program:`mongod` and :program:`mongos` instances.

.. important:: Auditing, like all new features in 2.5.2, is in ongoing
   development. Specifically the interface, output format, audited
   events and the structure of audited events will change
   significantly in the in the 2.5 series before the release of 2.6.

To enable auditing, start :program:`mongod` or :program:`mongos` with
the following argument:

.. code-block:: sh

   --setParameter auditLogPath=<option>

The value of ``<option>`` is one of the following:

- a path. This may be the same as the :setting:`logpath` for MongoDB's
  process log. If you specify the same log file, then the path
  specification must be *exactly* the same as the :setting:`logpath`
  specification.

- the string ``:console`` to output audit log messages to standard
  output.

- the string ``:syslog`` to output audit log messages to the system's
  syslog facility.

.. tip:: As of 2.5.2, auditing does not support filtering of audit
   events.

MongoDB Enterprise for Windows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

MongoDB Enterprise for Windows is now available. It includes advanced
Kerberos security, SSL, and SNMP support.

SASL Library Change
~~~~~~~~~~~~~~~~~~~

MongoDB Enterprise uses Cyrus SASL instead of GNU SASL (``libgsasl``).
This change has the following SASL2 and Cyrus SASL library and GSSAPI
plugin dependencies:

For Debian or Ubuntu, install the following:

.. code-block:: sh

   sudo apt-get install cyrus-sasl2-dbg cyrus-sasl2-mit-dbg libsasl2-2 libsasl2-dev libsasl2-modules libsasl2-modules-gssapi-mit

For CentOS, Red Hat Enterprise Linux, and Amazon AMI, install the
following:

.. code-block:: sh

   sudo yum install cyrus-sasl cyrus-sasl-lib cyrus-sasl-devel cyrus-sasl-gssapi

For SUSE, install the following:

.. code-block:: sh

   sudo zypper install cyrus-sasl cyrus-sasl-devel cyrus-sasl-gssapi


LDAP Support for Authentication
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB Enterprise provides support for proxy authentication of users.  This
change allows administrators to configure a MongoDB cluster to authenticate
users via Linux PAM or by proxying authentication requests to a specified LDAP
service.

.. warning::

   Because this change uses ``SASL PLAIN`` mechanism to transmit the
   user password to the MongoDB server, you should, in general, use
   only on a trusted channel (VPN, SSL, trusted wired network).

Configuration
`````````````

LDAP support for user authentication requires proper configuration of
the ``saslauthd`` daemon process as well as introduces a new server
parameter, ``saslauthdPath``. ``saslauthdPath`` is the path to the Unix
Domain Socket of the ``saslauthd`` instance to use for proxy
authentication.

``saslauthd`` Configuration
^^^^^^^^^^^^^^^^^^^^^^^^^^^

On systems that configure ``saslauthd`` with a
``/etc/sysconfig/saslauthd`` file, such as Red Hat Enterprise Linux,
Fedora, CentOS, Amazon Linux AMI, set the mechanism ``MECH`` to
``ldap``:

.. code-block:: none

   MECH=ldap

On systems that configure ``saslauthd`` with a
``/etc/default/saslauthd`` file, set the mechanisms option to
``ldap``:

.. code-block:: none

   MECHANISMS="ldap"

To use with *ActiveDirectory*, start ``saslauthd`` with the following
configuration options:

.. code-block:: none

   ldap_servers: <ldap uri, e.g. ldaps://ad.example.net>
   ldap_use_sasl: yes
   ldap_mech: DIGEST-MD5
   ldap_auth_method: fastbind

To connect to an OpenLDAP server, use a test ``saslauthd.conf`` with
the following content:

.. code-block:: none

   ldap_servers: <ldap uri, e.g. ldaps://ad.example.net>
   ldap_search_base: ou=Users,dc=example,dc=com
   ldap_filter: (uid=%u)

To use this sample OpenLDAP configuration, create users with a ``uid``
attribute (login name) and place under the ``Users`` organizational
unit (``ou``).

To test the ``saslauthd`` configuration, use ``testsaslauthd`` utility,
as in the following example:

.. code-block:: sh

   testsaslauthd -u testuser -p testpassword -s mongod -f /var/run/saslauthd/mux

For more information on ``saslauthd`` configuration, see
`<http://www.openldap.org/doc/admin24/guide.html#Configuring saslauthd>`_.

MongoDB Server Configuration
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Configure the MongoDB server with the ``authenticationMechanisms``
parameter and the ``saslauthdPath`` parameters using either the command
line option :option:`--setParameter <mongod --setParameter>` or the
:doc:`configuration file </reference/configuration-options>`:

- If ``saslauthd`` has a socket path of ``/<some>/<path>/saslauthd``,
  set the ``saslauthdPath`` parameter to
  ``/<some>/<path>/saslauthd/mux`` and the ``authenticationMechanisms``
  parameter to ``PLAIN``, as in the following command line example:

  .. code-block:: sh

     mongod --setParameter saslauthdPath=/<some>/<path>/saslauthd/mux --setParameter authenticationMechanisms=PLAIN

  Or to set the configuration in the :doc:`configuration file
  </reference/configuration-options>`, add the parameters:

  .. code-block:: sh

     setParameter=saslauthdPath=/<some>/<path>/saslauthd/mux
     setParameter=authenticationMechanisms=PLAIN

- Otherwise, set the ``saslauthdPath`` to the empty string ``""`` to use
  the library's default value and the ``authenticationMechanisms``
  parameter to ``PLAIN``, as in the following command line example:

  .. code-block:: sh

     mongod --setParameter saslauthdPath="" --setParameter authenticationMechanisms=PLAIN

  Or to set the configuration in the :doc:`configuration file
  </reference/configuration-options>`, add the parameters:

  .. code-block:: sh

     setParameter=saslauthdPath=""
     setParameter=authenticationMechanisms=PLAIN

Authenticate in the ``mongo`` Shell
```````````````````````````````````

To use this authentication mechanism in the :program:`mongo` shell, you
**must** pass ``digestPassword: false`` to :method:`db.auth()` when
authenticating on the ``$external`` database, since the server must
receive an undigested password to forward on to ``saslauthd``, as in
the following example:

.. code-block:: javascript

   use $external
   db.auth(
            {
              mechanism: "PLAIN",
              user: "application/reporting@EXAMPLE.NET",
              pwd: "some1nterestingPwd",
              digestPassword: false
            }
          )
