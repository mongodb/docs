:orphan:

========================================================
Release Notes for MongoDB 2.6 (Development Series 2.5.x)
========================================================

.. default-domain:: mongodb

.. contents:: See the :doc:`full index of this page <2.6-changes>` for
              a complete list of changes included in 2.6 (Development
              Series 2.5.x).
   :backlinks: none
   :class: long-toc
   :local:
   :depth: 2

MongoDB 2.6 is currently in development, as part of the 2.5
development release series. While 2.5-series releases are currently
available, these versions of MongoDB are for **testing only and
not for production use**.

This document will eventually contain the full release notes for
MongoDB 2.6; before its release this document covers the 2.5
development series as a work-in-progress.

Downloading
-----------

You can download the current 2.5 development release on the `downloads
page`_ in the :guilabel:`Development Release (Unstable)`
section. There are no distribution packages for development releases,
but you can use the binaries provided for testing purposes. See
:doc:`/tutorial/install-mongodb-on-linux`,
:doc:`/tutorial/install-mongodb-on-windows`, or
:doc:`/tutorial/install-mongodb-on-os-x` for the basic installation
process.

.. _`downloads page`: http://www.mongodb.org/downloads

Compatibility Changes
---------------------

.. important:: The MongoDB 2.5-series, which will become MongoDB 2.6,
   is for testing and development **only**. All identifiers, names,
   interfaces are subject to change. Do **not** use a MongoDB 2.5
   release in production situations.

SNMP Enterprise Identifier Changed
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. DOCS-1696

In 2.5.1, the IANA enterprise identifier for MongoDB changed from
37601 to 34601. Users of SNMP monitoring must modify their SNMP
configuration (i.e. MIB) accordingly.

Default ``bind_ip`` for RPM and DEB Packages
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the packages provided by 10gen for MongoDB in RPM (Red Hat, CentOS,
Fedora Linux, and derivatives) and DEB (Debian, Ubuntu, and
derivatives,) the default :setting:`bind_ip` value attaches MongoDB
components to the localhost interface *only*. These packages set this
default in the default configuration file
(i.e. ``/etc/mongodb.conf``.)

If you use one of these packages and have *not* modified the default
``/etc/mongodb.conf`` file, you will need to set :setting:`bind_ip`
before or during the upgrade.

There is no default ``bind_ip`` setting in any other 10gen distributions
of MongoDB.

``isMaster`` Command includes Wire Protocol Versions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.0

In order to support changes to the wire protocol both now and in the
future, the output of :dbcommand:`isMaster` now contains two new
fields that report the earliest version of the wire protocol that this
:program:`mongod` instance supports and the highest version of the
wire protocol that this :program:`mongo` instance supports. See
:data:`~isMaster.minWireVersion` and :data:`~isMaster.maxWireVersion`
for more information.

Replica Set Vote Configuration Validation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

MongoDB now deprecates giving any :term:`replica set` member more than
a single vote. During configuration,
:data:`local.system.replset.members[n].votes` should only have a value
of 1 for voting members and 0 for non-voting members. MongoDB treats
values other than 1 or 0 as a value of 1 and produces a warning message.

.. _agg-helper-incompatibility:

Behavior of ``aggregate()`` Method in the ``mongo`` Shell
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionchanged:: 2.5.3

.. the text of this message will improve and become more clear before
   2.6 when we remove mention of 2.5-series releases.


The :method:`db.collection.aggregate()` helper now :ref:`returns a
cursor <rn-2.6-aggregation-cursor>`. As a result, you cannot use the
:method:`~db.collection.aggregate()` method from a 2.5.3 (or later)
version of the :program:`mongo` shell while connected to 2.4 (and
earlier) versions of MongoDB.

To perform aggregation on earlier versions of MongoDB, use either a
previous version of the :program:`mongo` shell or if using the 2.5.3
(or later) version of the :program:`mongo` shell, run the
:dbcommand:`aggregate` command, not the
:method:`db.collection.aggregate()` helper, without specifying the
``cursor`` option.

.. TODO DOCS-1948 Uncomment when this feature is complete

   MongoDB Refuses to Insert Documents that Cannot be Indexed
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   In 2.5.3, MongoDB will *not* insert documents into collections if
   the content of an indexed field exceeds the :limit:`Maximum Index
   Key Length <Index Key>` and return an error. In previous versions of
   MongoDB, such documents were inserted but not indexed.

.. _authentication-incompatibility:

Authentication and Authorization Incompatibility
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. important::
   For authentication/authorization, the 2.5.3 release does not
   offer an automatic upgrade process to go from version 2.4 model for
   user credentials and privileges to the 2.5.3 model. However, version
   2.5.4 **will** provide an automatic upgrade process.

MongoDB 2.5.3 does not offer an automatic upgrade process to go from
version 2.4 model :doc:`user privilege documents
</reference/privilege-documents>` to the :ref:`2.5.3. model
<user-defined-roles>`.

In order to *test* your existing database with the :ref:`MongoDB 2.5.3
authentication/authorization <user-defined-roles>`, you must remove all
the users from the ``system.users`` collection in the ``admin``
database and create new users with the new user privilege model. One
option is to delete all the users while running with
:option:`authorization <--auth>` disabled, and create the first user
with the role { role: "root", db: "admin" } using the
:method:`db.addUser` helper in the :program:`mongo` shell.

Version 2.5.3 is for testing and development **only**.

``$mod`` Query Operator Enforces Strict Syntax
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :query:`$mod` operator now only accepts an array with exactly two
elements, and errors when passed an array with fewer or more elements.
In previous versions, if passed an array with one element, the
:query:`$mod` operator uses ``0`` as the second element, and if passed
an array with more than two elements, the :query:`$mod` ignores all but
the first two elements. Previous versions do return an error when
passed an empty array.

See :ref:`mod-not-enough-elements` and :ref:`mod-too-many-elements` for
details.

Changes
-------

.. important:: The MongoDB 2.5-series, which will become MongoDB 2.6,
   is for testing and development **only**. All identifiers, names,
   interfaces are subject to change. Do **not** use a MongoDB 2.5
   release in production situations.

Aggregation Pipeline Changes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. _aggregation-method-change:

``db.collection.aggregation()`` Accepts Second Parameter
````````````````````````````````````````````````````````

In the 2.5.3 version of the :program:`mongo` shell, the
:method:`db.collection.aggregate()` helper can now accept as a second
parameter a document of options:

.. code-block:: javascript

   db.collection.aggregate( [ <pipeline> ], { options } )

The second parameter is *optional*.

The updated :method:`db.collection.aggregate()` helper supports legacy
syntax and accepts the pipeline stages as separate arguments. For
example,

.. code-block:: javascript

   db.collection.aggregate( { $match: ... }, { $group: ...} )

However, if you do not specify the ``<pipeline>`` in an array, you
cannot specify options.

.. seealso:: :ref:`agg-helper-incompatibility`

``$out`` Stage to Write Data to a Collection
````````````````````````````````````````````

.. versionadded:: 2.5.2

The aggregation pipeline adds a new stage named :pipeline:`$out` that
writes the result of the pipeline operation to an output collection and
returns an empty result set. In version 2.5.3 of the :program:`mongo`
shell, because the :method:`db.collection.aggregate()` method returns a
cursor, specifying an :pipeline:`$out` stage returns an empty cursor.

See the :doc:`$out documentation </reference/operator/aggregation/out>`
for more information.

.. _rn-2.6-aggregation-cursor:

Aggregation Operations Now Return Cursors
`````````````````````````````````````````

.. There's a few other edits in the content below to make our statements stronger.

.. DOCS-1835

The :method:`db.collection.aggregate()` helper in the :program:`mongo`
shell now returns a cursor. By returning a cursor,
aggregation pipelines can return result sets of any size. In previous
versions, the result of an aggregation operation could be no larger
than 16 megabytes.

To perform aggregation on older servers, use either a previous version
of the :program:`mongo` shell or if using the 2.5.3 :program:`mongo`
shell, run the :dbcommand:`aggregate` command, not the
:method:`db.collection.aggregate()` helper, without specifying the
``cursor`` option.

Cursors returned from aggregation only supports cursor methods that
operate on evaluated cursors (i.e. cursors whose first batch has been
retrieved), such as the following methods:

.. hlist::
   :columns: 2

   * :method:`cursor.hasNext()`
   * :method:`cursor.next()`
   * :method:`cursor.toArray()`
   * :method:`cursor.forEach()`
   * :method:`cursor.map()`
   * :method:`cursor.objsLeftInBatch()`
   * :method:`cursor.itcount()`
   * :method:`cursor.pretty()`

.. include:: /includes/important-uses-new-aggregate-helper.rst

The following example returns a cursor from the aggregation operation:

.. code-block:: javascript

   var results = db.records.aggregate(
                                       [
                                         { $project : { name: 1, email: 1, _id: 0 } },
                                         { $sort : { name: 1 } }
                                       ]
                                     )

Like the cursor returned from :method:`db.collection.find()`, in the
:program:`mongo` shell, if the cursor returned from the
:method:`db.collection.aggregate()` is not assigned to a variable using
the ``var`` keyword, then the cursor is automatically iterated up to 20
times. See :doc:`/core/cursors` for cursor behavior in the
:program:`mongo` shell and :doc:`/tutorial/iterate-a-cursor` for
handling cursors in the :program:`mongo` shell.

To specify an *initial* batch size for the cursor, set the option (e.g.
``cursor: { batchSize: <num> }``) in the :ref:`second parameter
<aggregation-method-change>` of the :method:`db.collection.aggregate()`
method. A ``batchSize`` of ``0`` means an empty first batch and is
useful if you want to quickly get back a cursor or a failure message
without doing significant server-side work, as in the following example:

.. code-block:: javascript

   var results = db.records.aggregate(
                                       [
                                         { $project : { name: 1, email: 1, _id: 0 } },
                                         { $sort : { name: 1 } }
                                       ],
                                       {
                                          cursor: { batchSize: 0 }
                                       }
                                     )

The :dbcommand:`aggregate` command may also return a cursor rather than
a result document. To return a cursor object, specify the ``cursor``
option. You can also specify an optional initial batch size to the
command. Using the :dbcommand:`aggregate` command to return a cursor is
a low-level operation, intended for authors of drivers. Most users
should use the :method:`db.collection.aggregate()` helper provided in
the :program:`mongo` shell or in their driver.

The following command returns a document that can be used to
instantiate an object.

.. code-block:: javascript

   db.runCommand(
      { aggregate: "records",
        pipeline: [
           { $project: { name: 1, email: 1, _id: 0 } },
           { $sort: { name: 1 } }
        ],
        cursor: { }
      }
   )

To specify an *initial* batch size, specify the ``batchSize`` in the
``cursor`` field, as in the following example:

.. code-block:: javascript

   db.runCommand(
      { aggregate: "records",
        pipeline: [
           { $project: { name: 1, email: 1, _id: 0 } },
           { $sort: { name: 1 } }
        ],
        cursor: { batchSize: 0 }
      }
   )

The ``{batchSize: 0 }`` document specifies the size of the *initial*
batch size only. Specify subsequent batch sizes to :ref:`OP_GET_MORE
<wire-op-get-more>` operations as with other MongoDB cursors. A
``batchSize`` of ``0`` means an empty first batch and is useful if you
want to quickly get back a cursor or failure message, without doing
significant server-side work.

Improved Sorting
````````````````

.. versionadded:: 2.5.2

The :pipeline:`$sort` and :pipeline:`$group` stages now use a more
efficient sorting system within the :program:`mongod` process. This
improves performance for sorting operations that cannot rely on an
index or that exceed the maximum memory use limit, see
:limit:`Aggregation Sort Operation` for more information.

For large sort operations these "external sort" operations can write
data to the ``_tmp`` sub-directory in the :setting:`dbpath` directory.

To enable external sort, specify the ``allowDiskUsage`` option as the
:ref:`second parameter <aggregation-method-change>` to the
:method:`db.collection.aggregate()` helper.

.. include:: /includes/important-uses-new-aggregate-helper.rst

.. code-block:: javascript

   var results = db.records.aggregate(
                                       [
                                          { $project : { name: 1, email: 1, _id: 0 } },
                                          { $sort : { name : 1 } }
                                       ],
                                       {
                                         allowDiskUsage: true
                                       }
                                     )

For the :dbcommand:`aggregate` command, add the new ``allowDiskUsage``
argument to the :dbcommand:`aggregate` command, as in the following
prototype:

.. code-block:: javascript

   {
     aggregate: "<collection>",
     pipeline: [<pipeline>],
     allowDiskUsage: <boolean>
   }


``$redact`` Stage to Provide Filtering for Field-Level Access Control
`````````````````````````````````````````````````````````````````````

.. include:: /includes/important-uses-new-aggregate-helper.rst

.. pipeline:: $redact

   .. versionadded:: 2.5.2

   Provides a method to restrict the content of a returned document on
   a per-field level.

   .. example::

      Given a collection with the following document in a ``test``
      collection:

      .. code-block:: javascript

         { a: {
                level: 1,
                b: {
                    level: 5,
                    c: {
                        level: 1,
                        message: "Hello"
                    }
                },
                d: "World."
             }
         }

      Consider the following aggregation operation:

      .. code-block:: javascript

         db.test.aggregate(
            { $match: {} },
            { $redact: { $cond: { if: { $lt: [ '$level', 3 ] },
                                  then: "$$DESCEND",
                                  else: "$$PRUNE" }
                       }
            }
         )

      This operation evaluates every object-typed field at every level for all
      documents in the ``test`` collection, and uses the
      :expression:`$cond` expression and the variables ``$$DESCEND``
      and ``$$PRUNE`` to specify the redaction of document parts in the
      aggregation pipeline.

      Specifically, if the field ``level`` is less than 3, (i.e. ``{
      $lt: [ '$level', 3' ] }``) :pipeline:`$redact` continues (i.e.
      ``$$DESCEND``) evaluating the fields and sub-documents at this
      level of the input document. If the value of ``level`` is greater
      than ``3``, then :pipeline:`$redact` removes all data at this
      level of the document.

      The result of this aggregation operation is as follows:

      .. code-block:: javascript

         { a: {
                level: 1,
                d: "World."
         }    }

      You may also specify ``$$KEEP`` as a variable to
      :expression:`$cond`, which returns the entire sub-document
      without traversing, as ``$$DESCEND``.

      .. see:: :expression:`$cond`.

Set Expression Operations in ``$project``
`````````````````````````````````````````

In 2.5.2, the :pipeline:`$project` aggregation pipeline stage now
supports the following set expressions:

.. important:: Set operators take arrays as their arguments and treat
   these arrays as sets. The set operators ignore duplicate entries in
   an input array and produce arrays containing unique entries.

.. expression:: $setIsSubset

   Takes two arrays and returns ``true`` when the first array is a
   subset of the second and ``false`` otherwise.

.. expression:: $setEquals

   Takes two arrays and returns ``true`` when they contain the same
   elements, and ``false`` otherwise.

.. expression:: $setDifference

   Takes two arrays and returns an array containing the elements that
   only exist in the first array.

.. expression:: $setIntersection

   Takes any number of arrays and returns an array that contains the
   elements that appear in every input array.

.. expression:: $setUnion

   Takes any number of arrays and returns an array that containing the
   elements that appear in any input array.

.. expression:: $allElementsTrue

   Takes a single expression that returns an array and returns ``true``
   if all its values are ``true`` and ``false`` otherwise. An empty
   array returns ``true``.

   :expression:`$anyElementsTrue` was ``$all`` in versions of 2.5
   before 2.5.3.

.. expression:: $anyElementTrue

   Takes a single expression that returns an array and returns ``true``
   if any of its values are ``true`` and ``false`` otherwise. An empty
   array returns ``false``.

   :expression:`$anyElementTrue` was ``$any`` in versions of 2.5 before
   2.5.3.

``$map`` and ``$let`` Expressions in Aggregation Pipeline Stages
````````````````````````````````````````````````````````````````

.. tip:: For :expression:`$let` and :expression:`$map`, the
   aggregation framework introduces variables. To specify a variable,
   use the name of the variable prefixed by **2** dollar signs
   (i.e. ``$$``) as in: ``$$<name>``.

The :expression:`$let` and :expression:`$map` make it possible to
declare and manipulate variables within an aggregation pipeline
stages, specifically the :pipeline:`$project`, :pipeline:`$group`, and
:pipeline:`$redact` stages. See: :doc:`/reference/operator/aggregation/let` and
:doc:`/reference/operator/aggregation/map` for more information.

``$literal`` Expression for Aggregation Pipeline Stages
```````````````````````````````````````````````````````

The new :expression:`$literal` operator allows users to explicitly
specify documents in aggregation operations that the pipeline stage
would otherwise interpret directly. See
:doc:`/reference/operator/aggregation/literal` for more information.

``explain`` Option for the Aggregation Pipeline
```````````````````````````````````````````````

The new ``explain`` option for aggregation provides information about
how the command processes the pipeline. The returned document contains
information on each stage of the pipeline.

The intended readers of the ``explain`` output document are humans, and
not machines, and the output format is subject to change between
releases.

To use ``explain``, specify ``explain: true`` as the :ref:`second
parameter <aggregation-method-change>` to the
:method:`db.collection.aggregate()` helper:

.. include:: /includes/important-uses-new-aggregate-helper.rst

.. code-block:: javascript

   db.collection.aggregate( [ <pipeline operations> ],
                            {explain: true }
                          )

.. example::

   In the :program:`mongo` shell, given the following aggregation

   .. code-block:: javascript

      db.records.aggregate(
                            [ { $sort: { name : -1 } },
                              { $limit: 5 }
                            ],
                            { explain: true }
                          )

   The returned document provides information on how
   :dbcommand:`aggregate` processed the pipeline. For this example, the
   returned document may show, among other details, which index, if
   any, the operation used. If the operation did not use an index and
   since the :pipeline:`$sort` immediately precedes the
   :pipeline:`$limit`, the output would show the :pipeline:`$sort`
   operation only maintaining the top 5 results as it progresses rather
   than sorting all input documents. If the ``record`` collection is a
   sharded collection, the output also shows the division of labor
   between the shards and the merge,, and for targeted queries, shows
   the targeted shards.

For the :dbcommand:`aggregate` command, add the ``explain: true`` to the
command, as shown:

.. code-block:: javascript

   db.runCommand( { aggregate: "<collection>",
                    explain: true,
                    pipeline: [ <pipeline operations> ] } )


``$cond`` Accepts Objects as Arguments
``````````````````````````````````````

.. versionadded:: 2.5.3

The ternary :expression:`$cond` expression can now take either an object
or an array. Previously :expression:`$cond` always took an array. See
:doc:`/reference/operator/aggregation/cond` for more information.

New ``$size`` Operator for the Aggregation Pipeline
```````````````````````````````````````````````````

.. include:: /includes/important-uses-new-aggregate-helper.rst

.. versionadded:: 2.5.3

The new :expression:`$size` operator for the :doc:`aggregation
pipeline </core/aggregation-pipeline>` returns the size of a specified
array. See :doc:`/reference/operator/aggregation/size` for more
information.

Write Operation Improvements
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded 2.5.3

MongoDB has updated the wire protocol to include new ``insert``,
``update``, and ``delete`` commands for batch operations. You may
specify a single write concern for each batch of writes. The new
commands support a number of other configuration options including
the ability to proceed if any individual write fails.

MongoDB also introduces new changes to the update language:

``$mul`` Update Operator
````````````````````````

The new :update:`$mul` operator allows you to multiply the value of a
field by the specified amount. See :update:`$mul` for details.

``xor`` operation for ``$bit`` Operator
```````````````````````````````````````

The :update:`$bit` operator now supports bitwise updates using a logical
``xor`` operation. See the documentation of :update:`$bit` for more
information on bitwise updates. Consider the following operation:

``$min`` Update Operator
````````````````````````

The new :update:`$min` operator updates the value of the field to a
specified value *if* the specified value is **less than** the current
value of the field. See :update:`$min` for details.

``$max`` Update Operator
````````````````````````

The new :update:`$max` operator updates the value of the field to a
specified value *if* the specified value is **greater than** the
current value of the field. See :update:`$max` for details.

``$currentDate`` Update Operator
````````````````````````````````

The :update:`$currentDate` operator sets the value of a field to the
current date, either as a :ref:`Date <document-bson-type-date>` or a
:ref:`timestamp <document-bson-type-timestamp>`. See
:update:`$currentDate` for details.

Enhanced Modifiers for ``$push`` Update Operator
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionchanged:: 2.5.3

The :update:`$push` operator has enhanced support for the
:update:`$sort`, :update:`$slice`, and :update:`$each` modifiers
to increase functionality and usability. MongoDB also provides a new
:update:`$position` modifier for the :update:`$push` operator.

``$each`` Modifier Changes
``````````````````````````

When used in conjunction with the :update:`$sort`, the
:update:`$slice`, and the :update:`$position` modifiers, the
:update:`$each` modifier no longer needs to be the first modifier for
the :update:`$push`.

``$sort`` Modifier Enhancements
```````````````````````````````

The :update:`$sort` modifier can sort the array elements as a whole.
This change means that the :update:`$sort` modifier can now sort
array elements that are not documents. Or, if the array elements are
documents, the modifier can sort by the whole documents, and not just
by the field in the documents. The :update:`$sort` no longer requires
the :update:`$slice` modifier. See :update:`$sort` for details.

``$slice`` Modifier Enhancements
````````````````````````````````

The :update:`$slice` modifier can accept positive numbers to slice
from the front of the array. See :update:`$slice` for details.

``$position`` Modifier
``````````````````````

The :update:`$position` modifier specifies the insert position for
the :update:`$push` operator. See :update:`$position`.

Sharding Improvements
~~~~~~~~~~~~~~~~~~~~~

Support for Removing Orphan Data From Shards
````````````````````````````````````````````

.. versionadded:: 2.5.2

The new :dbcommand:`cleanupOrphaned` is available to remove orphaned
data from a sharded cluster. Orphaned data are those documents in a
collection that exist on shards that belong to another shard in the
cluster. Orphaned data are the result of failed migrations or incomplete
migration cleanup due to abnormal shutdown.

.. dbcommand:: cleanupOrphaned

   :dbcommand:`cleanupOrphaned` removes documents from *one* orphaned
   chunk range on shard and runs directly on the shard's
   :program:`mongod` instance, and requires the
   :authrole:`clusterAdmin` for systems running with :setting:`auth`.
   You do **not** need to disable the :term:`balancer` to run
   :dbcommand:`cleanupOrphaned`.

   In the common case, :dbcommand:`cleanupOrphaned` takes the
   following form:

   .. code-block:: javascript

      { cleanupOrphaned: <namespace>, startingFromKey: { } }

   The ``startingFromKey`` field specifies the lowest value of the
   :term:`shard key` to begin searching for orphaned data. The empty
   document (i.e. ``{ }``) is equivalent to the minimum value for the
   shard key (i.e. ``$minValue``).

   The :dbcommand:`cleanupOrphaned` command returns a document that
   contains a field named ``stoppedAtKey`` that you can use to
   construct a loop, as in the following example in the
   :program:`mongo` shell:

   .. code-block:: javascript

      db = db.getSiblingDB("admin")

      var nextKey = {};

      while (
         nextKey = db.runCommand( { cleanupOrphaned : "test.user", startingFromKey : nextKey } ).stoppedAtKey
         ) { printjson(nextKey); }

   This loop removes all orphaned data on the shard.

Ability to Merge Co-located Contiguous Chunks
`````````````````````````````````````````````

.. versionadded:: 2.5.2

The :dbcommand:`mergeChunks` provides the ability for users to combine
contiguous chunks located on a single shard. This makes it possible to
combine chunks in situations where document removal leaves a sharded
collection with too many empty chunks.

See :doc:`/reference/command/mergeChunks` for more information and
:doc:`/tutorial/merge-chunks-in-sharded-cluster` for full
documentation of this operation.

.. _collection-level-access-control:

Collection-Level Access Control
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB 2.5.3 provides the ability to specify user privileges at a
collection-level granularity. To specify collection-level access
control, create a custom role that pairs its actions to a particular
collection in a specific database in the :ref:`resource document
<resource-document>`. The MongoDB :doc:`built-in roles
</reference/user-privileges>` grant privileges at a database-level
only, and thus cannot be used to control privileges at the
collection-level.

See :ref:`user-defined-roles` for more information.

.. _user-defined-roles:

User Defined Roles
~~~~~~~~~~~~~~~~~~

.. important:: For authentication/authorization, the 2.5.3 release does not
   offer an automatic upgrade process to go from version 2.4 model for
   user credentials and privileges to the 2.5.3 model. See
   :ref:`authentication-incompatibility`.

MongoDB provides the ability to create custom user roles in addition to
the roles provided by MongoDB. In addition, MongoDB now provides global
user management, storing all user and user-defined role data in the
admin database and providing a new set of commands for managing users
and roles.

For more information on the new authentication model, see
:doc:`/reference/user-privileges`.

SSL Improvements
~~~~~~~~~~~~~~~~

Optionally Prompt for SSL Certificate Passphrases at Server Startup
```````````````````````````````````````````````````````````````````

In MongoDB 2.6, a :program:`mongod` or :program:`mongos` can now
interactively prompt the user at startup to enter the passphrase for the
locally encrypted SSL key. This provides an alternative to providing a
cleartext passphrase on the command line or in a configuration file.

The passphrase prompt option is available if you run the MongoDB instance in the
foreground with a connected terminal. The prompt will not work if you run the
process in a non-interactive session (e.g. without a terminal or as a
service on Windows).

To receive the passphrase prompt, start the MongoDB instance with the
``.pem`` file that contains the SSL certificate and key but *do not*
specify the passphrase. MongoDB interactively prompts
for a passphrase.

You can use the passphrase prompt with both the :setting:`sslPEMKeyFile`
option and the new :setting:`sslClusterFile` option (see
:ref:`rn26-x509-authentication`).

For the :setting:`sslPEMKeyFile` option, specify the encrypted SSL
private key/certificate ``.pem`` file with :setting:`sslPEMKeyFile` but
do not specify an :setting:`sslPEMKeyPassword`.

For the :setting:`sslClusterFile` option, specify an x.509 certificate-and-key
``.pem`` file with :setting:`sslClusterFile` but do not specify an
:setting:`sslClusterPassword`.

For instructions on configuring SSL see :doc:`/tutorial/configure-ssl`.

Tools Now Support SSL
`````````````````````

.. versionadded:: 2.5.3

MongoDB programs add support for connecting to :program:`mongod` and
:program:`mongos` instances using SSL connection. See
:doc:`/tutorial/configure-ssl` for more information
Tools with SSL support include:

- :program:`mongodump`
- :program:`mongoexport`
- :program:`mongofiles`
- :program:`mongoimport`
- :program:`mongooplog`
- :program:`mongorestore`
- :program:`mongostat`
- :program:`mongotop`

.. tip:: To use SSL connections with these tools, use the same
   SSL options as the :program:`mongo` shell.

MongoDB Allows Only Strong SSL Ciphers
``````````````````````````````````````

.. DOCS-1921

MongoDB's SSL encryption only allows use of strong SSL ciphers, with a minimum
of 128-bit key length for all connections.

The strong-cipher requirement prevents an old or malicious client from forcing
use of a weak cipher.

Support for SSL and non-SSL Connections on the Same Port
````````````````````````````````````````````````````````

.. merge this under the new ~~~ header created by DOCS-1921

.. DOCS-1941

.. draft, waiting for feature complete before sending to technical review

MongoDB supports mixed SSL and non-SSL connections on the same port to
allow upgrades to SSL without forcing downtime. MongoDB provides
a new command-line option and server command that configure a server
port to allow unencrypted internal connections while maintaining
encrypted external connections.

To use such mixed SSL modes on a port, you must restrict access at the
network level. You cannot at this time restrict encryption based on
MongoDB user or role. Outgoing connections from the MongoDB server
cannot choose encryption based on connection target.

You can only increase security level on a server. Changing a server's
listening behavior does not require a restart of the server.

The --sslMode Command-Line Option
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

MongoDB provides the following new server command-line option to handle
mixed SSL mode:

.. code-block:: sh

   --sslMode <parameter>

The value of ``<parameter>`` is one of the following:

- ``noSSL``. The server does not use SSL.

- ``sslOnly``. The server uses only SSL.

- ``acceptSSL``. Outgoing connections do not use SSL. For incoming
  connections, the server accepts both SSL and non-SSL.

- ``sendAcceptSSL``. Outgoing connections use SSL. For incoming
  connections, the server accepts both SSL and non-SSL.

Upgrade a Cluster to Use SSL
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To upgrade from a MongoDB cluster using no SSL encryption to one using
*only* SSL encryption, do the following:

1. Perform a rolling upgrade to MongoDB 2.6 on all nodes, and activate
   mixed-mode SSL by using the ``--sslMode`` command-line option
   set to ``acceptSSL``:

  .. code-block:: javascript

     --sslMode=acceptSSL

2. Switch all clients to use SSL.

3. Switch all outgoing server connections to use SSL by restarting each server
   with the ``--sslMode`` option set to ``sendAcceptSSL``.

   At this point, all connections should be using SSL.

4. Switch all servers to accept only SSL connections by restarting each server
   with the ``--sslMode`` option set to ``sslOnly`` parameter on each server.

.. _rn26-x509-authentication:

x.509 Authentication
````````````````````

MongoDB introduces :doc:`x.509 certificate authentication
</tutorial/configure-x509>` for use with a secure :doc:`SSL connection
</tutorial/configure-ssl>`.

.. important:: To use SSL, you must either use MongoDB Enterprise or
   build MongoDB locally using ``scons`` with the ``--ssl`` option.

The x.509 authentication allows clients to authenticate to servers with
certificates instead of with username and password. The x.509
authentication also allows sharded cluster members and replica set
members to use x.509 certificates to verify their membership to the
cluster or the replica set instead of using key files. The membership
authentication is an internal process.

The change for x.509 authentication introduces a new ``MONGODB-X509``
protocol. For internal authentication for membership, the change also
introduces the :option:`--clusterAuthMode`, :option:`--sslClusterFile` and the
:option:`--sslClusterPassword` options.

For details on x.509 certificate authentication, see
:doc:`/tutorial/configure-x509`.

Index Building Improvements
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Background Index Builds Replicate to Secondaries
````````````````````````````````````````````````

Starting in MongoDB 2.5.0, if you initiate a :ref:`background index
build <index-creation-background>` on a :term:`primary`, the
secondaries will replicate the index build in the background.
In previous versions of MongoDB, secondaries built all indexes in the
foreground, even if the primary built an index in the background.

For all index builds, secondaries will not begin building indexes
until the primary has successfully completed the index build.

``mongod`` Automatically Continues in Progress Index Builds Following Restart
`````````````````````````````````````````````````````````````````````````````

If your :program:`mongod` instance was building an index when it
shutdown or terminated, :program:`mongod` will now continue building
the index when the :program:`mongod` restarts. Previously, the index
build *had* to finish building before :program:`mongod` shutdown.

To disable this behavior the 2.5 series adds a new run time option,
:setting:`noIndexBuildRetry` (or via, ``--noIndexBuildRetry`` on the
command line,) for :program:`mongod`. :setting:`noIndexBuildRetry`
prevents :program:`mongod` from continuing rebuilding indexes that did
not finished building when the :program:`mongod` last shut down.

Tool Improvements
~~~~~~~~~~~~~~~~~

Global ``mongorc.js`` File
``````````````````````````

If the file :file:`mongorc.js` exists in the :file:`/etc` directory (or
:file:`%ProgramData%\\MongoDB` directory on Windows), the
:program:`mongo` shell evaluates the contents of this file on start-up.
Then, the :program:`mongo` shell evaluates the user's
:file:`.mongorc.js` file if the file exists in the user's :envvar:`HOME
directory`.

The :option:`--norc` option for :program:`mongo` suppresses only the
user's :file:`.mongorc.js` file.

.. important::
   The :file:`mongorc.js` in :file:`/etc` directory must have read
   permission for the user running the shell.

Support for ``--quiet`` Option for all Tools
````````````````````````````````````````````

.. versionadded:: 2.5.0

All MongoDB :doc:`executable files </reference/program>` now support
the ``--quiet`` option. This option suppresses all logging output
except for error messages.

``mongoimport`` Uses Filename If Collection Name Is Not Specified
`````````````````````````````````````````````````````````````````

.. versionadded:: 2.5.3

When invoked without the ``-c`` or ``--collection`` command-line argument,
the :program:`mongoimport` tool uses the input filename as the name
of the collection. MongoDB omits the extension of the file from the
collection name if the input file has an extension.

.. example::

   The following command imports data from the ``contacts.csv`` file
   into the ``contacts`` collection:

   .. code-block:: none

      mongoimport --db users --type csv --file /opt/backups/contacts.csv

   To specify the collection to import, use the ``-c`` or
   ``--collection`` option:

   .. code-block:: none

      mongoimport --db users --collection contacts --type csv --file /opt/backups/contacts.csv

``mongostat`` Can Support ``--rowcount`` Option with ``--discover`` Option
``````````````````````````````````````````````````````````````````````````

.. versionadded:: 2.5.3

The :program:`mongostat` program now produces the specified
number of lines of output when using :option:`--rowcount` (:option:`-n`)
with the :option:`--discover` option. In earlier versions of
:program:`mongostat`, the :option:`--discover` option would override
:option:`--rowcount`, and would continue to produce output until the
user terminated the program.

Limit for ``maxConns`` Removed
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Starting in MongoDB 2.5.0, there is no longer any upward limit for the
:setting:`maxConns`, or :program:`mongod --maxConns` and
:program:`mongos --maxConns` options. Previous versions capped the
maximum possible :setting:`maxConns` setting at ``20,000``
connections.

See :setting:`maxConns`.

Geospatial Enhancements
~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.2

MongoDB added support for the following `GeoJSON
<http://geojson.org/geojson-spec.html>`_ object types for use with
:doc:`2dsphere indexes </core/2dsphere>`:

- `MultiPoint <http://geojson.org/geojson-spec.html#id5>`_

- `MultiLineString <http://geojson.org/geojson-spec.html#id6>`_

- `MultiPolygon <http://geojson.org/geojson-spec.html#id7>`_

- `GeometryCollection <http://geojson.org/geojson-spec.html#geometrycollection>`_

C++ Driver Enhancement
~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.0

The C++ driver now monitors :term:`replica set` health with the
:dbcommand:`isMaster` command instead of :dbcommand:`replSetGetStatus`.
This allows the C++ driver to support systems that have access control
enabled.

MSI Package for MongoDB Available for Windows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

MongoDB now distributes MSI packages for Microsoft Windows. This is the
recommended method for MongoDB installation under Windows.

New Replica Set Status Methods
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB provides two additional methods to provide information
regarding the status of a :term:`replica set`:
:method:`rs.printReplicationInfo()` and
:method:`rs.printSlaveReplicationInfo()`.

The :method:`rs.printReplicationInfo()` method provides a formatted
report of the status of a :term:`replica set` from the perspective of
the primary set member. The output is identical to that of the
:method:`db.printReplicationInfo()` method.

The :method:`rs.printSlaveReplicationInfo()` method provides a
formatted report of the status of a :term:`replica set` from the
perspective of a secondary set member. The output is identical to that
of the :method:`db.printSlaveReplicationInfo()` method.

MongoDB Enterprise Features
---------------------------

Support for Auditing
~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

.. important:: Auditing, like all new features in 2.5.3, is in ongoing
   development. Specifically, the interface, output format, audited
   events and the structure of audited events will change
   significantly in the 2.5 series before the release of 2.6.

MongoDB Enterprise adds features to audit server and client activity
for :program:`mongod` and :program:`mongos` instances. See
:ref:`auditing` for details.

MongoDB Enterprise for Windows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

MongoDB Enterprise for Windows is now available. It includes advanced
Kerberos security, SSL, and SNMP support.

.. include:: /includes/admonition-mongodb-enterprise-windows-ldap.rst

SASL Library Change
~~~~~~~~~~~~~~~~~~~

MongoDB Enterprise uses Cyrus SASL instead of GNU SASL (``libgsasl``).
This change has the following SASL2 and Cyrus SASL library and GSSAPI
plugin dependencies:

For Debian or Ubuntu, install the following:

.. code-block:: sh

   sudo apt-get install cyrus-sasl2-dbg cyrus-sasl2-mit-dbg libsasl2-2 libsasl2-dev libsasl2-modules libsasl2-modules-gssapi-mit

For CentOS, Red Hat Enterprise Linux, and Amazon AMI, install the
following:

.. code-block:: sh

   sudo yum install cyrus-sasl cyrus-sasl-lib cyrus-sasl-devel cyrus-sasl-gssapi

For SUSE, install the following:

.. code-block:: sh

   sudo zypper install cyrus-sasl cyrus-sasl-devel cyrus-sasl-gssapi

LDAP Support for Authentication
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB Enterprise provides support for proxy authentication of users.
This allows administrators to configure a MongoDB cluster to
authenticate users via Linux PAM or by proxying authentication requests
to a specified Lightweight Directory Access Protocol (LDAP) service.
See :doc:`/tutorial/configure-ldap-sasl-authentication`.

.. include:: /includes/admonition-mongodb-enterprise-windows-ldap.rst

Expanded SNMP Support
~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 2.5.3

MongoDB Enterprise has greatly expanded its SNMP support. Enterprise
clients who need fine-grained server statistics now have SNMP access to
nearly the full range of metrics provided by
:dbcommand:`db.serverStatus()`.
