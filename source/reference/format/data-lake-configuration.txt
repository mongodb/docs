
.. _datalake-configuration-file:

=================================
{+data-lake-short+} Configuration
=================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. _datalake-configuration-file-overview:

Overview 
--------

The {+adl+} configuration is in |json| format. It contains mappings between 
your {+data-lake-stores+} and {+data-lake-short+}. {+dl+} supports |s3| 
buckets, |service| clusters, and publicly accessible |url|\s as 
{+data-lake-stores+}. You must define mappings in your {+dl+} to your |s3| 
bucket, |service| cluster, and |http| {+data-lake-stores+} to run queries.

Example Configuration for Individual Data Stores 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Click on the tab below to learn more about the {+dl+} configuration for that data store.

.. tabs:: 

   .. tab:: S3  
      :tabid: s3 

      .. example::

         Consider a S3 bucket ``datacenter-alpha`` containing data 
         collected from a datacenter:

         .. code-block:: none
            :copyable: false

            |--metrics
              |--hardware

         The ``/metrics/hardware`` path stores JSON files with metrics derived
         from the datacenter hardware, where each filename is the UNIX 
         timestamp in milliseconds of the 24 hour period covered by that file:

         .. code-block:: none
            :copyable: false

            /hardware/1564671291998.json

         The following configuration:

         - Defines a {+data-lake-store+} on the ``datacenter-alpha`` S3 bucket
           in the ``us-east-1`` AWS region. The {+data-lake-store+} is 
           specifically restricted to only datafiles in the ``metrics`` folder 
           path.

         - Maps files from the ``hardware`` folder to a MongoDB database
           ``datacenter-alpha-metrics`` and collection ``hardware``. The
           configuration mapping includes parsing logic for capturing the
           timestamp implied in the filename.

         .. code-block:: json

            {
              "stores" : [
                {
                  "name" : "datacenter-alpha",
                  "provider" : "s3",
                  "region" : "us-east-1",
                  "bucket" : "datacenter-alpha",
                  "additionalStorageClasses" : [
                    "STANDARD_IA"
                  ],
                  "prefix" : "/metrics",
                  "delimiter" : "/"
                }
              ],
              "databases" : [ 
                {
                  "name" : "datacenter-alpha-metrics", 
                  "collections" : [
                    {
                      "name" : "hardware",
                      "dataSources" : [
                        {
                          "storeName" : "datacenter-alpha",
                          "path" : "/hardware/{date date}"
                        }
                      ]
                    }
                  ]
                }
              ]
            }

         {+data-lake+} parses the S3 bucket ``datacenter-alpha`` and processes 
         all files under ``/metrics/hardware/``. The ``collections`` uses the 
         :ref:`path parsing syntax <datalake-path-syntax>` to map the filename 
         to the ``date`` field, which is an ISO-8601 date, in each document. 
         If a matching ``date`` field does not exist in a document, it will be 
         added.

         Users connected to the {+data-lake-short+} can use the MongoDB Query 
         Language and supported aggregations to analyze data in the |s3| 
         bucket through the ``datacenter-metrics.hardware`` collection.

      .. seealso:: 

         :ref:`query-s3`

   .. tab:: Atlas  
      :tabid: atlas 

      .. note:: 

         To use |service| as a {+data-lake-store+}, {+dl+} requires ``M10`` or 
         higher cluster.

      .. example:: 

         Consider a ``M10`` or higher |service| cluster named ``myDataCenter`` 
         containing data in the ``metrics.hardware`` collection. The ``metrics.
         hardware`` collection contains JSON documents with metrics derived 
         from the hardware in a datacenter. The following configuration:

         - Specifies the |service| cluster named ``myDataCenter`` in the 
           specified project as a {+data-lake-store+}.

         - Maps documents from the ``metrics.hardware`` collection in the 
           |service| cluster to the ``dataCenter.inventory`` collection in the 
           storage configuration.

         .. code-block:: json 

            {
              "stores" : [
                {
                  "name" : "atlasClusterStore",
                  "provider" : "atlas",
                  "clusterName" : "myDataCenter",
                  "projectId" : "5e2211c17a3e5a48f5497de3"
                }
              ],
              "databases" : [ 
                {
                  "name" : "dataCenter", 
                  "collections" : [
                    {
                      "name" : "inventory",
                      "dataSources" : [
                        {
                          "storeName" : "atlasClusterStore",
                          "database" : "metrics",
                          "collection" : "hardware"
                        }
                      ]
                    }
                  ]
                }
              ]
            }

         {+data-lake+} maps all the documents in the ``metrics.hardware`` 
         collection to the ``dataCenter.inventory`` collection in the storage 
         configuration.

         Users connected to the {+data-lake-short+} can use the MongoDB Query 
         Language and supported aggregations to analyze data in the |service| 
         cluster through the ``dataCenter.inventory`` collection. When you run 
         queries, the query first goes to {+adl+}. Therefore, if you run 
         aggregation queries that are supported by your |service| cluster but 
         not by {+adl+}, the queries will fail. To learn more about supported 
         and unsupported commands in {+dl+}, see :ref:`data-lake-mql-support`.

      .. seealso:: 

         :ref:`query-atlas`

   .. tab:: HTTP  
      :tabid: http 

      .. include:: /includes/extracts/fact-http-beta-message.rst

      Consider |url|\s ``https://www.datacenter-hardware.com/data.json``, 
      ``https://www.datacenter-software.com/data.json``, and
      ``https://www.datacenter-metrics.com/data.json`` containing data 
      collected from a datacenter. The following configuration:

      - Specifies the publicly accessible URLs that contain data in files as a 
        {+data-lake-store+}. 

      - Creates a partition for each |url|.

      .. code-block:: json 

         {
           "stores" : [
             {
               "name" : "httpStore",
               "provider" : "http",
               "allowInsecure" : false,
               "urls" : [
                 "https://www.datacenter-hardware.com/data.json",
                 "https://www.datacenter-software.com/data.json"
               ],
               "defaultFormat" : ".json"
             }
           ],
           "databases" : [ 
             {
               "name" : "dataCenter", 
               "collections" : [
                 {
                   "name" : "inventory",
                   "dataSources" : [
                     {
                       "storeName" : "httpStore",
                       "allowInsecure" : false,
                       "urls" : [
                         "https://www.datacenter-metrics.com/data"
                       ],
                       "defaultFormat" : ".json"
                     }
                   ]
                 }
               ]
             }
           ]
         }

      .. seealso:: 

         :ref:`query-http`

Example Configuration for Running Federated Queries 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can define mappings between your |s3|, |service| cluster, and |http|  
{+data-lake-stores+} and {+data-lake-short+} in the storage configuration 
to run federated queries. 

.. example::

   For the preceding sample |s3|, |service| cluster, and |http| 
   {+data-lake-stores+}, the {+dl+} configuration for federated queries 
   resembles the following:

   .. code-block:: json

      {
        "stores" : [
          {
            "name" : "datacenter-alpha",
            "provider" : "s3",
            "region" : "us-east-1",
            "bucket" : "datacenter-alpha",
            "additionalStorageClasses" : [
              "STANDARD_IA"
            ],
            "prefix" : "/metrics",
            "delimiter" : "/"
          },
          {
            "name" : "atlasClusterStore",
            "provider" : "atlas",
            "clusterName" : "myDataCenter",
            "projectId" : "5e2211c17a3e5a48f5497de3"
          },
          {
            "name" : "httpStore",
            "provider" : "http",
            "allowInsecure" : false,
            "urls" [
              "https://www.datacenter-hardware.com/data.json",
              "https://www.datacenter-software.com/data.json"
            ],
            "defaultFormat" : ".json"
          }
        ],
        "databases" : [ 
          {
            "name" : "datacenter-metrics", 
            "collections" : [
              {
                "name" : "inventory",
                "dataSources" : [
                  {
                    "storeName" : "datacenter-alpha",
                    "path" : "/hardware/{date date}"
                  },
                  {
                    "storeName" : "atlasClusterStore",
                    "database" : "metrics",
                    "collection" : "hardware"
                  },
                  {
                    "storeName" : "httpStore",
                    "allowInsecure" : false,
                    "urls": [
                      "https://www.datacenter-metrics.com/data.json"
                    ],
                    "defaultFormat" : ".json"
                  }
                ]
              }
            ]
          }
        ]
      }

.. important:: 

   If the database in the storage configuration contains collections 
   from |s3|, |service|, and |http| {+data-lake-stores+}, the query results 
   might contain data from all the {+data-lake-stores+}.

.. seealso:: 

   :ref:`federated-queries`

.. _datalake-configuration-format:

Configuration Format
--------------------

The {+data-lake-short+} configuration has the following format:

.. tabs:: 
   :hidden:

   .. tab:: S3  
      :tabid: s3

      .. code-block:: json

         {
           "stores" : [
             {
               "name" : "<string>",
               "provider": "<string>",
               "region" : "<string>", 
               "bucket" : "<string>",
               "additionalStorageClasses" : ["<string>"],
               "prefix" : "<string>", 
               "includeTags": <boolean>, 
               "delimiter": "<string>"
             }
           ],
             "databases" : [
               {
                 "name" : "<string>",
                 "collections" : [
                   {
                     "name" : "<string>",
                     "dataSources" : [
                       {
                         "storeName" : "<string>",
                         "path" : "<string>",
                         "defaultFormat" : "<string>" 
                       }
                     ]
                   }
                 ],
                 "maxWildcardCollections" : <integer>,
                 "views" : [ 
                   {
                     "name" : "<string>", 
                     "source" : "<string>", 
                     "pipeline" : "<string>" 
                   }
                 ] 
               }
             ]
           }

   .. tab:: Atlas Cluster 
      :tabid: atlas 

      .. code-block:: json

         {
           "stores" : [
             {
               "name" : "<string>",
               "provider": "<string>",
               "clusterName": "<string>", 
               "projectId": "<string>"
             }
           ],
             "databases" : [
               {
                 "name" : "<string>",
                 "collections" : [
                   {
                     "name" : "<string>",
                     "dataSources" : [
                       {
                         "storeName" : "<string>",
                         "database" : "<string>",
                         "collection" : "<string>" 
                       }
                     ]
                   }
                 ],
                 "views" : [ 
                   {
                     "name" : "<string>", 
                     "source" : "<string>", 
                     "pipeline" : "<string>" 
                   }
                 ] 
               }
             ]
           }

   .. tab:: HTTP 
      :tabid: http 

      .. code-block:: json

         {
           "stores" : [
             {
               "name" : "<string>",
               "provider": "<string>",
               "defaultFormat" : "<string>",
               "allowInsecure": <boolean>,
               "urls": ["<string>"]
             }
           ],
             "databases" : [
               {
                 "name" : "<string>",
                 "collections" : [
                   {
                     "name" : "<string>",
                     "dataSources" : [
                       {
                         "storeName" : "<string>",
                         "allowInsecure" : <boolean>,
                         "urls" : ["<string>"],
                         "defaultFormat" : "<string>"
                       }
                     ]
                   }
                 ],
                 "views" : [ 
                   {
                     "name" : "<string>", 
                     "source" : "<string>", 
                     "pipeline" : "<string>" 
                   }
                 ] 
               }
             ]
           }

:ref:`datalake-stores-reference`
  The ``stores`` object defines each {+data-lake-store+} associated
  to the {+data-lake-short+}. {+data-lake-short+} can only access
  {+data-lake-stores+} defined in the ``stores`` object.

:ref:`datalake-databases-reference`
  The ``databases`` object defines the mapping between each
  {+data-lake-store+} defined in ``stores`` and MongoDB collections 
  in the databases. 

.. _datalake-stores-reference:

``stores``
~~~~~~~~~~

.. tabs:: 
   :hidden:

   .. tab:: S3  
      :tabid: s3

      .. code-block:: json

         "stores" : [
           {
             "name" : "<string>",
             "provider" : "<string>",
             "region" : "<string>",
             "bucket" : "<string>",
             "additionalStorageClasses" : ["<string>"],
             "prefix" : "<string>",
             "delimiter" : "<string>",
             "includeTags": <boolean>
           }
         ]

   .. tab:: Atlas Cluster
      :tabid: atlas

      .. code-block:: json 

         "stores" : [
           {
             "name" : "<string>",
             "provider" : "<string>",
             "clusterName" : "<string>",
             "projectId": "<string>"
           }
         ]

   .. tab:: HTTP
      :tabid: http

      .. code-block:: json 

         "stores" : [
           {
             "name" : "<string>",
             "provider" : "<string>",
             "allowInsecure" " <boolean>,
             "urls" : ["<string>"],
             "defaultFormat" : "<string>"
           }
         ]

.. datalakeconf:: stores

   The ``stores`` object defines an array of {+data-lake-stores+} associated 
   with a {+data-lake-short+}. The {+data-lake-store+} captures files in an S3 
   bucket, documents in |service| cluster, or files stored at publicly 
   accessible |url|\s. An {+adl+} can only access {+data-lake-stores+} defined 
   in the ``stores`` object.

.. datalakeconf:: stores.[n].name

   Name of the {+data-lake-store+}. The
   :datalakeconf:`databases.[n].collections.[n].dataSources.[n].storeName`
   field references this value as part of mapping configuration.

.. datalakeconf:: stores.[n].provider

   Defines where the data is stored. Value can be one of the following: 
   
   - ``s3`` for an |aws| |s3| bucket.
   - ``atlas`` for a collection in an |service| cluster.
   - ``http`` for data in files hosted at publicly accessible |url|\s.

.. tabs:: 
   :hidden:

   .. tab:: S3  
      :tabid: s3

      .. datalakeconf:: stores.[n].region

         Name of the |aws| region in which the S3 bucket is hosted. For
         a list of valid region names, see :atlas:`Amazon Web Services 
         (AWS) </reference/amazon-aws/#amazon-aws>`. 

      .. datalakeconf:: stores.[n].bucket

         Name of the |aws| S3 bucket. Must exactly match the name of an S3
         bucket which {+data-lake-short+} can access given the
         configured |aws| IAM credentials.

      .. datalakeconf:: stores.[n].additionalStorageClasses

         *Optional.* Array of |aws| |s3| `storage classes 
         <https://aws.amazon.com/s3/storage-classes/>`__. {+adl+} will 
         include the files in these storage classes in the query results. 
         Valid values are: 

         - ``INTELLIGENT_TIERING`` to include files in the `Intelligent 
           Tiering <https://aws.amazon.com/s3/storage-classes/#Unknown_or_changing_access>`__ 
           storage class
         - ``STANDARD_IA`` to include files in the `Standard-Infrequent Access 
           <https://aws.amazon.com/s3/storage-classes/#Infrequent_access>`__ 
           storage class

         .. note:: 

            Files in the `Standard 
            <https://aws.amazon.com/s3/storage-classes/#General_purpose>`__ 
            storage class are supported by default.

      .. datalakeconf:: stores.[n].prefix

         *Optional.* Prefix {+data-lake-short+} applies when searching for 
         files in the S3 bucket. 

         For example, consider an S3 bucket ``metrics`` with the following 
         structure:

         .. code-block:: text
            :copyable: false

            metrics
              |--hardware
              |--software
                 |--computed

         The {+data-lake-store+} prepends the value of ``prefix`` to the
         :datalakeconf:`databases.[n].collections.[n].dataSources.[n].path` 
         to create the full path for files to ingest. Setting the ``prefix``
         to ``/software`` restricts any :datalakeconf:`databases` 
         objects using the {+data-lake-store+} to only subpaths 
         ``/software``.

         If omitted, {+data-lake-short+} searches all files from the
         root of the S3 bucket.

      .. datalakeconf:: stores.[n].delimiter
   
         *Optional.* The delimiter that separates 
         :datalakeconf:`databases.[n].collections.[n].dataSources.[n].path` 
         segments in the {+data-lake-store+}. |data-lake| uses the delimiter 
         to efficiently traverse |s3| buckets with a hierarchical directory 
         structure. You can specify any character supported by the |s3| `object 
         keys <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html>`__ 
         as the delimiter. For example, you can specify an underscore (``_``) or a 
         plus sign (``+``) or multiple characters such as double underscores (``__``) 
         as the delimiter.

         If omitted, defaults to ``"/"``.

      .. datalakeconf:: stores.[n].includeTags

         *Optional.* Determines whether or not to use |s3| tags on the files in 
         the given path as additional partition attributes. Valid values are 
         ``true`` and ``false``. 

         If omitted, defaults to ``false``.

         If set to ``true``, {+data-lake-short+} does the following:

         - Adds the |s3| tags as additional partition attributes. 

         - Adds new top level BSON elements that associates each tag to each 
           document for the tagged files.

         .. warning::

            If set to ``true``, {+data-lake-short+} processes the files for 
            additional partition attributes by making extra calls to |s3| to get the 
            tags. This behavior might impact performance.

   .. tab:: Atlas Cluster
      :tabid: atlas

      .. datalakeconf:: stores.[n].clusterName 

         Name of the |service| cluster on which the store is based. Note that 
         the cluster must be a M10 or higher cluster and must exist in the same 
         project as your {+dl+}. The ``source`` field on the data partition is 
         the name of the |service| cluster.

      .. datalakeconf:: stores.[n].projectId 

         Unique identifier of the project that contains the |service| cluster 
         on which the store is based.

   .. tab:: HTTP  
      :tabid: http

      .. datalakeconf:: stores.[n].allowInsecure 

         .. include:: /includes/extracts/param-allow-insecure.rst

      .. datalakeconf:: stores.[n].urls

         *Optional.* Comma-separated list of publicly accessible 
         |http| |url|\s where data is stored. You can't specify |url|\s that 
         require authentication. If empty or omitted, the 
         :ref:`storageGenerateConfig <datalake-storagegenconfig>` command will 
         not generate any virtual {+adl+} databases or collections that 
         reference the {+data-lake-store+}.

      .. datalakeconf:: stores.[n].defaultFormat
      
         .. include:: /includes/extracts/param-default-format.rst

         The specified format only applies to the |url|\s specified in the 
         :datalakeconf:`stores` object.

         .. seealso:: 

            :ref:`data-lake-data-formats`

.. _datalake-databases-reference:

``databases``
~~~~~~~~~~~~~

.. tabs:: 
   :hidden:

   .. tab:: S3  
      :tabid: s3

      .. code-block:: json

         "databases" : [
           {
             "name" : "<string>",
             "collections" : [
               {
                 "name" : "<string>",
                 "dataSources" : [
                   {
                     "storeName" : "<string>",
                     "defaultFormat" : "<string>",
                     "path" : "<string>"
                   }
                 ]
               }
             ], 
             "maxWildcardCollections" : <integer>,
             "views" : [
               {
                 "name" : "<string>",
                 "source" : "<string>",
                 "pipeline" : "<string>"
               }
             ]
           }
         ]

   .. tab:: Atlas Cluster 
      :tabid: atlas

      .. code-block:: json

         "databases" : [
           {
             "name" : "<string>",
             "collections" : [
               {
                 "name" : "<string>",
                 "dataSources" : [
                   {
                     "storeName" : "<string>",
                     "database" : "<string>",
                     "collection" : "<string>"
                   }
                 ]
               }
             ]
           }
         ]

   .. tab:: HTTP 
      :tabid: http

      .. code-block:: json

         "databases" : [
           {
             "name" : "<string>",
             "collections" : [
               {
                 "name" : "<string>",
                 "dataSources" : [
                   {
                     "storeName" : "<string>",
                     "allowInsecure" : <boolean>,
                     "urls" : ["<string>"],
                     "defaultFormat" : "<string>"
                   }
                 ]
               }
             ]
           }
         ]

.. datalakeconf:: databases

   Array of objects where each object represents a database, its collections, 
   and, optionally, any :manual:`views </core/views/>` on the collections. Each 
   database can have multiple ``collections`` and ``views`` objects.

.. datalakeconf:: databases.[n].name

   Name of the database to which {+data-lake-short+} maps the
   data contained in the {+data-lake-store+}.  

.. datalakeconf:: databases.[n].collections

   Array of objects where each object represents a collection and data 
   sources that map to a :datalakeconf:`stores` {+data-lake-store+}.

.. datalakeconf:: databases.[n].collections.name

   Name of the collection to which {+data-lake-short+} maps the
   data contained in each
   :datalakeconf:`databases.[n].collections.[n].dataSources.[n].storeName`. 
   Each object in the array represents the mapping between the collection 
   and an object in the :datalakeconf:`stores` array. 

   .. tabs:: 
      :hidden:

      .. tab:: S3 
         :tabid: s3

         You can generate collection names dynamically from file paths by 
         specifying ``*`` for the collection name and the ``collectionName()`` 
         function in the 
         :datalakeconf:`~databases.[n].collections.[n].dataSources.[n].path`
         field. See :ref:`datalake-advanced-path-generate-collection` for examples. 

      .. tab:: Atlas Cluster 
         :tabid: atlas

         You can generate collection names dynamically by specifying ``*`` for 
         the collection name and omitting the 
         :datalakeconf:`~databases.[n].collections[n].dataSources.[n].collection` field. 

      .. tab:: HTTP 
         :tabid: http
         
         You cannot generate wildcard ``*`` collections.

.. datalakeconf:: databases.[n].collections.[n].dataSources 

   Array of objects where each object represents a :datalakeconf:`stores` 
   {+data-lake-store+} to map with the collection.

.. datalakeconf:: databases.[n].collections.[n].dataSources.[n].storeName

   Name of a {+data-lake-store+} to map to the ``<collection>``. 
   Must match the :datalakeconf:`~stores.[n].name` of an object in the 
   :datalakeconf:`stores` array. 

.. tabs:: 
   :hidden:

   .. tab:: S3 
      :tabid: s3

      .. datalakeconf:: databases.[n].collections.[n].dataSources.[n].path

         Controls how {+data-lake+} searches for and parses files in the
         :datalakeconf:`~databases.[n].collections.[n].dataSources.[n].storeName` 
         before mapping them to the ``<collection>``. {+data-lake-short+} 
         prepends the :datalakeconf:`stores.[n].prefix` to the ``path`` to 
         build the full path to search within. Specify ``/`` to capture all 
         files and folders from the ``prefix`` path.

         For example, consider an S3 bucket ``metrics`` with the following 
         structure:

         .. code-block:: text
            :copyable: false

            metrics
            |--hardware
            |--software
               |--computed

         A ``path`` of ``/`` directs {+data-lake-short+} to search
         all files and folders in the ``metrics`` bucket.

         A ``path`` of ``/hardware`` directs {+data-lake-short+} to
         search only that path for files to ingest.

         If the :datalakeconf:`~stores.[n].prefix` is ``software``,
         {+data-lake-short+} searches for files only in the path
         ``/software/computed``.

         Appending the ``*`` wildcard character to the path 
         directs {+data-lake-short+} to include all files and folders from 
         that point in the path. For example, ``/software/computed*``
         would match files like ``/software/computed-detailed``,
         ``/software/computedArchive``, and ``/software/computed/errors``.

         :datalakeconf:`~databases.[n].collections.[n].dataSources.[n].path`
         supports additional syntax for parsing filenames, including:

         - Generating document fields from filenames.
         - Using regular expressions to control field generation.
         - Setting boundaries for bucketing filenames by timestamp.
   
         See :ref:`datalake-path-syntax` for more information.

         .. include:: /includes/fact-path-delimiter.rst

      .. datalakeconf:: databases.[n].collections.[n].dataSources.[n].defaultFormat
      
         .. include:: /includes/extracts/param-default-format.rst

         .. seealso:: 

            :ref:`data-lake-data-formats`

      .. datalakeconf:: databases.[n].maxWildcardCollections 

         .. include:: /includes/extracts/param-max-wildcard-collections.rst 

   .. tab:: Atlas Cluster  
      :tabid: atlas 

      .. datalakeconf:: databases.[n].collections.[n].dataSources.[n].database 

         Name of the database on the |service| cluster that contains the 
         collection. 

      .. datalakeconf:: databases.[n].collections[n].dataSources.[n].collection 

         Name of the collection in the |service| cluster on which the 
         {+dl+} {+data-lake-store+} is based. When creating a wildcard 
         collection, this must not be specified.

   .. tab:: HTTP  
      :tabid: http 

      .. datalakeconf:: databases.[n].collections.[n].dataSources.[n].allowInsecure 

         .. include:: /includes/extracts/param-allow-insecure.rst

      .. datalakeconf:: databases.[n].collections.[n].dataSources.[n].urls 

         *Optional*. Comma-separated list of publicly accessible |url|\s 
         where the data is stored. {+dl+} creates a partition for each |url|. 
         You can specify |url|\s that are not in the 
         :datalakeconf:`~stores.[n].urls`; however, the collection will contain 
         a union of data from |url|\s in both the 
         :datalakeconf:`~stores.[n].urls` and 
         :datalakeconf:`~databases.[n].collections.[n].dataSources.[n].urls`. 
         If omitted, {+dl+} uses the :datalakeconf:`~stores.[n].urls` in the 
         specified :datalakeconf:`~databases.[n].collections.[n].dataSources.[n].storeName`.

      .. datalakeconf:: databases.[n].collections.[n].dataSources.[n].defaultFormat
      
         .. include:: /includes/extracts/param-default-format.rst

         The specified format only applies to the |url|\s specified in the 
         :datalakeconf:`databases.[n].collections.[n].dataSources` object.

         .. seealso:: 

            :ref:`data-lake-data-formats`

.. datalakeconf:: databases.[n].views 

   Array of objects where each object represents an :manual:`aggregation 
   pipeline </core/aggregation-pipeline/#id1>` on a collection. To learn 
   more about views, see :manual:`Views </core/views/>`.

.. datalakeconf:: databases.[n].views.[n].name 

   Name of the view. 

.. datalakeconf:: databases.[n].views.[n].source 

   Name of the source collection for the view.

.. datalakeconf:: databases.[n].views.[n].pipeline 
 
   :manual:`Aggregation pipeline stage(s) </core/aggregation-pipeline/#id1>` 
   to apply to the 
   :datalakeconf:`~databases.[n].views.[n].source` collection.

.. seealso::

   - :ref:`Configure Atlas Data Lake <config-datalake>` 
   - `Tutorial: Federated Queries and $out to S3 
     <https://developer.mongodb.com/how-to/atlas-data-lake-federated-queries-out-aws-s3>`__
