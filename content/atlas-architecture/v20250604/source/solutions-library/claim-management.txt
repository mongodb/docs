.. _arch-center-is-claim-management:

======================================================
Claims Management Using LLMs and Vector Search for RAG
======================================================

.. facet::
   :name: genre
   :values: tutorial

.. meta:: 
   :keywords: RAG, Atlas
   :description: Combine Atlas Vector Search and large language models to streamline the claim adjustment process.
   
.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Discover how to combine MongoDB Atlas Vector Search and Large Language Models
(LLMs) to streamline the claims adjustment process.

**Use cases:** `Gen AI <https://www.mongodb.com/use-cases/artificial-intelligence>`__, 
`Content Management <https://www.mongodb.com/solutions/use-cases/content-management>`__

**Industries:** `Insurance <https://www.mongodb.com/industries/insurance>`__,
`Finance <https://www.mongodb.com/industries/financial-services>`__,
`Manufacturing and Mobility <https://www.mongodb.com/industries/manufacturing>`__, 
`Retail <https://www.mongodb.com/industries/retail>`__

**Products:** `MongoDB Atlas <http://mongodb.com/atlas>`__, 
`MongoDB Atlas Vector Search <https://www.mongodb.com/products/platform/atlas-vector-search>`__

**Partners:** `LangChain <https://www.mongodb.com/developer/products/mongodb/langchain-vector-search/>`__, 
`FastAPI <https://www.mongodb.com/developer/technologies/fastapi/>`__

Solution Overview
-----------------

One of the biggest challenges for claims adjusters is aggregating information
from diverse systems and data formats. Over the years, insurance
companies have accumulated terabytes of `unstructured data
<https://www.mongodb.com/unstructured-data>`__ in their datastores, which can
help uncover business insights, deliver better customer experiences, and
streamline operations. However, many companies fail to capitalize on this.

To help your organization overcome these challenges, you can build a claims
management solution with MongoDB that combines `Atlas Vector Search
<https://www.mongodb.com/products/platform/atlas-vector-search>`__ and `LLMs
<https://www.mongodb.com/basics/large-language-models>`__ in a `retrieval
augmented generation (RAG)
<https://www.mongodb.com/basics/retrieval-augmented-generation>`__ system. This
framework helps organizations go beyond the limitations of basic foundational
models and use their proprietary data to make models context-aware, streamlining
operations with AI’s full potential.

Reference Architecture
----------------------

MongoDB provides a unified development experience by storing documents alongside
their vector embeddings and associated metadata, eliminating the need to
retrieve data elsewhere. This allows users to focus on building their
application instead of maintaining a separate technology. Ultimately, the data
obtained from MongoDB Vector Search is fed to the LLM as context.

The process of the RAG querying flow is as follows:

#. The user writes a prompt in natural language.

#. Voyage AI's embedding model vectorizes the prompt.

#. Atlas Vector Search uses the vectorized prompt to retrieve relevant
   documents.

#. LLM uses both the context and original question to generate an answer.

#. The user receives an answer.

.. figure:: /includes/images/industry-solutions/rag-querying-flow.svg
   :figwidth: 1200px
   :alt: RAG Querying Flow

   Figure 1. RAG querying flow

Data Model Approach
-------------------

In the demo solution, the data model is a simplified design that emulates
real-world insurance claim data. The approach leverages MongoDB's flexible
document model to handle the diverse data structure that stores embeddings
alongside their related document.

The ``claims_final`` collection stores claim information. The relevant fields
are the ``claimDescription`` field and its corresponding embedding
``claimDescriptionEmbedding``. This embedding is indexed and used to retrieve
documents associated with the user prompt. The documents in this collection are
as follows:

.. code-block:: javascript
          
   {
   "_id": {
      "$oid": "65cc809c76da22d0089dfb2e"
   },
   "customerID": "c105",
   "policyNumber": "p105",
   "claimID": "cl105",
   "claimStatusCode": "Subrogation",
   "claimDescription": "High winds caused ...",
   "totalLossAmount": 4200,
   "claimFNOLDate": "2023-10-27",
   "claimClosedDate": "2024-09-01",
   "claimLineCode": "Auto",
   "damageDescription": "Roof caved in ...",
   "insurableObject": {
      "insurableObjectId": "abc105",
      "vehicleMake": "Make105",
      "vehicleModel": "Model105"
   },
   "coverages": [
      {
         "coverageCode": "888",
         "description": "3rd party responsible"
      },
      {
         "coverageCode": "777",
         "description": "Vehicle rental/loaner service for customer"
      }
   ],
   "claimDescriptionEmbedding": [-0.017, ..., 0.011],
   "damageDescriptionEmbedding": [-0.047, ..., -0.043],
   "photo": "105.jpg",
   "photoEmbedding": [9.629, ..., 14.075]
   }

Build the Solution
------------------

For detailed setup instructions, follow the ``README`` of `this
GitHub repository <https://github.com/mongodb-industry-solutions/RAG-Insurance>`__.
The instructions guide you through the following steps:

.. procedure::
   :style: normal

   .. step:: Set up MongoDB database and collections

      Create a new database in MongoDB Atlas called ``demo_rag_insurance`` and
      use the provided dataset ``demo_rag_insurance_claims.json`` to create a
      collection called ``claims_final``.

   .. step:: Create a Vector Search Index

      Create and configure an :ref:`Atlas Vector Search index
      <atlas-ui-create-vector-search>` for ``claimDescriptionEmbeddingCohere``
      called ``vector_index_claim_description_cohere``. You must structure the
      search index as follows:

      .. code-block:: json
         :copyable: true 

         {
            "fields": [
               { 
                  "type": "vector", 
                  "path": "claimDescriptionEmbeddingCohere",
                  "numDimensions": 350, 
                  "similarity": "cosine"
               }
            ]
         }

   .. step:: Configure the Backend
      
      Set up a virtual environment using Poetry.

   .. step:: Interact with the API

      Start the backend server. 

   .. step:: Connect to the Frontend

      Configure environment variables and run the frontend.

You have to run both the front and back end. You’ll access a web UI
that allows you to ask questions to the LLM, obtain an answer, and see the
reference documents used as context.

To try MongoDB's semantic search tool now, visit the :ref:`Atlas Vector Search
Quick Start guide <vector-search-quick-start>`.

Key Learnings
-------------

- **Generate Text Embeddings:** You can create embeddings using different models
  and deployment options. It is important to consider privacy and data
  protection requirements. You can deploy a model locally if your data needs to
  remain on the servers. Otherwise you can call an API and get your vector
  embeddings back, as explained in `this
  <https://www.mongodb.com/docs/atlas/atlas-vector-search/create-embeddings/>`__
  tutorial. You can use `Voyage AI
  <https://www.mongodb.com/blog/post/redefining-database-ai-why-mongodb-acquired-voyage-ai>`__
  or open-source models. 

- **Create Vector Search Indexes:** You can build Vector Search indexes in
  MongoDB Atlas. Alternatively, you can also build indexes for :ref:`local
  deployments <atlas-cli-deploy-local>`.

- **Perform a Vector Search Query:** You can run :ref:`Vector Search queries
  <return-vector-search-results>` with MongoDB's :ref:`aggregation pipeline
  <aggregation>`, allowing you to concatenate multiple operations in your
  workflow. This approach eliminates the need to learn another programming
  language or change context.

- **Develop a Fast RAG Implementation:** You can develop a fast RAG
  implementation with a :ref:`LangChain <langchain>` framework that combines
  MongoDB Atlas Vector Search and LLMs.

Authors
-------

- Luca Napoli, Industry Solutions, MongoDB 
- Jeff Needham, Industry Solutions, MongoDB