.. index:: balancing; migration

=============================
Chunk Migration Across Shards
=============================

.. default-domain:: mongodb

Chunk migration moves the chunks of a sharded collection from one shard
to another and is part of the :doc:`balancer
</core/sharding-balancing>` process.

.. include:: /images/sharding-migrating.rst

.. _sharding-chunk-migration:

Chunk Migration
---------------

MongoDB migrates chunks in a :term:`sharded cluster` to distribute the
chunks of a sharded collection evenly among shards. Migrations may be
either:

- Manual. Only use manual migration in limited cases, such as
  to distribute data during bulk inserts. See :doc:`Migrating Chunks
  Manually </tutorial/migrate-chunks-in-sharded-cluster>` for more details.

- Automatic. The :doc:`balancer </core/sharding-balancing>` process
  automatically migrates chunks when there is an uneven distribution of
  a sharded collection's chunks across the shards. See :ref:`Migration
  Thresholds <sharding-migration-thresholds>` for more details.

All chunk migrations use the following procedure:

#. The balancer process sends the :dbcommand:`moveChunk` command to
   the source shard.

#. The source starts the move with an internal :dbcommand:`moveChunk`
   command. During the migration process, operations to the chunk
   route to the source shard. The source shard is responsible for
   incoming write operations for the chunk.

#. The destination shard begins requesting documents in the chunk and
   starts receiving copies of the data.

#. After receiving the final document in the chunk, the destination
   shard starts a synchronization process to ensure that it has the
   changes to the migrated documents that occurred during the migration.

#. When fully synchronized, the destination shard connects to the
   :term:`config database` and updates the cluster metadata with the new
   location for the chunk.

#. After the destination shard completes the update of the metadata,
   and once there are no open cursors on the chunk, the source shard
   deletes its copy of the documents. 

   .. versionchanged:: 2.4 

      If the balancer needs to perform additional chunk migrations from
      the source shard, the balancer can start the next chunk
      migration without waiting for the current
      migration process to finish this deletion step. See
      :ref:`chunk-migration-queuing`.

The migration process ensures consistency and maximizes the availability of
chunks during balancing.

.. _chunk-migration-queuing:

Chunk Migration Queuing
~~~~~~~~~~~~~~~~~~~~~~~

.. versionchanged:: 2.4

To migrate multiple chunks from a shard, the balancer migrates the
chunks one at a time. However, the balancer does not wait for the
current migration's delete phase to complete before starting the next
chunk migration. See :ref:`sharding-chunk-migration` for the chunk
migration process and the delete phase.

This queuing behavior allows shards to unload chunks more quickly in
cases of heavily imbalanced cluster, such as when performing initial
data loads without pre-splitting and when adding new shards.

This behavior also affect the :dbcommand:`moveChunk` command, and
migration scripts that use the :dbcommand:`moveChunk` command may
proceed more quickly.

In some cases, the delete phases may persist longer. If multiple delete
phases are queued but not yet complete, a crash of the replica set's
primary can orphan data from multiple migrations.

.. _chunk-migration-write-concern:

Chunk Migration Write Concern
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionchanged:: 2.4

   ``secondaryThrottle`` defaults to ``true``. With
   ``secondaryThrottle`` set to ``true``, the :dbcommand:`moveChunk`
   command and the MongoDB balancer use an approximate write concern
   of :ref:`w: 2 <write-concern-replica-acknowledged>` for all chunk
   copy and delete operations. With ``secondaryThrottle`` set to
   ``false``, chunk copy and delete operations have an approximate
   write concern of :ref:`w: 1 <write-concern-acknowledged>`.

   Write concern is identified only approximately here, because the
   operations are internal to MongoDB, and are handled in a more
   complex way than normal write operations.

   Regardless of the value of ``secondaryThrottle``, certain parts
   of chunk migration have a stricter replication policy:

   - MongoDB stops application writes to the source shard before
     updating the config servers with the chunk locations on
     the destination shard, and restarts application writes
     afterwards. During that time some chunk migrations may
     still need time to complete. Those remaining operations
     have a write concern of ``w: majority`` and :ref:`j: true
     <write-concern-replica-journaled>`.

   - After a chunk migration occurs on the primary
     member of the target shard's replica set, the migration must
     replicate to a majority of the replica set members before
     the balancer can migrate more chunks to that shard. This
     is equivalent to replication having a write concern of ``w:
     majority` for those operations.

   See also :v2.2:`Secondary Throttle in the v2.2 Manual
   </tutorial/configure-sharded-cluster-balancer/#sharded-cluster-config-secondary-throttle>`.

