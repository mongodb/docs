title: "Click the deployment whose logs you want to download, then click :guilabel:`Request Logs`"
stepnum: 1
level: 4
ref: request-logs
content: |
  Click the ellipsis [:guilabel:`...`] icon on the line for any
  process, :term:`replica set`, or :term:`sharded cluster` in the
  project, then click :guilabel:`Request Logs`.
---
title: "Select which types of log |mms| per process to collect and the maximum cumulative size of these logs."
stepnum: 2
level: 4
ref: request-logs-options
content: |

  To choose logs to download, perform the following actions:

  .. list-table::
     :widths: 30 70
     :header-rows: 1

     * - Action
       
       - Purpose

     * - Click :guilabel:`MongoDB Logs`
       
       - Gather logs from deployed MongoDB processes.

     * - Click :guilabel:`FTDC Data`

       - Gather the diagnostic data files from the (:abbr:`FTDC 
         (full-time diagnostic data capture)`) collection mechanism, such 
         as server statistics and status messages.

     * - Click :guilabel:`{+aagent+} Logs`
       
       - Gather logs from the deployed
         {+aagent+}s.

     * - Click :guilabel:`Backup Agent Logs`
       
       - Gather logs from all deployed Backup
         Agent.

         .. note::

            This differs from other logs. The logs collected are not
            limited to the selected hosts, but include all Backup Agent
            logs in the deployment.

     * - Click :guilabel:`Monitoring Agent Logs`
       
       - Gather logs from all deployed
         :term:`Monitoring Agent`.

         .. note::

            This differs from other logs. The logs collected are not
            limited to the selected hosts, but include all Monitoring
            Agent logs in the deployment.

     * - Set :guilabel:`Size per Log Type` in MB

       - Enter the maximum cumulative uncompressed size in megabytes  
         of all selected log files.

         - This limit is *cumulative*. If you set this value to ``50`` 
           MB, |mms| gathers a total of 50 MB of uncompressed log file
           from all logs you chose to download. Those log files are 
           then archived and compressed.

         - If the current log file is less than the specified size,
           |mms| gathers the most recent rotated file as well.

         - If the total size of the log files reaches the specified 
           size part way through a log file, this last log file is 
           truncated to the most recent line that falls within the 
           specified size.

         - The maximum amount of log files that can be collected is 20
           GB. This maximum includes all collected log files that have
           not expired. If you request additional logs and collecting
           those logs results in more than 20 GB of logs collected,
           |mms| generates an error. The total amount of logs 
           collected compared to the limit is displayed as  
           :guilabel:`Estimated Total Size`.

  .. example::

     You choose to collect 20 MB of logs from all processes in a
     :term:`replica set`. This replica set has three :program:`mongod`
     processes on two hosts:

     - ``host1:27017``
     - ``host2:27017``
     - ``host2:27018``

     Your deployment runs the following agents:

     .. list-table::
        :widths: 50 50

        * - {+aagent+}
          - ``host1``, ``host2``, ``host4``, ``host5``

        * - Backup Agent
          - ``host4``

        * - Monitoring Agent
          - ``host4``, ``host5`` 

     When you choose all the log types for this replica set, and limit
     to 20 MB per process, |mms| shows that the :guilabel:`Estimated
     Total Size` is 220 MB (11 processes * 20 MB) out of 20 GB. 

     Once the log collection begins, |mms| scans the log directories 
     for the ``mongod`` processes and their associated 
     :abbr:`FTDC (full-time diagnostic data capture)` from the most 
     current log entry until 20 MB of log files or the end of the last 
     log is collected. All the monitoring and backup agents in the 
     deployment are also scanned.

     - The Backup Agent has 60 MB of logs.
     - Each MongoDB process (3) has 7 MB of logs plus 15 MB of 
       :abbr:`FTDC (full-time diagnostic data capture)` data per 
       process.
     - Each Monitoring Agent (2) has 30 MB of logs.
     - Each {+aagent+} (2) has 12 MB of logs.

     The total size of logs collected is **150 MB**:

     (20 + (3 * (7 + 15)) + (2 * 20) + (2 * 12)) = 150

     - The maximum of 20 MB of logs from the Backup Agent is collected.
     - All of the logs for each MongoDB process are collected: 
       7 MB of MongoDB + 15 MB of 
       :abbr:`FTDC (full-time diagnostic data capture)` data. 
     - The maximum of 20 MB of logs from each Monitoring Agent is 
       collected. 
     - All of the {+aagent+} logs from ``host1`` and ``host2`` 
       are collected. ``host4`` and ``host5`` do not host any processes
       in the :term:`replica set`.

     The resulting archive structure within the downloaded archive is:

     .. code-block:: sh

        host1/27017/mongodb
        host1/27017/ftdc
        host1/automation_agent
        host2/27017/mongodb
        host2/27017/ftdc
        host2/27018/mongodb
        host2/27018/ftdc
        host2/automation_agent
        host4/backup_agent
        host4/monitoring_agent
        host5/monitoring_agent

---
title: "(Optional) Redact sensitive information from the logs."
stepnum: 3
level: 4
ref: redact-log-data
content: |

  To anonymize your logs, select
  :guilabel:`Replace IP addresses, hostnames, namespaces, strings with randomized values`.

  .. note::

     This does not use the
     :manual:`$redact </reference/operator/aggregation/redact>`
     aggregation pipeline. That is a separate capability with a
     broader feature set.

---
title: "Click :guilabel:`Request Logs`."
stepnum: 4
level: 4
ref: request-logs-button
content: |


---
title: "View the progress on the :guilabel:`Log Request History` page."
stepnum: 5
level: 4
ref: switch-log-request-history
content: |

  Entry Status shows :guilabel:`Collecting Logs...` and automatically
  updates its status as log collection continues.

  - If |mms| fails to retrieve log files, click :guilabel:`Retry` to 
    retrieve the failed log files again.

  - If a failure has occurred, you can still download the archive. Some
    of the requested log files will be missing.

---
title: "Download the collected logs archive."
stepnum: 6
level: 4
ref: download-logs
content: |
  Click the :guilabel:`Download icon`.

  The size listed for the archive on the :guilabel:`Log Request 
  History` page is the uncompressed size. The archive consumes 
  that amount of disk space on the target host once it is extracted.

  This download can only be restarted and not resumed. If the download
  fails, you must download the logs again.

  The archive is named ``mongodb-logfiles_<instance_or_process>_<ISO8601_Format_Date>.tar.gz``.

  The extracted files use the following directory structure:

  .. code-block:: sh

     <host>
       automation_agent
         automation-agent-verbose.log
         automation-agent-verbose.log.<ISO8601_Format_Date>
       backup_agent
         backup-agent-verbose.log
         backup-agent-verbose.log.<ISO8601_Format_Date>
       monitoring_agent
         monitoring-agent-verbose.log
         monitoring-agent-verbose.log.<ISO8601_Format_Date>
       <replica_set> // Sharded Cluster Only
         <port>
           ftdc
             metrics.<ISO8601_Format_Date>
             metrics.interim
           mongodb
             mongodb.log
             mongodb.log.<ISO8601_Format_Date>
       <port> // Replica Set or Standalone
         ftdc
           metrics.<ISO8601_Format_Date>
           metrics.interim
         mongodb
           mongodb.log
           mongodb.log.<ISO8601_Format_Date>

  .. note::

     When you extract the ``tar`` archive on a Microsoft Windows host, 
     use an archive extraction utility that supports `PAX extended 
     headers <https://www.gnu.org/software/tar/manual/html_section/tar_71.html#SEC148>`_. 
     Some Windows archive utilities have issues with PAX extended 
     headers for ``tar``.


   Collected logs expire and are removed after 7 days. To extend the 
   lifetime of a particular log file, click the :guilabel:`extend` link
   for that archive on the :guilabel:`Log Request History` page.
...
