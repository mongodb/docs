name = "kafka-connector"
title = "Kafka Connector"
intersphinx = ["https://www.mongodb.com/docs/manual/objects.inv"]
toc_landing_pages = [
    "/introduction",
    "/tutorials",
    "/sink-connector",
    "/source-connector",
    "/sink-connector/configuration-properties",
    "/source-connector/configuration-properties",
    "/sink-connector/fundamentals",
    "/source-connector/fundamentals",
    "/source-connector/usage-examples",
    "/security-and-authentication",
    "/troubleshooting",
]

[constants]
atlas-sp = "Atlas Stream Processing"
connector = "MongoDB Kafka Connector"
connector-short = "Kafka Connector"
connector-long = "MongoDB Connector for Apache Kafka"
kafka = "Apache Kafka"
kafka-connect = "Kafka Connect"
kafka-connect-long = "Confluent Kafka Connect"
avro-long = "Apache Avro"
avro = "Avro"
avro-converter = "Kafka Connect Avro Converter (Avro Converter)"
aws = ":abbr:`AWS (Amazon Web Services)`"
azure = "Microsoft Azure"
protobuf-converter = "Kafka Connect Protobuf Converter"
json-schema-converter = "Kafka Connect JSON Schema Converter"
connector_version = "2.0"
connector_patch_version = "3"
connector_driver_version = "4.7"
connector_version_github_tag = "master"
connector_kafka_version_major = "3"
connector_kafka_version_minor = "8"
connector_kafka_version_docs = "https://kafka.apache.org/{+connector_kafka_version_major+}{+connector_kafka_version_minor+}"
service = "Atlas"
sink-connector = "MongoDB Kafka sink connector"
source-connector = "MongoDB Kafka source connector"
sink-connector-title = "MongoDB Kafka Sink Connector"
source-connector-title = "MongoDB Kafka Source Connector"
connector_driver_url_base = "https://www.mongodb.com/docs/drivers/java/sync/v{+connector_driver_version+}/"
connector_driver_api_doc_url_base = "https://mongodb.github.io/mongo-java-driver/{+connector_driver_version+}/"
pipeline-size = "2.4 GB"
stable-api = "Stable API"
default-heartbeat-topic = "__mongodb_heartbeats"
query-api = "MongoDB Query API"
jmx-long = "Java Management Extensions"
jmx-hover = ":abbr:`JMX ({+jmx-long+})`"
l4j = "Log4j"
metrics-path = "com.mongodb.kafka.connect"
java-se = "Java Platform, Standard Edition"
jconsole = "JConsole"
jconsole_command = "jconsole"
kafka_api_docs_base = "https://kafka.apache.org/32/"
write-exception-version = "1"
write-concern-exception-version = "1"
mongodb-port-mapping = "35001"
jmx-port-mapping = "35000"
sandbox-directory = "kafka-edu/docs-examples/mongodb-kafka-base/"
win-sandbox-directory = "kafka-edu\\docs-examples\\mongodb-kafka-base\\"
cluster = "MongoDB cluster"
clusters = "MongoDB clusters"

[[composables]]
id = "converter"
title = "Converter"
default = "avro"
options = [
   {id = "avro", title = "Avro"},
   {id = "protobuf", title = "Protobuf"},
   {id = "json-schema", title = "JSON Schema"},
   {id = "json-converter", title = "JSON Converter"},
   {id = "string-converter", title = "String Converter (Raw JSON)"},
]

[[composables]]
id = "json-schema-type"
title = "Schema Type"
default = "registry"
dependencies = [{converter = "json-schema"}]
options = [
   {id = "registry", title = "Schema Registry"},
   {id = "embedded", title = "Embedded Schema"},
]

[[composables]]
id = "event-producer"
title = "CDC Event Producer"
default = "mongodb"
options = [
   {id = "mongodb", title = "MongoDB"},
   {id = "debezium", title = "Debezium"},
   {id = "qlik-replicate", title = "Qlik Replicate"},
]