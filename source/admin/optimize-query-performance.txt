.. _optimize-query-perf:

==================================
Optimization for Query Performance
==================================

.. default-domain:: mongodb

.. meta::
   :keywords: |data-lake|

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

The performance of your {+data-lake+} is affected by the
following factors:

- The structure of your data in |s3| and how you represent it in your
  {+data-lake+} :doc:`configuration 
  </reference/format/data-lake-configuration>`.
- The size of your data files.
- The format and structure of your data files.

Data Structure in |s3|
----------------------

For easier management, ensure that your data is logically grouped 
into partitions. {+adl+} utilizes partitions you create with the field 
values that you specify in your :ref:`partition syntax 
<datalake-path-syntax>`. You can improve your {+dl+}\'s performance by 
ensuring that your partition structure maps to your query patterns and 
the partition structure is defined in your 
:datalakeconf:`databases.[n].collections.[n].dataSources.[n].path`. For 
the partition, choose fields that you query frequently and order them 
from the most frequently queried in the first position to the least 
queried field in the last position.

The order of fields listed in the 
:datalakeconf:`databases.[n].collections.[n].dataSources.[n].path` is 
important in the same way as it is in :manual:`Compound Indexes 
</core/index-compound/>`. The specified path corresponds to data that 
is partitioned first by the value of the first field, and then by the 
value of the next field, and so on. 

.. example::

   Consider a collection with the ``software``, ``computer``, and 
   ``OS`` fields and partitions on the |s3| bucket named ``metrics`` 
   first for the ``software`` field, followed by  the ``computer`` 
   field, and then the ``OS`` field. 
   
   .. code-block:: text
      :copyable: false

      metrics
      |--software
         |--computer
            |--OS

   {+adl+} uses the partitions for queries on the these fields:
   
   - the ``software`` field,
   - the ``software`` field and the ``computer`` field,
   - the ``software`` field and the ``computer`` field and the 
     ``OS`` field.

   {+adl+} can use the partitions to support a query on the 
   ``software`` and ``OS`` fields. However, in this case, {+adl+} is 
   not as efficient for the query as it would be if the query was on 
   the ``software`` and ``computer`` fields only. Partitions are parsed 
   in order; if a query omits a particular partition, {+adl+} is less 
   efficient in making use of any partitions that follow the partition. 
   Because a query on ``software`` and ``OS`` omits ``computer``, 
   {+adl+} uses the ``software`` partition more efficiently than the 
   ``OS`` partition to support this query. 
   
   {+adl+} can't use the partitions to support queries on fields not 
   specified in the 
   :datalakeconf:`databases.[n].collections.[n].dataSources.[n].path`. 
   Also, {+adl+} can't use the partitions to support queries that 
   include the following fields without the ``software`` field:
   
   - the ``computer`` field,
   - the ``OS`` field, or
   - the ``computer`` and ``OS`` fields.

You can use partitions to improve {+dl+} performance by mapping 
them to partition attributes in your :doc:`configuration 
</reference/format/data-lake-configuration>`. By mapping your 
*partition attributes* (the parts of your |s3| prefix that looks like a 
folder) to a query attribute, {+adl+} can selectively open the files 
that contain data related to your query. This reduces the amount of 
time a query takes and decreases cost, because {+dl+} reads and 
downloads less files from |aws|.

.. example::

   Consider an |s3| bucket ``metrics`` with the following structure:

   .. code-block:: text
      :copyable: false

      metrics
      |--hardware
      |--software
         |--computer
         |--phone
   
   You can set a partition attribute for "metric type" by defining
   ``/metrics/{metric_type string}/*`` in your configuration. If
   you issue a query that contains ``{metric_type: software}``,
   {+data-lake-short+} only processes the files with the prefix
   ``/software`` and ignores files with the prefix ``/hardware``. 
   
   You can then set a partition attribute for "software type" by
   defining ``/metrics/{metric_type string}/{software_type string}`` in
   your configuration . If you issue a query that contains
   ``{metric_type: software, software_type: computer}``,
   {+data-lake-short+} ignores files with the prefix ``/phone``.

For more information on mapping partition attributes to a collection
:datalakeconf:`databases.[n].collections.[n].dataSources.[n].path`, see
:ref:`datalake-path-syntax`.

Data File Size
--------------

Each file that {+data-lake-short+} handles requires a certain amount of
compute resources. If your {+data-lake-store+} contains many small data
files, the resources required compound and can reduce performance.
Alternatively, many large data files are problematic as
{+data-lake-short+} then downloads and processes unnecessary data.

For most use cases, a performant file size is **100 to 200 MB**.

Data File Format
----------------

{+data-lake+} supports several :ref:`data file formats
<data-lake-data-formats>`. You can improve performance by compressing
certain file formats or by optimizing file contents for your queries.

Compression
~~~~~~~~~~~

When you compress data files, they take less time to download. Reduced
download time has a greater performance benefit than parsing
uncompressed data.

You can compress the following file formats using `gzip
<https://www.gnu.org/software/gzip/manual/gzip.html>`__:

- |json|
- |bson|
- :ref:`CSV <data-lake-csv-tsv-data>` 
- :ref:`TSV <data-lake-csv-tsv-data>` 

File Structure
~~~~~~~~~~~~~~

`Parquet <https://parquet.apache.org/documentation/latest/>`_, `Avro
<https://avro.apache.org/docs/current/>`_, and `ORC
<https://orc.apache.org/docs/>`_ files contain metadata about the file
itself so that an application can traverse the file contents in
different ways. If you structure your data file to align with the
queries you want to run, {+data-lake+} can leverage this metadata to
quickly jump to the right data. 

Of these formats, `Parquet
<https://parquet.apache.org/documentation/latest/>`_ files provide the
best performance and space efficiency for {+data-lake+}, as it is
optimized to parse row and column groups for `Parquet
<https://parquet.apache.org/documentation/latest/>`_. 
