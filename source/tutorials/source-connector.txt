.. _kafka-tutorial-source-connector:

=======================================================
Getting Started with the MongoDB Kafka Source Connector
=======================================================

.. meta::
   :description: Learn how to configure a MongoDB Kafka source connector to read data from a change stream and publish it to an Apache Kafka topic in this tutorial.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Follow this tutorial to learn how to configure a {+source-connector+}
to read data from a change stream and publish it to an Apache Kafka topic.

Get Started with the MongoDB Kafka Source Connector
---------------------------------------------------

.. procedure::
   :style: connected

   .. step:: Complete the Tutorial Setup

      .. include:: /includes/tutorials/setup.rst

   .. step:: Configure the Source Connector

      Create an interactive shell session on the tutorial Docker container
      downloaded for the Tutorial Setup using the following command:

      .. code-block:: bash

         docker exec -it mongo1 /bin/bash

      Create a source configuration file called ``simplesource.json`` with
      the following command:

      .. code-block:: bash

         nano simplesource.json

      Paste the following configuration information into the file and save
      your changes:

      .. literalinclude:: /includes/tutorials/source-connector/source.json
         :language: json

      Run the following command in the shell to start the source connector
      using the configuration file you created:

      .. code-block:: bash

         cx simplesource.json

      .. note::

         The ``cx`` command is a custom script included in the tutorial
         development environment. This script runs the following
         equivalent request to the Kafka Connect REST API to create a new
         connector:

         .. code-block:: bash

            curl -X POST -H "Content-Type: application/json" -d @simplesource.json http://connect:8083/connectors -w "\n"

      Run the following command in the shell to check the status of the
      connectors:

      .. code-block:: bash

         status

      If your source connector started successfully, you should see the
      following output:

      .. literalinclude:: /includes/tutorials/source-connector/output/status.out
         :language: text
         :copyable: false

   .. step:: Create Change Events

      In the same shell, connect to MongoDB using ``mongosh``, the MongoDB
      shell by running the following command:

      .. code-block:: bash

         mongosh "mongodb://mongo1"

      After you connect successfully, you should see the following
      MongoDB shell prompt:

      .. code-block::
         :copyable: false

         rs0 [direct: primary] test>

      At the prompt, type the following commands to insert a new document:

      .. code-block:: javascript

         use Tutorial1
         db.orders.insertOne( { 'order_id' : 1, 'item' : 'coffee' } )

      Once MongoDB completes the insert command, you should receive an
      acknowledgment that resembles the following text:

      .. code-block:: json
         :copyable: false

         {
           acknowledged: true,
           insertedId: ObjectId("627e7e...")
         }

      Exit the MongoDB shell by entering the command ``exit``.

      Check the status of your Kafka environment using the following
      command:

      .. code-block:: bash

         status

      In the output of the preceding command, you should see the new topic
      that the source connector created after receiving the change event:

      .. code-block::
         :copyable: false
         :emphasize-lines: 2

         ...
         "topic": "Tutorial1.orders",
         ...

      Confirm the content of data on the new Kafka topic by running the
      following command:

      .. code-block:: bash

         kc Tutorial1.orders

      .. note::

         The ``kc`` command is a helper script that outputs the content of
         a Kafka topic.

      You should see the following Kafka topic data, organized by "Key"
      and "Value" sections when you run the preceding command:

      .. literalinclude: /includes/tutorials/source-connector/output/kc.out
         :language: text
         :copyable: false
         :emphasize-lines: 3,5,7,9

      From the "Value" section of the output, you can find the part of the
      ``payload`` that includes the ``fullDocument`` data as highlighted in
      the following formatted JSON document:

      .. literalinclude:: /includes/tutorials/source-connector/output/document.json
         :language: json
         :copyable: false
         :emphasize-lines: 15-20

   .. step:: Reconfigure the Change Stream

      You can omit the metadata from the events created by the change
      stream by configuring it to only return the ``fullDocument`` field.

      Stop the connector using the following command:

      .. code-block:: bash

         del mongo-simple-source

      .. note::

         The ``del`` command is a helper script that calls the Kafka
         Connect REST API to stop the connector and is equivalent to the
         following command:

         .. code-block:: bash

            curl -X DELETE connect:8083/connectors/<parameter>

      Edit the source configuration file called ``simplesource.json`` with
      the following command:

      .. code-block:: bash

         nano simplesource.json

      Remove the existing configuration, add the following configuration,
      and save the file:

      .. literalinclude:: /includes/tutorials/source-connector/source-full.json
         :language: json

      Run the following command in the shell to start the source connector
      using the configuration file you updated:

      .. code-block:: bash

         cx simplesource.json

      Connect to MongoDB using ``mongosh`` using the following command:

      .. code-block:: bash

         mongosh "mongodb://mongo1"

      At the prompt, type the following commands to insert a new document:

      .. code-block:: bash

         use Tutorial1
         db.orders.insertOne( { 'order_id' : 2, 'item' : 'oatmeal' } )

      Exit ``mongosh`` by running the following command:

      .. code-block:: bash

         exit

      Confirm the content of data on the new Kafka topic by running the
      following command:

      .. code-block:: bash

         kc Tutorial1.orders

      The ``payload`` field in the "Value" document should contain only the
      following document data:

      .. literalinclude:: /includes/tutorials/source-connector/output/kc.json 
         :language: json
         :copyable: false

   .. step:: (Optional) Stop the Docker Containers

      .. include:: /includes/tutorials/stop-containers.rst

Summary
-------

In this tutorial, you started a source connector using different
configurations to alter the change stream event data published to a Kafka
topic.

Learn More
----------

Read the following resources to learn more about concepts mentioned in
this tutorial:

- :ref:`Source Connector Configuration Properties <source-configuration-index>`
- `Kafka Connect REST API <https://developer.confluent.io/learn-kafka/kafka-connect/rest-api/>`__

