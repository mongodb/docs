.. _upgrade-config-servers-rs:

=====================================
Upgrade Config Servers to Replica Set
=====================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Starting in 3.2, config servers for a sharded cluster can be deployed
as a replica set.  Using a
replica set for the config servers improves consistency across the
config servers, since MongoDB can take advantage of the standard
replica set read and write protocols for the config data. In addition,
this allows a sharded cluster to have more than 3 config servers since
a replica set can have up to 50 members.

The following procedure upgrades three mirrored config servers to a
:ref:`config server replica set <csrs>` without downtime. To use this
procedure, all the sharded cluter binaries must be at least version
3.2.4.

During this procedure there will be a period of time where 
the config servers will be read-only.  During this period, certain catalog 
operations will fail if attempted.  Operations that will
not be available include adding and dropping shards, creating and dropping
databases, creating and dropping sharded collections, and migrating chunks
(both manually and via the balancer process).  Normal read and write
operations to existing collections will not be affected.

.. seealso:: :doc:`/tutorial/upgrade-config-servers-to-replica-set-downtime`

Prerequisites
-------------

- All binaries in the sharded clusters must be at least version
  **3.2.4**. See :ref:`3.2-upgrade-cluster` for instructions to upgrade
  the sharded cluster.

- The existing config servers must be in sync.

Procedure
---------

.. note:: 

   The procedure refers to the first config server, second config
   server, and the third config server as listed in the
   :setting:`~sharding.configDB` setting of the :program:`mongos`. This
   means, that for the following example:

   .. code-block:: sh

      mongos --configdb confServer1:port1,confServer2:port2,confServer3:port3

   - The first config server refers to ``confServer1``.
   - The second config server refers to ``confServer2``.
   - The third config server refers to ``confServer3``.

#. **Disable the balancer** as described in
   :ref:`sharding-balancing-disable-temporarily`.

#. Connect a :program:`mongo` shell to the *first* config server listed
   in the :setting:`~sharding.configDB` setting of the :program:`mongos` and
   run :method:`rs.initiate()` to initiate the single member replica set.

   .. code-block:: javascript

      rs.initiate( {
         _id: "csReplSet",
         configsvr: true,
         members: [ { _id: 0, host: "<host>:<port>" } ]
      } )

   - :rsconf:`_id` corresponds to the replica set name for the config
     servers.

   - :rsconf:`configsvr` must be set be ``true``.

   - :rsconf:`members` array contains a document that specifies:

     - :rsconf:`members._id <members[n]._id>` which is a numeric identifier for the
       member.

     - :rsconf:`members.host <members[n].host>` which is a string corresponding to the config
       server's hostname and port.

#. Restart this config server as a single member replica set with:

   - the :option:`--replSet` option set to the replica set name specified
     during the :method:`rs.initiate()`,

   - the :option:`--configsvrMode` option set to the legacy config server
     mode Sync Cluster Connection Config (``sccc``), 

   - the :option:`--configsvr` option,

   - the :option:`--storageEngine` option set to the storage engine used by
     this config server. For this upgrade procedure, the existing
     config server can be using either MMAPv1 or WiredTiger, and

   - the :option:`--port` option set to the same port as before restart, and

   - the :option:`--dbpath` option set to the same path as before restart.

   Include additional options as specific to your deployment.

   .. important::

      The config server must use the same port as before. [#same-port]_

   .. code-block:: sh

      mongod --configsvr --replSet csReplSet --configsvrMode=sccc --storageEngine <storageEngine> --port <port> --dbpath <path>

   Or if using a :doc:`configuration file
   </reference/configuration-options>`, specify the:
   
   - :setting:`sharding.clusterRole`,
   - :setting:`sharding.configsvrMode`, 
   - :setting:`replication.replSetName`,
   - :setting:`storage.dbPath`,
   - :setting:`storage.engine`, and
   - :setting:`net.port`.

   .. code-block:: yaml

      sharding:
         clusterRole: configsvr
         configsvrMode: sccc
      replication:
         replSetName: csReplSet
      net:
         port: <port>
      storage:
         dbPath: <path>
         engine: <storageEngine>

   .. [#same-port]

      If before the restart, your config server did not explicitly
      specify the ``--configsvr`` option or the ``--port`` option, the
      restart with the ``--configsvr`` will result in a change of port.

      To ensure that the port used by the config server does not
      change, include the :option:`--port` option or 
      :setting:`net.port` set to the same port as before the restart.

#. Start the new :program:`mongod` instances to add to the replica set.
   These instances must use the :doc:`WiredTiger </core/wiredtiger>`
   storage engine. Starting in 3.2, the default storage engine is
   WiredTiger for new :program:`mongod` instances with new data paths.

   .. important::

      - Do not add existing config servers to the replica set.
      - Use new dbpaths for the new instances.

   The number of new :program:`mongod` instances to add depends on the
   config server currently in the single-member replica set:

   - If the config server is using MMAPv1, start 3 new :program:`mongod`
     instances.

   - If the config server is using WiredTiger, start 2 new
     :program:`mongod` instances.

   .. note:: The example in this procedure assumes that the existing
      config servers use MMAPv1.

   For each new :program:`mongod` instance to add, include the
   ``--configsvr`` and the ``--replSet`` options:

   .. code-block:: sh

      mongod --configsvr --replSet csReplSet --port <port> --dbpath <path>

   Or if using a :doc:`configuration file
   </reference/configuration-options>`:

   .. code-block:: yaml

      sharding:
         clusterRole: configsvr
      replication:
         replSetName: csReplSet
      net:
         port: <port>
      storage:
         dbPath: <path>

#. Using the :program:`mongo` shell connected to the replica set config
   server, add the new :program:`mongod` instances as :ref:`non-voting
   <replica-set-non-voting-members>`, :doc:`priority 0
   </core/replica-set-priority-0-member>` members:

   .. code-block:: javascript

      rs.add( { host: <host:port>, priority: 0, votes: 0 } )

#. Once all the new members have been added as :ref:`non-voting
   <replica-set-non-voting-members>`, :doc:`priority 0
   </core/replica-set-priority-0-member>` members, ensure that the new
   nodes have completed the :ref:`initial sync
   <replica-set-initial-sync>` and have reached :replstate:`SECONDARY`
   state. To check the state of the replica set members, run
   :method:`rs.status()` in the :program:`mongo` shell:

   .. code-block:: javascript

      rs.status()

#. Shut down one of the other non-replica set config servers; i.e.
   either the second and third config server listed in the
   :setting:`~sharding.configDB` setting of the :program:`mongos`.
   At this point the config servers will go read-only, meaning certain
   operations - such as creating and dropping databases and sharded
   collections - will not be available.

#. Reconfigure the replica set to allow all members to vote and have
   default priority of ``1``.

   .. code-block:: javascript

      var cfg = rs.conf();

      cfg.members[0].priority = 1;
      cfg.members[1].priority = 1;
      cfg.members[2].priority = 1;
      cfg.members[3].priority = 1;
      cfg.members[0].votes = 1;
      cfg.members[1].votes = 1;
      cfg.members[2].votes = 1;
      cfg.members[3].votes = 1;

      rs.reconfig(cfg);

#. Step down the first config server, i.e. the server started with
   ``--configsvrMode=sccc``.

   .. code-block:: javascript

      rs.stepDown(600)

#. Shut down the first config server. 

#. Restart the first config server in config server replica set
   (``CSRS``) mode; i.e. restart **without** the ``--configsvrMode=sccc``
   option:

   .. code-block:: sh

      mongod --configsvr --replSet csReplSet --storageEngine <storageEngine> --port <port> --dbpath <path>

   Or if using a :doc:`configuration file
   </reference/configuration-options>`, omit the
   :setting:`sharding.configsvrMode` setting:

   .. code-block:: yaml

      sharding:
         clusterRole: configsvr
      replication:
         replSetName: csReplSet
      net:
         port: <port>
      storage:
         dbPath: <path>
         engine: <storageEngine>

   If the first config server uses the MMAPv1 storage engine, the
   member will transition to ``"REMOVED"`` state.
   
   At this point the config server data will return to being writeable and all
   catalog operations - including creating and dropping databases and 
   sharded collections - will once again be possible.

#. Restart :program:`mongos` instances with updated :option:`--configdb` or
   :setting:`sharding.configDB` setting. 

   For the updated :option:`--configdb` or :setting:`sharding.configDB`
   setting, specify the replica set name for the config servers and the
   members in the replica set.

   .. code-block:: sh

      mongos --configdb csReplSet/<rsconfigsver1:port1>,<rsconfigsver2:port2>,<rsconfigsver3:port3>

#. Verify that the restarted :program:`mongos` instances
   are aware of the protocol change. Connect a :program:`mongo` shell to
   a :program:`mongos` instance and check the ``mongos`` collection in
   the ``config`` database:

   .. code-block:: javascript

      use config
      db.mongos.find()

   The ``ping`` value for the :program:`mongos` instances should
   indicate some time after the restart.

#. If the first config server uses the MMAPv1 storage engine, remove
   the member from the replica set. Connect a :program:`mongo` shell to
   the current primary and use :method:`rs.remove()`:

   .. important::

      Only if the config server uses the MMAPv1 storage engine.

   .. code-block:: javascript

      rs.remove("<hostname>:<port>")

#. Shut down the remaining non-replica set config server.

#. **Re-enable the balancer** as described in
   :ref:`sharding-balancing-enable`.
