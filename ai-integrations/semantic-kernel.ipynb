{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Vector Search - Semantic Kernel Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [Semantic Kernel Get Started](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/semantic-kernel/) page. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/ai-integrations/semantic-kernel.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade semantic-kernel openai motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (OpenAIChatCompletion, OpenAITextEmbedding)\n",
    "from semantic_kernel.connectors.memory.mongodb_atlas import MongoDBAtlasMemoryStore\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY  = \"<api-key>\"\n",
    "ATLAS_CONNECTION_STRING = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_service = OpenAIChatCompletion(\n",
    "   service_id=\"chat\",\n",
    "   ai_model_id=\"gpt-3.5-turbo\",\n",
    "   api_key=OPENAI_API_KEY\n",
    ")\n",
    "embedding_service = OpenAITextEmbedding(\n",
    "   ai_model_id=\"text-embedding-ada-002\",\n",
    "   api_key=OPENAI_API_KEY\n",
    ")\n",
    "kernel.add_service(chat_service)\n",
    "kernel.add_service(embedding_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_atlas_memory_store = MongoDBAtlasMemoryStore(\n",
    "   connection_string=ATLAS_CONNECTION_STRING,\n",
    "   database_name=\"semantic_kernel_db\",\n",
    "   index_name=\"vector_index\"\n",
    ")\n",
    "\n",
    "memory = SemanticTextMemory(\n",
    "   storage=mongodb_atlas_memory_store,\n",
    "   embeddings_generator=embedding_service\n",
    ")\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def populate_memory(kernel: sk.Kernel) -> None:\n",
    "    await memory.save_information(\n",
    "       collection=\"test\", id=\"1\", text=\"I am a developer\"\n",
    "    )\n",
    "    await memory.save_information(\n",
    "       collection=\"test\", id=\"2\", text=\"I started using MongoDB two years ago\"\n",
    "    )\n",
    "    await memory.save_information(\n",
    "       collection=\"test\", id=\"3\", text=\"I'm using MongoDB Vector Search with Semantic Kernel to implement RAG\"\n",
    "    )\n",
    "    await memory.save_information(\n",
    "       collection=\"test\", id=\"4\", text=\"I like coffee\"\n",
    "    )\n",
    "\n",
    "print(\"Populating memory...\")\n",
    "await populate_memory(kernel)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Atlas cluster and specify the collection\n",
    "client = MongoClient(ATLAS_CONNECTION_STRING)\n",
    "collection = client[\"semantic_kernel_db\"][\"test\"]\n",
    "\n",
    "# Create your index model, then create the search index\n",
    "search_index_model = SearchIndexModel(\n",
    "   definition={\n",
    "      \"fields\": [\n",
    "         {\n",
    "         \"type\": \"vector\",\n",
    "         \"path\": \"embedding\",\n",
    "         \"numDimensions\": 1536,\n",
    "         \"similarity\": \"cosine\"\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "   name=\"vector_index\",\n",
    "   type=\"vectorSearch\"\n",
    ")\n",
    "\n",
    "collection.create_search_index(model=search_index_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await memory.search(\"test\", \"What is my job title?\")\n",
    "print(f\"Retrieved document: {result[0].text}, {result[0].relevance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_id = \"chat\"\n",
    "settings = kernel.get_service(service_id).instantiate_prompt_execution_settings(\n",
    "   service_id=service_id\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "   Answer the following question based on the given context.\n",
    "\n",
    "   Question: {{$input}}\n",
    "   Context: {{$context}}\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt_template_config = PromptTemplateConfig(\n",
    "   execution_settings=settings,\n",
    "   input_variables=[\n",
    "       InputVariable(name=\"input\"),\n",
    "       InputVariable(name=\"context\")\n",
    "   ],\n",
    "   template=prompt_template\n",
    ")\n",
    "\n",
    "prompt = kernel.add_function(\n",
    "   function_name=\"RAG\",\n",
    "   plugin_name=\"TextMemoryPlugin\",\n",
    "   prompt_template_config=chat_prompt_template_config,\n",
    ")\n",
    "\n",
    "question = \"When did I start using MongoDB?\"\n",
    "results = await memory.search(\"test\", question)\n",
    "retrieved_document = results[0].text\n",
    "answer = await prompt.invoke(\n",
    "   kernel=kernel, input=question, context=retrieved_document\n",
    ")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
