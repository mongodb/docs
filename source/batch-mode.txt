==========
Batch Mode
==========

.. meta::
   :description: Explore how to use the Spark Connector to read and write data to MongoDB in batch mode using Spark's Dataset and DataFrame APIs.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. toctree::

   Read </batch-mode/batch-read>
   Write </batch-mode/batch-write>

Overview
--------

In batch mode, you can use the Spark Dataset and DataFrame APIs to process data at
a specified time interval.

The following sections show you how to use the {+connector-short+} to read data from
MongoDB and write data to MongoDB in batch mode:

- :ref:`batch-read-from-mongodb`
- :ref:`batch-write-to-mongodb`

.. tip:: Apache Spark Documentation

   To learn more about using Spark to process batches of data, see the 
   `Spark Programming Guide
   <https://spark.apache.org/docs/latest/sql-programming-guide.html>`__.