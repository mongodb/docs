.. _spark-write-conf:

===========================
Write Configuration Options
===========================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. _spark-output-conf:

Write Configuration
-------------------

The following options for writing to MongoDB are available:

.. note::

   If you use ``SparkConf`` to set the connector's write configurations,
   prefix ``spark.mongodb.write.`` to each property.

.. list-table::
   :header-rows: 1
   :widths: 35 65

   * - Property name
     - Description

   * - ``mongoClientFactory``
     - | MongoClientFactory configuration key.
       | You can specify a custom implementation which must implement the
         ``com.mongodb.spark.sql.connector.connection.MongoClientFactory``
         interface.
       |
       | **Default:** ``com.mongodb.spark.sql.connector.connection.DefaultMongoClientFactory``

   * - ``connection.uri``
     - | **Required.**
       | The connection string configuration key.
       |
       | **Default:** ``mongodb://localhost:27017/``

   * - ``database``
     - | **Required.**
       | The database name configuration.

   * - ``collection``
     - | **Required.**
       | The collection name configuration.


   * - ``maxBatchSize``
     - | Specifies the maximum number of operations to batch in bulk
         operations.

       |
       | **Default:** ``512``

   * - ``ordered``
     - | Specifies whether to perform ordered bulk operations.
       |
       | **Default:** ``true``

   * - ``operationType``
     - | Specifies the type of write operation to perform. You can set
         this to one of the following values:

       - ``insert``: insert the data.
       - ``replace``: replace an existing document that matches the
         ``idFieldList`` value with the new data, or insert the data if
         no match exists.
       - ``update``: update an existing document that matches the
         ``idFieldList`` value with the new data, or inserts the data if
         no match exists.

       |
       | **Default:** ``replace``

   * - ``idFieldList``
     - | Field or list of comma-separated fields to use to identify a document.
       |
       | **Default:** ``_id``

   * - ``writeConcern.w``
     - | Specifies ``w``, a write concern option to acknowledge the level to
         which the change propagated in the MongoDB replica set. You can
         specify one of the following values:

       - ``MAJORITY``
       - ``W1``, ``W2``, or ``W3``
       - ``ACKNOWLEDGED``
       - ``UNACKNOWLEDGED``

       |
       | For more information on ``w`` values, see the MongoDB server guide on
         the :manual:`WriteConcern w option
         </reference/write-concern/#w-option>`.

       |
       | **Default:** ``ACKNOWLEDGED``

   * - ``writeConcern.journal``
     - | Specifies ``j``, a write concern option to enable request for
         acknowledgment that the data is confirmed on on-disk journal for
         the criteria specified in the ``w`` option. You can specify
         either ``true`` or ``false``.
       |
       | For more information on ``j`` values, see the MongoDB server
         guide on the
         :manual:`WriteConcern j option </reference/write-concern/#j-option>`.

   * - ``writeConcern.wTimeoutMS``
     - | Specifies ``wTimeoutMS``, a write concern option to return an error
         when a write operation exceeds the number of milliseconds. If you
         use this optional setting, you must specify a non-negative integer.
       |
       | For more information on ``wTimeoutMS`` values, see the MongoDB server
         guide on the
         :manual:`WriteConcern wtimeout option </reference/write-concern/#wtimeout>`.

.. _configure-output-uri:

``connection.uri`` Configuration Setting
----------------------------------------

You can set all :ref:`spark-output-conf` via the write ``connection.uri``.

.. note::

   If you use ``SparkConf`` to set the connector's write configurations,
   prefix ``spark.mongodb.write.`` to the setting.

.. code:: cfg

  spark.mongodb.write.connection.uri=mongodb://127.0.0.1/test.myCollection

The configuration corresponds to the following separate configuration
settings:

.. code:: cfg

  spark.mongodb.write.connection.uri=mongodb://127.0.0.1/
   spark.mongodb.write.database=test
   spark.mongodb.write.collection=myCollection

If you specify a setting both in the ``connection.uri`` and in a separate
configuration, the ``connection.uri`` setting overrides the separate
setting. For example, given the following configuration, the
database for the connection is ``foobar``:

.. code:: cfg

  spark.mongodb.write.connection.uri=mongodb://127.0.0.1/foobar
   spark.mongodb.write.database=bar
