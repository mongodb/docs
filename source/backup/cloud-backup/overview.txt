.. _backup-cloud-provider:

==========================================
{+Cloud-Backup+}s
==========================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. include:: /includes/fact-atlas-free-tier-limits.rst

|service| {+Cloud-Backup+}s provide localized backup storage using the
native snapshot functionality of the cluster's cloud service provider.

|service| supports {+cloud-backup+} for clusters served on:

- :ref:`Microsoft Azure <microsoft-azure>`
- :ref:`Amazon Web Services (AWS) <amazon-aws>`
- :ref:`Google Cloud Platform (GCP) <google-gcp>`

You can enable {+cloud-backup+} during the
:doc:`cluster creation </tutorial/create-new-cluster>` or during the
:doc:`modification of an existing cluster </scale-cluster>`.
From the cluster configuration modal, toggle
:guilabel:`Turn on Cloud Backup` to :guilabel:`Yes`.

If you need to retain any {+old-backup+} snapshots for archival
purposes, download them before you switch to {+Cloud-Backup+} from
{+old-backup+}s. To learn how to download a snapshot, see
:doc:`/backup/legacy-backup/restore`.

.. admonition:: Limitations of {+cloud-backup+}
   :class: note

   {+Cloud-Backup+}s:

   - Can support sharded clusters running MongoDB version 3.6 or later.

   - Cannot guarantee :ref:`causal consistency <causal-consistency>`
     of your data.

   - Cannot restore an existing snapshot to a cluster after you add or
     remove a shard from it. You may restore an existing snapshot to
     another cluster with a matching topology.

   - Cannot take a consistent snapshot of a cluster if
     :manual:`chunks are manually migrated </tutorial/migrate-chunks-in-sharded-cluster>`
     while the snapshot is being taken.

.. _encrypted-cloud-provider-snapshot:

Encryption at Rest using Customer Key Management
------------------------------------------------

|service| encrypts all snapshot volumes, ensuring the security of
cluster data at rest. For projects and clusters using
:ref:`security-kms-encryption`, |service| applies an additional layer
of encryption to your snapshot storage volumes using the Key Management
Service (KMS) provider configured for the cluster.

.. tabs::

   .. tab:: AWS Identity and Access Management (IAM)
      :tabid: aws-kms

      For clusters using :doc:`AWS IAM </security-aws-kms>` as their
      Key Management Service, |service| uses the project's customer
      master key (CMK) and AWS |iam| user credentials at the time of
      the snapshot to automatically encrypt the snapshot data files.
      This is an additional layer of encryption on the existing
      encryption applied to all |service| storage and snapshot
      volumes. :term:`Oplog <oplog>` data collected for |pit| restores
      is also encrypted with the customer's |cmk|.

      |service| stores the unique ID of the |cmk| and the |aws| |iam|
      user credentials used to access the |cmk|. |service| uses this
      information when restoring the snapshot. For complete
      documentation on restoring an encrypted snapshot, see
      :ref:`restore-encrypted-snapshot`.

   .. tab:: Azure Key Vault
      :tabid: azure-kms

      For clusters using :doc:`Azure Key Vault </security-azure-kms>`
      as their Key Management Service, |service| uses the project's
      Key Identifier, Key Vault Credentials, and Active Directory
      application account credentials at the time of the snapshot to
      automatically encrypt the snapshot data files. This is an
      additional layer of encryption on the existing encryption
      applied to all |service| storage and snapshot volumes.

      |service| stores the unique ID of the Azure Key Identifier used
      the encrypt the snapshot. |service| also stores the Azure Key
      Vault credentials and the Active Domain application account
      credentials used to access the Key Identifier. |service| uses
      this information when restoring the snapshot. For complete
      documentation on restoring an encrypted snapshot, see
      :ref:`restore-encrypted-snapshot`.

   .. tab:: Google Cloud KMS
      :tabid: gcp-kms

      |service| uses your |gcp| Service Account Key to encrypt and
      decrypt your MongoDB master keys. These MongoDB master keys are
      used to encrypt cluster database files and :ref:`cloud providers
      snapshots <backup-cloud-provider>`. For complete documentation
      on restoring an encrypted snapshot, see
      :ref:`restore-encrypted-snapshot`.

To view the key used to encrypt a snapshot:

#. From the :guilabel:`Clusters` view of the |service| UI, click
   on the cluster name.

#. Click the :guilabel:`Backup` tab, then click
   :guilabel:`Snapshots`.

#. Note the :guilabel:`Encryption Key ID` for each snapshot in
   the cluster. |service| lists the Key Identifier
   used to encrypt the snapshot. Unencrypted snapshots display
   :guilabel:`Not enabled`.

.. include:: /includes/fact-encrypted-backups-master-key-requirements.rst

For complete documentation on configuring Encryption at Rest using
your Key Management for an |service| project,
see :doc:`/security-kms-encryption`. You can then either
:ref:`deploy <create-cluster-enable-encryption>` a new cluster or
:ref:`enable <scale-cluster-enable-encryption>` an existing cluster
with Encryption at Rest using your Key Management.

.. _single-region-cloud-backup:

Single-Region Cluster Backups
-----------------------------

With single-region cluster backups, |service|:

- Selects the lowest priority node of the cluster *at the time the
  snapshot is taken*. (If two or more nodes have the same priority,
  |service| selects the node with the lexicographically smallest name.)
- Stores the snapshots in the same cloud region as the cluster.
- Retains snapshots based on your
  :ref:`retention policy <cloud-provider-retention-policy>`.

.. .. include:: /images/cloud-provider-snapshot-single-region-primary.rst

If the node goes offline, |service| selects the next-lowest priority
cluster node in the same region to execute and store snapshots.

.. .. include:: /images/cloud-provider-snapshot-single-region-secondary.rst

|service| automatically creates a new snapshot storage volume if the
existing snapshot storage volume becomes invalid. |service| creates the
new volume in the same region as the cluster's current primary.
|service| then takes a full-copy snapshot to maintain backup
availability and continues using that member and its corresponding
region for further incremental snapshots.

Events that can trigger storage invalidation include:

- Changing the |service| cluster tier,
- Modifying the |service| cluster's storage volume or speed,
- Changing the |service| cluster's |aws| region, and
- Maintenance performed by |service| or |aws|.

.. seealso::

   To learn more about snapshot retention, see
   :ref:`cloud-provider-retention-policy`.

.. _multi-region-cloud-backup:

Multi-Region Cluster Backups
----------------------------

With multi-region cluster backups, |service|:

- Selects lowest priority cluster node in the highest priority region to
  execute and store snapshots. (If two or more nodes have the same
  priority, |service| selects the node with the lexicographically
  smallest name.)
- Retains snapshots based on your
  :ref:`retention policy <cloud-provider-retention-policy>`.

.. .. include:: /images/cloud-provider-snapshot-multi-region-primary.rst

If the node goes offline, |service| selects the next-lowest priority
cluster node in the same region to execute and store snapshots.

.. .. include:: /images/cloud-provider-snapshot-multi-region-secondary.rst

|service| automatically creates a new snapshot storage volume if the
existing snapshot storage volume becomes invalid. |service| creates the
new volume in the same region as the cluster's current primary.
|service| then takes a full-copy snapshot to maintain backup
availability and continues using that member and its corresponding
region for further incremental snapshots.

Events that can trigger storage invalidation include:

- Changing the |service| cluster tier,
- Modifying the |service| cluster's storage volume or speed,
- Changing the |service| cluster's |aws| region, and
- Maintenance performed by |service| or |aws|.

.. seealso::

   To learn more about snapshot retention, see
   :ref:`cloud-provider-retention-policy`.

.. _sharded-global-cluster-backup:

Global Cluster Backups
----------------------

|service| can back up :doc:`Global Clusters </global-clusters>` using
{+Cloud-Backup+}s as their backup method. |service| restores the shards
in the source cluster to the corresponding shards in the target cluster
using the same order as specified in the cluster configuration.

.. example::

   ``shard0`` in the source cluster is restored to ``shard0`` in the
   target cluster.

.. note::

   If you used the |api| to create your Global Cluster, the zones are
   defined in the ``replicationSpecs`` parameter in the
   :doc:`Create a Cluster </reference/api/clusters-create-one>` and
   :doc:`Modify a Cluster </reference/api/clusters-modify-one>`
   |api| endpoints.

If the cluster configurations of the source and target clusters do not
match, shard data may migrate to a different cloud provider zone than
where it resided in the source cluster. After |service| completes the
restore operation, the MongoDB :term:`balancer` for the target cluster
migrates the data back to the zone where it resided in the source
cluster if your clusters meet the following requirements:

- Both clusters have enabled a |global-write-cluster| on the same
  collection

- Both clusters use the same :term:`shard key` for the
  |global-write|-enabled collection

.. note::

   If the |global-write|-enabled collection on the target cluster does
   not contain any data, the MongoDB balancer for the cluster
   automatically distributes any data that you later add to the
   collection among the target cluster's shards.

To enable global writes on the target cluster:

1. Click :guilabel:`Collections` beneath the target cluster on the
   :guilabel:`Clusters` page.

#. Click :guilabel:`Enable Global Writes`.

.. _pit-restore:

{+PIT-Restore+}s
--------------------------------------------------------

Continuous cloud backups replay the :term:`oplog` to restore a cluster from a
particular point in time within a window specified in the Backup
Policy.

You may opt to
:ref:`enable {+PIT-Restore+} restores <create-cluster-backups>`.
Configure your {+pit-restore+} window with the
:ref:`Backup Policy Editor <cps-backup-policies>`.

.. note::

   Enabling {+pit-restore+}s increases the monthly cost of your
   cluster.

   To learn more about the cost implications, see
   :ref:`billing <billing-backup-cloud-provider-snapshots>`.

Your cluster's oplog backups stay within the cloud provider's storage
service under the cluster or shard's :ref:`highest priority region
<deploy-across-multiple-regions>`. Oplog backups use standard |aws|
|s3| encryption.

.. note::

   All clusters with {+pit-restore+}s enabled store :term:`oplog` data
   on |aws| |s3|, including clusters backed by Azure and |gcp|.

The following actions cause all existing oplog backups to be deleted.
All existing snapshots remain intact, but previously preserved oplog
data is removed:

- Disabling {+pit-restore+}s for your cluster.
- Changing the :ref:`highest priority region <deploy-across-multiple-regions>`
  on your cluster.

.. _cloud-provider-backup-schedule:
.. _cloud-provider-retention-policy:
.. _cps-backup-policies:

Snapshot Scheduling and Retention Policy
----------------------------------------

Use the Backup Policy Editor to configure a backup policy for {+Cloud-Backup+}s.

1. From the :guilabel:`Clusters` view, click the cluster name.

#. Click the :guilabel:`Backup` tab.

#. Click :guilabel:`Backup Policy`.

A backup policy has the following sections:

- A time of day, in |utc|, at which to create snapshots.

- A frequency interval and duration of retention.

- If |pit| Restores are enabled, a |pit| window that allows you
  to restore to any point in time in the last X days where X is the window.

.. example::

   The default backup policy specifies a snapshot time of ``18:00``
   |utc| and the following four policy items:

   .. list-table::
      :widths: 30 30 40

      * - Policy Type
        - Snapshot Taken
        - Snapshot Retained
      * - Hourly
        - Every one hour
        - 2 days
      * - Daily
        - Every day
        - 7 days
      * - Weekly
        - Every Saturday
        - 4 weeks
      * - Monthly
        - Last day of the month
        - 12 months

For complete documentation on {+Cloud-Backup+} billing, see :ref:`billing-backup-cloud-provider-snapshots`.

.. _changine-backup-policy-time:

Changing the Backup Policy Time
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To modify the backup policy time:

1. In the :guilabel:`Backup Policy Editor`, select the hour at
   which |service| takes a snapshot each day from :guilabel:`hr`
   beneath :guilabel:`Snapshot Time (UTC)`.

2. Select the number of minutes after :guilabel:`hr` at which |service|
   takes a snapshot from :guilabel:`min` beneath
   :guilabel:`Snapshot Time (UTC)`.

3. Click :guilabel:`Save Changes`.

.. _creating-backup-policy:

Configuring the Backup Policy
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each row in the :guilabel:`Backup Policy Frequency and Retention` table
represents a backup policy item. Configure the policy items and,
optionally, add new policy items to configure a new backup policy.

.. tip::

   |service| displays an estimate of the total snapshot count
   associated with your changes below the
   :guilabel:`Backup Policy Frequency and Retention` table.

To specify a backup policy item:

1. Select the frequency unit from :guilabel:`Frequency Unit` for a
   policy item.

   Alternatively, click :guilabel:`Add Frequency Unit` to add a new
   policy item to the backup policy.

   .. note::

      You cannot specify multiple :guilabel:`Hourly` and
      :guilabel:`Daily` backup policy items.

2. Select the frequency for the frequency unit from :guilabel:`Every`.

3. Specify the retention time for the policy item in
   :guilabel:`Retention Time` and the units for the retention time from
   the list to the right.

   .. note::

      |service| requires that the value specified for
      :guilabel:`Retention Time` for less frequent policy items be
      equal to or larger than the value specified for more frequent
      policy items. For example, if the hourly policy item specifies a
      retention of two days or greater, the retention for the weekly
      snapshot must be two weeks or greater.

4. (Optional) To apply the retention changes in the updated backup
   policy to snapshots that |service| took previously, check
   :guilabel:`Apply policy retention changes to existing snapshots`.

   .. note::

      This option affects only snapshots created by the updated policy
      items and whose retention has not been updated individually with
      the
      :doc:`/reference/api/cloud-backup/schedule/modify-one-schedule`
      API.

5. Click :guilabel:`Save Changes`.

.. note::

   To take a snapshot sooner than the next scheduled snapshot,
   use the :doc:`/reference/api/cloud-backup/backup/take-one-ondemand-backup` API.

.. note::

   .. include:: /includes/fact-overlapping-backup-policy-items.rst

.. important::

   If you disable {+Cloud-Backup+}s for a cluster or terminate a
   cluster that had snapshots enabled, |service| immediately
   deletes the backup snapshots for that cluster. For clusters not
   using :ref:`security-kms-encryption`
   you can :ref:`download the latest snapshot
   <restore-cloud-provider-snapshot-download>` to preserve any data
   stored in the cluster.

.. _viewing-snapshots:

Viewing Snapshots
~~~~~~~~~~~~~~~~~

|service| displays existing snapshots on the :guilabel:`Snapshots`
page. To view snapshots that |service| has already taken:

1. From the :guilabel:`Clusters` view, click the cluster name.

#. Click the :guilabel:`Backup` tab.

#. Click :guilabel:`Snapshots`.

By default, |service| displays both on-demand and policy-based
snapshots. To view only policy-based snapshots:

1. Click :guilabel:`Policy` under :guilabel:`View Snapshots by`.

   Alternatively, click :guilabel:`On-demand` to display only snapshots
   taken by clicking :guilabel:`Take Snapshot Now`.

Snapshots taken according to the backup policy display the frequency of
the policy item that generated the snapshot in the
:guilabel:`Frequency` column: ``Monthly``, ``Weekly``, ``Daily``, or
``Hourly``.

.. note::

   .. include:: /includes/fact-overlapping-backup-policy-items.rst

.. _cloud-provider-snapshots-on-demand:
.. _on-demand-snapshots:

On-Demand Snapshots
-------------------

|service| takes on-demand snapshots immediately, unlike scheduled
snapshots which occur at
:doc:`regular intervals </reference/api/cloud-backup/schedule/schedules>`.
If there is already an on-demand snapshot with a status of ``queued``
or ``inProgress``, you must wait until |service| has completed the
on-demand snapshot before taking another. If there is already a
scheduled snapshot with a status of ``queued`` or ``inProgress``, you
may queue an on-demand snapshot. You must have the
:authrole:`Organization Owner` or :authrole:`Project Owner` role to
successfully call this endpoint.

To take an on-demand snapshot:

1. From the :guilabel:`Clusters` view, click the :icon:`ellipsis-h`
   button below the cluster name then click
   :guilabel:`Take Snapshot Now`.

#. In the :guilabel:`On-Demand Snapshot` modal, enter the following:

   a. In the :guilabel:`Retention` box, enter the number of days that
      you want |service| to retain the snapshot.

   b. In the :guilabel:`Description` box, enter a descriptive name
      for the snapshot.

#. Click :guilabel:`Take Snapshot`.

Click the :guilabel:`Backup` tab, then click :guilabel:`Snapshots` for
the cluster to view the on-demand snapshot.

.. note::

   The :guilabel:`Take Snapshot Now` button also appears on the
   :guilabel:`Snapshots` page for the cluster.

.. class:: hidden

   .. toctree::
      :titlesonly:

      /backup/cloud-backup/restore
