.. _rm-ai-and-data-usage:

=============================
AI and Data Usage Information
=============================

.. meta::
   :description: Understand how the Query Converter uses Generative AI, data handling practices, and how to manage data storage preferences.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Query Converter is powered by Generative AI
(Gen AI), and may give inaccurate responses. Please see the `Generative AI FAQ 
<https://dochub.mongodb.org/core/faq-ai-features>`__ 
for more information about Gen AI in MongoDB products.

Third Party Providers
---------------------

By default, Query Converter uses the GPT-4o model with the `Azure OpenAI
Service
<https://azure.microsoft.com/en-us/products/ai-services/openai-service>`__ 
hosted by Microsoft. You can :ref:`configure Relational Migrator to use a
different AI provider or Large Language Model (LLM)<rm-query-converter-set-llm>`.

.. _rm-supported-llms:

Supported Providers and LLMs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MongoDB tests Query Converter with the following AI providers and models:

.. list-table::
   header-rows: 1

   * - Provider
     - Models

   * - `Microsoft Azure OpenAI <https://azure.microsoft.com/en-us/products/ai-services/openai-service>`__
     - `GPT-4o <https://platform.openai.com/docs/models#gpt-4o>`__, `GPT-4 <https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4>`__

   * - `OpenAI <https://platform.openai.com/docs/overview>`__
     - `GPT-4o <https://platform.openai.com/docs/models#gpt-4o>`__, `GPT-4 <https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4>`__

   * - `Amazon Bedrock <https://aws.amazon.com/bedrock/>`__
     - `Claude 3.5 (Sonnet) <https://docs.anthropic.com/en/api/claude-on-amazon-bedrock>`__, `Mistral Large <https://docs.mistral.ai/deployment/cloud/aws/>`__

   * - `GCP Vertex AI <https://cloud.google.com/vertex-ai>`__
     - `Gemini 1.5 Pro <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`__

   * - Self-managed local/Cloud
     - `Llama 3.1 405B <https://www.llama.com/docs/getting_the_models>`__

.. note::

   You can configure Query Converter to run models on different providers,
   like running Llama 3.1 on Blackrock AWS, but MongoDB provides no
   performance or stability guarantees for these configurations.


How Your Data is Used
---------------------

When you use Query Converter, the following information is sent to 
MongoDB's backend and/or the third party AI provider:

- The full text of your query or stored procedure.
- The definition of any relational database tables used in the query.
  These definitions include the table names, column names, data types,
  and any primary or foreign key relationships.
- The definition of your MongoDB collections and mapping rules. 
  These definitions include the relationships between the collections 
  and tables used in the query and the collection names, field names 
  and data types.

The information that is sent is not shared with any other third 
parties or stored by the AI provider. {+rel-mig+} does not send 
database connection strings, credentials, or any raw data from your 
databases.

By default, your original query text and the AI-converted query 
telemetry data is stored by MongoDB for up to one year to help us 
provide support and improve the service. If you do not want
your data to be stored, you have the option to opt out:

.. include:: /includes/fact-disable-query-converter.rst

Disable Query Converter
-----------------------

Query Converter is only available if you :ref:`enable it <rm-enable-query-converter>`. 
If you no longer want to use the feature, you can ignore it and no data 
is sent to generative AI models. If needed, you can hide the 
feature by clearing all browser data for the {+rel-mig+} host.
