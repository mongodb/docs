.. _mongoimport:

===============
``mongoimport``
===============

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. |arrow| unicode:: U+27A4
.. |tool-binary| replace:: :binary:`~bin.mongoimport`
.. |mongodb-aws-example| replace:: :ref:`mongoimport-example-connect-using-aws-iam`

Synopsis
--------

The :binary:`~bin.mongoimport` tool imports content from an
:manual:`Extended JSON </reference/mongodb-extended-json>`, CSV, or TSV export
created by :binary:`~bin.mongoexport`, or potentially, another third-party export
tool.

.. include:: /includes/extracts/require-cmd-line-mongoimport.rst

.. seealso::

   :binary:`~bin.mongoexport` which provides the corresponding
   structured data export capability.

Versioning
~~~~~~~~~~

.. include:: /includes/extracts/dbtools-version-single.rst

.. admonition:: Quick links to older documentation
   :class: note

   - `MongoDB 4.2 mongoimport <https://docs.mongodb.com/v4.2/reference/program/mongoimport>`__
   - `MongoDB 4.0 mongoimport <https://docs.mongodb.com/v4.0/reference/program/mongoimport>`__
   - `MongoDB 3.6 mongoimport <https://docs.mongodb.com/v3.6/reference/program/mongoimport>`__

This documentation is for version ``{+release+}`` of |tool-binary|. 

Compatibility
-------------

MongoDB Server Compatibility
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. include:: /includes/extracts/dbtools-compatibility-single.rst

Platform Support
~~~~~~~~~~~~~~~~

|tool-binary| version ``{+release+}`` is supported on the following
platforms:

.. include:: /includes/fact-platform-support.rst

Installation
------------

.. include:: /includes/fact-see-install-guide.rst

Syntax
------

The :binary:`~bin.mongoimport` command has the following form:

.. code-block:: sh

   mongoimport <options> <connection-string> <file>

.. include:: /includes/extracts/require-cmd-line-mongoimport.rst

Behavior
--------

.. include:: /includes/fact-type-fidelity-loss.rst

JSON Format
~~~~~~~~~~~

:binary:`~bin.mongoimport` requires import data to be in
:manual:`Extended JSON v2.0 (Canonical or Relaxed mode)
</reference/mongodb-extended-json>` format by default. For import data
formatted using Extended JSON v1.0, specify the
:option:`--legacy <mongoimport --legacy>` option.

.. tip::

   In general, the versions of :binary:`~bin.mongoexport` and
   :binary:`~bin.mongoimport` should match. That is, to import data
   created from :binary:`~bin.mongoexport`, you should use the
   corresponding version of :binary:`~bin.mongoimport`.

Encoding
~~~~~~~~

:binary:`~bin.mongoimport` only supports data files that are UTF-8 encoded.
Using other encodings will produce errors.

FIPS
~~~~

:binary:`~bin.mongoimport` automatically creates FIPS-compliant
connections to a :binary:`~bin.mongod`/:binary:`~bin.mongos` that is
:manual:`configured to use FIPS mode </tutorial/configure-fips>`.

Write Concern
~~~~~~~~~~~~~

If you specify write concern in both the
:option:`--writeConcern <mongoimport --writeConcern>` option and the
:option:`--uri connection string <mongoimport --uri>` option, the
:option:`--writeConcern <mongoimport --writeConcern>` value overrides
the write concern specified in the URI string.

Batches
~~~~~~~

:binary:`~bin.mongoimport` uses a maximum batch size of 100,000 to
perform bulk insert/upsert operations.

Required Access
---------------

In order to connect to a :binary:`~bin.mongod` that enforces authorization
with the :option:`--auth <mongod.--auth>` option, you must use the
:option:`--username <mongoexport --username>` and :option:`--password
<mongoexport --password>` options. The connecting user must
possess, at a minimum, the :authrole:`readWrite` role on the database
into which they are importing data.

Options
-------

.. binary:: mongoimport

.. program:: mongoimport

.. option:: --help

   Returns information on the options and use of :program:`mongoimport`.


.. option:: --verbose, -v

   Increases the amount of internal reporting returned on standard output
   or in log files. Increase the verbosity with the ``-v`` form by
   including the option multiple times, (e.g. ``-vvvvv``.)
   


.. option:: --quiet

   Runs :program:`mongoimport` in a quiet mode that attempts to limit the amount
   of output.

   This option suppresses:
   
   - output from :term:`database commands <database command>`
   
   - replication activity
   
   - connection accepted events
   
   - connection closed events


.. option:: --version

   Returns the :program:`mongoimport` release number.


.. option:: --uri=<connectionString>
   
   Specifies the resolvable :manual:`URI connection string
   </reference/connection-string/>` of the MongoDB deployment, enclosed
   in quotes:
   
   .. code-block:: none
   
      --uri "mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]"
   
   .. include:: /includes/extracts/uri-positional-mongoimport.rst

   For information on the components of the connection string, see
   the :manual:`Connection String URI Format
   </reference/connection-string/>` documentation. 

   .. include:: /includes/fact-uri-with-conflicting-info.rst          


.. option:: --host=<hostname><:port>, -h=<hostname><:port>

   *Default*: localhost:27017

   Specifies the resolvable hostname of the MongoDB deployment. By
   default, :program:`mongoimport` attempts to connect to a MongoDB
   instance running on the localhost on port number ``27017``.
   
   To connect to a replica set, specify the
   :setting:`~replication.replSetName` and a seed list of set members, as in
   the following:
   
   .. code-block:: none
   
      --host=<replSetName>/<hostname1><:port>,<hostname2><:port>,<...>
   
   When specifying the replica set list format, :program:`mongoimport` always connects to
   the :term:`primary <Primary>`. 
   
   You can also connect to any single member of the replica set by specifying
   the host and port of only that member:
   
   .. code-block:: none
   
      --host=<hostname1><:port>

   If you use IPv6 and use the ``<address>:<port>`` format, you must
   enclose the portion of an address and port combination in
   brackets (e.g. ``[<address>]``).

   .. include:: /includes/extracts/uri-used-with-host.rst


.. option:: --port=<port>

   *Default*: 27017

   Specifies the TCP port on which the MongoDB instance listens for
   client connections.
   
   .. include:: /includes/extracts/uri-used-with-port.rst



.. option:: --ssl

   Enables connection to a :binary:`~bin.mongod` or :binary:`~bin.mongos` that has
   TLS/SSL support enabled.
   
   .. include:: /includes/extracts/uri-used-with-ssl.rst

   .. include:: /includes/extracts/ssl-facts-see-more.rst
   


.. option:: --sslCAFile=<filename>

   Specifies the :file:`.pem` file that contains the root certificate chain
   from the Certificate Authority. Specify the file name of the
   :file:`.pem` file using relative or absolute paths.
   
   .. include:: /includes/extracts/uri-used-with-sslcafile.rst

   .. include:: /includes/extracts/ssl-facts-see-more.rst


.. option:: --sslPEMKeyFile=<filename>

   Specifies the :file:`.pem` file that contains both the TLS/SSL certificate
   and key. Specify the file name of the :file:`.pem` file using relative
   or absolute paths.
   
   This option is required when using the :option:`--ssl` option to connect
   to a :binary:`~bin.mongod` or :binary:`~bin.mongos` that has
   :setting:`~net.ssl.CAFile` enabled *without*
   :setting:`~net.ssl.allowConnectionsWithoutCertificates`.
   
   .. include:: /includes/extracts/uri-used-with-sslpemkeyfile.rst

   .. include:: /includes/extracts/ssl-facts-see-more.rst
   


.. option:: --sslPEMKeyPassword=<value>

   Specifies the password to de-crypt the certificate-key file (i.e.
   :option:`--sslPEMKeyFile`). Use the :option:`--sslPEMKeyPassword` option only if the
   certificate-key file is encrypted. In all cases, the :program:`mongoimport` will
   redact the password from all logging and reporting output.
   
   If the private key in the PEM file is encrypted and you do not specify
   the :option:`--sslPEMKeyPassword` option, the :program:`mongoimport` will prompt for a passphrase. See
   :ref:`ssl-certificate-password`.
   
   .. include:: /includes/extracts/uri-used-with-sslpemkeypassword.rst

   .. include:: /includes/extracts/ssl-facts-see-more.rst


.. option:: --sslCRLFile=<filename>

   Specifies the :file:`.pem` file that contains the Certificate Revocation
   List. Specify the file name of the :file:`.pem` file using relative or
   absolute paths.
   
   .. include:: /includes/extracts/ssl-facts-see-more.rst
   


.. option:: --sslAllowInvalidCertificates

   Bypasses the validation checks for server certificates and allows
   the use of invalid certificates. When using the
   :setting:`~net.ssl.allowInvalidCertificates` setting, MongoDB logs as a
   warning the use of the invalid certificate.
   
   .. include:: /includes/extracts/ssl-facts-invalid-cert-warning-clients.rst
   
   .. include:: /includes/extracts/uri-used-with-sslallowinvalidcertificates.rst

   .. include:: /includes/extracts/ssl-facts-see-more.rst
   


.. option:: --sslAllowInvalidHostnames

   Disables the validation of the hostnames in TLS/SSL certificates. Allows
   :program:`mongoimport` to connect to MongoDB instances even if the hostname in their
   certificates do not match the specified hostname.
   
   .. include:: /includes/extracts/uri-used-with-sslallowinvalidhostnames.rst
   
   .. include:: /includes/extracts/ssl-facts-see-more.rst


.. option:: --username=<username>, -u=<username>

   Specifies a username with which to authenticate to a MongoDB database
   that uses authentication. Use in conjunction with the :option:`--password` and
   :option:`--authenticationDatabase` options.

   .. include:: /includes/extracts/uri-used-with-username.rst

   .. include:: /includes/extracts/mongodb-aws-username-mongoimport.rst


.. option:: --password=<password>, -p=<password>

   Specifies a password with which to authenticate to a MongoDB database
   that uses authentication. Use in conjunction with the :option:`--username` and
   :option:`--authenticationDatabase` options.

   To prompt the user for the password, pass the :option:`--username`
   option without :option:`--password` or specify an empty string as the
   :option:`--password` value, as in ``--password ""`` .

   .. include:: /includes/extracts/uri-used-with-password.rst

   .. include:: /includes/extracts/mongodb-aws-password-mongoimport.rst


.. option:: --awsSessionToken=<AWS Session Token>

   .. include:: /includes/extracts/mongodb-aws-session-token-mongoimport.rst


.. option:: --authenticationDatabase=<dbname>

   Specifies the authentication database where the specified :option:`--username` has been created.
   See :ref:`user-authentication-database`.

   .. include:: /includes/fact-auth-database-use-external.rst
 
   .. include:: /includes/extracts/uri-used-with-authenticationdatabase.rst


.. option:: --authenticationMechanism=<name>

   *Default*: SCRAM-SHA-1

   Specifies the authentication mechanism the :program:`mongoimport` instance uses to
   authenticate to the :binary:`~bin.mongod` or :binary:`~bin.mongos`.

   .. versionchanged:: 100.1.0
   
      Starting in version ``100.1.0``, :program:`mongoimport` adds support
      for the ``MONGODB-AWS`` authentication mechanism when connecting
      to a `MongoDB Atlas
      <https://www.mongodb.com/cloud/atlas?tck=docs_server>`__ cluster.

   .. include:: /includes/list-table-auth-mechanisms.rst
   
   .. include:: /includes/extracts/uri-used-with-authenticationmechanism.rst


.. option:: --gssapiServiceName=<serviceName>

   Specify the name of the service using :manual:`GSSAPI/Kerberos
   </core/kerberos>`. Only required if the service does not use the
   default name of ``mongodb``.
   
   This option is available only in MongoDB Enterprise.
   


.. option:: --gssapiHostName=<hostname>

   Specify the hostname of a service using :manual:`GSSAPI/Kerberos
   </core/kerberos>`. *Only* required if the hostname of a machine does
   not match the hostname resolved by DNS.
   
   This option is available only in MongoDB Enterprise.
   


.. option:: --db=<database>, -d=<database>

   Specifies the name of the database on which to run the :program:`mongoimport`.
   
   .. include:: /includes/extracts/uri-used-with-db.rst


.. option:: --collection=<collection>, -c=<collection>

   Specifies the collection to import. If you do not specify
   :option:`--collection`, :binary:`~bin.mongoimport` takes the
   collection name from the input filename, omitting the file's
   extension if it has one.


.. option:: --fields=<field1[,field2]>, -f=<field1[,field2]>

   Specify a comma separated list of field names when importing :term:`csv`
   or :term:`tsv` files that do not have field names in the first (i.e.
   header) line of the file. 
   
   To also specify the field type as well as the field name, use
   :option:`--fields` with :option:`--columnsHaveTypes`.

   If you attempt to include :option:`--fields` when importing JSON data,
   :program:`mongoimport` will return an error. :option:`--fields` is only for :term:`csv`
   or :term:`tsv` imports.


.. option:: --fieldFile=<filename>

   As an alternative to :option:`--fields`, the :option:`--fieldFile`
   option allows you to specify a file that holds a list of field names if
   your :term:`csv` or :term:`tsv` file does not include field names in the
   first line of the file (i.e. header). Place one field per line.
   
   To also specify the field type as well as the field name, use
   :option:`--fieldFile` with :option:`--columnsHaveTypes`.

   If you attempt to include :option:`--fieldFile` when importing JSON data,
   :program:`mongoimport` will return an error. :option:`--fieldFile` is only for :term:`csv`
   or :term:`tsv` imports.


.. option:: --ignoreBlanks

   Ignores empty fields in :term:`csv` and :term:`tsv` exports. If not
   specified, :binary:`~bin.mongoimport` creates fields without values in
   imported documents.
   

   If you attempt to include :option:`--ignoreBlanks` when importing JSON data,
   :program:`mongoimport` will return an error. :option:`--ignoreBlanks` is only for :term:`csv`
   or :term:`tsv` imports.


.. option:: --type=<json|csv|tsv>

   Specifies the file type to import. The default format is :term:`JSON`,
   but it's possible to import :term:`csv` and :term:`tsv` files.
   
   The ``csv`` parser accepts that data that complies with RFC
   :rfc:`4180`. As a result, backslashes are *not* a valid escape
   character. If you use double-quotes to enclose fields in the CSV
   data, you must escape internal double-quote marks by prepending
   another double-quote.
   


.. option:: --file=<filename>

   Specifies the location and name of a file containing the data to import.
   If you do not specify a file, :binary:`~bin.mongoimport` reads data from
   standard input (e.g. "stdin").
   


.. option:: --drop

   Modifies the import process so that the target instance drops
   the collection before importing the data from the input.
   


.. option:: --headerline

   If using :option:`--type csv <mongoimport --type>` or :option:`--type
   tsv <mongoimport --type>`, uses the first line as field names.
   Otherwise, :binary:`~bin.mongoimport` will import the first line as a
   distinct document.
   

   If you attempt to include :option:`--headerline` when importing JSON data,
   :program:`mongoimport` will return an error. :option:`--headerline` is only for :term:`csv`
   or :term:`tsv` imports.


.. option:: --useArrayIndexFields

   .. versionadded:: 100.0.0

   Interpret natural numbers in fields as array indexes when importing
   :term:`csv` or :term:`tsv` files.

   Field names must be in the form ``<colName>.<arrayIndex>`` where 
   ``arrayIndex`` is a natural number beginning with ``0`` and
   increasing sequentially by ``1`` for each member of the array.

   For example, with the following :term:`csv` file:
   
   .. code-block:: javascript

      a.0,a.1,a.2,a.3
      red,yellow,green,blue

   An import with the :option:`--useArrayIndexFields` option would
   result in the following document:

   .. code-block:: javascript

      "a" : [ "red", "yellow", "green", "blue" ]

   If using the :option:`--columnsHaveTypes` option as well, use the
   form ``<colName>.<arrayIndex>.<type>(<arg>)`` to specify both the
   array index and type for each field. See :option:`--columnsHaveTypes`
   for more information.
   
   Numerical keys with leading zeros (e.g. ``a.000,a.001``) are not
   interpreted as array indexes.

   If the first part of a key is a natural number (e.g. ``0.a,1.a``), it
   is interpreted as a document key, and not an array index.

   If using the :option:`--ignoreBlanks` option with
   :option:`--useArrayIndexFields`, :program:`mongoimport` will log an
   error if you attempt to import a document that contains a
   blank value (e.g. ``""``) for an array index field.

   The :option:`--useArrayIndexFields` option has no effect when
   importing :term:`JSON` data, as arrays are already encoded in
   :term:`JSON` format.


.. option:: --mode=<insert|upsert|merge|delete>

   *Default*: insert
   
   Specifies how the import process should handle existing documents
   in the database that match documents in the import file.
   
   By default, :program:`mongoimport` uses the ``_id`` field to match documents in
   the collection with documents in the import file.
   To specify the fields against which to match existing
   documents for the ``upsert``, ``merge``, and ``delete`` modes,
   use :option:`--upsertFields`.
   
   .. list-table::
      :header-rows: 1
      :widths: 20 40
   
      * - Value
        - Description
   
      * - ``insert``
   
        - Insert the documents in the import file. :program:`mongoimport` will log
          an error if you attempt to import a document that contains a
          duplicate value for a field with a :ref:`unique index
          <index-type-unique>`, such as ``_id``.
   
      * - ``upsert``
   
        - Replace existing documents in the database with matching
          documents from the
          import file. :program:`mongoimport` will insert all other
          documents. :ref:`ex-mongoimport-upsert` describes how to
          use :option:`--mode` ``upsert``.
   
      * - ``merge``
   
        - Merge existing documents that match a document in the import file with
          the new document. :program:`mongoimport` will insert all other documents.
          :ref:`ex-mongoimport-merge` describes how to use :option:`--mode`
          ``merge``.

      * - ``delete``
   
        - Delete existing documents in the database that match a
          document in the import file. :program:`mongoimport` takes
          *no action* on non-matching documents.
          :ref:`ex-mongoimport-delete` describes how to use
          :option:`--mode` ``delete``.

          .. versionadded:: 100.0.0


.. option:: --upsertFields=<field1[,field2]>

   Specifies a list of fields for the query portion of the
   import process. :option:`--upsertFields` can be used with
   :option:`--mode` ``upsert``, ``merge``, and ``delete``.

   Use this option if the ``_id`` fields in the
   existing documents don't match the field in the document, but
   another field or field combination can uniquely identify
   documents as a basis for performing upsert operations.

   If you do not specify a field, :option:`--upsertFields` will upsert
   on the basis of the ``_id`` field.

   To ensure adequate performance, indexes should exist for the
   field or fields you specify with :option:`--upsertFields`.


.. option:: --stopOnError

   Forces :program:`mongoimport` to halt the insert operation at the
   first error rather than continuing the operation despite errors.
   
   By default, :binary:`~bin.mongoimport` continues an operation
   when it encounters duplicate key and document validation errors. 
   To ensure that the program stops on these errors, specify
   :option:`--stopOnError <mongoimport --stopOnError>`.


.. option:: --jsonArray

   Accepts the import of data expressed with multiple MongoDB documents
   within a single :term:`JSON` array. Limited to
   imports of 16 MB or smaller.
   
   Use :option:`--jsonArray` in conjunction with :option:`mongoexport --jsonArray`.


.. option:: --legacy

   Indicates that the import data is in :manual:`Extended JSON v1 format
   </reference/mongodb-extended-json-v1>` instead of the default
   :manual:`Extended JSON v2 format </reference/mongodb-extended-json>`.

   .. tip::

      In general, the versions of :binary:`~bin.mongoexport` and
      :binary:`~bin.mongoimport` should match. That is, to import
      data created from :binary:`~bin.mongoexport`, you should use
      the corresponding version of :binary:`~bin.mongoimport`.

   For example, if the import data is in v1 format:
   
   .. code-block:: javascript

      {"_id":1.0,"myregfield":{"$regex":"foo","$options":"i"}}
   
   Import without the :option:`--legacy <mongoimport --legacy>` option results in
   the following document in the collection:
   
   .. code-block:: javascript
   
      { "_id" : 1, "myregfield" : { "$regex" : "foo", "$options" : "i" } }

   Import with the :option:`--legacy <mongoimport --legacy>` results in
   the following document in the collection:

   .. code-block:: javascript

      { "_id" : 1, "myregfield" : { "$regularExpression" : { "pattern" : "foo", "options" : "i" } } }

.. option:: --maintainInsertionOrder

   *Default*: false
   
   If specified, :program:`mongoimport` inserts the documents in the
   order of their appearance in the input source. That is, both the
   bulk write batch order and document order within the batches are
   maintained. 
   
   Specifying :option:`--maintainInsertionOrder` also enables
   :option:`--stopOnError <mongoimport --stopOnError>` and sets
   :option:`numInsertionWorkers <mongoimport --numInsertionWorkers>` to
   1.
   
   If unspecified, :program:`mongoimport` may perform the insertions in
   an arbitrary order.


.. option:: --numInsertionWorkers=<int>

   *Default*: 1

   Specifies the number of insertion workers to run concurrently.

   For large imports, increasing the number of insertion workers
   may increase the speed of the import.
   


.. option:: --writeConcern=<document>

   *Default*: majority

   Specifies the :term:`write concern` for each write operation that :program:`mongoimport`
   performs.
   
   Specify the write concern as a document with :ref:`w options <wc-w>`:
      
   .. code-block:: sh
   
      --writeConcern "{w:'majority'}"

   
   If the write concern is also included in the :option:`--uri
   connection string <--uri>`, the command-line
   :option:`--writeConcern` overrides the write concern specified in
   the URI string.


.. option:: --bypassDocumentValidation

   Enables :program:`mongoimport` to bypass :manual:`document validation </core/schema-validation>`
   during the operation. This lets you insert documents that do not
   meet the validation requirements.


.. option:: --columnsHaveTypes

   Instructs :program:`mongoimport` that the
   field list specified in :option:`--fields`, :option:`--fieldFile`,
   or :option:`--headerline` specifies the types of each field.
   
   Field names must be in the form of ``<colName>.<type>(<arg>)``. You
   must backslash-escape the following characters if you wish to include
   them in an argument: ``(``, ``)``, and ``\``.
   
   .. list-table::
      :header-rows: 1
      :widths: 20 33 47
   
      * - ``type``
        - Supported Arguments
        - Example Header Field
   
      * - ``auto()``
        - None.
        - ``misc.auto()``
   
      * - ``binary(<arg>)``
        - - ``base32`` (`RFC4648`_ encoding schema)
          - ``base64`` (`RFC4648`_ encoding schema)
          - ``hex``
        - ``user thumbnail.binary(base64)``
   
      * - ``boolean()``
        - None.
        - ``verified.boolean()``
   
      * - ``date(<arg>)``
        - Alias for ``date_go(<arg>)``. `Go Language time.Parse format`_.
        - ``created.date(2006-01-02 15:04:05)``
   
      * - ``date_go(<arg>)``
        - `Go Language time.Parse format`_
        - ``created.date_go(2006-01-02 15:04:05)``
   
      * - ``date_ms(<arg>)``
        - `Microsoft SQL Server FORMAT format
          <https://msdn.microsoft.com/en-us/library/hh213505.aspx>`_
        - ``created.date_ms(yyyy-MM-dd H:mm:ss)``
   
      * - ``date_oracle(<arg>)``
        - `Oracle Database TO_DATE format
          <https://docs.oracle.com/cd/B19306_01/server.102/b14200/functions183.htm>`_.
        - ``created.date_oracle(YYYY-MM-DD HH24:MI:SS)``
   
      * - ``decimal()``
        - None
        - ``price.decimal()``
   
      * - ``double()``
        - None.
        - ``revenue.double()``
   
      * - ``int32()``
        - None.
        - ``followerCount.int32()``
   
      * - ``int64()``
        - None.
        - ``bigNumber.int64()``
   
      * - ``string()``
        - None.
        - ``zipcode.string()``
   
   .. _Go Language time.Parse format: https://golang.org/src/time/format.go
   .. _RFC4648: https://tools.ietf.org/html/rfc4648
   
   See :ref:`example-csv-import-types` for sample usage.

   If you attempt to include :option:`--columnsHaveTypes` when importing JSON data,
   :program:`mongoimport` will return an error. :option:`--columnsHaveTypes` is only for :term:`csv`
   or :term:`tsv` imports.


.. option:: --parseGrace=<grace>

   *Default*: stop

   Specifies how :program:`mongoimport` handles type coercion failures when importing
   CSV or TSV files with :option:`--columnsHaveTypes`.
   
   :option:`--parseGrace` has no effect when importing JSON documents.
   
   .. list-table::
      :widths: 20 80
      :header-rows: 1
   
      * - Value
        - Description
   
      * - ``autoCast``
        - Assigns a type based on the value of the field.
          For example, if a field is defined as a ``double`` and the
          value for that field was ``"foo"``, :program:`mongoimport` would make
          that field value a string type.
   
      * - ``skipField``
        - For the row being imported, :program:`mongoimport` does not include the
          field whose type does not match the expected type.
   
      * - ``skipRow``
        - :program:`mongoimport` does not import rows containing a value whose
          type does not match the expected type.
   
      * - ``stop``
        - :program:`mongoimport` returns an error that ends the import.


Examples
--------

.. include:: /includes/extracts/require-cmd-line-mongoimport.rst

Simple Import
~~~~~~~~~~~~~

:binary:`~bin.mongoimport` restores a database from a backup taken with
:binary:`~bin.mongoexport`. Most of the arguments to :binary:`~bin.mongoexport` also
exist for :binary:`~bin.mongoimport`.

In the following example, :binary:`~bin.mongoimport` imports
the :term:`JSON` data from the ``contacts.json`` file into the collection
``contacts`` in the ``users`` database.

.. code-block:: sh

   mongoimport --db=users --collection=contacts --file=contacts.json

.. _ex-mongoimport-upsert:

Replace Matching Documents during Import
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

With :option:`--mode <mongoimport --mode>` ``upsert``, :binary:`~bin.mongoimport` replaces
existing documents in the database that match a document in the
import file with the document from the import file.
Documents that do not match an existing document in the database are
inserted as usual. By default :binary:`~bin.mongoimport` matches documents
based on the ``_id`` field. Use :option:`--upsertFields <mongoimport --upsertFields>` to specify
the fields to match against.

Consider the following document in the ``people`` collection in the
``example`` database:

.. code-block:: javascript

   {
      "_id" : ObjectId("580100f4da893943d393e909"),
      "name" : "Crystal Duncan",
      "region" : "United States",
      "email" : "crystal@example.com"
   }

The following document exists in a ``people-20160927.json`` JSON file.
The ``_id`` field of the JSON object matches the ``_id`` field of the
document in the ``people`` collection.

.. code-block:: javascript

   {
      "_id" : ObjectId("580100f4da893943d393e909"),
      "username" : "crystal",
      "likes" : [ "running", "pandas", "software development" ]
   }

To import the ``people-20160927.json`` file and replace documents in
the database that match the documents in the import file, specify :option:`--mode`
``upsert``, as in the following:

.. code-block:: sh

   mongoimport -c=people -d=example --mode=upsert --file=people-20160927.json

The document in the ``people`` collection would then contain only
the fields from the imported document, as in the following:

.. code-block:: javascript

   {
      "_id" : ObjectId("580100f4da893943d393e909"),
      "username" : "crystal",
      "likes" : [ "running", "pandas", "software development" ]
   }

.. _ex-mongoimport-merge:

Merge Matching Documents during Import
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

With :option:`--mode <mongoimport --mode>` ``merge``, :binary:`~bin.mongoimport` enables you to
merge fields from a new record with an existing document in the
database. Documents that do not match an existing document in the
database are inserted as usual. By default :binary:`~bin.mongoimport`
matches documents based on the ``_id`` field. Use
:option:`--upsertFields <mongoimport --upsertFields>` to specify the fields to match against.

The ``people`` collection in the ``example`` database contains the
following document:

.. code-block:: javascript

 {
    "_id" : ObjectId("580100f4da893943d393e909"),
    "name" : "Crystal Duncan",
    "region" : "United States",
    "email" : "crystal@example.com"
 }

The following document exists in a ``people-20160927.json`` JSON file.
The ``_id`` field of the JSON object matches the ``_id`` field of the
document in the ``people`` collection.

.. code-block:: javascript

   {
      "_id" : ObjectId("580100f4da893943d393e909"),
      "username" : "crystal",
      "email": "crystal.duncan@example.com",
      "likes" : [ "running", "pandas", "software development" ]
   }

To import the ``people-20160927.json`` file and merge documents from
the import file with matching documents in the database, specify
:option:`--mode <mongoimport --mode>` ``merge``, as in the following:

.. code-block:: sh

   mongoimport -c=people -d=example --mode=merge --file=people-20160927.json

The import operation combines the fields from the JSON file with the
original document in the database,
matching the documents based on the ``_id`` field.
During the import process, :binary:`~bin.mongoimport` adds the new ``username`` and
``likes`` fields to the document and updates the ``email`` field with
the value from the imported document, as in the following:

.. code-block:: javascript

   {
      "_id" : ObjectId("580100f4da893943d393e909"),
      "name" : "Crystal Duncan",
      "region" : "United States",
      "email" : "crystal.duncan@example.com",
      "username" : "crystal",
      "likes" : [
         "running",
         "pandas",
         "software development"
      ]
   }

.. _ex-mongoimport-delete:

Delete Matching Documents
~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 100.0.0

With :option:`--mode <mongoimport --mode>` ``delete``,
:binary:`~bin.mongoimport` deletes existing documents in the database
that match a document in the import file. Documents that do not match an
existing document in the database are ignored. By default
:binary:`~bin.mongoimport` matches documents based on the ``_id`` field.
Use :option:`--upsertFields <mongoimport --upsertFields>` to specify
the fields to match against.

.. note::

   With :option:`--mode <mongoimport --mode>` ``delete``,
   :binary:`~bin.mongoimport` will only delete one existing document per
   match. Ensure that documents from the import file match a single
   existing document from the database.

The ``people`` collection in the ``example`` database contains the
following document:

.. code-block:: javascript

 {
    "_id" : ObjectId("580100f4da893943d393e909"),
    "name" : "Crystal Duncan",
    "region" : "United States",
    "email" : "crystal@example.com",
    "employee_id" : "5463789356"
 }

The following document exists in a ``people-20160927.json`` JSON file.
The ``_id`` field of the JSON object matches the ``_id`` field of the
document in the ``people`` collection.

.. code-block:: javascript

   {
      "_id" : ObjectId("580100f4da893943d393e909"),
      "username" : "crystal",
      "email": "crystal.duncan@example.com",
      "likes" : [ "running", "pandas", "software development" ],
      "employee_id" : "5463789356"
   }

To delete the documents in the database that match a document in the
``people-20160927.json`` file, specify
:option:`--mode <mongoimport --mode>` ``delete``, as in the following:

.. code-block:: sh

   mongoimport -c=people -d=example --mode=delete --file=people-20160927.json

Because the ``_id`` fields match between the database and the input
file, :binary:`~bin.mongoimport` deletes the matching document from the
``people`` collection. The same results could also have been achieved
by using :option:`--upsertFields <mongoimport --upsertFields>` to
specify the ``employee_id`` field, which also matches between the
database and the input file.

Import ``JSON`` to Remote Host Running with Authentication
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the following example, :binary:`~bin.mongoimport` imports data from the
file ``/opt/backups/mdb1-examplenet.json`` into the ``contacts`` collection
within the database ``marketing`` on a remote MongoDB
database with authentication enabled.

:binary:`~bin.mongoimport` connects to the :binary:`~bin.mongod` instance running on
the host ``mongodb1.example.net`` over port ``37017``. It authenticates with the
username ``user``; the example omits the :option:`--password <mongoimport --password>`
option to have :binary:`~bin.mongoimport` prompt for the password:

.. code-block:: sh

   mongoimport --host=mongodb1.example.net --port=37017 --username=user --collection=contacts --db=marketing --file=/opt/backups/mdb1-examplenet.json

``CSV`` Import
~~~~~~~~~~~~~~

General CSV Import
``````````````````

In the following example, :binary:`~bin.mongoimport` imports the :term:`csv`
formatted data in the ``/opt/backups/contacts.csv`` file into the
collection ``contacts`` in the ``users`` database on the MongoDB
instance running on the localhost port numbered
``27017``.

Specifying :option:`--headerline <mongoimport --headerline>` instructs
:binary:`~bin.mongoimport` to determine the name of the fields using the first
line in the CSV file.

.. code-block:: sh

   mongoimport --db=users --collection=contacts --type=csv --headerline --file=/opt/backups/contacts.csv

:binary:`~bin.mongoimport` uses the input file name, without the
extension, as the collection name if ``-c`` or ``--collection`` is
unspecified. The following example is therefore equivalent:

.. code-block:: none

   mongoimport --db=users --type=csv --headerline --file=/opt/backups/contacts.csv

.. _example-csv-import-types:

Import CSV with Specified Field Types
`````````````````````````````````````

When specifying the field name, you can also specify the data type. To
specify field names and type, include
:option:`--columnsHaveTypes <mongoimport --columnsHaveTypes>` with
either: :option:`--fields <mongoimport --fields>`, :option:`--fieldFile
<mongoimport --fieldFile>`, or :option:`--headerline <mongoimport
--headerline>`.

Specify field names and data types in the form
``<colName>.<type>(<arg>)``. 

For example, a ``/example/file.csv`` file contains the following data:

.. code-block:: none

   Katherine Gray, 1996-02-03, false, 1235, TG9yZW0gaXBzdW0gZG9sb3Igc2l0IGFtZXQsIGNvbnNlY3RldHVyIGFkaXBpc2NpbmcgZWxpdCwgc2VkIGRvIGVpdXNtb2QgdGVtcG9yIGluY2lkaWR1bnQgdXQgbGFib3JlIGV0IGRvbG9yZSBtYWduYSBhbGlxdWEuIFV0IGVuaW0gYWQgbWluaW0gdmVuaWFtLCBxdWlzIG5vc3RydWQgZXhlcmNpdGF0aW9uIHVsbGFtY28gbGFib3JpcyBuaXNpIHV0IGFsaXF1aXAgZXggZWEgY29tbW9kbyBjb25zZXF1YXQuIER1aXMgYXV0ZSBpcnVyZSBkb2xvciBpbiByZXByZWhlbmRlcml0IGluIHZvbHVwdGF0ZSB2ZWxpdCBlc3NlIGNpbGx1bSBkb2xvcmUgZXUgZnVnaWF0IG51bGxhIHBhcmlhdHVyLiBFeGNlcHRldXIgc2ludCBvY2NhZWNhdCBjdXBpZGF0YXQgbm9uIHByb2lkZW50LCBzdW50IGluIGN1bHBhIHF1aSBvZmZpY2lhIGRlc2VydW50IG1vbGxpdCBhbmltIGlkIGVzdCBsYWJvcnVtLg==
   Albert Gilbert, 1992-04-24, true, 13, Q3VwY2FrZSBpcHN1bSBkb2xvciBzaXQgYW1ldCB0b290c2llIHJvbGwgYm9uYm9uIHRvZmZlZS4gQ2FuZHkgY2FuZXMgcGllIGNyb2lzc2FudCBjaG9jb2xhdGUgYmFyIGxvbGxpcG9wIGJlYXIgY2xhdyBtYWNhcm9vbi4gU3dlZXQgcm9sbCBjdXBjYWtlIGNoZWVzZWNha2Ugc291ZmZsw6kgYnJvd25pZSBpY2UgY3JlYW0uIEp1anViZXMgY2FrZSBjdXBjYWtlIG1hY2Fyb29uIGRhbmlzaCBqZWxseS1vIHNvdWZmbMOpLiBDYWtlIGFwcGxlIHBpZSBnaW5nZXJicmVhZCBjaG9jb2xhdGUgc3VnYXIgcGx1bS4gU3dlZXQgY2hvY29sYXRlIGNha2UgY2hvY29sYXRlIGNha2UganVqdWJlcyB0aXJhbWlzdSBvYXQgY2FrZS4gU3dlZXQgc291ZmZsw6kgY2hvY29sYXRlLiBMaXF1b3JpY2UgY290dG9uIGNhbmR5IGNob2NvbGF0ZSBtYXJzaG1hbGxvdy4gSmVsbHkgY29va2llIGNha2UgamVsbHkgYm==

The following operation uses :binary:`~bin.mongoimport` with the
:option:`--fields <mongoimport --fields>` and
:option:`--columnsHaveTypes <mongoimport --columnsHaveTypes>` option
to specify both the field names and the BSON types of the imported CSV
data.

.. code-block:: sh

   mongoimport --db=users --collection=contacts --type=csv \
      --columnsHaveTypes \
      --fields="name.string(),birthdate.date(2006-01-02),contacted.boolean(),followerCount.int32(),thumbnail.binary(base64)" \
      --file=/example/file.csv

Ignore Blank Fields
```````````````````

Use the :option:`--ignoreBlanks <mongoimport --ignoreBlanks>` option
to ignore blank fields. For :term:`CSV` and :term:`TSV` imports, this
option provides the desired functionality in most cases because it avoids
inserting fields with null values into your collection.

The following example imports the data from ``data.csv``, skipping
any blank fields:

.. code-block:: sh

   mongoimport --db=users --collection=contacts --type=csv --file=/example/data.csv --ignoreBlanks

.. _mongoimport-example-connect-using-aws-iam:

Connect to a MongoDB Atlas Cluster using AWS IAM Credentials
````````````````````````````````````````````````````````````

.. versionadded:: 100.1.0

To connect to a `MongoDB Atlas
<https://www.mongodb.com/cloud/atlas?tck=docs_server>`__ cluster which
has been configured to support authentication via `AWS IAM credentials
<https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html>`__,
provide a :option:`connection string <mongoimport --uri>` to
|tool-binary| similar to the following:

.. code-block:: none

   mongoimport 'mongodb+srv://<aws access key id>:<aws secret access key>@cluster0.example.com/testdb?authSource=$external&authMechanism=MONGODB-AWS' <other options>

Connecting to Atlas using AWS IAM credentials in this manner uses the
``MONGODB-AWS`` :urioption:`authentication mechanism <authMechanism>`
and the ``$external`` :urioption:`authSource`, as shown in this example.

If using an `AWS session token
<https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html>`__,
as well, provide it with the ``AWS_SESSION_TOKEN``
:urioption:`authMechanismProperties` value, as follows:

.. code-block:: none

   mongoimport 'mongodb+srv://<aws access key id>:<aws secret access key>@cluster0.example.com/testdb?authSource=$external&authMechanism=MONGODB-AWS&authMechanismProperties=AWS_SESSION_TOKEN:<aws session token>' <other options>

If the AWS access key ID, the secret access key, or the session token
include the 'at' sign ``@``, colon ``:``, slash ``/``, or the percent
sign ``%`` characters, those characters must be converted using
`percent encoding <https://tools.ietf.org/html/rfc3986#section-2.1>`__.

Alternatively, the AWS access key ID, secret access key, and optionally
session token can each be provided outside of the connection string
using the :option:`--username`, :option:`--password`, and
:option:`--awsSessionToken` options instead, like so:

.. code-block:: none

   mongoimport 'mongodb+srv://cluster0.example.com/testdb?authSource=$external&authMechanism=MONGODB-AWS' --username <aws access key id> --password <aws secret access key> --awsSessionToken <aws session token> <other options>

When provided as command line parameters, these three options do not
require percent encoding.

You may also set these credentials on your platform using standard
`AWS IAM environment variables
<https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html#envvars-list>`__.
|tool-binary| checks for the following environment variables when you
use the ``MONGODB-AWS``
:urioption:`authentication mechanism <authMechanism>`:

- ``AWS_ACCESS_KEY_ID``
- ``AWS_SECRET_ACCESS_KEY``
- ``AWS_SESSION_TOKEN``

If set, these credentials do not need to be specified in the connection
string or via their explicit options.

.. note::

   If you chose to use the AWS environment variables to specify these
   values, you cannot mix and match with the corresponding explicit or 
   connection string options for these credentials. Either use the
   environment variables for access key ID *and* secret access key
   (*and* session token if used), **or** specify each of these using the
   explicit or connection string options instead.

The following example sets these environment variables in the ``bash``
shell:

.. code-block:: none

   export AWS_ACCESS_KEY_ID='<aws access key id>'
   export AWS_SECRET_ACCESS_KEY='<aws secret access key>'
   export AWS_SESSION_TOKEN='<aws session token>'

Syntax for setting environment variables in other shells will be
different. Consult the documentation for your platform for more
information.

You can verify that these environment variables have been set with the
following command:

.. code-block:: none

   env | grep AWS

Once set, the following example connects to a MongoDB Atlas cluster
using these environment variables:

.. code-block:: none

   mongoimport 'mongodb+srv://cluster0.example.com/testdb?authSource=$external&authMechanism=MONGODB-AWS'  <other options>
