============================
Distributed Write Operations
============================

.. default-domain:: mongodb

.. _write-operations-sharded-clusters:

Write Operations on Sharded Clusters
------------------------------------

For sharded collections in a :term:`sharded cluster`, the
:program:`mongos` directs write operations from applications to the
shards that are responsible for the specific *portion* of the data
set. The :program:`mongos` uses the cluster metadata from the
:ref:`config database <sharding-config-server>` to route the write
operation to the appropriate shards.

.. include:: /images/sharded-cluster.rst

MongoDB partitions data in a sharded collection into *ranges* based on
the values of the :term:`shard key`. Then, MongoDB distributes these
chunks to shards. The shard key determines the distribution of chunks to
shards. This can affect the performance of write operations in the
cluster.

.. include:: /images/sharding-range-based.rst

.. important:: Update operations that affect a *single* document
   **must** include the :term:`shard key` or the ``_id``
   field. Updates that affect multiple documents are more efficient in
   some situations if they have the :term:`shard key`, but can be
   broadcast to all shards.

If the value of the shard key increases or decreases with every
insert, all insert operations target a single shard. As a result, the
capacity of a single shard becomes the limit for the insert capacity
of the sharded cluster.

For more information, see :doc:`/administration/sharded-clusters` and
:ref:`write-operations-bulk-insert`.

.. _write-operations-replica-sets:

Write Operations on Replica Sets
--------------------------------

In :term:`replica sets <replica set>`, all write operations go to the
set's :term:`primary`, which applies the write operation then records
the operations on the primary's operation log or :term:`oplog`. The
oplog is a reproducible sequence of operations to the data
set. :term:`Secondary` members of the set are continuously replicating the
oplog and applying the operations to themselves in an asynchronous
process.

.. include:: /images/replica-set-read-write-operations-primary.rst

Large volumes of write operations, particularly bulk operations, may
create situations where the secondary members have difficulty applying
the replicating operations from the primary at a sufficient rate: this
can cause the secondary's state to fall behind that of the primary. Secondaries
that are significantly behind the primary present problems for normal
operation of the replica set, particularly :ref:`failover
<replica-set-failover-administration>` in the form of :ref:`rollbacks
<replica-set-rollback>` as well as general :doc:`read consistency
</applications/replication>`.

To help avoid this issue, you can customize the :ref:`write concern
<write-operations-write-concern>` to return confirmation of the write
operation to another member [#write-concern-throttling]_ of the replica
set every 100 or 1,000 operations. This provides an opportunity for
secondaries to catch up with the primary. Write concern can slow the
overall progress of write operations but ensure that the secondaries
can maintain a largely current state with respect to the primary.

.. include:: /images/crud-write-concern-w2.rst

For more information on replica sets and write operations, see
:ref:`replica-set-write-concern`, :ref:`replica-set-oplog-sizing`, and
:doc:`/tutorial/change-oplog-size`.

.. [#write-concern-throttling] Intermittently issuing a write concern 
   with a ``w`` value of ``2`` or ``majority`` will
   slow the throughput of write traffic; however, this practice will
   allow the secondaries to remain current with the state of the
   primary.

   .. include:: /includes/fact-master-slave-majority.rst
