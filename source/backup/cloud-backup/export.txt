.. _cloud-provider-snapshot-export:

================================
Export {+Cloud-Backup+} Snapshot
================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. include:: /includes/fact-atlas-free-tier-limits.rst

|service| lets you export your {+Cloud-Backup+} snapshots to an |aws| 
|s3| bucket. 

How |service| Exports Snapshots 
-------------------------------

You can  manually export individual snapshots or set up an export 
policy for automatic export of your snapshots. For automatic exports, 
you must specify a frequency in your export policy: 

- Daily
- Weekly
- Monthly

|service| automatically exports any backup snapshot with the
frequency type that matches the export frequency. The exported result 
is a full backup of that snapshot.

.. example::

   Consider the following: 

   - A backup policy that sets a weekly and monthly snapshot schedule 
   - An export policy that sets a monthly export frequency

   Suppose, at the end of the month, the weekly and monthly snapshots 
   happen on the same day. There would be ``4`` snapshots of which 
   ``3`` would be weekly snapshots and the fourth snapshot, although 
   treated as a weekly snapshot by |service|, would also be the monthly 
   snapshot because it happened on the same day. |service| will export 
   the monthly snapshot only because the export frequency matches the 
   snapshot frequency for that snapshot. To export the weekly snapshots 
   as well, update the export policy to export weekly snapshots also. 
   If the export frequency is set to weekly, |service| would export all 
   ``4`` snapshots.

|service| exports snapshots for collections one at a time. As the 
export progresses, you may see partial results in your |s3| bucket. 
|service| queues any new job if |service| is currently exporting 5 or 
more replica sets. For sharded clusters, |service| always exports the 
snapshots of all the shards simultaneously, regardless of the number 
of shards. 

.. include:: /includes/fact-snapshot-export-cost.rst

Files |service| Uploads
~~~~~~~~~~~~~~~~~~~~~~~

|service| uploads an empty file to ``/exported_snapshots/.permissioncheck`` 
when you:

- Add a new |aws| |s3| export bucket
- Start an export

After |service| finishes exporting, |service| uploads a metadata file 
named ``.complete`` and a metadata file named ``metadata.json`` for 
each collection. 

.. tabs:: 

   .. tab:: .complete File 
      :tabid: complete

      |service| uploads the metadata file named ``.complete`` in the 
      following path on your |s3| bucket: 

      .. code-block:: shell
         :copyable: false

         /exported_snapshots/<orgUUID>/<projectUUID>/<clusterName>/<initiationDateOfSnapshot>/<timestamp>/

      .. note:: 

         By default, |service| uses organization and project UUIDs in 
         the path for the metadata files. To use organization and 
         project names instead of UUIDs, set the 
         ``useOrgAndGroupNamesInExportPrefix`` flag to ``true`` via the 
         :oas-atlas-op:`API 
         </updateCloudBackupBackupPolicyForOneCluster>`. |service| 
         replaces any spaces with underscores (``_``) and removes any 
         :aws:`characters that might require special handling 
         </AmazonS3/latest/userguide/object-keys.html>` and 
         :aws:`characters to avoid 
         </AmazonS3/latest/userguide/object-keys.html>` from the 
         organization and project names in the path.

      The ``.complete`` metadata file is in |json| format and contains 
      the following fields: 

      .. list-table::
         :header-rows: 1
         :widths: 35 65 

         * - Field
           - Description 

         * - ``orgId``
           - Unique 24-hexadecimal digit string that identifies the 
             |service| organization.

         * - ``orgName``
           - Name of the |service| organization. 

         * - ``groupId``
           - Unique 24-hexadecimal digit string that identifies the 
             project in the |service| organization.

         * - ``groupName``
           - Name of the |service| project. 

         * - ``clusterUniqueId``
           - Unique 24-hexadecimal digit string that identifies the 
             |service| cluster.

         * - ``clusterName``
           - Name of the |service| project.

         * - ``snapshotInitiationDate``
           - Date when snapshot was taken.

         * - ``totalFiles``
           - Total number of files uploaded to the |s3| bucket.

         * - ``labels``
           - Labels of the cluster whose snapshot was exported.

         * - ``customData``
           - Custom data, if any, that you specified when creating the 
             export job.

      .. example:: 

         .. code-block:: json 
            :copyable: false 

            {
              "orgId": "60512d6f65e4047fe0842095",
              "orgName": "org1",
              "groupId": "60512dac65e4047fe084220f",
              "groupName": "group1",
              "clusterUniqueId": "60512dac65e4047fe0842212",
              "clusterName": "cluster0",
              "snapshotInitiationDate": "2020-04-03T05:50:29.321Z"
              "totalFiles": 23,
              "labels": [
                {
                  "key": "key1",
                  "value": "xyz"
                },
                {
                  "key": "key2",
                  "value": "xyzuio"
                }
              ],
              "customData": [
                {
                  "key": "key1",
                  "value": "xyz"
                },
                {
                  "key": "key2",
                  "value": "xyzuio"
                }
              ]
            }

   .. tab:: metadata.json File 
      :tabid: metadata

      |service| uploads the ``metadata.json`` file for each collection 
      in the following path on your |s3| bucket: 

      .. code-block:: shell
         :copyable: false

         /exported_snapshots/<orgUUID>/<projectUUID>/<clusterName>/<initiationDateOfSnapshot>/<timestamp>/<dbName>/<collectionName>/metadata.json

      .. note:: 

         By default, |service| uses organization and project UUIDs in 
         the path for the metadata files. To use organization and 
         project names instead of UUIDs, set the 
         ``useOrgAndGroupNamesInExportPrefix`` flag via the 
         :oas-atlas-op:`API 
         </updateCloudBackupBackupPolicyForOneCluster>` to true. 
         |service| replaces any spaces with underscores (``_``) and 
         removes any :aws:`characters that might require special 
         handling </AmazonS3/latest/userguide/object-keys.html>` and 
         :aws:`characters to avoid 
         </AmazonS3/latest/userguide/object-keys.html>` from the 
         organization and project names in the path.

      The metadata file is in |json| format and contains the following 
      fields: 

      .. list-table::
         :header-rows: 1
         :widths: 35 65 

         * - Field
           - Description 

         * - ``collectionName``
           - Human-readable label that identifies the collection.

         * - ``indexes``
           - List of all the indexes on the collection in the format 
             returned by :manual:`db.collection.getIndexes 
             </reference/method/db.collection.getIndexes/#output>` 
             command. 

         * - ``options``
           - Configuration options defined on the collection. To learn 
             more about the options, see :manual:`db.createCollection() 
             </reference/method/db.createCollection/>` command.

         * - ``type``
           - Type of collection. Value can be one of the following: 

             - ``view`` - for a view on a collection 
             - ``timeseries`` - for a timeseries collection 

             This field is not returned for a standard collection.

         * - ``uuid``
           - Collection's UUID. To learn more about UUID, see 
             :manual:`UUID </reference/method/UUID/>`.

      .. example:: 

         .. code-block:: json 
            :copyable: false 

            {
              "options":{
                "viewOn":"othercol",
                "pipeline":[{"$project":{"namez":"$name"}}]
              },
              "indexes":[],
              "collectionName":"viewcol",
              "type":"view"
            }

         .. code-block:: json 
            :copyable: false

            {
              "options":{
                "timeseries":{
                  "timeField":"timestamp",
                  "granularity":"seconds",
                  "bucketMaxSpanSeconds":{"$numberInt":"3600"}
                }
              },
              "indexes":[],
              "collectionName":"timeseriescol",
              "type":"timeseries"
            }

         .. code-block:: json 
            :copyable: false

            {
              "indexes": [
                {
                  "v":{"$numberInt":"2"},
                  "key":{
                    "_id":{"$numberInt":"1"}
                  },
                  "name":"_id_"
                }
              ],
              "uuid":"342c40a937c34c478bab03de8ce44f3e",
              "collectionName":"somecol"
            }

If an export job fails: 

- |service| doesn't automatically try to export again.
- |service| doesn't remove any partial data in your |s3| bucket.

Exported Data Format
--------------------

|service| uploads the contents of your database to |s3| in ``.json.gz`` 
format with documents in extended |json| format within. The path 
to the files on |s3| is: 

.. code-block:: sh 
   :copyable: false 

   /exported_snapshots/<orgName>/<projectName>/<clusterName>/<initiationDateOfSnapshot>/<timestamp>/<dbName>/<collectionName>/<shardName>.<increment>.json.gz

Where: 

.. list-table:: 
   :widths: 35 65

   * - ``<orgName>``
     - Name of your |service| organization.

   * - ``<projectName>``
     - Name of your |service| project.

   * - ``<clusterName>``
     - Name of your |service| cluster.

   * - ``<initiationDateOfSnapshot>``
     - Date when snapshot was taken.

   * - ``<timestamp>``
     - Timestamp when the export job was created.

   * - ``<dbName>``
     - Name of the database in the |service| cluster.

   * - ``<collectionName>``
     - Name of the |service| collection.

   * - ``<shardName>``
     - Name of the replica set.

   * - ``<increment>``
     - Count that is incremented as chunks are uploaded. Starts at 
       ``0``.

Limitations 
-----------

The following limitations apply:

- You can only export to |aws| |s3| buckets.
- You can only export snapshots for `currently supported versions of MongoDB <https://www.mongodb.com/support-policy/lifecycles>`__, but you can always 
  download saved snapshots, regardless of the version.
- You can't export :ref:`fallback snapshots <cps-fallback-snapshots>`.
- You can have only one active export per snapshot.

 

.. important::
   
   When you export snapshots from a sharded cluster to |s3| buckets, the export from each 
   shard might have a different timestamp. This can result in duplicate or inconsistent 
   data across the shards.

Prerequisites
-------------

To export your {+Cloud-Backup+} snapshots to an |aws| |s3| bucket, you 
will need the following:

1. ``M10`` or higher |service| cluster with {+Cloud-Backup+} 
   :ref:`enabled <backup-cloud-provider>`.
#. |aws| `IAM role <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use.html>`__ 
   with ``STS:AssumeRole`` that grants |service| access to your |aws| 
   resources. To learn more about configuring |aws| access for 
   |service|, see :ref:`set-up-unified-aws-access`.
#. |aws| `IAM role policy <https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html>`__ 
   that grants |service| write access or the ``S3:PutObject`` and 
   ``S3:GetBucketLocation`` permissions to your |aws| resources. To 
   learn more about configuring write access to |aws| resources, see 
   :ref:`set-up-unified-aws-access`.

   .. example:: 

      .. code-block:: json

         {
           "Version": "2012-10-17",
           "Statement": [
             {
               "Effect": "Allow",
               "Action": "s3:GetBucketLocation",
               "Resource": "arn:aws:s3:::bucket-name"
             },
             {
               "Effect": "Allow",
               "Action": "s3:PutObject",
               "Resource": "arn:aws:s3:::bucket-name/*"
             }
           ]
         }

Export Management 
-----------------

.. tabs::

   .. tab:: {+atlas-cli+}
      :tabid: atlascli

      Manage Export Jobs
      ~~~~~~~~~~~~~~~~~~

      You can manage export jobs using the {+atlas-cli+} by creating or viewing export jobs.

      Create an Export Job
      `````````````````````

      .. include:: /includes/extracts/atlas-backups-exports-jobs-create.rst

      View Export Jobs
      `````````````````

      .. include:: /includes/extracts/atlas-backups-exports-jobs-describe-and-list.rst

      Manage Export Buckets
      ~~~~~~~~~~~~~~~~~~~~~

      You can manage export buckets using the {+atlas-cli+} by creating, viewing, or deleting export buckets.

      Create an Export Bucket
      ```````````````````````

      .. include:: /includes/extracts/atlas-backups-exports-buckets-create.rst

      View Export Buckets
      ```````````````````

      .. include:: /includes/extracts/atlas-backups-exports-buckets-describe-and-list.rst

      Delete an Export Bucket
      ```````````````````````

      .. include:: /includes/extracts/atlas-backups-exports-buckets-delete.rst

   .. tab:: {+atlas-admin-api+}
      :tabid: api

      Use the following APIs to: 

      - Manage export policy including :oas-atlas-op:`modifying 
        </updateCloudBackupBackupPolicyForOneCluster>` and 
        :oas-atlas-op:`retrieving </returnOneCloudBackupSchedule>` 
        snapshot policy for :oas-atlas-tag:`exporting 
        </Cloud-Backup-Export>`.
      - :oas-atlas-tag:`Manage </Cloud-Backup-Export>` export buckets  
        including :oas-atlas-op:`creating 
        </grantAccessToAwsS3BucketForCloudBackupSnapshotExports>`,
        :oas-atlas-op:`retrieving 
        </returnAllAwsS3BucketsUsedForCloudBackupSnapshotExports>`, and 
        :oas-atlas-op:`deleting 
        </revokeAccessToAwsS3BucketForCloudBackupSnapshotExports>` 
        export buckets.
      - :oas-atlas-tag:`Manage <Cloud-Backup-Export>` export jobs 
        including :oas-atlas-op:`creating 
        </createOneCloudBackupSnapshotExportJob>` and 
        :oas-atlas-op:`retrieving 
        </returnAllCloudBackupSnapshotExportJobs>` export jobs.
