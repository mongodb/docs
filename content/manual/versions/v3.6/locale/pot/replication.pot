# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008-2019
# This file is distributed under the same license as the mongodb-manual package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: mongodb-manual 3.6\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-03-19 11:30-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/replication.txt:5
msgid "Replication"
msgstr ""

#: ../source/replication.txt:18
msgid "A *replica set* in MongoDB is a group of :binary:`~bin.mongod` processes that maintain the same data set. Replica sets provide redundancy and :term:`high availability`, and are the basis for all production deployments. This section introduces replication in MongoDB as well as the components and architecture of replica sets. The section also provides tutorials for common tasks related to replica sets."
msgstr ""

#: ../source/replication.txt:26
msgid "Redundancy and Data Availability"
msgstr ""

#: ../source/replication.txt:28
msgid "Replication provides redundancy and increases :term:`data availability <high availability>`. With multiple copies of data on different database servers, replication provides a level of fault tolerance against the loss of a single database server."
msgstr ""

#: ../source/replication.txt:34
msgid "In some cases, replication can provide increased read capacity as clients can send read operations to different servers. Maintaining copies of data in different data centers can increase data locality and availability for distributed applications. You can also maintain additional copies for dedicated purposes, such as disaster recovery, reporting, or backup."
msgstr ""

#: ../source/replication.txt:42
msgid "Replication in MongoDB"
msgstr ""

#: ../source/replication.txt:44
msgid "A replica set is a group of :binary:`~bin.mongod` instances that maintain the same data set. A replica set contains several data bearing nodes and optionally one arbiter node. Of the data bearing nodes, one and only one member is deemed the primary node, while the other nodes are deemed secondary nodes."
msgstr ""

#: ../source/replication.txt:50
msgid "The :doc:`primary node </core/replica-set-primary>` receives all write operations. A replica set can have only one primary capable of confirming writes with :writeconcern:`{ w: \"majority\" } <\"majority\">` write concern; although in some circumstances, another mongod instance may transiently believe itself to also be primary. [#edge-cases-2-primaries]_ The primary records all changes to its data sets in its operation log, i.e. :doc:`oplog </core/replica-set-oplog>`. For more information on primary node operation, see :doc:`/core/replica-set-primary`."
msgstr ""

#: ../source/replication.txt:62
msgid "The :doc:`secondaries </core/replica-set-secondary>` replicate the primary's oplog and apply the operations to their data sets such that the secondaries' data sets reflect the primary's data set. If the primary is unavailable, an eligible secondary will hold an election to elect itself the new primary. For more information on secondary members, see :doc:`/core/replica-set-secondary`."
msgstr ""

#: ../source/replication.txt:71
msgid "You may add an extra :binary:`~bin.mongod` instance to a replica set as an :doc:`arbiter </core/replica-set-arbiter>`. Arbiters do not maintain a data set. The purpose of an arbiter is to maintain a quorum in a replica set by responding to heartbeat and election requests by other replica set members. Because they do not store a data set, arbiters can be a good way to provide replica set quorum functionality with a cheaper resource cost than a fully functional replica set member with a data set. If your replica set has an even number of members, add an arbiter to obtain a majority of votes in an election for primary. Arbiters do not require dedicated hardware. For more information on arbiters, see :doc:`/core/replica-set-arbiter`."
msgstr ""

#: ../source/replication.txt:85
msgid "An :doc:`arbiter </core/replica-set-arbiter>` will always be an arbiter whereas a :doc:`primary </core/replica-set-primary>` may step down and become a :doc:`secondary </core/replica-set-secondary>` and a :doc:`secondary </core/replica-set-secondary>` may become the primary during an election."
msgstr ""

#: ../source/replication.txt:94
msgid "Asynchronous Replication"
msgstr ""

#: ../source/replication.txt:96
msgid "Secondaries apply operations from the primary asynchronously. By applying operations after the primary, sets can continue to function despite the failure of one or more members. For more information on replication mechanics, see :ref:`replica-set-oplog` and :ref:`replica-set-sync`."
msgstr ""

#: ../source/includes/fact-slow-oplog-log-message-footnote.rst:1
msgid "For MongoDB 3.6 deployments, starting in version 3.6.11, secondary members of a replica set now :ref:`log oplog entries <slow-oplog>` that take longer than the slow operation threshold to apply. These slow oplog messages are logged for the secondaries in the :option:`diagnostic log <mongod --logpath>` under the :data:`REPL` component with the text ``applied op: <oplog entry> took <num>ms``. These slow oplog entries depend only on the slow operation threshold. They do not depend on the log levels (either at the system or component level), or the profiling level, or the slow operation sample rate. The profiler does not capture slow oplog entries."
msgstr ""

#: ../source/replication.txt:107
msgid "Automatic Failover"
msgstr ""

#: ../source/replication.txt:109
msgid "When a primary does not communicate with the other members of the set for more than the configured :rsconf:`electionTimeoutMillis` period (10 seconds by default), an eligible secondary calls for an election to nominate itself as the new primary. The cluster attempts to complete the election of a new primary and resume normal operations."
msgstr ""

#: ../source/replication.txt:117
msgid "The replica set cannot process write operations until the election completes successfully.  The replica set can continue to serve read queries if such queries are configured to :ref:`run on secondaries <replica-set-read-preference>` while the primary is offline."
msgstr ""

#: ../source/includes/fact-election-latency.rst:1
msgid "The median time before a cluster elects a new primary should not typically exceed 12 seconds, assuming default :rsconf:`replica configuration settings <settings>`. This includes time required to mark the primary as :ref:`unavailable <replication-auto-failover>` and call and complete an :ref:`election <replica-set-elections>`. You can tune this time period by modifying the :rsconf:`settings.electionTimeoutMillis` replication configuration option. Factors such as network latency may extend the time required for replica set elections to complete, which in turn affects the amount of time your cluster may operate without a primary. These factors are dependent on your particular cluster architecture."
msgstr ""

#: ../source/replication.txt:125
msgid "Lowering the :rsconf:`~settings.electionTimeoutMillis` replication configuration option from the default ``10000`` (10 seconds) can result in faster detection of primary failure. However, the cluster may call elections more frequently due to factors such as temporary network latency even if the primary is otherwise healthy. This can result in increased :ref:`rollbacks <replica-set-rollback>` for :ref:`w : 1 <wc-w>` write operations."
msgstr ""

#: ../source/includes/fact-retryable-writes-failover-election.rst:1
msgid "Your application connection logic should include tolerance for automatic failovers and the subsequent elections."
msgstr ""

#: ../source/includes/fact-retryable-writes-failover-election.rst:6
msgid "MongoDB 3.6+ drivers can detect the loss of the primary and automatically :ref:`retry certain write operations <retryable-writes>` a single time, providing additional built-in handling of automatic failovers and elections."
msgstr ""

#: ../source/replication.txt:135
msgid "See :ref:`replica-set-elections` for complete documentation on replica set elections."
msgstr ""

#: ../source/replication.txt:138
msgid "To learn more about MongoDB's failover process, see:"
msgstr ""

#: ../source/replication.txt:140
msgid ":ref:`replica-set-elections`"
msgstr ""

#: ../source/replication.txt:141
msgid ":ref:`retryable-writes`"
msgstr ""

#: ../source/replication.txt:142
msgid ":ref:`replica-set-rollback`"
msgstr ""

#: ../source/replication.txt:149
msgid "Read Operations"
msgstr ""

#: ../source/replication.txt:151
msgid "By default, clients read from the primary [#edge-cases-2-primaries]_; however, clients can specify a :doc:`read preference </core/read-preference>` to send read operations to secondaries. :ref:`Asynchronous replication <asynchronous-replication>` to secondaries means that reads from secondaries may return data that does not reflect the state of the data on the primary. For information on reading from replica sets, see :doc:`/core/read-preference`."
msgstr ""

#: ../source/includes/extracts/concurrent-operations-read-uncommitted.rst:1
msgid "In MongoDB, clients can see the results of writes before the writes are :term:`durable`:"
msgstr ""

#: ../source/includes/list-visibility-of-data.rst:1
msgid "Regardless of :doc:`write concern </reference/write-concern>`, other clients using :readconcern:`\"local\"` or :readconcern:`\"available\"` readConcern can see the result of a write operation before the write operation is acknowledged to the issuing client."
msgstr ""

#: ../source/includes/list-visibility-of-data.rst:6
msgid "Clients using :readconcern:`\"local\"` or :readconcern:`\"available\"` readConcern can read data which may be subsequently :doc:`rolled back </core/replica-set-rollbacks>`."
msgstr ""

#: ../source/replication.txt:161
msgid "For more information on read isolations, consistency and recency for MongoDB, see :doc:`/core/read-isolation-consistency-recency`."
msgstr ""

#: ../source/replication.txt:165
msgid "Additional Features"
msgstr ""

#: ../source/replication.txt:167
msgid "Replica sets provide a number of options to support application needs. For example, you may deploy a replica set with :doc:`members in multiple data centers </core/replica-set-architecture-geographically-distributed>`, or control the outcome of elections by adjusting the :rsconf:`members[n].priority` of some members. Replica sets also support dedicated members for reporting, disaster recovery, or backup functions."
msgstr ""

#: ../source/replication.txt:176
msgid "See :ref:`replica-set-secondary-only-members`, :ref:`replica-set-hidden-members` and :ref:`replica-set-delayed-members` for more information."
msgstr ""

#: ../source/includes/footnote-two-primaries-edge-cases.rst:1
msgid "In :ref:`some circumstances <edge-cases>`, two nodes in a replica set may *transiently* believe that they are the primary, but at most, one of them will be able to complete writes with :writeconcern:`{ w: \"majority\" } <\"majority\">` write concern. The node that can complete :writeconcern:`{ w: \"majority\" } <\"majority\">` writes is the current primary, and the other node is a former primary that has not yet recognized its demotion, typically due to a :term:`network partition`. When this occurs, clients that connect to the former primary may observe stale data despite having requested read preference :readmode:`primary`, and new writes to the former primary will eventually roll back."
msgstr ""

