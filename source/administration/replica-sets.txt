==========================
Replica Set Administration
==========================

.. default-domain:: mongodb

:term:`Replica sets <replica set>` automate most administrative tasks
associated with database replication.  Nevertheless, several
operations related to deployment and systems management require
administrator intervention remain. This document provides an overview
of those tasks, in addition to a collection of troubleshooting
suggestions for administers of replica sets.

.. seealso::

   - :method:`rs.status()` and :method:`db.isMaster()`
   - :ref:`Replica Set Reconfiguration Process <replica-set-reconfiguration-usage>`
   - :method:`rs.conf()` and :method:`rs.reconfig()`
   - :doc:`/reference/replica-configuration`

   The following tutorials provide task-oriented instructions for
   specific administrative tasks related to replica set operation.

   - :doc:`/tutorial/change-hostnames-in-a-replica-set`
   - :doc:`/tutorial/change-oplog-size`
   - :doc:`/tutorial/convert-replica-set-to-replicated-shard-cluster`
   - :doc:`/tutorial/convert-secondary-into-arbiter`
   - :doc:`/tutorial/deploy-geographically-distributed-replica-set`
   - :doc:`/tutorial/deploy-replica-set`
   - :doc:`/tutorial/expand-replica-set`

.. _replica-set-node-configurations:
.. _replica-set-member-configurations:

Member Configurations
---------------------

All :term:`replica sets <replica set>` have a single :term:`primary` and one or more
:term:`secondaries <secondary>`. Replica sets allow you to configure
secondary members in a variety of ways. This section describes these
configurations.

.. note::

   A replica set can have up to 12 members, but only 7 members can have
   votes. For configuration information regarding non-voting members, see
   :ref:`replica-set-non-voting-members`.

.. warning::

   The :method:`rs.reconfig()` shell command can force the current
   primary to step down, which causes an :ref:`election <replica-set-elections>`. When the primary
   steps down, the :program:`mongod` closes all client
   connections. While, this typically takes 10-20 seconds, attempt to
   make these changes during scheduled maintenance periods.

.. include:: /includes/seealso-elections.rst

.. index:: replica set members; secondary only
.. _replica-set-secondary-only-members:
.. _replica-set-secondary-only-configuration:

Secondary-Only Members
~~~~~~~~~~~~~~~~~~~~~~

The secondary-only configuration prevents a :term:`secondary` member in a
:term:`replica set` from ever becoming a :term:`primary` in a
:term:`failover`. You can set secondary-only mode for any member of
the set.

For example, you may want to configure all members of a replica sets
located outside of the main data centers as secondary-only to prevent
these members from ever becoming primary.

To configure a member as secondary-only, set its
:data:`members[n].priority` value to ``0``. Any member with a
:data:`members[n].priority` equal to ``0`` will never seek
:ref:`election <replica-set-elections>` and cannot become primary in any
situation. For more information on priority levels, see
:ref:`replica-set-node-priority`.

As an example of modifying member priorities, assume a four-member
replica set with member ``_id`` values of: ``0``, ``1``, ``2``, and
``3``. Use the following sequence of operations in the :program:`mongo`
shell to modify member priorities:

.. code-block:: javascript

   cfg = rs.conf()
   cfg.members[0].priority = 0
   cfg.members[1].priority = 0.5
   cfg.members[2].priority = 1
   cfg.members[3].priority = 2
   rs.reconfig(cfg)

This sets the following:

- Member ``0`` to a priority of ``0`` so that it can never become :term:`primary`.

- Member ``1`` to a priority of ``0.5``, which makes it less likely to
  become primary than other members but doesn't prohibit the
  possibility.

- Member ``2`` to a priority of ``1``, which is the default value.
  Member ``2`` becomes primary if no member with a *higher* priority is
  eligible.

- Member ``3`` to a priority of ``2``. Member ``3`` becomes primary, if
  eligible, under most circumstances.

.. note::

   If your replica set has an even number of members, add an
   :ref:`arbiter <replica-set-arbiters>` to ensure that
   members can quickly obtain a majority of votes in an
   election for primary.

.. seealso:: :data:`members[n].priority` and :ref:`Replica Set
   Reconfiguration <replica-set-reconfiguration-usage>`.

.. index:: replica set members; hidden
.. _replica-set-hidden-members:
.. _replica-set-hidden-configuration:

Hidden Members
~~~~~~~~~~~~~~

Hidden members are part of a replica set but cannot become
primary and are invisible to client applications. *However,*
hidden members **do** vote in :ref:`elections <replica-set-elections>`.

Hidden members are ideal for instances that will have significantly
different usage patterns than the other members and require separation
from normal traffic. Typically, hidden members provide reporting,
dedicated backups, and dedicated read-only testing and integration
support.

Hidden members have :data:`members[n].priority` set
``0`` and have :data:`members[n].hidden` set to ``true``.

To configure a :term:`hidden member`, use the following sequence of
operations in the :program:`mongo` shell:

.. code-block:: javascript

   cfg = rs.conf()
   cfg.members[0].priority = 0
   cfg.members[0].hidden = true
   rs.reconfig(cfg)

After re-configuring the set, the member with the ``_id`` of ``0``
has a priority of ``0`` so that it cannot become primary. The
other members in the set will not advertise the hidden member in the
:dbcommand:`isMaster` or :method:`db.isMaster()` output.

.. note::

   You must send the :method:`rs.reconfig()` command to a set member
   that *can* become :term:`primary`. In the above example, if you issue
   the :method:`rs.reconfig()` operation to the member with the ``_id``
   of ``0``, the operation fails.

.. seealso:: :ref:`Replica Set Read Preference <replica-set-read-preference>`
   and :ref:`Replica Set Reconfiguration <replica-set-reconfiguration-usage>`.

.. index:: replica set members; delayed
.. _replica-set-delayed-members:
.. _replica-set-delayed-configuration:

Delayed Members
~~~~~~~~~~~~~~~

Delayed members copy and apply operations from the primary's :term:`oplog` with
a specified delay. If a member has a delay of one hour, then
the latest entry in this member's oplog will not be more recent than
one hour old, and the state of data for the member will reflect the state of the
set an hour earlier.

.. example:: If the current time is 09:52 and the secondary is a
   delayed by an hour, no operation will be more recent than 08:52.

Delayed members may help recover from various kinds of human error. Such
errors may include inadvertently deleted databases or botched
application upgrades. Consider the following factors when determining
the amount of slave delay to apply:

- Ensure that the length of the delay is equal to or greater than your
  maintenance windows.

- The size of the oplog is sufficient to capture *more than* the
  number of operations that typically occur in that period of
  time. For more information on oplog size, see the
  :ref:`replica-set-oplog-sizing` topic in the :doc:`/core/replication` document.

Delayed members must have a :term:`priority` set to ``0`` to prevent
them from becoming primary in their replica sets. Also these members
should be :ref:`hidden <replica-set-hidden-members>` to prevent your
application from seeing or querying this member.

To configure a :term:`replica set` member with a one hour delay, use the
following sequence of operations in the :program:`mongo` shell:

.. code-block:: javascript

   cfg = rs.conf()
   cfg.members[0].priority = 0
   cfg.members[0].slaveDelay = 3600
   rs.reconfig(cfg)

After the replica set reconfigures, the set member with the ``_id`` of
``0`` has a priority of ``0`` and cannot become :term:`primary`. The :data:`slaveDelay <members[n].slaveDelay>` value
delays both replication and the member's :term:`oplog` by 3600 seconds (1
hour). Setting :data:`slaveDelay <members[n].slaveDelay>` to a
non-zero value also sets :data:`hidden <members[n].hidden>` to
``true`` for this replica set so that it does not receive application
queries in normal operations.

.. warning::

   The length of the secondary :data:`slaveDelay
   <members[n].slaveDelay>` must fit within the window of the
   oplog. If the oplog is shorter than the :data:`slaveDelay
   <members[n].slaveDelay>` window, the delayed member cannot
   successfully replicate operations.

.. seealso:: :data:`members[n].slaveDelay`, :ref:`Replica Set Reconfiguration
   <replica-set-reconfiguration-usage>`, :ref:`replica-set-oplog-sizing`,
   :ref:`replica-set-procedure-change-oplog-size` in this document,
   and the :doc:`/tutorial/change-oplog-size` tutorial.

.. index:: replica set members; arbiters
.. _replica-set-arbiters:
.. _replica-set-arbiter-configuration:

Arbiters
~~~~~~~~

Arbiters are special :program:`mongod` instances that do not hold a
copy of the data and thus cannot become primary. Arbiters exist solely
participate in :ref:`elections <replica-set-elections>`.

.. note::

   Because of their minimal system requirements, you may safely deploy an
   arbiter on a system with another workload such as an application
   server or monitoring member.

.. warning::

   Do not run arbiter processes on a system that is an active
   :term:`primary` or :term:`secondary` of its replica set.

Arbiters never receive the contents of any collection but do have the
following interactions with the rest of the replica set:

- Credential exchanges that authenticate the arbiter with
  the replica set. All MongoDB processes within a replica set use
  keyfiles. These exchanges are encrypted.

- The *only* cryptographically secure exchange is
  authentication. Replica set configuration data and voting are not
  encrypted.

If your MongoDB deployment uses SSL, then all communications between
arbiters and the other members of the replica set are secure. See the
documentation for :doc:`/administration/ssl` for more information. Run
all arbiters on secure networks, as with all MongoDB components.

To start an arbiter, use the following command:

.. code-block:: sh

   mongod --replSet [setname]

Replace ``[setname]`` with the name of the :term:`replica set` that the
arbiter will join. Then in the :program:`mongo` shell, while connected
to the *current* :term:`primary`, issue the following command:

.. code-block:: javascript

   rs.addArb("[hostname]:[port]")

Replace the ``[hostname]:[port]`` string with the arbiter's
hostname and the port.

.. seealso:: :setting:`replSet`, :option:`--replSet <mongod --replSet>`,
   and :method:`rs.addArb()`.

.. index:: replica set members; non-voting
.. _replica-set-non-voting-members:
.. _replica-set-non-voting-configuration:

Non-Voting Members
~~~~~~~~~~~~~~~~~~

You may choose to change the number of votes that each member has in
:ref:`elections <replica-set-elections>` for :term:`primary`. In general, all
members should have only 1 vote to prevent intermittent ties, deadlock,
or the wrong members from becoming :term:`primary`. Use :ref:`replica
set priorities <replica-set-node-priority>` to control which members
are more likely to become primary.

To disable a member's ability to vote in elections, use the following
command sequence in the :program:`mongo` shell.

.. code-block:: javascript

   cfg = rs.conf()
   cfg.members[3].votes = 0
   cfg.members[4].votes = 0
   cfg.members[5].votes = 0
   rs.reconfig(cfg)

This sequence gives ``0`` votes to set members with the ``_id``
values of ``3``, ``4``, and ``5``. This setting allows the set to
elect these members as :term:`primary` but does not allow them to
vote in elections. If you have three non-voting members, you can add
three additional voting members to your set. Place voting members so that
your designated primary or primaries can reach a majority of votes in
the event of a network partition.

.. note::

   In general and when possible, all members should have only 1 vote. This
   prevents intermittent ties, deadlocks, or the wrong members from
   becoming primary. Use :ref:`Replica Set Priorities
   <replica-set-node-priority>` to control which members are more
   likely to become primary.

.. seealso:: :data:`members[n].votes` and :ref:`Replica Set
   Reconfiguration <replica-set-reconfiguration-usage>`.

Procedures
----------

.. _replica-set-admin-procedure-add-member:

Adding Members
~~~~~~~~~~~~~~

Before adding a new member to an existing :term:`replica set`, do one of
the following to prepare the new member's :term:`data directory <dbpath>`:

- Make sure the new member's data directory *does not* contain data. The
  new member will copy the data from an existing member.

  If the new member is in a :term:`recovering` state, it must exit and
  become a :term:`secondary` before MongoDB
  can copy all data as part of the replication process. This process
  takes time but does not require administrator intervention.

- Manually copy the data directory from an existing member. The new
  member becomes a secondary member and will catch up to the current
  state of the replica set after a short interval. Copying the data over
  manually shortens the amount of time for the new member to become
  current.

  Ensure that you can copy the data directory to the new member and
  begin replication within the :ref:`window allowed by the oplog <replica-set-oplog-sizing>`. If the
  difference in the amount of time between the most recent operation and
  the most recent operation to the database exceeds the length of the
  :term:`oplog` on the existing members, then the new instance will have
  to completely re-synchronize.

   Use :method:`db.printReplicationInfo()` to check the current state of
   replica set members with regards to the oplog.

For the procedure to add a member to a replica set, see
:doc:`/tutorial/expand-replica-set`.

.. _replica-set-admin-procedure-remove-members:

Removing Members
~~~~~~~~~~~~~~~~

You may remove a member of a replica at any time. Use the
:method:`rs.remove()` function in the :program:`mongo` shell while
connected to the current :term:`primary`. Issue the
:method:`db.isMaster()` command when connected to *any* member of the
set to determine the current primary. Use a command in either
of the following forms to remove the member:

.. code-block:: javascript

   rs.remove("mongo2.example.net:27017")
   rs.remove("mongo3.example.net")

This operation disconnects the shell briefly and forces a
re-connection as the :term:`replica set` renegotiates which member
will be primary. The shell displays an error even if this
command succeeds.

You can re-add a removed member to a replica set at any time using the
:ref:`procedure for adding replica set members <replica-set-admin-procedure-add-member>`.
Additionally, consider using the :ref:`replica set reconfiguration procedure
<replica-set-reconfiguration-usage>` to change the
:data:`members[n].host` value to rename a member in a replica set
directly.

.. _replica-set-admin-procedure-replace-member:

Replacing a Member
~~~~~~~~~~~~~~~~~~

Use this procedure to replace a member of a replica set when the host
name has changed. This procedure preserves all existing configuration
for a member, except its hostname/location.

You may need to replace a replica set member if you want to replace an
existing system and only need to change the hostname rather than
completely replace all configured options related to the previous
member.

Use :method:`rs.reconfig()` to change the value of the
:data:`members[n].host` field to reflect the new hostname or port
number. :method:`rs.reconfig()` will not change the value of
:data:`members[n]._id`.

.. code-block:: javascript

   cfg = rs.conf()
   cfg.members[0].host = "mongo2.example.net:27019"
   rs.reconfig(cfg)

.. warning::

   Any replica set configuration change can trigger the current
   :term:`primary` to step down, which forces an :ref:`election <replica-set-elections>`. This
   causes the current shell session, and clients connected to this replica set,
   to produce an error even when the operation succeeds.

.. _replica-set-node-priority-configuration:
.. _replica-set-member-priority-configuration:

Adjusting Priority
~~~~~~~~~~~~~~~~~~~~

To change the value of the :data:`members[n].priority` value in the
replica set configuration, use the following sequence of commands in
the :program:`mongo` shell:

.. code-block:: javascript

   cfg = rs.conf()
   cfg.members[0].priority = 0.5
   cfg.members[1].priority = 2
   cfg.members[2].priority = 2
   rs.reconfig(cfg)

The first operation uses :method:`rs.conf()` to set the local variable
``cfg`` to the contents of the current replica set configuration, which
is a :term:`document`. The next three operations change the
:data:`members[n].priority` value in the ``cfg`` document for
:data:`members[n]._id` of ``0``, ``1``, or ``2``. The final operation
calls :method:`rs.reconfig()` with the argument of ``cfg`` to initialize
the new configuration.

If a member has :data:`members[n].priority` set to ``0``, it is
ineligible to become :term:`primary` and will not seek
election. :ref:`Hidden members <replica-set-hidden-members>`,
:ref:`delayed members <replica-set-delayed-members>`, and
:ref:`arbiters <replica-set-arbiters>` all have :data:`members[n].priority`
set to ``0``.

All members have a :data:`members[n].priority` equal to ``1`` by default.

The value of :data:`members[n].priority` can be any floating point
(i.e. decimal) number between ``0`` and ``1000``. Priorities
are only used to determine the preference in election. The priority
value is used only in relation to other members. With the exception of
members with a priority of ``0``, the absolute value of the
:data:`members[n].priority` value is irrelevant.

Replica sets will preferentially elect and maintain the primary status
of the member with the highest :data:`members[n].priority` setting.

.. warning::

   Replica set reconfiguration can force the current primary to step
   down, leading to an election for primary in the replica
   set. Elections cause the current primary to close all open
   :term:`client` connections.

   Perform routine replica set reconfiguration during scheduled
   maintenance windows.

.. seealso:: The :ref:`Replica Reconfiguration Usage
   <replica-set-reconfiguration-usage>` example revolves around
   changing the priorities of the :data:`members` of a replica set.

.. _replica-set-procedure-change-oplog-size:

Changing Oplog Size
~~~~~~~~~~~~~~~~~~~

The following is an overview of the procedure for changing the size of the oplog:

.. include:: /includes/procedure-change-oplog-size.rst

For a detailed procedure, see :doc:`/tutorial/change-oplog-size`.

.. _replica-set-security:

Security
--------

In most cases, the most effective ways to control access and to secure
the connection between members of a :term:`replica set` depend on
network-level access control. Use your environment's firewall and
network routing to ensure that traffic *only* from clients and other
replica set members can reach your :program:`mongod` instances. If needed,
use virtual private networks (VPNs) to ensure secure connections
over wide area networks (WANs.)

Additionally, MongoDB provides an authentication mechanism for
:program:`mongod` and :program:`mongos` instances connecting to
replica sets. These instances enable authentication but specify a
shared key file that serves as a shared password.

.. versionadded:: 1.8 for replica sets (1.9.1 for sharded replica sets) added support for authentication.

To enable authentication add the following option to your configuration file:

.. code-block:: cfg

   keyFile = /srv/mongodb/keyfile

.. note::

   You may chose to set these run-time configuration options using the
   :option:`--keyFile <mongod --keyFile>` (or :option:`mongos --keyFile`)
   options on the command line.

Setting :setting:`keyFile` enables authentication and specifies a key
file for the replica set members to use when authenticating to each
other. The content of the key file is arbitrary but must be the same
on all members of the replica set and on all :program:`mongos`
instances that connect to the set.

The key file must be less one kilobyte in size and may only contain
characters in the base64 set. The key file must not have group or "world"
permissions on UNIX systems. Use the following command to use the
OpenSSL package to generate "random" content for use in a key file:

.. code-block:: bash

   openssl rand -base64 753

.. note::

   Key file permissions are not checked on Windows systems.

Troubleshooting
---------------

This section defines reasonable troubleshooting processes for common
operational challenges. While there is no single causes or guaranteed
response strategies for any of these symptoms, the following sections
provide good places to start a troubleshooting investigation with
:term:`replica sets <replica set>`.

.. seealso:: :doc:`/administration/monitoring`.

.. _replica-set-replication-lag:

Replication Lag
~~~~~~~~~~~~~~~

Replication lag is a delay between an operation on the :term:`primary`
and the application of that operation from the :term:`oplog` to the
:term:`secondary`. Such lag can be a significant issue and can
seriously affect MongoDB :term:`replica set` deployments. Excessive
replication lag makes "lagged" members ineligible to quickly become
primary and increases the possibility that distributed
read operations will be inconsistent.

Identify replication lag by checking the value of
:data:`members[n].optimeDate` for each member of the replica set
using the :method:`rs.status()` function in the :program:`mongo`
shell.

Also, you can monitor how fast replication occurs by watching the oplog
time in the "replica" graph in the `MongoDB Monitoring Service`_. Also
see the `documentation for MMS`_.

.. _`MongoDB Monitoring Service`: http://mms.10gen.com/
.. _`documentation for MMS`: http://mms.10gen.com/help/

Possible causes of replication lag include:

- **Network Latency**

  Check the network routes between the members of your set to ensure
  that there is no packet loss or network routing issue.

  Use tools including ``ping`` to test latency between set
  members and ``traceroute`` to expose the routing of packets
  network endpoints.

- **Disk Throughput**

  If the file system and disk device on the secondary is
  unable to flush data to disk as quickly as the primary, then
  the secondary will have difficulty keeping state. Disk-related
  issues are incredibly prevalent on multi-tenant systems, including
  vitalized instances, and can be transient if the system accesses
  disk devices over an IP network (as is the case with Amazon's
  EBS system.)

  Use system-level tools to assess disk status, including
  ``iostat`` or ``vmstat``.

- **Concurrency**

  In some cases, long-running operations on the primary can block
  replication on secondaries. You can use :term:`write concern` to
  prevent write operations from returning if replication cannot keep up
  with the write load.

  Use the :term:`database profiler` to see if there are slow queries
  or long-running operations that correspond to the incidences of lag.

- **Appropriate Write Concern**

  If you are performing a large data ingestion or bulk load operation
  that requires a large number of writes to the primary, the
  secondaries will not be able to read the :term:`oplog` fast enough to keep
  up with changes. Setting some level :ref:`write concern <write-concern>`, can
  slow the overall progress of the batch, but will prevent the
  secondary from falling too far behind.

  To prevent this, use write concern so that MongoDB will perform
  a safe write (i.e. call :dbcommand:`getLastError`) after every 100,
  1,000, or other designated number of operations.
  This provides an opportunity for secondaries to catch up with the primary.
  Using safe writes, even in batches, can impact write throughout;
  however, calling :dbcommand:`getLastError` will prevents the
  secondaries from falling too far behind the primary.

  For more information see:

  - :ref:`replica-set-write-concern`.
  - The :ref:`replica-set-oplog-sizing` topic in the :doc:`/core/replication` document.
  - The :ref:`replica-set-oplog` topic in the :doc:`/core/replication-internals` document.
  - The :ref:`replica-set-procedure-change-oplog-size` topic this document.
  - The :doc:`/tutorial/change-oplog-size` tutorial.

.. index:: pair: replica set; failover
.. _replica-set-failover-administration:
.. _failover:

Failover and Recovery
~~~~~~~~~~~~~~~~~~~~~

Replica sets feature automated failover. If the :term:`primary`
goes offline or becomes unresponsive and a majority of the original
set members can still connect to each other, the set will elect a new
primary.

While :term:`failover` is automatic, :term:`replica set`
administrators should still understand exactly how this process
works. This section below describe failover in detail.

In most cases, failover occurs without administrator intervention
seconds after the :term:`primary` either steps down, becomes inaccessible,
or becomes otherwise ineligible to act as primary. If your MongoDB deployment
does not failover according to expectations, consider the following
operational errors:

- No remaining member is able to form a majority. This can happen as a
  result of network partitions that render some members
  inaccessible. Design your deployment to ensure that a majority of
  set members can elect a primary in the same facility as core
  application systems.

- No member is eligible to become primary. Members must have a
  :data:`members[n].priority` setting greater than ``0``, have a state
  that is less than ten seconds behind the last operation to the
  :term:`replica set`, and generally be *more* up to date than the
  voting members.

In many senses, :ref:`rollbacks <replica-set-rollbacks>` represent a
graceful recovery from an impossible failover and recovery situation.

Rollbacks occur when a primary accepts writes that other members of
the set do not successfully replicate before the primary steps
down. When the former primary begins replicating again it performs a
"rollback." Rollbacks remove those operations from the instance that
were never replicated to the set so that the data set is in a
consistent state. The :program:`mongod` program writes rolled back
data to a :term:`BSON` file that you can view using
:program:`bsondump`, applied manually using :program:`mongorestore`.

You can prevent rollbacks by ensuring safe writes by using
the appropriate :term:`write concern`.

.. include:: /includes/seealso-elections.rst
