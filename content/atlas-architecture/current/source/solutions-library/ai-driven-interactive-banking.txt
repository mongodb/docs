.. _arch-center-is-interactive-banking:

==========================================
AI-Driven Interactive Banking
==========================================

.. meta:: 
   :keywords: AI, Generative AI, Interactive Banking, Chatbots, MongoDB Atlas, Vector Search, Large Language Models, Financial Services, Personalization.
   :description: Build an application using MongoDB Atlas Vector Search and large language models to improve the interactivity of banking applications.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Build an application using MongoDB Atlas Vector Search and large
language models to improve the interactivity of banking applications.

- **Use cases**: `Gen AI <https://www.mongodb.com/solutions/use-cases/artificial-intelligence>`_, 
  `Personalization <https://www.mongodb.com/solutions/use-cases/personalization>`_
- **Industries**: `Financial Services <https://www.mongodb.com/solutions/industries/financial-services>`_
- **Partners**: `Amazon Bedrock <https://aws.amazon.com/bedrock>`_

Solution Overview
-----------------

Interactive banking represents a new era in financial services where customers engage with
digital platforms that anticipate, understand, and meet their needs in real time.

This approach uses generative artificial intelligence (gen AI) technologies like chatbots
and virtual assistants to enhance basic day-to-day banking operations. By leveraging gen
AI, banks can enable self-service digital channels while simultaneously elevating the
customer experience through tailored, context-aware interactions. From AI-powered chatbots
that resolve queries instantly to predictive analytics that offer tailored financial
advice, interactive banking is no longer just about convenience—it’s about creating a
smarter, more engaging and more intuitive banking journey for every user.

By integrating AI-driven advisors into the digital banking experience, banks can provide a
seamless, in-app solution that delivers instant, relevant answers. This removes the need
for customers to leave the app to sift through pages of bank documentation in search of
answers, or worse, endure the inconvenience of calling customer service. The result is a
smoother and more user-friendly interaction, where customers feel supported in their
self-service journey, free from the frustration of navigating traditional, cumbersome
information sources. The entire experience remains within the digital space, enhancing
convenience and efficiency.

.. video:: https://www.youtube.com/watch?v=Pn0IOrn3TKI

Reference Architectures
-----------------------

The problem with traditional terms and conditions is that they are dense, unstructured,
and not easily usable within digital banking environments. To remedy this MongoDB and its
partner propose the following reference architecture:

 
.. figure:: /includes/images/industry-solutions/leafy-bank-in-aws.svg
   :width: 750px
   :alt: Reference architecture for AI-driven interactive banking proposal.

   Figure 1. AI-driven interactive banking architecture

MongoDB is positioned as an operational data store (ODS) acting as a medium layer between
the AI technologies and the application layer, which allows organizations to operate with
a more unified dataset. This unification streamlines data management, ensuring that
structured, semi-structured, and unstructured data can coexist, enabling faster
development cycles and more accurate AI-driven insights. By breaking down data silos,
businesses can deliver richer, more consistent customer experiences across their digital
platforms.

Data Model Approach
-------------------

We store both the text chunks from the PDF and their embeddings directly within the same
document in our MongoDB collection. This streamlined approach, illustrated in the image
below, enables efficient and unified data access.

By using MongoDB’s flexible and scalable document model, we can store text and vector
embeddings together, simplifying queries and ensuring high performance without bolting on
additional solutions. This approach allows companies to build AI-enriched applications on
MongoDB’s modern, multi-cloud database platform, unifying real-time, operational,
unstructured, and AI-driven data. With this foundation, businesses can efficiently adapt,
extend, and iterate their applications to seize emerging technological opportunities.

.. figure:: /includes/images/industry-solutions/sol_lib_doc.svg
   :width: 750px
   :alt: View of chunk and embedding structure in MongoDB

Building the Solution
---------------------

.. procedure::
   :style: normal

   .. step:: Document preprocessing and chunking

      The initial step involves processing and transforming the text-based unstructured data
      (such as the Terms & Conditions PDF), that will serve as the source for answering customer
      queries.

      The document is divided into `N chunks
      <https://www.mongodb.com/developer/products/atlas/choosing-chunking-strategy-rag/>`_,
      which are stored in |service-fullname|. A custom script scans the document, creates the chunks,
      and vectorizes them (as illustrated in the figure below). The chunking process uses a
      sliding window technique, ensuring that transitional data between chunks is preserved
      while maintaining continuity and context.

      Once the document has been transformed into vectorized chunks, they are passed through an
      embedding model to generate vector embeddings. The embedding model can be selected
      according to the user's requirements. For illustration purposes, we are using Cohere
      'cohere.embed-english-v3' on AWS Bedrock for the embedding creation.

      Both the chunks and their corresponding vectors are stored in |service-fullname|. In this
      sample scenario, we are using `SuperDuper <https://superduper.io/>`_ (an open-source
      Python framework that integrates AI models and workflows directly with MongoDB) as the
      process orchestrator, enabling more flexible and scalable custom enterprise AI solutions.

   .. step:: Vector Search and querying

      After we’ve stored both the chunks and their embeddings in MongoDB, we can begin
      leveraging `MongoDB Atlas Vector Search
      <https://www.mongodb.com/products/platform/atlas-vector-search#query>`_ for semantic
      querying.

   .. step:: Building the chatbot UI

      The next step involves building an application—in our case, an interactive chatbot. This
      chatbot is powered by MongoDB Atlas Vector Search and a pre-trained |llm|. When a user
      inputs a question, that question is first vectorized, and MongoDB Atlas Vector Search is
      used to find documents with similar embeddings.

      Once relevant documents are retrieved, the next step is to send this data to an LLM. In
      this case, we use Amazon Bedrock as the `LLM
      <https://www.mongodb.com/resources/basics/artificial-intelligence/large-language-models>`_
      container. For this specific use case, we are leveraging Claude from Anthropic. The LLM
      receives both the question and the retrieved documents, using the documents as context to
      generate a more comprehensive and accurate response. This framework is known as
      `retrieval-augmented generation
      <https://www.mongodb.com/resources/basics/artificial-intelligence/retrieval-augmented-generation>`_
      (|rag|) architecture. RAG enhances the chatbot’s ability to provide accurate answers by
      combining semantic search with powerful language model generation.

      .. figure:: /includes/images/industry-solutions/chatbot.gif
         :width: 750px
         :alt: Leafy Bank mock-up chatbot in action

         Figure 2. Leafy Bank chatbot in action

Key Learnings
-------------

- AI-driven technologies like chatbots simplify customer interactions by providing
  instant, context-aware responses, allowing users to navigate banking operations
  independently without wading through complex terms and conditions.
- By `using Atlas Vector Search
  <https://www.mongodb.com/products/platform/atlas-vector-search>`_
  and document chunking, MongoDB enables efficient querying of dense legal documents,
  ensuring customers receive accurate, context-rich answers.
- MongoDB's integration with vector search, LLMs, and dedicated search infrastructure
  allows financial institutions to scale AI solutions, improving performance and
  responsiveness as customer demands grow.

Technologies and Products Used
------------------------------

MongoDB Developer Data Platform
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- `Atlas Database <https://www.mongodb.com/products/platform/atlas-database>`_
- `Atlas Vector Search <https://www.mongodb.com/products/platform/atlas-vector-search>`_

Partner Technologies
~~~~~~~~~~~~~~~~~~~~

- `Amazon Bedrock <https://aws.amazon.com/bedrock>`_

Authors
-------

- Luis Pazmino Diaz, FSI Principal EMEA, MongoDB
- Ainhoa Múgica, Senior Specialist, Industry Solutions, MongoDB
- Pedro Bereilh, Specialist, Industry Solutions, MongoDB
- Andrea Alaman Calderon, Senior Specialist, Industry Solutions, MongoDB