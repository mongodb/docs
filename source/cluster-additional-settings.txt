.. _create-cluster-additional-settings:

=============================
Configure Additional Settings
=============================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: reference

.. meta:: 
   :keywords: Atlas additional cluster settings, atlas ui, atlas cli

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

You can configure the following additional settings for your
|service| {+cluster+}.

.. _create-cluster-version:

Select the MongoDB Version of the {+Cluster+}
---------------------------------------------

.. include:: /includes/extracts/fact-mongodb-version.rst

.. include:: /includes/fact-upgrade-best-practices.rst

To select the MongoDB version for your cluster, use the
dropdown in the :guilabel:`Additional Settings` section
of the {+cluster+} form.

You can upgrade an existing |service| {+cluster+} to a newer major
MongoDB version, if available, when you 
:ref:`scale a cluster <scale-cluster-version>`. However, you 
can't downgrade a {+cluster+} from one major version to a previous
major version.

.. important::

   If your project contains a :ref:`custom role <mongodb-roles>`
   that uses actions introduced in a specific MongoDB version, you
   can't create a {+cluster+} with a MongoDB version less than that
   version unless you delete the custom role.

.. _release-cadence:

Choosing a Release Cadence
~~~~~~~~~~~~~~~~~~~~~~~~~~

You can set your |service| {+cluster+}s to follow either a 
:ref:`major release <major-releases>` cadence or a
rapid release cadence.

Free-tier and shared-tier {+cluster+}s must follow a major release 
cadence. You can configure a dedicated-tier {+cluster+} to follow a 
major release cadence by selecting a specific MongoDB version from the
dropdown in the :guilabel:`Additional Settings` section
of the {+cluster+} form.

|service| does not automatically upgrade {+cluster+}s on the major 
release cadence. You must schedule a manual upgrade to each new 
major release as it enters general availability.

You can configure a dedicated-tier {+cluster+} to follow a rapid 
release cadence by selecting :guilabel:`Latest Release` from the
dropdown in the :guilabel:`Additional Settings` section
of the {+cluster+} form.

You can configure a {+cluster+} for rapid releases only if it 
is running the most recent major release of MongoDB. If your
{+cluster+} is running a prior major release, manually upgrade
to the most recent major release to enable the transition to rapid 
release.

|service| uses the most recent MongoDB release for {+cluster+}s 
that follow the rapid release cadence. |service| automatically upgrades
these {+cluster+}s to the new major *and* rapid release versions
via a rolling process to maintain {+cluster+} availability
as each release becomes available. During the upgrade to the next rapid 
release version, the {+cluster+} in the |service| UI 
:guilabel:`Clusters` page might show the |fcv-link| 
of your {+cluster+} instead of the MongoDB version to reflect the 
features that are currently available on your cluster.

.. note::

   If you switch a {+cluster+} from the major release to the rapid
   release cadence, it will upgrade directly to the currently available
   rapid release. For example, if MongoDB 6.2 is the latest rapid 
   release and you configure a {+cluster+} running 6.0 for rapid 
   release, it will upgrade directly to MongoDB 6.2

You can revert a {+cluster+} that follows the rapid release cadence to
the major release cadence by selecting the most recent major release
from the :guilabel:`Select a Version` dropdown menu. However, you can
only do this before the first rapid release of the year is available. 
After a {+cluster+} updates from a major release version to a rapid 
release version, you can't revert the {+cluster+} until the next major 
release.

To learn more about MongoDB versions, see :manual:`MongoDB Versioning
</reference/versioning>` in the MongoDB Manual. For additional details
about the rapid release cadence, see 
`Understanding the MongoDB Stable API and Rapid Release Cadence <https://www.mongodb.com/blog/post/understanding-mongodb-stable-api-rapid-release-cadence>`__.

.. _create-cluster-backups:

Configure Backup Options for the {+Cluster+}
--------------------------------------------

This section describes the backup configuration options for your
|service| {+cluster+}.

M2/M5 Tier Backup Options
~~~~~~~~~~~~~~~~~~~~~~~~~

|service| automatically enables backups for ``M2`` and ``M5``
{+Shared-clusters+} and you can't disable them. To learn more, see
:ref:`m2-m5-snapshots`.

M10+ Tier Backup Options
~~~~~~~~~~~~~~~~~~~~~~~~

To enable backups for an ``M10+`` |service| {+cluster+}, toggle
:guilabel:`Turn on Backup (M10 and up)` to ``Yes``.
If enabled, |service| takes snapshots of your databases at
regular intervals and retains them according to your project's
:ref:`retention policy <cloud-provider-retention-policy>`.

.. note::

   If you have a :ref:`{+bcp+} enabled <backup-compliance-policy>`, you 
   can't disable {+Cloud-Backup+}. You can't disable {+PIT-Restore+} if 
   the {+bcp+} has the 
   :guilabel:`Require Point in Time Restore to all clusters` option set 
   to :guilabel:`On` without MongoDB Support. To disable 
   {+PIT-Restore+}, the security or legal representative specified for 
   the {+bcp+} must :ref:`request support <request-support>` and 
   complete an extensive verification process.

|service| provides the following backup options for ``M10+``
clusters:

.. list-table::
   :widths: 30 70
   :header-rows: 1

   * - Backup Option
     - Description

   * - :ref:`Cloud Backup <cloud-backup-overview>`

     - |service| takes incremental snapshots of the data in your 
       {+cluster+} and lets you restore the data from those snapshots. 
       |service| stores snapshots in the same cloud provider region as 
       the replica set member targeted for snapshots.

   * - :ref:`{+PIT-Restore+} <pit-restore>`

     - After |service| restores a snapshot, |service| replays the 
       :term:`oplog` to restore a {+cluster+} from a particular point 
       in time within a window specified in the :ref:`backup policy 
       <configure-backup-policy>`.

.. _create-cluster-termination-protection:

Termination Protection
----------------------

To enable :guilabel:`Termination Protection` for a {+cluster+}, toggle
:guilabel:`Termination Protection` to :guilabel:`Yes`.

If enabled, |service| prevents users from deleting the
cluster. To delete a cluster that has termination protection
enabled, you must first disable termination protection. By default,
|service| disables termination protection for
all {+database-deployments+}.

To learn more about terminating your cluster, see :ref:`terminate-cluster`.

.. _create-cluster-sharding:
.. _cluster-option-sharding:

Deploy a Sharded {+Cluster+}
----------------------------

.. tip:: 

   .. include:: /includes/fact-online-archive-recommendation.rst

To deploy your cluster as a :term:`sharded cluster <sharded cluster>`,
toggle :guilabel:`Shard your cluster (M30 and up)` to ``Yes``.

:term:`Sharded clusters <sharded cluster>` support horizontal scaling 
and consist of :manual:`shards </core/sharded-cluster-shards>`,
:ref:`config servers <sharding-config-server>` and
:term:`mongos <mongos>` routers.  To learn more, see
:ref:`nodes-for-config-server`. Config servers must remain readable for sharded read operations to continue to function.

If you enable {+managed-configs+}, |service| may colocate config server
data with application data instead of using a dedicated config server.
To learn more, see :ref:`config-server-management`.

.. _nodes-per-shard:

About Shard Deployment
~~~~~~~~~~~~~~~~~~~~~~

|service| deploys each :manual:`shard </core/sharded-cluster-shards>` 
as a three-node replica set, where each node deploys using the 
configured :guilabel:`Cloud Provider & Region`, 
:guilabel:`Cluster Tier`, and :guilabel:`Additional Settings`. 
|service| deploys one :binary:`~bin.mongod` per shard node.

For cross-region {+clusters+}, the number of nodes per shard 
is equal to the total number of electable and read-only nodes across
all configured regions. |service| distributes the shard nodes across
the selected regions.

.. _nodes-for-config-server:

About Config Servers Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For dedicated config servers, |service| deploys the :ref:`config servers <sharding-config-server>`
as a three-node replica set. The config servers run on M30 {+cluster+}
tiers. In multi-region {+clusters+}, config servers are distributed
across regions. 

For cross-region {+clusters+}, |service| distributes the config server 
replica set nodes to ensure optimal availability. For example, 
|service| might deploy the config servers across three distinct 
availability zones and three distinct regions if supported by
the selected cloud service provider and region configuration. Config
servers must remain readable for sharded read operations to continue to
function. To learn more, see :manual:`Config Server Availability
</core/sharded-cluster-config-servers/#config-server-availability>`.

If you enable {+managed-configs+}, |service| may colocate config server
data with application data instead of using a dedicated config server.
To learn more, see :ref:`config-server-management`.

.. include:: /includes/fact-outage-sharded-cluster-impact.rst

.. _mongos-per-shard:

About ``mongos`` Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~

|service| deploys one :binary:`mongos <bin.mongos>` router for each 
node in each shard. For cross-region clusters, this allows clients 
using a MongoDB driver to connect to the geographically "nearest" 
:binary:`mongos <bin.mongos>`.

To calculate the number of :binary:`mongos <bin.mongos>` 
routers in a cluster, multiply the number of shards by the number of 
replica set nodes per shard.

.. include:: /includes/fact-conversion-sharded-clusters.rst

To learn more about how the number of server instances affect cost, see
:ref:`server-number-costs`.

To learn more about sharded clusters, see
:manual:`Sharding </sharding>` in the MongoDB manual.

.. _create-cluster-shardNum:

Configure the Number of Shards
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. include:: /includes/extracts/cluster-option-clusterShardingNum.rst

Consideration for Upgrading a Replica Set to a Sharded {+Cluster+}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If your {+cluster+} tier is ``M30`` or higher, you can upgrade 
your replica set deployment to a sharded {+cluster+} deployment.

.. include:: /includes/fact-upgrade-to-sharded-cluster-warning.rst

.. _create-cluster-enable-bi:

Enable |bic|
------------

.. include:: /includes/abic-deprecation.rst

To enable `BI Connector for Atlas
<https://www.mongodb.com/docs/bi-connector/master/>`__ for this 
{+cluster+}, toggle :guilabel:`Enable Business Intelligence Connector 
(M10 and up)` to :guilabel:`Yes`.

.. note::

   .. include:: /includes/extracts/cluster-option-bi-cluster-requirements.rst

If enabled, select the node type from which |bic|
should read.

.. _bic-read-preferences:

Read Preferences
~~~~~~~~~~~~~~~~

The following table describes the available read preferences for
|bic-short| and their corresponding
:manual:`readPreference </reference/read-preference>` and
:manual:`readPreferenceTag </core/read-preference-tags>`
connection string options.

.. list-table::
   :header-rows: 1
   :widths: 20 30 20 30

   * - |bic-short-no-link| Read Preference
     - Description
     - readPreference
     - readPreferenceTags

   * - Primary
     - Read from the :term:`primary` node.
     - ``primary``
     - None

   * - Secondary
     - Read from :term:`secondary` nodes.
     - ``secondary``
     - ``{ nodeType : ELECTABLE }`` or ``{ nodeType : READ_ONLY }``

   * - Analytics
     - Read from :term:`analytics nodes <analytics node>`.
     - ``secondary``
     - ``{ nodeType : ANALYTICS }``

Node Types
``````````

The ``nodeType`` read preference tag dictates the type of node |bic|
connects to. You can specify the following values for this option:

- ``ELECTABLE`` restricts |bic-short| to the :term:`primary` and
  electable :term:`secondary` nodes.

- ``READ_ONLY`` restricts |bic-short| to connecting to
  non-electable :term:`secondary` nodes.

- ``ANALYTICS`` restricts |bic-short| to connecting to
  :ref:`analytics nodes <analytics-nodes-overview>`.

  .. tip::

     When you use the :guilabel:`Analytics` read preference, |service|
     places |bic| on the same hardware as the analytics nodes that
     |bic| reads from.

     By isolating electable data-bearing nodes from the |bic|, electable
     nodes don't compete for resources with |bic|, thus improving
     {+cluster+} reliability and performance.

For high traffic production environments, connecting to the
:guilabel:`Secondary Node(s)` or :guilabel:`Analytics Node(s)` may
be preferable to connecting to the :guilabel:`Primary Node`.

For {+clusters+} with one or more
:ref:`analytics nodes <analytics-nodes-overview>`, select
:guilabel:`Analytics Node` to isolate |bic| queries from
your operational workload and read from dedicated, read-only
analytics nodes. With this option, electable nodes don't compete
for resources with |bic|, thus improving cluster reliability and
performance.

Sampling Settings
~~~~~~~~~~~~~~~~~

To generate a relational schema, the |bic-short-no-link| requires
:bic:`sampling data </schema/cached-sampling/>` from MongoDB.

You can't use a ``.drdl`` file, or use the :bic:`mongodrdl <reference/mongodrdl/>`
command to replace the sampling stage in the |service| |bic-short-no-link|.

You can configure the following sampling settings:

.. list-table::
   :widths: 25 10 65
   :header-rows: 1
   :stub-columns: 1

   * - |bic-short-no-link| Option
     - Type
     - Description

   * - Schema Sample Size
     - integer
     - *Optional.* The number of documents that the BI Connector
       samples for each database when it gathers schema information.
       To learn more, see the
       :bic:`BI Connector documentation
       </reference/mongosqld/#cmdoption-mongosqld-samplesize>`.

   * - Sample Refresh Interval
     - integer
     - *Optional.* The frequency, in seconds, at which the BI
       Connector re-samples data to recreate the schema.To learn more, 
       see the :bic:`BI Connector documentation </reference/mongosqld/#cmdoption-mongosqld-samplerefreshintervalsecs>`.

.. _create-cluster-enable-encryption:

Manage Your Own Encryption Keys
-------------------------------

.. include:: /includes/fact-atlas-free-tier-limits.rst

|service| encrypts all {+cluster+} storage and snapshot volumes,
ensuring the security of all {+cluster+} data at rest
(Encryption at Rest). |service|
:authrole:`Project Owners <Project Owner>` can configure
an added layer of encryption on their data at rest using the
MongoDB :manual:`Encrypted Storage Engine 
</core/security-encryption-at-rest>`
and their |service|-compatible Encryption at Rest provider.

|service| supports the following Encryption at Rest providers:

- :ref:`AWS Key Management Services <security-aws-kms>`
- :ref:`Azure Key Vault <security-azure-kms>`
- :ref:`Google Cloud KMS <security-gcp-kms>`

Prerequisites
~~~~~~~~~~~~~

- You must configure the |service| project for Encryption at Rest
  using your Key Management before you enable the feature for your
  |service| {+clusters+}. To learn more,
  see :ref:`security-kms-encryption`.

- To switch from one Encryption at Rest provider on your
  {+cluster+} to another, you must first disable Encryption at Rest for
  your {+cluster+}, then re-enable it with your desired Encryption at
  Rest provider. To learn more, see :doc:`/security-kms-encryption`.

Procedure
~~~~~~~~~

To start managing your own encryption keys for this {+cluster+},
toggle :guilabel:`Encryption using your Key Management (M10 and up)`
to :guilabel:`Yes`.

|service| Encryption at Rest using your Key Management is available for
``M10+`` replica set {+clusters+}. |service| Encryption
at Rest supports encrypting :ref:`backup-cloud-provider` **only**.

Managing your own encryption keys incurs an increase to the hourly run
costs of your {+clusters+}. To learn more about |service| billing for
advanced security features, see :ref:`advanced-security`.

.. important::

   If |service| can't access the |service| project key management
   provider or the encryption key used to encrypt a {+cluster+},
   that {+cluster+} becomes inaccessible and unrecoverable. Exercise
   extreme caution before you modify, delete, or disable an
   encryption key or the key management provider credentials that
   |service| uses.

.. _create-cluster-more-configuration-options:

Configure Additional Options
----------------------------

You can configure the following |mongod| runtime options on ``M10+``
paid tier {+clusters+}.

Considerations
~~~~~~~~~~~~~~

|service| dynamically modifies the :guilabel:`Oplog Size` for replica
sets and sharded clusters. However, for the :guilabel:`Minimum TLS
Protocol Version` and :guilabel:`Allow Server-Side JavaScript`
settings, it performs a rolling restart of the shard members
and the config server replica set. To learn more about how |service|
supports high availability during maintenance operations, see
:ref:`high-availability`.

View and Edit Additional Settings
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To view and edit these settings:

.. tabs::

   .. tab:: {+atlas-cli+}
      :tabid: atlascli

      .. include:: /includes/extracts/atlas-clusters-advancedSettings-update.rst

   .. tab:: {+atlas-ui+}
      :tabid: ui
      
      To view and edit these settings with the {+atlas-ui+}, open the
      :guilabel:`More Configuration Options` under
      :guilabel:`Additional Settings` in the cluster form.

.. _set-oplog-min-window:

Set Minimum Oplog Window
~~~~~~~~~~~~~~~~~~~~~~~~

Modify the retention duration for oplog entries in the 
:term:`oplog` of the {+cluster+}. By default, |service| retains entries 
for 24 hours before the |mongod| removes them from the oplog.

This option corresponds to modifying the
:setting:`storage.oplogMinRetentionHours` configuration file option 
for each |mongod| in the {+cluster+}.

To set the minimum oplog window:

1. Verify that storage auto-scaling is enabled and that you didn't opt
   out of it. |service| enables auto-scaling by default.
2. Set the minimum oplog window to the desired value. If you don't set
   this value, |service| retains oplog entries for 24 hours before the
   |mongod| removes them from the oplog.

.. _set-oplog-size:
.. _set-fixed-oplog-size:

Set Oplog Size
~~~~~~~~~~~~~~

You can set a fixed oplog size, which helps during live migration or
during an intensive data load.

You can set the :guilabel:`Set Oplog Size` configuration setting only
if you opt out of the {+cluster+}'s storage auto-scaling. You can't use
the MongoDB command :ref:`replSetResizeOplog <paid-tier-command-limitations>`
to resize the oplog on a {+cluster+} in |service|.

For {+clusters+} that have storage auto-scaling enabled, you can set the
:guilabel:`Minimum Oplog Window` instead. See :ref:`set-oplog-min-window`.
|service| enables storage auto-scaling by default.

The minimum oplog size you can set is 990 megabytes.
|service| returns an error if the oplog size you choose leaves your
{+cluster+}'s disk with less than 25 percent of its capacity free.

To check the current oplog size and replication lag time:

1. Connect to your {+cluster+} via {+mongosh+}.
2. Authenticate as a user with the :atlasrole:`Atlas admin` role.
3. Run the
   :method:`rs.printReplicationInfo() <rs.printReplicationInfo>` method.

|service| displays the current oplog size and replication lag time.

To set a fixed oplog size:

1. Opt out of :ref:`storage autoscaling <opt-out-autoscaling>`.
2. Set the :ref:`Minimum Oplog Window <set-oplog-min-window>` to ``0``.
3. Determine the size of the oplog that you need:

   - Monitor the lag time during the migration process in the {+atlas-ui+}.
   - If the lag time shown in the {+atlas-ui+} during migration approaches
     the replication lag time that you obtained using
     the :method:`rs.printReplicationInfo() <rs.printReplicationInfo>` method,
     increase the oplog size.

4. Specify your desired :guilabel:`Oplog Size` in megabytes in the
   input box. This setting configures the uncompressed size of the oplog, 
   not the size on disk.

   For sharded {+cluster+} deployments, this option modifies the oplog 
   size of each shard in the {+cluster+}.

   This option corresponds to modifying the
   :setting:`replication.oplogSizeMB` configuration file option for each
   |mongod| in the {+cluster+}.

   .. warning::

      Reducing the size of the oplog requires removing data from the
      oplog. |service| can't access or restore any oplog entries removed
      as a result of oplog reduction. Consider the ramifications of this
      data loss before you reduce the oplog.

Disk Space Considerations
`````````````````````````

*Don't* reduce the size of the oplog to increase the available disk 
space. Only the oplog collection (``local.oplog.rs``)
can reclaim the space that reducing the oplog size saves. Other
collections don't benefit from reducing oplog storage.

Enforce Index Key Limit
~~~~~~~~~~~~~~~~~~~~~~~

Enable or disable enforcement of the 1024-byte index key limit.
Documents can only be updated or inserted if, for all indexed fields on
the target collection, the corresponding index entries don't exceed
1024 bytes.

If disabled, |mongod| writes documents that breach the limit but
*doesn't* index them. This option corresponds to modifying the
``param.failIndexKeyTooLong``
parameter via the :dbcommand:`setParameter` command for each |mongod|
in the {+cluster+}.

.. include:: /includes/admonitions/removed-fail-index-key-too-long.rst

Allow Server-Side JavaScript
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. include:: /includes/fact-javascriptEnabled-description.rst

.. include:: /includes/admonitions/changed-javascript-enabled-mongos.rst

Enable Logging of Redacted and Anonymized Query Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Include redacted and anonymized ``$queryStats`` output in MongoDB logs.
``$queryStats`` output does not contain literals or field values.
Enabling this setting might impact the performance of your cluster.

.. note::

   You can enable logging of query data only for |service| {+clusters+} 
   that run MongoDB 7.1 or later.

.. _set-minimum-tls-protocol-version:
   
Set Minimum TLS Protocol Version
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Set the minimum TLS version that the {+cluster+} accepts for incoming
connections. This option corresponds to configuring the
:setting:`net.tls.disabledProtocols` configuration file option
for each |mongod| in the {+cluster+}.

.. include:: /includes/tls-deprecation.rst

.. _set-custom-cipher-suite-configuration:
   
Set Custom Cipher Suite Configuration
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

From a list of cipher suites, select which will be used for your
cluster's node-to-node and client-to-{+service+} communications.
The list of available ciphers will depend on the cluster's
:ref:`minimum TLS version <set-minimum-tls-protocol-version>`.

Require Indexes for All Queries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Enable or disable the execution of queries that require a collection
scan to return results. This option corresponds to modifying the
:parameter:`notablescan <param.notablescan>` parameter via the
:dbcommand:`setParameter` command for each |mongod| in
the {+cluster+}.

Default Write Concern
~~~~~~~~~~~~~~~~~~~~~

Set the 
:manual:`default level of acknowledgment requested from MongoDB for write operations </reference/write-concern/>` for this {+cluster+}.

Starting with MongoDB 5.0, the default write concern for {+clusters+}
is :manual:`majority </reference/write-concern>`.

Set Transaction Lifetime
~~~~~~~~~~~~~~~~~~~~~~~~

Set the maximum lifetime of :manual:`multi-document transactions
</core/transactions/>`. This option corresponds to modifying the
:parameter:`transactionLifetimeLimitSeconds
<param.transactionLifetimeLimitSeconds>` parameter via the 
:dbcommand:`setParameter` command for each |mongod| in the {+cluster+}.

.. important::
  
   You can't set the transaction lifetime to less than one second.

The default transaction lifetime for {+clusters+} is 60 seconds.

Set Chunk Migration Concurrency 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For sharded |service| {+clusters+} running MongoDB version 5.0.15 or
6.0.6 and higher versions, you can set the number of threads on the source
and receiving shard to improve the performance of :manual:`chunk
migration </tutorial/migrate-chunks-in-sharded-cluster>`. You can set
the value to half the total number of CPU cores.

.. _disk-pre-warming:

Enable or Disable Fast Disk Pre-Warming 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To enable fast :aws:`disk pre-warming </AWSEC2/latest/UserGuide/ebs-initialize.html>`
for a {+cluster+}, toggle :guilabel:`Allow Fast Disk Pre-Warming` to :guilabel:`Yes`.

To disable fast disk pre-warming for a {+cluster+}, toggle
:guilabel:`Allow Fast Disk Pre-Warming` to :guilabel:`No`.

Due to the design of the underlying cloud provider infrastructure, disk
pre-warming occurs whenever |service| needs to provision a new node in a
{+cluster+}, such as when you add a new node to an existing region. Disk 
pre-warming temporarily uses a :manual:`hidden secondary node
</core/replica-set-hidden-member>`.

Fast disk pre-warming is quicker than background disk warming. By
default, |service| enables fast disk pre-warming for your deployment. When
disk pre-warming is enabled, |service| hides the node and this prevents
this node from running read operations.

Consider the following recommendations:

- If you have workloads that seek consistent query latency, enable
  this setting.
- If you have workloads that seek maximum availability guarantees over
  consistent query performance, and you require that the newly added or
  replaced node is immediately active and visible, disable this setting,
  and :ref:`use a custom
  connection string with tags <reduce-secondary-disk-warming-example>` for
  the node that undergoes pre-warming, until the pre-warming process completes.
  Using this connection string prevents reads on the node while most of
  its |iops| are utilized by the pre-warming process.

.. _default-timeout-read-operations:

Set Default Timeout for Read Operations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For {+clusters+} running MongoDB version 8.0+, you can specify the default maximum 
timeout in milliseconds of all read operations for these {+clusters+}. This protects your 
database against unintentional long-running queries. This option corresponds to the 
cluster parameter `defaultMaxTimeMS <https://www.mongodb.com/docs/upcoming/reference/cluster-parameters/defaultMaxTimeMS/>`__.

.. _replica-set-scaling-mode:

Configure Replica Set Scaling Mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Modify the :term:`replica set <replica set>` scaling mode for your
{+cluster+}. By default, |service| scales nodes :guilabel:`In Parallel
By Workload Type`, which means |service| scales your :term:`analytics
<analytics node>` in parallel to your :term:`operational nodes
<operational node>`.

|service| can also scale a replica set with the :guilabel:`In Parallel
By Node Type` and :guilabel:`Sequential` modes.

:guilabel:`In Parallel By Node Type` mode is for large, dynamic
workloads requiring frequent and timely {+cluster+} tier scaling. In
this mode, |service| scales your :term:`electable <electable node>`
nodes in parallel with your :term:`read-only <read-only node>` and
:term:`analytics <analytics node>` nodes. This is the fastest scaling
strategy, but it might impact latency of workloads when performing
extensive secondary reads.

:guilabel:`Sequential` mode is for steady-state workloads and applications
performing latency-sensitive secondary reads, which means |service|
scales all nodes sequentially.

.. _database-log-redaction:

Enable Log Redaction
~~~~~~~~~~~~~~~~~~~~

Toggle this on to prevent logging of potentially sensitive information in field values.
For more information, see :manual:`Log Redaction </administration/monitoring/#log-redaction>`.

A rolling restart is required for enabling and disabling log redaction.

.. _config-server-management:

{+Managed-Configs+} for Sharded {+Clusters+}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Enable or disable |service| management of the :ref:`config server
<sharding-config-server>` type for a new sharded {+cluster+}. 
An {+managed-config+} automatically switches the 
:ref:`config server type <config-server-types>` based on :ref:`criteria
<config-server-change-criteria>` for optimal performance and
cost savings. If you don't enable an {+managed-config+} for
a sharded {+cluster+}, |service| always uses a dedicated config server
for the {+cluster+}.

For all 8.0 |service| sharded {+clusters+}, {+managed-configs+} are
:guilabel:`On` by default. To disable {+managed-configs+}, set the
toggle to :guilabel:`Off`. If the {+cluster+} has less than four shards and
embedded config servers, turning off {+managed-configs+} immediately
transitions the {+cluster+} to dedicated config servers.

.. note::

   Embedded config servers or config shards are not supported on 
   :doc:`Global Clusters </global-clusters>`.

.. _config-server-types:

Config Server Types
```````````````````

For each new sharded {+cluster+} with {+managed-configs+} enabled,
|service| deploys an embedded config server for clusters with less than
four shards and a dedicated config server for clusters with more than
three shards.

Embedded config servers colocate your application data with config data
on a config shard. Embedded config server {+clusters+} cost less because
they use fewer resources. 

Dedicated config servers use a separate, dedicated config server
replica set for config data. Your application data is not colocated
with config data for dedicated config servers. Dedicated config server
{+clusters+} cost more because they use an additional replica set.

To learn more about considerations for config server types, see
:ref:`config-server-considerations`.

.. _config-server-change-criteria:

Config Server Change Criteria
`````````````````````````````

If you enable {+managed-configs+}, |service| determines the initial
{+cluster+} config server type as follows:

- If the {+cluster+} shard count is greater than three, 
  |service| uses a dedicated config server.
- If the {+cluster+} shard count is three or less, |service|
  uses an embedded config server.

When you add or remove shards with {+managed-configs+} enabled, 
|service| automatically re-selects your sharded cluster's config server
type using the same criteria.

.. _config-server-considerations:

Config Server Considerations
````````````````````````````

All {+clusters+} with a version lower than MongoDB 8.0 use a dedicated
config server.

|service| will not change your config server type if you use any of the
following features: 

- :manual:`Time series data </core/timeseries-collections/>`
- :manual:`Queryable encryption </core/queryable-encryption/>`
- :ref:`Atlas Search indexes <default-index-definition>`

If you have a {+cluster+} with more than three shards that is unable to
transition to a dedicated config server due to the use of these
features, contact :ref:`MongoDB Support <request-support>` to change
your configuration server type.

If you enable {+managed-configs+}, the following considerations apply:

- For {+clusters+} running MongoDB 8.0 or later, replica set IDs
  **don't** reflect the type of data stored on the replica set.

  - Replica sets that contain the
    term ``shard`` in their replica set ID might store application
    data, config data, or both (for example: ``atlas-abc123-shard-0``).
  - Replica sets that contain the
    term ``config`` in their replica set ID might store application
    data (for example: ``atlas-abc123-config-0``).

Backup Snapshot Considerations
++++++++++++++++++++++++++++++

- You can restore snapshots from a {+cluster+} with a
  dedicated config server only to a {+cluster+} that also uses a
  dedicated config server.
- You can restore snapshots from a {+cluster+} with an
  embedded config server only to a {+cluster+} that also uses an
  embedded config server.

