.. _arch-center-latency-strategies:

=========================================
Multi-Region Latency Reduction Strategies
=========================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: onecol

Multi-region {+service+} deployments can be used to enhance performance by 
reducing latency. The following sections list the factors and configuration 
choices you can make to reduce latency.

Physical Distance
-----------------
Physical distance is the primary cause of latency. The distance between 
users and your application, between your application and your data, and between 
{+cluster+} nodes all impact system latency and application performance.

To reduce latency for read operations, it's crucial to place both your 
application and data geographically closer to users. 

Replication Configuration
-------------------------

:manual:`Replication </replication>` is the copying of data from the primary 
node to secondary nodes. How you configure replication contributes to latency. 
Consider the following factors:

- **Write Concern Levels:** There is a trade-off between write durability and 
  write latency. The write concern level you configure (for example, 
  ``w: "majority"``) defines replication across multiple data centers, 
  potentially increasing latency for more durable writes. However, this ensures 
  that all data is committed to secondaries and protects you from rolling back 
  writes in the event of failover.

- **Priority of Regions:** The order of regions in your configuration can determine 
  the priority for the primary node location, which can impact write latency 
  depending on where your users are located. For example, if most of your users 
  are in Asia, you should set the highest priority for the Asia region so that 
  it is elected the primary. 

- **Mirrored Reads:** Mirrored reads reduce the impact of primary elections 
  following an outage by pre-warming the caches on the secondary nodes. For more 
  information, see :manual:`Mirrored Reads </replication/#std-label-mirrored-reads>`.

- **Read Preference:** By default, applications send read operations to the 
  primary node. However, you can configure the read preference to send read 
  operations to secondary nodes. By doing so, you ensure reads go to the 
  geographically closest cluster. For guidance on implementing the best 
  configuration for your needs, contact MongoDB's {+ps+} team.  
  
  .. important:: 
  
     Keep in mind that there is the possibility of a secondary node returning 
     stale data due to replication lag. For more information on 
     configuring read consistency and isolation, see 
     :manual:`Read Concern </reference/read-concern>`.

- **Data Distribution:** Distributing data across regions by using replica sets 
  or sharded clusters is an effective approach when your data is geographically 
  oriented. For example, if you have data that is only read from the EU, and other 
  data that is only read in North America, you can create clusters that distribute 
  that data appropriately. 

Network Configuration
---------------------

You can increase security and potentially reduce latency using 
:atlas:`private endpoints 
</data-federation/admin/manage-private-endpoint/>`. Private endpoints 
establish direct and secure connections between your application's 
virtual network and your |service| cluster, potentially reducing 
network hops and improving latency.

Monitoring and Testing Latency
------------------------------

{+service+} provides the 
:atlas:`Real-Time Performance Panel (RTPP) </real-time-performance-panel/>` to 
observe latency metrics for different regions. You can also implement 
application-level monitoring to track end-to-end latency to and from the 
application. Before final production deployment, we suggest conducting performance 
testing under the various :ref:`multi-region scenarios <arch-center-paradigms-multi-region>` 
to identify and address latency bottlenecks.

Connection Configuration Options
--------------------------------

We recommend that you use a connection method built on the most `current driver version <https://www.mongodb.com/docs/drivers/>`__ 
for your application's programming language whenever possible. And while the 
default connection string |service| provides is a good place to start, you might 
want to tune it for performance in the context of your specific application 
and deployment architecture. 

For enterprise level application deployments, it's especially important 
to `Tune your connection pool settings <https://www.mongodb.com/docs/manual/tutorial/connection-pool-performance-tuning/>`__ 
for your application to help you meet user demand without incurring 
additional operational latency. Opening database client connections 
incurs considerable network overhead, so it's important to consider how 
and when the majority of your database client connections should open 
and configure your connection pool settings to align with your 
preferences. You can use the ``minPoolSize`` connection pool option to 
specify the number of database client connections that open at 
application startup. After these initial connections, connection pools 
open sockets on demand to support concurrent requests to MongoDB, up 
until the ``maxPoolSize`` number of connections is met. 

If your ``minPoolSize`` and ``maxPoolSize`` values are similar, the majority of your 
database client connections open at application startup. For example, if your
``minPoolSize`` is set to ``10`` and your ``maxPoolSize`` is set to ``12``, 10 
client connections open at application startup, and only 2 more connections 
can then be opened during application runtime. This incurs the majority 
of your network cost at application startup, as opposed to incurring it 
dynamically on an as-needed basis during application runtime. Opening 
new database connection pools during application runtime can 
potentially impact operational latency for end-users if there is a 
sudden spike in requests that requires a large number of additional 
connections to be opened at once.

Your application's architecture is central to this consideration. If, for example, 
you deploy your application as microservices, consider which services should 
call |service| directly as a means of controlling the dynamic expansion and 
contraction of your connection pool. Alternatively, if your application deployment 
is leveraging single-threaded resources, like AWS Lambda, your application will 
only ever be able to open and use one client connection, so your ``minPoolSize`` 
and your ``maxPoolSize`` should both be set to ``1``.

To learn more about how and where to create and use a connection pool, 
and where to specify connection pool settings, see 
:manual:`Connection Pool Overview 
</administration/connection-pool-overview>`. 

Query Latency Options
---------------------

You can set global and operation-level default :manual:`query timeout 
</tutorial/query-documents/specify-query-timeout>` limits on your 
deployment to reduce the amount of time your application waits for a 
response before timing out. 

You can also configure global :manual:`read concerns 
</reference/read-concern>` on your deployment to specify the number of 
nodes across which data must be replicated before a read operation is 
reported to have been successful. {+service+} has a default read 
concern of local, which means that when queried, {+service+} retrieves 
data from only one node in your cluster to provide higher availability 
and lower latency without guaranteeing that the data has been written 
to a majority of the replica set members.

Sharded Workload Distribution
-----------------------------

.. include:: /includes/cloud-docs/move-collection.rst
