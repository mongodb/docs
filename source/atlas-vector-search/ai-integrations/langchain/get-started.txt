.. _langchain-get-started:

==========================================
Get Started with the LangChain Integration
==========================================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: tutorial

.. facet::
   :name: programming_language
   :values: python

.. meta::
   :description: Use the LangChain integration for MongoDB to implement RAG with Atlas Vector Search.
   :keywords: RAG, retrieval, langchain, chatbot, vector database, vector search, semantic search, integration, OpenAI

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

.. note::

   This tutorial uses LangChain's `Python library 
   <https://python.langchain.com/docs/get_started/introduction>`__. 
   For a tutorial that uses the JavaScript library, see :ref:`langchain-js`.

You can integrate {+avs+} with LangChain
to build |llm| applications and implement 
retrieval-augmented generation (RAG). This tutorial demonstrates
how to start using {+avs+} with LangChain to perform
semantic search on your data and build a |rag| implementation. 
Specifically, you perform the following actions:

#. Set up the environment.
#. Store custom data on |service|.
#. Create an {+avs+} index on your data.
#. Run the following vector search queries:

   - Semantic search.
   - Semantic search with score.
   - Semantic search with metadata pre-filtering.

#. Implement |rag| by using {+avs+} to answer questions on your data.

.. cta-banner::
   :url: https://github.com/mongodb/docs-notebooks/blob/main/ai-integrations/langchain.ipynb?tck=docs
   :icon: Code

   Work with a runnable version of this tutorial as a :github:`Python notebook <mongodb/docs-notebooks/blob/main/ai-integrations/langchain.ipynb?tck=docs>`.

Background
----------

.. include:: /includes/ai-integrations/langchain/langchain-background.rst

Prerequisites
-------------

To complete this tutorial, you must have the following:

- .. include:: /includes/avs/shared/avs-requirements-cluster.rst

- .. include:: /includes/avs/shared/avs-requirements-openai-api-key.rst

- An environment to run interactive Python notebooks 
  such as `Colab <https://colab.research.google.com>`__.

Set Up the Environment
----------------------

.. include:: /includes/avs/shared/set-up-python-notebook-environment.rst

.. include:: /includes/ai-integrations/langchain/langchain-set-up-environment.rst

.. _langchain-ingest-data:

Use |service| as a Vector Store
-------------------------------

Then, load custom data into |service| and instantiate |service| as 
a vector database, also called a `vector store 
<https://python.langchain.com/docs/how_to/#vector-stores>`__.
Copy and paste the following code snippets into your notebook.

.. include:: /includes/ai-integrations/langchain/langchain-create-vector-store.rst

.. _langchain-create-index:

Create the {+avs+} Index
------------------------------------

.. include:: /includes/avs/facts/note-avs-index-required-access.rst

To enable vector search queries on your vector store,
create an {+avs+} index on the ``langchain_db.test`` collection 
by using the LangChain helper method or the
PyMongo driver method.

Run the following code in your notebook for
your preferred method. The index definition specifies 
indexing the following fields:

- ``embedding`` field as the :ref:`vector <avs-types-vector-search>` type. 
  The ``embedding`` field contains the embeddings
  created using OpenAI's ``text-embedding-3-large`` embedding model. 
  The index definition specifies ``3072`` vector dimensions 
  and measures similarity using ``cosine``.

- ``page_label`` field as the :ref:`filter <avs-types-vector-search>` type
  for pre-filtering data by the page number in the PDF.

.. tabs::
   
   .. tab:: LangChain
      :tabid: langchain

      ..
         NOTE: If you edit this Python code, also update the Jupyter Notebook
         at https://github.com/mongodb/docs-notebooks/blob/main/ai-integrations/langchain.ipynb

      .. literalinclude:: /includes/ai-integrations/langchain/create-index-langchain-method.py
         :language: python
         :copyable:

      .. tip::

         `create_vector_search_index API reference <https://langchain-mongodb.readthedocs.io/en/latest/langchain_mongodb/index/langchain_mongodb.index.create_vector_search_index.html>`__

   .. tab:: PyMongo
      :tabid: pymongo

      .. literalinclude:: /includes/ai-integrations/langchain/create-index-pymongo.py
         :language: python
         :copyable:

.. include:: /includes/search-shared/fact-index-build-initial-sync.rst

.. _langchain-run-queries:

Run Vector Search Queries
-------------------------

Once |service| builds your index, run vector search queries on your data. 
The following examples demonstrate various queries that you can 
run on your vectorized data.

.. include:: /includes/ai-integrations/langchain/langchain-query-examples.rst

.. tip::

   For a full list of semantic search methods, refer to 
   the `API reference 
   <https://langchain-mongodb.readthedocs.io/en/latest/langchain_mongodb/vectorstores/langchain_mongodb.vectorstores.MongoDBAtlasVectorSearch.html>`__.

.. _langchain-rag:

Answer Questions on Your Data
-----------------------------

This section demonstrates how to implement |rag| in your 
application with {+avs+} and LangChain. Now that you've used {+avs+} 
to retrieve semantically similar documents, run the following code examples 
to prompt the |llm| to answer questions based on those documents.

.. include:: /includes/ai-integrations/langchain/langchain-perform-qa.rst
