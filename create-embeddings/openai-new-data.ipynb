{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Vector Search - Create Embeddings - OpenAI - New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [Create Embeddings](https://www.mongodb.com/docs/atlas/atlas-vector-search/create-embeddings/) page. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "This notebook takes you through how to generate embeddings from **new data** by using OpenAI's ``text-embedding-3-small`` model.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/create-embeddings/openai-new-data.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade openai pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Use an Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Specify your OpenAI API key and embedding model\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<api-key>\"\n",
    "model = \"text-embedding-3-small\"\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Define a function to generate embeddings\n",
    "def get_embedding(text):\n",
    "   \"\"\"Generates vector embeddings for the given text.\"\"\"\n",
    "\n",
    "   embedding = openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "   return embedding\n",
    "\n",
    "# Generate an embedding\n",
    "embedding = get_embedding(\"foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Convert your embeddings\n",
    "\n",
    "Optionally, run the following code to define a function that converts your embeddings into BSON `binData` vectors for efficient [storage and retrieval](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-quantization/#use-cases-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.binary import Binary \n",
    "from bson.binary import BinaryVectorDtype\n",
    "\n",
    "# Define a function to generate BSON vectors\n",
    "def generate_bson_vector(vector, vector_dtype):\n",
    "   return Binary.from_vector(vector, vector_dtype)\n",
    "\n",
    "# Generate BSON vectors using the `BinaryVectorDtype` class\n",
    "bson_float32_embedding = generate_bson_vector(embedding, BinaryVectorDtype.FLOAT32)\n",
    "\n",
    "# Print the converted embedding\n",
    "print(f\"The converted BSON embedding is: {bson_float32_embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "texts = [\n",
    "  \"Titanic: The story of the 1912 sinking of the largest luxury liner ever built\",\n",
    "  \"The Lion King: Lion cub and future king Simba searches for his identity\",\n",
    "  \"Avatar: A marine is dispatched to the moon Pandora on a unique mission\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings from the sample data\n",
    "embeddings = get_embedding(texts)\n",
    "\n",
    "# Print the embeddings\n",
    "print(\"Generated embeddings:\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Float32 Embedding: {embeddings[i][:3]}... (truncated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Convert your embeddings\n",
    "\n",
    "Run the following code if you defined the `generate_bson_vector` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.binary import BinaryVectorDtype\n",
    "\n",
    "# Convert each embedding to BSON\n",
    "bson_embeddings = []\n",
    "for (f32_emb) in embeddings:\n",
    "   bson_embeddings.append(generate_bson_vector(f32_emb, BinaryVectorDtype.FLOAT32))\n",
    "\n",
    "# Print the BSON embeddings\n",
    "for idx, text in enumerate(texts):\n",
    "   print(f\"\\nText: {text}\")\n",
    "   print(f\"Float32 BSON embedding: {bson_embeddings[idx]}\")\n",
    "\n",
    "# Use the BSON embeddings instead of the float32 embeddings\n",
    "embeddings = bson_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Embeddings into Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs_with_embeddings(embeddings, data):\n",
    "   docs = []\n",
    "   for i, (embedding, text) in enumerate(zip(embeddings, data)):\n",
    "      doc = {\n",
    "            \"_id\": i,\n",
    "            \"data\": text,\n",
    "            \"embedding\": embedding,\n",
    "      }\n",
    "      docs.append(doc)\n",
    "   return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents with embeddings and sample data\n",
    "docs = create_docs_with_embeddings(embeddings, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connect to your Atlas cluster\n",
    "mongo_client = pymongo.MongoClient(\"<connection-string>\")\n",
    "db = mongo_client[\"sample_db\"]\n",
    "collection = db[\"embeddings\"]\n",
    "\n",
    "# Ingest data into Atlas\n",
    "collection.insert_many(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index and Query Your Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.operations import SearchIndexModel\n",
    "import time\n",
    "\n",
    "# Create your index model, then create the search index\n",
    "search_index_model = SearchIndexModel(\n",
    "  definition = {\n",
    "    \"fields\": [\n",
    "      {\n",
    "        \"type\": \"vector\",\n",
    "        \"path\": \"embedding\",\n",
    "        \"similarity\": \"dotProduct\",\n",
    "        \"numDimensions\": 1536\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  name=\"vector_index\",\n",
    "  type=\"vectorSearch\"\n",
    ")\n",
    "result = collection.create_search_index(model=search_index_model)\n",
    "\n",
    "# Wait for initial sync to complete\n",
    "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
    "predicate=None\n",
    "if predicate is None:\n",
    "  predicate = lambda index: index.get(\"queryable\") is True\n",
    "\n",
    "while True:\n",
    "  indices = list(collection.list_search_indexes(result))\n",
    "  if len(indices) and predicate(indices[0]):\n",
    "    break\n",
    "  time.sleep(5)\n",
    "print(result + \" is ready for querying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding for the search query\n",
    "query_embedding = get_embedding(\"ocean tragedy\")\n",
    "\n",
    "# Sample vector search pipeline\n",
    "pipeline = [\n",
    "   {\n",
    "      \"$vectorSearch\": {\n",
    "            \"index\": \"vector_index\",\n",
    "            \"queryVector\": query_embedding,\n",
    "            \"path\": \"embedding\",\n",
    "            \"exact\": True,\n",
    "            \"limit\": 5\n",
    "      }\n",
    "   }, \n",
    "   {\n",
    "      \"$project\": {\n",
    "         \"_id\": 0, \n",
    "         \"text\": 1,\n",
    "         \"score\": {\n",
    "            \"$meta\": \"vectorSearchScore\"\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "]\n",
    "\n",
    "# Execute the search\n",
    "results = collection.aggregate(pipeline)\n",
    "\n",
    "# Print results\n",
    "for i in results:\n",
    "   print(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
