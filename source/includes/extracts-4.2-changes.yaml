ref: 4.2-changes-index-names
content: |

   MongoDB removes the index name length limit of 127 byte maximum. 

---
ref: 4.2-changes-geoNear-limit
content: |

   MongoDB removes the ``limit`` and ``num`` options for the 
   :pipeline:`$geoNear` stage as well as the default limit of 100 documents. 
   To limit the results of :pipeline:`$geoNear`, use the :pipeline:`$geoNear` 
   stage with the :pipeline:`$limit` stage.
---
ref: 4.2-changes-passwordPrompt
content: |

   You can use the :method:`passwordPrompt()` method in conjunction with
   various user authentication management methods and commands to prompt
   for the password instead of specifying the password directly in the
   method or command call. However, you can still specify the password
   directly as you would with earlier versions of the
   ``mongo`` shell.
---
ref: 4.2-changes-opcounters-type
content: |

   The returned opcounters.* values are type NumberLong.
---
ref: 4.2-changes-opcountersRepl-type
content: |

   The returned opcountersRepl.* values are 
   type NumberLong. 
---
ref: 4.2-changes-out-linearizable
content: |

   The :pipeline:`$out` stage cannot be used in conjunction with read concern 
   :readconcern:`"linearizable"`. If you specify :readconcern:`"linearizable"` 
   read concern for :method:`db.collection.aggregate()`, you cannot include the
   :pipeline:`$out` stage in the pipeline.
---
ref: 4.2-changes-linearizable-merge-restriction
content: |

   The :pipeline:`$merge` stage cannot be used in conjunction with read
   concern :readconcern:`"linearizable"`. That is, if you specify
   :readconcern:`"linearizable"` read concern for
   :method:`db.collection.aggregate()`, you cannot include the
   :pipeline:`$merge` stage in the pipeline.
---
ref: 4.2-changes-linearizable-agg
content: |

   You cannot use the :pipeline:`$out` or the :pipeline:`$merge` stage
   in conjunction with read concern :readconcern:`"linearizable"`. That
   is, if you specify :readconcern:`"linearizable"` read concern for
   :method:`db.collection.aggregate()`, you cannot include either
   stages in the pipeline.

---
ref: 4.2-changes-usedDisk
content: |

   The :ref:`profiler log messages
   <database-profiler>` and :ref:`diagnostic log
   messages <log-messages-ref>` includes a ``usedDisk``
   indicator if any aggregation stage wrote data to temporary files due
   to :ref:`memory restrictions <agg-memory-restrictions>`.
---
ref: 4.2-changes-keyfile-fmt
content: |

   :ref:`Keyfiles for internal membership authentication 
   <internal-auth-keyfile>` use YAML format to allow for multiple keys in a 
   keyfile. The YAML format accepts either:

   - A single key string (same as in earlier versions)
   
   - A sequence of key strings

   The YAML format is compatible with the existing single-key
   keyfiles that use the text file format.
---
ref: 4.2-changes-slow-oplog-log-message-footnote
content: |

   Secondary members of a replica set now :ref:`log oplog entries
   <slow-oplog-application>` that take longer than the slow operation
   threshold to apply. These slow oplog messages:
      
   - Are logged for the secondaries in the
     :option:`diagnostic log <mongod --logpath>`.
     
   - Are logged under the :data:`REPL` component with the text
     ``applied op: <oplog entry> took <num>ms``.
   
   - Do not depend on the log levels (either at the system or component
     level)
   
   - Do not depend on the profiling level.

   - Are affected by :setting:`~operationProfiling.slowOpSampleRate`.

   The profiler does not capture slow oplog entries.
---
ref: 4.2-changes-type-0
content: |

   Users can no longer use the query filter ``$type: 0`` as a synonym for
   ``$exists:false``. To query for null or missing fields, see
   :doc:`/tutorial/query-for-null-fields`.
   
---
ref: 4.2-changes-log-storage
content: |

   For slow operations, the :ref:`profiler
   entries <database-profiler>` and
   :ref:`diagnostic log messages <log-messages-ref>` include
   :data:`~system.profile.storage` information.
---
ref: 4.2-changes-log-query-shapes-plan-cache-key
content: |

   The :ref:`profiler entries <database-profiler>` and the 
   :ref:`diagnostic log messages (i.e. mongod/mongos logmessages) 
   <log-message-slow-ops>` for read/write operations include:

   - ``planCacheShapeHash`` to help identify slow queries with the same
     :term:`plan cache query shape`.
     
     .. include:: /includes/plan-cache-rename.rst

   - ``planCacheKey`` to provide more insight into the :doc:`query plan
     cache </core/query-plans>` for slow queries.

---
ref: 4.2-changes-query-shapes
content: |

   To help identify slow queries with the same :term:`plan cache query
   shape`, each plan cache query shape is associated with a query hash.
   The plan cache query shape hash is a hexadecimal string that
   represents a hash of the query shape and is dependent only on the
   query shape.

   .. note::

      As with any hash function, two different query shapes may result
      in the same hash value. However, the occurrence of hash
      collisions between different query shapes is unlikely.

      .. include:: /includes/plan-cache-rename.rst

---
ref: 4.2-changes-plan-cache-key
content: |

   To provide more insight into the :doc:`query plan cache
   </core/query-plans>`, MongoDB offers the ``planCacheKey``. 
   
   ``planCacheKey`` is a hash of the key for the plan cache entry
   associated with the query.

   .. note::

      Unlike ``planCacheShapeHash``, ``planCacheKey`` is a function of
      both the query shape and the currently available indexes for the
      shape. That is, if indexes that can support the query shape are
      added/dropped, the ``planCacheKey`` value may change whereas the
      ``planCacheShapeHash`` value would not change.

      .. include:: /includes/plan-cache-rename.rst

---
ref: 4.2-changes-planCacheStats
content: |
   
   MongoDB includes a new aggregation pipeline stage
   :pipeline:`$planCacheStats` that provides :doc:`plan cache
   </core/query-plans>` information for a collection.

---
ref: 4.2-changes-planCacheStats-pref
content: |

   The :pipeline:`$planCacheStats` aggregation stage is preferred over
   the following methods and commands, which have been deprecated in 4.2:
      
   - ``PlanCache.getPlansByQuery()``
     method/``planCacheListPlans`` command, and


   - ``PlanCache.listQueryShapes()``
     method/``planCacheListQueryShapes`` command.

---
ref: 4.2-changes-options-tls-ssl
content: |

   MongoDB deprecates the SSL options and instead adds new
   corresponding TLS options.
---
ref: 4.2-changes-options-tlsClusterCAFile
content: |
   MongoDB adds
   |tlsClusterCAFile|/:setting:`net.tls.clusterCAFile`. 
---
ref: 4.2-changes-options-tls-ssl-upgrade
content: |
   MongoDB deprecates the SSL options for the
   ``mongod``, the ``mongos``, and the ``mongo`` shell as
   well as the corresponding ``net.ssl`` configuration
   file options.

   To avoid deprecation messages, use the new ``TLS`` options for the
   :ref:`mongod <tls-mongod-options>`, the :ref:`mongos
   <mongos-tls-options>`, and the ``mongo``.

   - For the command-line TLS options, refer to the :ref:`mongod
     <tls-mongod-options>`, :ref:`mongos <mongos-tls-options>`, and
     ``mongo`` shell pages.

   - For the corresponding ``mongod`` and ``mongos`` configuration file
     options, refer to the :ref:`configuration file
     <net-tls-conf-options>` page.

   - For the connection string ``tls`` options, refer to the
     :ref:`connection string <uri-options-tls>` page.
---
ref: 4.2-changes-options-tls-ssl-downgrade
content: |

   MongoDB adds ``"tls"``-prefixed options as
   aliases for the ``"ssl"-prefixed`` options.

   If your deployments or clients use the ``"tls"``-prefixed options,
   replace with the corresponding ``"ssl"-prefixed`` options for the
   ``mongod``, the ``mongos``, and the ``mongo`` shell and drivers.
---
ref: 4.2-changes-agg-out-explain
content: |

   You cannot run the :dbcommand:`explain`
   command/:method:`db.collection.explain()` in ``executionStats`` mode
   or ``allPlansExecution`` mode for an :method:`aggregation pipeline
   <db.collection.aggregate>` that contains the :pipeline:`$out` stage.
   Instead, you can either:

   - run the explain in ``queryPlanner`` mode or 

   - run the explain in ``executionStats`` mode or ``allPlansExecution``
     mode but without the :pipeline:`$out` stage to return information
     for the stages that precede the :pipeline:`$out` stage.
---
ref: 4.2-changes-debug-log-message
content: |

   Starting in version 4.2, MongoDB includes the Debug verbosity level
   (1-5) in the :ref:`log messages <log-severity-levels>`. For example,
   if the verbosity level is 2, MongoDB logs ``D2``. In previous
   versions, MongoDB log messages only specified ``D`` for Debug level.
---
ref: 4.2-changes-downgrade-command-line-options
content: |

   If you use command-line options instead of a configuration file,
   update the command-line options as appropriate during the restart.

   - If your command-line options include :ref:`"tls"-prefixed
     options <tls-mongod-options>`, update to ``"ssl"-prefixed`` options.

   - If the :binary:`~bin.mongod` instance used ``zstd`` data compression, 
   
     - Update :option:`--dbpath <mongod --dbpath>` to the new directory
       (created during the prerequisites).
       
     - Remove :option:`--wiredTigerCollectionBlockCompressor <mongod
       --wiredTigerCollectionBlockCompressor>` to use the default
       ``snappy`` compressor (or, alternatively, explicitly set to a
       4.0 supported compressor).

   - If the :binary:`~bin.mongod` instance used ``zstd`` journal
     compression,

     - Remove :option:`--wiredTigerJournalCompressor <mongod
       --wiredTigerJournalCompressor>` to use the default ``snappy``
       compressor (or, alternatively, explicitly set to a 4.0 supported
       compressor).

   - If the :binary:`~bin.mongod` instance included ``zstd`` network
     message compression,
     
     - Remove :option:`--networkMessageCompressors <mongod
       --networkMessageCompressors>` to enable message compression
       using the default ``snappy,zlib`` compressors. Alternatively,
       explicitly specify the compressor(s).

---
ref: 4.2-changes-downgrade-command-line-options-mongos
content: |
   If you use command-line options instead of a configuration file,
   update the command-line options as appropriate during the restart.

   - If your :binary:`~bin.mongos` command-line options include
     :ref:`"tls"-prefixed options <mongos-tls-options>`, update to
     ``"ssl"-prefixed`` options.

   - If the :binary:`~bin.mongos` instance included ``zstd`` network
     message compression, remove :option:`--networkMessageCompressors
     <mongos --networkMessageCompressors>` to use the default
     ``snappy,zlib`` compressors. Alternatively, specify the list of
     compressors to use.
---
ref: 4.2-changes-zstd-downgrade-prereq
content: |

   #. Create a new empty :option:`data directory <mongod --dbpath>` for
      the :binary:`~bin.mongod` instance. This directory will be used
      in the downgrade procedure below.

      .. important::

         Ensure that the user account running :binary:`~bin.mongod` has
         read and write permissions for the new directory.

   #. If you use a :doc:`configuration file
      </reference/configuration-options>`, update the file to prepare for
      the downgrade procedure:

      a. Delete
         :setting:`storage.wiredTiger.collectionConfig.blockCompressor`
         to use the default compressor (``snappy``) or
         set to another 4.0 supported compressor.

      #. Update :setting:`storage.dbPath` to the new
         data directory.

      | If you use command-line options instead, you will have to update
        the options in the procedure below.

---
ref: 4.2-changes-zstd-journal-compression-config-only
content: |

   - If using a :doc:`configuration file
     </reference/configuration-options>`, delete
     :setting:`storage.wiredTiger.engineConfig.journalCompressor` to
     use the default compressor (``snappy``) or set to another 4.0
     supported compressor.

   - If using command-line options instead, you will have to update the
     options in the procedure below.
---
ref: 4.2-changes-zstd-network-compression
content: |

   The :term:`zstd` compression library is available for network
   message compression starting in version 4.2.

   To prepare for the downgrade:

   #. For |binary| that uses :term:`zstd` for network message
      compression and uses a :doc:`configuration file
      </reference/configuration-options>`, update the
      :setting:`net.compression.compressors` setting to prepare for the
      restart during the downgrade procedure.

      | If you use command-line options instead, you will have to update
        the options in the procedure below.

   #. For any client that specifies ``zstd`` in its :urioption:`URI
      connection string <compressors>`, update to remove ``zstd`` from the
      list.

   #. For any ``mongo`` shell that specifies ``zstd`` in its
      ``--networkMessageCompressors``, update to remove ``zstd`` from 
      the list.

   .. important::

      Messages are compressed when both parties enable network
      compression. Otherwise, messages between the parties are
      uncompressed.
---
ref: 4.2-changes-fips-program
content: |
   Starting in version 4.2, MongoDB removes the ``--sslFIPSMode``
   option for |tool-binary|. |tool-binary|
   will use FIPS compliant connections to
   :binary:`mongod` / :binary:`mongos` if the
   :binary:`mongod` / :binary:`mongos` instances are
   :ref:`configured to use FIPS mode <configure-mdb-for-fips>`.
---
ref: 4.2-changes-fips-program-mongod
content: |
   Starting in version 4.2, MongoDB removes the ``--sslFIPSMode``
   option for |tool-binary|. |tool-binary|
   will use FIPS compliant connections to the
   :binary:`~bin.mongod` if the
   :binary:`~bin.mongod` instance is
   :ref:`configured to use FIPS mode <configure-mdb-for-fips>`.

---
ref: 4.2-changes-fips
content: |

   Starting in version 4.2, MongoDB removes the ``--sslFIPSMode``
   option for the following programs:

   - :binary:`~bin.mongodump`
   - :binary:`~bin.mongoexport`
   - :binary:`~bin.mongofiles`
   - :binary:`~bin.mongoimport`
   - :binary:`~bin.mongorestore`
   - :binary:`~bin.mongostat`
   - :binary:`~bin.mongotop`

   The programs will use FIPS compliant connections to
   :binary:`mongod` / :binary:`mongos` if the
   :binary:`mongod` / :binary:`mongos` instances are
   :ref:`configured to use FIPS mode <configure-mdb-for-fips>`.
---
ref: 4.2-changes-count-syntax-validation
content: |

   Starting in version 4.2, MongoDB implements a stricter validation of
   the option names for the :dbcommand:`count` command. The command now
   errors if you specify an unknown option name.
   
---
ref: 4.2-changes-stats-scaleFactor
content: |

   Starting in version 4.2, the output includes the ``scaleFactor``
   used to scale the size values.

---
ref: 4.2-downgrade-view-definitions
content: |

   Before downgrading the binaries, modify :doc:`read-only view
   </core/views>` definitions and :ref:`collection validation
   <schema-validation-query-expression>` definitions
   that include the :ref:`4.2 operators <4.2-agg>`, such as
   :pipeline:`$set`, :pipeline:`$unset`, :pipeline:`$replaceWith`.
   
   - For the :pipeline:`$set` stage, use the :pipeline:`$addFields`
     stage instead.

   - For the :pipeline:`$replaceWith` stage, use the
     :pipeline:`$replaceRoot` stage instead.

   - For the :pipeline:`$unset` stage, use the :pipeline:`$project`
     stage instead.

   You can modify a view either by:

   - dropping the view (:method:`db.myview.drop() <db.collection.drop()>` method) and
     recreating the view (:method:`db.createView()` method) or

   - using the :dbcommand:`collMod` command.

   You can modify the colleciton validation expressions by:
      
   - using the :dbcommand:`collMod` command.
---
ref: 4.2-changes-change-stream-modification-error
content: |

   Starting in MongoDB 4.2, change streams will throw an exception if
   the :ref:`change stream aggregation pipeline
   <change-stream-modify-output>` modifies an event's :ref:`_id
   <change-stream-event-id>` field.
---
ref: 4.2-changes-inmem-startup-warning
content: |
   Starting in version 4.2 (and 4.0.13 and 3.6.14 ), if a replica set
   member uses the :ref:`in-memory storage engine <storage-inmemory>`
   (voting or non-voting) but the replica set has
   :rsconf:`writeConcernMajorityJournalDefault` set to true, the
   replica set member logs a startup warning.
---
ref: 4.2-changes-SAN-matching
content: |
   Starting in MongoDB 4.2, when performing comparison of SAN, MongoDB
   supports comparison of DNS names or IP addresses. In previous versions,
   MongoDB only supports comparisons of DNS names.
---
ref: 4.2-changes-disconnect
content: |

   Starting in MongoDB 4.2, if the client that issued |operation|
   disconnects before the operation completes, MongoDB marks |operation| 
   for termination using :dbcommand:`killOp`.
---
ref: 4.2-changes-map-reduce-deprecation
content: |
   Starting in version 4.2, MongoDB deprecates:
   
   - The map-reduce option to *create* a new sharded collection as well
     as the use of the :ref:`sharded <mapreduce-out-cmd>` option for
     map-reduce. To output to a sharded collection, create the sharded
     collection first. MongoDB 4.2 also deprecates the replacement of
     an existing sharded collection.
---
ref: 4.2-changes-balancer-autosplit
content: |

   .. include:: /includes/autosplit-no-operation.rst
   
   In MongoDB versions earlier than 6.1:

   - The :dbcommand:`balancerStart` command and the
     ``mongo`` shell helper methods
     :method:`sh.startBalancer()` and
     :method:`sh.setBalancerState(true) <sh.setBalancerState>` also
     enable auto-splitting for the sharded cluster.
     
     | To disable auto-splitting when the balancer is enabled, you can
       use :method:`sh.disableAutoSplit()`.

   - The :dbcommand:`balancerStop` command and the ``mongo``
     shell helper methods :method:`sh.stopBalancer()` and
     :method:`sh.setBalancerState(false) <sh.setBalancerState>` also
     disable auto-splitting for the sharded cluster. 
     
     | To enable auto-splitting when the balancer is disabled, you can
       use :method:`sh.enableAutoSplit()`.

   The ``mongo`` methods
   :method:`sh.enableBalancing(namespace) <sh.enableBalancing>` and
   :method:`sh.disableBalancing(namespace) <sh.disableBalancing>` have no affect on the
   auto-splitting.
---
ref: 4.2-changes-start-balancer-autosplit
content: |

   .. include:: /includes/autosplit-no-operation.rst

   In MongoDB versions earlier than 6.0.3, :method:`sh.startBalancer()`
   also enables auto-splitting for the sharded cluster.
---
ref: 4.2-changes-stop-balancer-autosplit
content: |

   .. include:: /includes/autosplit-no-operation.rst

   In MongoDB versions earlier than 6.0.3, :method:`sh.stopBalancer()`
   also disables auto-splitting for the sharded cluster.
---
ref: 4.2-changes-global-lock-reporting
content: |

   Starting in version 4.2, MongoDB reports on
   ``ReplicationStateTransition`` lock information.
   
   In addition, MongoDB 4.2 separates ``ParallelBatchWriterMode`` lock
   information from ``Global`` lock information. Earlier MongoDB versions
   report ``ParallelBatchWriterMode`` lock information as part
   of ``Global`` locks.
   
   For operations that report on lock information, see:
   
   - :dbcommand:`serverStatus` command and :method:`db.serverStatus()` method.
   
   - :pipeline:`$currentOp` aggregation pipeline stage, :dbcommand:`currentOp` command, and :method:`db.currentOp()` method.
---
ref: 4.2-changes-findAndX-parameter-validation
content: |
   
   Starting in MongoDB 4.2 (and 4.0.12+ and 3.6.14+), the
   :dbcommand:`findAndModify` command and its associated
   ``mongo`` shell methods error if the specified query,
   sort, or projection argument is not a document.
   
   In earlier versions, the operation treated non-document query or
   sort argument as an empty document ``{}``.

   See:
      
   - :dbcommand:`findAndModify`
   - :method:`db.collection.findOneAndDelete()`
   - :method:`db.collection.findOneAndReplace()`
   - :method:`db.collection.findOneAndUpdate()`
   - :method:`db.collection.findAndModify()`
---
ref: 4.2-changes-flow-control-general-desc
content: |
   Administrators can limit the rate at which
   the primary applies its writes with the goal of keeping the :data:`majority
   committed <replSetGetStatus.optimes.lastCommittedOpTime>` lag under
   a configurable maximum value :parameter:`flowControlTargetLagSeconds`.
   
   By default, flow control is :parameter:`enabled <enableFlowControl>`.

   .. note::

      .. include:: /includes/extracts/4.2-changes-flow-control-requirements.rst

---
ref: 4.2-changes-flow-control-requirements
content: |

   For flow control to engage, the replica set/sharded cluster must
   have: :ref:`featureCompatibilityVersion (FCV)<view-fcv>` of
   ``4.2`` and read concern :setting:`majority enabled
   <replication.enableMajorityReadConcern>`. That is, enabled flow
   control has no effect if FCV is not ``4.2`` or if read concern
   majority is disabled.

---
ref: 4.2-changes-flow-control-specific-desc
content: |
   With flow control enabled, as the lag grows close to the
   :parameter:`flowControlTargetLagSeconds`, writes on the primary must obtain
   tickets before taking locks to apply writes. By limiting the number of
   tickets issued per second, the flow control mechanism attempts to keep 
   the lag under the target.
---
ref: 4.2-changes-extended-json-v2
content: |
   Starting in version 4.2:

   .. list-table::
      :header-rows: 1
      :widths: 20 80
   
      * - Binary
        - Changes
   
      * - :binary:`~bin.bsondump`

        - Uses Extended JSON v2.0 (Canonical
          mode) format.

      * - :binary:`~bin.mongodump`

        - Use Extended JSON v2.0 (Canonical mode) format for the
          metadata. Requires :binary:`~bin.mongorestore` version 4.2 or
          later that supports Extended JSON v2.0 (Canonical mode or
          Relaxed) format.
          
          In general, use corresponding versions of
          :binary:`~bin.mongodump` and :binary:`~bin.mongorestore`.
          To restore data files created with a specific
          version of :binary:`~bin.mongodump`, use the corresponding
          version of :binary:`~bin.mongorestore`.

      * - :binary:`~bin.mongoexport`

        - | Creates output data in Extended JSON v2.0 (Relaxed mode) by
            default.

          | Creates output data in Extended JSON v2.0 (Canonical mode) if
            used with ``--jsonFormat``.


      * - :binary:`~bin.mongoimport`
   
        - | Expects import data to be in Extended JSON v2.0 (either
            Relaxed or Canonical mode) by default.

          | Can recognize data that is in Extended JSON v1.0 format if the option
            ``--legacy`` is specified.

          In general, the versions of :binary:`~bin.mongoexport` and
          :binary:`~bin.mongoimport` should match. To import
          data created from :binary:`~bin.mongoexport`, you should use
          the corresponding version of :binary:`~bin.mongoimport`.
---
ref: 4.2-changes-extended-json-v2-query
content: |
   Starting in version 4.2, the query option for ``mongodump --query``
   and ``mongoexport --query`` must be in :doc:`Extended JSON v2 format
   (relaxed or canonical/strict mode)
   </reference/mongodb-extended-json>`, including enclosing the field
   names and the operators in quotes, as in the following:

   .. code-block:: bash

      mongoexport -d=test -c=records -q='{ "a": { "$gte": 3 }, "date": { "$lt": { "$date": "2016-01-01T00:00:00.000Z" } } }' --out=exportdir/myRecords.json

   In earlier versions, the query options uses the :doc:`Extended JSON v1
   format </reference/mongodb-extended-json-v1>` and the field names and
   the operators do not need to be in quotes:

   .. code-block:: bash

      mongoexport -d=test -c=records -q='{ a: { $gte: 3 }, date: { $lt: { "$date": "2016-01-01T00:00:00.000Z" } } }' --out=exportdir/myRecords.json
   
---
ref: 4.2-changes-mongoshell-emulation
content: |
   
   Starting in MongoDB 4.2 (and 4.0.13), the ``mongo`` shell displays a
   warning message when connected to non-genuine MongoDB instances as
   these instances may behave differently from the official MongoDB
   instances; e.g. missing or incomplete features, different feature
   behaviors, etc.
---
ref: 4.2-changes-drivers-retryWrites-default
content: |

   Drivers compatible with MongoDB 4.2 and higher enable
   :ref:`retryable-writes` by default. Earlier drivers require the
   :urioption:`retryWrites=true <retryWrites>` option. The
   :urioption:`retryWrites=true <retryWrites>` option can be omitted in
   applications that use drivers compatible with MongoDB 4.2 and
   higher.

   |

   To disable retryable writes, applications that use drivers
   compatible with MongoDB 4.2 and higher must include 
   :urioption:`retryWrites=false <retryWrites>` in the connection
   string.

---
ref: 4.2-changes-libldap
content: |

   For MongoDB 4.2 Enterprise binaries linked against
   ``libldap`` (such as when running on RHEL), access to the
   ``libldap`` is synchronized, incurring some performance/latency
   costs.

   For MongoDB 4.2 Enterprise binaries linked against
   ``libldap_r``, there is no change in behavior from earlier MongoDB
   versions.
---
ref: 4.2-changes-expansion-configuration-file-permission-rest
content: |
   
   If the configuration file includes the :configexpansion:`__rest`
   expansion, on Linux/macOS, the read access to the configuration file must be limited
   to the user running the :binary:`mongod` / :binary:`mongos`
   process only.
---
ref: 4.2-changes-expansion-configuration-file-permission-exec
content: |
   If the configuration file includes the :configexpansion:`__exec`
   expansion, on Linux/macOS, the write access to the configuration file must be
   limited to the user running the
   :binary:`mongod` / :binary:`mongos` process only.
---
ref: 4.2-changes-ese-key-rollover
content: |

   For :ref:`encrypted storage engine <encrypted-storage-engine>`
   configured with ``AES256-GCM`` cipher:

   - Restoring from Hot Backup
         Starting in 4.2, if you restore from files taken via "hot"
         backup (i.e. the :binary:`~bin.mongod` is running), MongoDB
         can detect "dirty" keys on startup and automatically rollover
         the database key to avoid IV (Initialization Vector) reuse.
     
   - Restoring from Cold Backup
         However, if you restore from files taken via "cold" backup
         (i.e. the :binary:`~bin.mongod` is not running), MongoDB
         cannot detect "dirty" keys on startup, and reuse of IV voids
         confidentiality and integrity guarantees.
     
         Starting in 4.2, to avoid the reuse of the keys after
         restoring from a cold filesystem snapshot, MongoDB adds a new
         command-line option :option:`--eseDatabaseKeyRollover <mongod
         --eseDatabaseKeyRollover>`. When started with the
         :option:`--eseDatabaseKeyRollover <mongod
         --eseDatabaseKeyRollover>` option, the :binary:`~bin.mongod`
         instance rolls over the database keys configured with
         ``AES256-GCM`` cipher and exits.
---
ref: 4.2-changes-rollback-user-ops
content: |
   Starting in version 4.2, MongoDB kills all in-progress user
   operations when a member enters the :replstate:`ROLLBACK` state.
---
ref: 4.2-changes-mongos-repl-connection-pool
content: |
   Starting in MongoDB 4.2, MongoDB adds the parameter
   :parameter:`ShardingTaskExecutorPoolReplicaSetMatching`. This 
   parameter determines the minimum size of the 
   :binary:`mongod` / :binary:`mongos` instance's 
   connection pool to each member of the sharded cluster. This value 
   can vary during runtime.
   
   :binary:`~bin.mongod` and :binary:`~bin.mongos` maintain connection
   pools to each replica set secondary for every replica set in the 
   sharded cluster. By default, these pools have a number of connections
   that is at least the number of connections to the primary.  

   To modify, see :parameter:`ShardingTaskExecutorPoolReplicaSetMatching`.
---
ref: 4.2-changes-sharded-collection-replacement
content: |

   Starting in MongoDB 4.2,
   
   - Operations which replace documents, such as
     :method:`~db.collection.replaceOne()` or
     :method:`~db.collection.update()` (when used with a replacement
     document), will first attempt to target a single shard by using the
     query filter. If the operation cannot target a single shard by the
     query filter, it then attempts to target by the replacement
     document. In earlier versions, these operations only attempt to
     target using the replacement document.

   - The ``save()`` method is deprecated: use the
     :method:`~db.collection.insertOne()` or
     :method:`~db.collection.replaceOne()` method instead. The
     ``save()`` method cannot be used with
     sharded collections that are *not* sharded by ``_id``, and
     attempting to do so will result in an error. 

   - For a replace document operation that includes ``upsert: true``
     and is on a sharded collection, the ``filter`` must include an
     equality match on the full shard key.
---
ref: 4.2-changes-bulkWrite-txn-error-handling
content: |

   Starting in MongoDB 4.2, if a :method:`db.collection.bulkWrite()`
   operation encounters an error inside a :doc:`transaction
   </core/transactions>`, the method throws a :ref:`BulkWriteException
   <bulkWrite-error-handling>` (same as outside a transaction). 

   In 4.0, if the ``bulkWrite`` operation encounters an error inside a
   transaction, the error thrown is not wrapped as a
   ``BulkWriteException``.
      
   Inside a transaction, the first error in a bulk write causes the
   entire bulk write to fail and aborts the transaction, even if the
   bulk write is unordered.

---
ref: 4.2-changes-downgrade-floor
content: |

   .. tip::

      If you downgrade, 

      - On Windows, downgrade to version 4.0.12 or later version. You
        cannot downgrade to a 4.0.11 or earlier version.

      - On Linux/macOS, if you are running change streams and want to
        seamlessly :ref:`resume change streams
        <change-stream-resume-token>`, downgrade to 4.0.7 or later
        versions.
---
ref: 4.2-changes-new-variable-reserved
content: |

   .. note::

      Starting in MongoDB 4.2.2, the ``$$new`` variable is
      reserved, and cannot be overridden.
...
