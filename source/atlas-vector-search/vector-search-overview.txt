:noprevnext:

.. _fts-vector-search:
.. _avs-overview:

============================
{+avs+} Overview
============================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: reference

.. meta::
   :keywords: vector search, semantic search, hybrid search, generative search, AI, search meaning, RAG
   :description: Use MongoDB Atlas Vector Search to create vector indexes and perform vector search, including semantic search and hybrid search, on your vector embeddings.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

You can use {+avs+} to perform vector search on your data in |service|.
When you define an {+avs+} index on your collection, you can 
seamlessly index vector data along with your other data and then 
perform vector search queries against the indexed fields.

{+avs+} enables various search :ref:`use cases <avs-use-cases>`, 
including semantic, hybrid, and generative search.
By storing :term:`vector embeddings` alongside your other data in 
|service|, you can filter semantic search queries on other fields 
in your collection and combine semantic search with full-text search. 
By using |service| as a vector database, 
you can also leverage {+avs+} in |ai| applications and integrate 
it with popular |ai| frameworks and services.

{+avs+} is supported on |service| {+clusters+} running MongoDB version
6.0.11, 7.0.2, or later for |ann| search and MongoDB version 6.0.16,
7.0.10, 7.32, or later for |enn| search.  

.. button:: Get Started with {+avs+}
   :uri: https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/

.. note::

   For optimal performance, we recommend deploying :ref:`separate search
   nodes for workload isolation <configure-search-nodes>`. Search Nodes
   support concurrent query execution to improve individual query
   latency. To learn more, see :ref:`avs-deployment-options`.

.. _avs-about-vector-search:

What is Vector Search?
----------------------

Vector search is a search method that returns results based on
your data's semantic, or underlying, meaning. Unlike traditional 
full-text search which finds text matches, vector search finds 
:term:`vectors <vector>` that are close to your search query 
in multi-dimensional space. The closer the vectors are to your query, 
the more similar they are in meaning.

By interpreting the meaning of your search query and data,
vector search allows you to consider the searcher's intent
and search context to retrieve more relevant results.

For example, if you searched for the term "red fruit," full-text search 
returns only data that explicitly contains these keywords. However, 
semantic search might return data that is similar in meaning,
such as fruits that are red in color like apples or strawberries.

.. _avs-key-concepts:

Key Concepts
~~~~~~~~~~~~

.. glossary::

   vector
      A vector is an array of numbers that represents your data 
      in multiple dimensions. Vectors can represent any kind of data, 
      from text, image, and audio data to unstructured data. Semantic 
      similarity is determined by measuring the distance between
      vectors.

      Specifically, {+avs+} uses dense vectors,
      which are a type of high-dimensional vector that favors 
      smaller storage and semantic richness. As opposed to sparse vectors, 
      dense vectors can be packed with more data,
      which enables {+avs+} to capture more complex relationships.

   vector embeddings
      Vector embeddings, or vectorization, is the process of converting 
      your data into vectors. These embeddings capture 
      meaningful relationships in your data and enable tasks like 
      semantic search and retrieval. To use |service| as a vector database,
      you create embeddings by passing your data through an 
      :term:`embedding model`, and you store these embeddings 
      as a field in the document.
      
      {+avs+} determines semantic similarity by identifying the
      vector embeddings that are closest in distance to
      your :ref:`query vector <avs-queries>`.

      To learn more, see :ref:`create-vector-embeddings`.

   embedding model
      Embedding models are algorithms that 
      you use to convert your data into vector embeddings.
      To do this, embedding models use |llm|\s, machine 
      learning models trained on a large corpus of data, to generate 
      vector embeddings that capture the semantic meaning of your data.

      The embedding model that you choose determines how you configure 
      your {+avs+} index and affects your query results based on 
      how the embedding model was trained. As a result, 
      `different embedding models
      <https://huggingface.co/spaces/mteb/leaderboard>`__
      offer varying advantages depending on your data and use case. 

.. _avs-indexes:

{+avs+} Indexes 
---------------------------

To perform vector search on your data in |service|, you must create 
an {+avs+} index. {+avs+} indexes are separate from your other database 
indexes and are used to efficiently retrieve documents that contain 
vector embeddings at query-time. In your {+avs+} index definition, 
you index the fields in your collection that contain your embeddings 
to enable vector search against those fields. {+avs+} supports embeddings 
that are less than and equal to 4096 dimensions in length.

You can also pre-filter your data by indexing any 
boolean, date, numeric, objectId, and string fields in your collection 
that you want to run your {+avs+} queries against. 
Filtering your data narrows the scope of your
search and ensures that certain vector embeddings
aren't considered for comparison.

To learn how to index fields for {+avs+}, 
see :ref:`avs-types-vector-search`. 

.. _avs-queries:

{+avs+} Queries 
---------------------------

{+avs+} supports approximate nearest neighbor (|ann|) search 
with the |hnsw| algorithm and exact nearest neighbor (|enn|) search.

To find the most similar vectors, {+avs+} performs |ann| search without
scanning every vector embedding and |enn| search exhaustively on all
the indexed vector embeddings. To learn more, see :ref:`vectorSearch
Definition <vectorSearch-agg-pipeline>`. 

{+avs+} queries consist of :manual:`aggregation pipeline stages 
</aggregation>` where the :pipeline:`$vectorSearch` stage is the
first stage in the pipeline. The process for a basic {+avs+} query 
is as follows:

#. You select either |ann| or |enn| search and specify the :ref:`query
   vector <vectorSearch-agg-pipeline-options>`, which is the vector
   embedding that represents your search query. 

#. {+avs+} finds vector embeddings in your data that are closest to the
   query vector. 

#. {+avs+} returns the documents that contain the most similar vectors.

To customize your vector search query, you can pre-filter your data on 
fields that you've indexed by using an :abbr:`MQL (MongoDB Query Language)` 
match expression with supported :manual:`query </reference/operator/query/>` 
or :manual:`aggregation operators </reference/operator/aggregation/>`,
or you can add additional :manual:`aggregation stages </reference/operator/aggregation-pipeline/>` 
to further process and organize your results.

To learn how to create and run {+avs+} queries,
see :ref:`return-vector-search-results`. 

.. _avs-use-cases: 

Use Cases
---------

{+avs+} supports the following types of vector search queries:

- **Semantic Search**: Query your vector embeddings based on semantic similarity
  by using the |ann| or |enn| search algorithm.

  To learn more, see :ref:`How to Perform Semantic Search 
  <vector-search-tutorial>` and :ref:`return-vector-search-results`.

- **Hybrid Search**: Combine results from both semantic search and 
  full-text search queries. To learn more, see :ref:`avs-reciprocal-rank-fusion`.

By using |service| as a :website:`vector database 
</basics/vector-databases>`, you can use {+avs+} to 
build natural language processing (NLP), machine learning (ML), 
and generative |ai| applications. 

Specifically, you can implement **Retrieval-Augmented Generation (RAG)** 
by storing data in |service|, using {+avs+} to retrieve relevant 
documents from your data, and leveraging an |llm| to answer questions
on your data. You can implement |rag| locally or by
:ref:`integrating <avs-integrations>` {+avs+} with popular 
frameworks and services. To learn more, see 
:ref:`AI Key Concepts <ai-key-concepts>`.

.. _avs-integrations:

AI Integrations
~~~~~~~~~~~~~~~

You can use {+avs+} with popular chat and embedding models 
from |ai| providers such as OpenAI, |aws|, and Google.
MongoDB and partners also provide specific product integrations to 
help you leverage {+avs+} in your |ai|-powered applications. 
These integrations include built-in tools and libraries 
that enable you to use |service| as a vector database, build generative 
|ai| applications, and implement |rag| from start to finish. 

For example, by integrating {+avs+} with open-source frameworks 
such as `LangChain <https://langchain.com/>`__ and
`LlamaIndex <https://llamaindex.ai/>`__, you can build applications 
that answer questions about your data on top of popular |llm|\s.

To learn more and get started, see :ref:`vector-search-integrations`.

Next Steps
-----------

For a hands-on experience creating {+avs+} indexes and running {+avs+} 
queries against sample data, try the :mdbu-course:`{+avs+} Course on MongoDB University 
</courses/using-vector-search-for-semantic-search>` and the tutorials in the following pages:

- :ref:`vector-search-quick-start`
- :ref:`avs-tutorials`

.. toctree::
   :titlesonly:

   Quick Start </atlas-vector-search/tutorials/vector-search-quick-start/>
   Create Embeddings </atlas-vector-search/create-embeddings/>
   Create and Manage Indexes </atlas-vector-search/vector-search-type>
   Create and Run Queries </atlas-vector-search/vector-search-stage>
   Review Deployment Options </atlas-vector-search/deployment-options>
   Tutorials </atlas-vector-search/tutorials>
   AI Integrations </atlas-vector-search/ai-integrations>
   Improve Performance </atlas-vector-search/tune-vector-search>
   Troubleshooting </atlas-vector-search/troubleshooting>
   Changelog </atlas-vector-search/changelog>
