.. index:: fundamentals; sharding
.. _sharding-fundamentals:

============================
Sharded Cluster Requirements
============================

.. TODO add something about which nodes need to be able to communicate
   with other nodes.

.. default-domain:: mongodb

While sharding is a powerful and compelling feature, sharded clusters
have significant infrastructure requirements and increases the overall
complexity of a deployment. As a result, only deploy sharded clusters
when indicated by application and operational requirements

Sharding is the *only* solution for some classes of deployments. Use
:term:`sharded clusters <sharded cluster>` if:

- your data set approaches or exceeds the storage capacity of a single
  MongoDB instance.

- the size of your system's active :term:`working set` *will soon*
  exceed the capacity of your system's *maximum* RAM.

- a single MongoDB instance cannot meet the demands of your write
  operations, and all other approaches have not reduced contention.

If these attributes are not present in your system, sharding will only
add complexity to your system without adding much benefit.

.. _sharding-capacity-planning:

.. important:: It takes time and resources to deploy sharding. If
   your system has *already* reached or exceeded its capacity, it
   will be difficult to deploy sharding without impacting
   your application.

   As a result, if you think you will need to partition your database
   in the future, **do not** wait until your system is overcapacity to
   enable sharding.

When designing your data model, take into consideration your sharding
needs.

.. _sharding-requirements-data:

Data Quantity Requirements
--------------------------

Your cluster should manage a large quantity of data if sharding is to
have an effect. The default :term:`chunk` size is 64 megabytes. And the
:ref:`balancer <sharding-balancing>` will not begin moving data across
shards until the imbalance of chunks among the shards exceeds the
:ref:`migration threshold <sharding-migration-thresholds>`. In
practical terms, unless your cluster has many hundreds of megabytes of
data, your data will remain on a single shard.

In some situations, you may need to shard a small collection of data.
But most of the time, sharding a small collection is not worth the
added complexity and overhead unless you need additional write
capacity. If you have a small data set, a properly configured single
MongoDB instance or a replica set will usually be enough for your
persistence layer needs.

:term:`Chunk <chunk>` size is
:option:`user configurable <mongos --chunkSize>`.
For most deployments, the default value is of 64
megabytes is ideal. See :ref:`sharding-chunk-size` for more information.
