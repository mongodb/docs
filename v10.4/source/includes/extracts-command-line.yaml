ref: list-command-line-specification
content: |
  - the ``--packages`` option to download the MongoDB Spark Connector
    package.  The following package is available:

    - ``mongo-spark-connector``

  - the ``--conf`` option to configure the MongoDB Spark Connnector.
    These settings configure the ``SparkConf`` object.

    .. note:: 

       If you use ``SparkConf`` to configure the {+connector-short+}, you
       must prefix the settings appropriately. For details and other
       available MongoDB Spark Connector options, see the
       :doc:`/configuration` guide.
---
ref: list-configuration-explanation
content: |
  - The ``spark.mongodb.read.connection.uri`` specifies the
    MongoDB server address (``127.0.0.1``), the database to connect
    (``test``), and the collection (``myCollection``) from which to read
    data, and the read preference.
  - The ``spark.mongodb.write.connection.uri`` specifies the
    MongoDB server address (``127.0.0.1``), the database to connect
    (``test``), and the collection (``myCollection``) to which to write
    data. Connects to port ``27017`` by default.
  - The ``packages`` option specifies the Spark Connector's
    Maven coordinates, in the format ``groupId:artifactId:version``.
---
ref: command-line-start-spark-shell
content: |

  .. include:: /includes/extracts/list-command-line-specification.rst

  For example,

  .. code-block:: sh

     ./bin/spark-shell --conf "spark.mongodb.read.connection.uri=mongodb://127.0.0.1/test.myCollection?readPreference=primaryPreferred" \
                       --conf "spark.mongodb.write.connection.uri=mongodb://127.0.0.1/test.myCollection" \
                       --packages org.mongodb.spark:{+artifact-id-2-12+}:{+current-version+}

  .. include:: /includes/extracts/list-configuration-explanation.rst

---
ref: command-line-start-pyspark
content: |

  .. include:: /includes/extracts/list-command-line-specification.rst

  The following example starts the ``pyspark`` shell from the command
  line:

  .. code-block:: sh

     ./bin/pyspark --conf "spark.mongodb.read.connection.uri=mongodb://127.0.0.1/test.myCollection?readPreference=primaryPreferred" \
                   --conf "spark.mongodb.write.connection.uri=mongodb://127.0.0.1/test.myCollection" \
                   --packages org.mongodb.spark:{+artifact-id-2-12+}:{+current-version+}

  .. include:: /includes/extracts/list-configuration-explanation.rst

  The examples in this tutorial will use this database and collection.
---
ref: command-line-start-sparkR
content: |

  .. include:: /includes/extracts/list-command-line-specification.rst

  For example,

  .. code-block:: sh

     ./bin/sparkR  --conf "spark.mongodb.read.connection.uri=mongodb://127.0.0.1/test.myCollection?readPreference=primaryPreferred" \
                   --conf "spark.mongodb.write.connection.uri=mongodb://127.0.0.1/test.myCollection" \
                   --packages org.mongodb.spark:{+artifact-id-2-12+}:{+current-version+}

  .. include:: /includes/extracts/list-configuration-explanation.rst
