==============
Backup Process
==============

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

|mms| backups, once started, are an ongoing and continuous process.
Data is continually backed up as long as the backup remains
synchronized with the database. This process works like 
:manual:`replica set data synchronization </core/replica-set-sync>`

The backup process:

1. Performs an :term:`initial sync` to back up all of your existing data in
   its current state. In sharded clusters, this occurs on each shard and on
   the config servers.

2. Takes snapshots of the ``data`` directory in a deployment as often
   as your
   :ref:`snapshot schedule <snapshot-frequency-and-retention>`
   specifies and then transfers the snapshots to a storage system.

   Sharded Clusters also can :ref:`enable checkpoints 
   <enable-cluster-checkpoints>` to permit restores at moments between 
   snapshots. To learn how sharded clusters use checkpoints, see 
   :ref:`checkpoints <checkpoint>`.

3. Monitors the :term:`oplog` constantly and adds new database
   operations to the latest backup to keep the local |onprem| copy of
   the data current.

The backup process works in this manner regardless of how snapshots are
stored.

.. _backup-stages:

Backup Definition and Operational States
----------------------------------------

Each backup is defined as a :term:`job <backup job>`. Each job defines
how much and how often data is backed up. Backup jobs are defined on a
per-project basis.

Operational States
~~~~~~~~~~~~~~~~~~

The following table lists the states of a backup job:

.. list-table::
   :widths: 20 27 27 26
   :header-rows: 1

   * - State
     - Retain Old Snapshots
     - Create New Snapshots
     - Apply Oplogs
  
   * - ``Active``
     - Yes
     - Yes
     - Yes

   * - ``Stopped`` 
     - Yes
     - No
     - No

   * - ``Inactive``
     - No
     - No
     - No

Change Operational States
~~~~~~~~~~~~~~~~~~~~~~~~~

Once backup jobs are active for a :term:`project`, they run without
further intervention until they are stopped or terminated. The operator
can change the state of a backup in the following ways:

.. list-table::
   :widths: 20 40 40
   :header-rows: 1

   * - Initial State

     - Desired State

     - Method

   * - ``Inactive``

     - :guilabel:`Active` after ``Initial Sync``

     - Click :guilabel:`Start`.

   * - ``Active``

     - :guilabel:`Stopped`

     - Click :guilabel:`Stop`.

   * - ``Stopped``

     - :guilabel:`Active` after ``Initial Sync``

     - Click :guilabel:`Restart`.

   * - ``Stopped``

     - :guilabel:`Inactive`

     - Click :guilabel:`Terminate`.
      
       .. warning::
          :guilabel:`Terminate` deletes all retained backups.

.. important::
   You may receive a :alert:`Backup requires a resync` alert
   for your backup jobs. This may require you to :doc:`/tutorial/resync-backup`. 
   This is not a different state, but a triggering of
   a new :ref:`backup-initial-sync`. The backup job, once ``Initial
   Sync`` completes, becomes :guilabel:`Active` again.

.. _backup-initial-sync:

Backup Process Flows
--------------------

Initial Backup
~~~~~~~~~~~~~~

Once created, a backup job goes through the following process flow:

.. include:: /images/backup-flow.rst

#. The :term:`Backup Agent` connects to, and authenticates with, the databases
   associated with the backup job.

#. The :term:`initial sync` begins and enters its ``starting`` phase.
   Initial sync is a transition state between :guilabel:`Inactive` and
   :guilabel:`Active`. Initial Sync goes through a series of phases 
   that are displayed on the :guilabel:`Backup` page to show progress.
   The Backup Agent streams the existing data to |onprem| in 10 MB compressed
   bundles of documents called slices. The Backup Agent creates slices at the
   point in time when the backup was created. Data inserted to the instance
   after that point in time is captured separately.

#. The ``transferring`` phase begins as the slices are streamed and stored in
   the :term:`Oplog Store <Oplog Store Database>` temporarily on the Backup
   Daemon's behalf. The Backup Daemon service cannot dedicate itself to
   processing the large stream of initial sync slices at the expense of
   processing other backup jobs. The Oplog Store stores the slices until the
   Backup Daemon can fetch them. The Oplog Store is created when the first
   :term:`Snapshot Store` is created.

#. While the Backup Agent is streaming the data, it tails the :term:`oplog`.
   This tailing collects any differences between the state of the deployment
   database when the backup began and the deployment database's current state.
   The oplog entries are sent in 10 MB compressed bundles of documents called
   :term:`oplog slices <oplog slice>`. These two streams of slices are
   collected in parallel to reduce the time needed to construct a complete
   backup.
   
#. The ``building`` phase begins once |onprem| has received all of the slices.
   In this phase, |onprem| creates a local version of the backed up database
   called a :term:`head database` on the host running the Backup Daemon
   service.

#. |onprem|, through the Backup Daemon service, inserts the documents stored
   in the Oplog Store into the head database.

#. The ``applying oplogs`` phase begins as |onprem| applies the 
   tailed oplog entries into the head database.

#. During the ``fetching missing documents`` phase, |onprem| queries
   the deployment database for documents missed during document insertion.
   |onprem| inserts the missing documents found in the deployment
   database into the head database.

#. After inserting the missing documents, the ``creating indexes`` phase
   begins as |onprem| creates all of the indexes found in the deployment
   databases in the head database. When the indexes finish, the initial sync
   ends and the phase changes to ``complete``.

#. Depending upon which snapshot store you chose to store your backup,
   a snapshot can be written out:

   a. As blocks to a :term:`blockstore <Backup Blockstore Database>`.
   #. As blocks to an :term:`AWS S3 bucket <S3 Snapshot Store>`. The metadata
      for those blocks is written to a MongoDB database on the |onprem| host.
   #. As snapshot files to a :term:`file system store <File System Store>`.

.. note::
   The characteristics of each storage method is covered in 
   :ref:`backup-configuration-options`.

Subsequent Backups
~~~~~~~~~~~~~~~~~~

The head database works as a full copy of the deployment database. It
needs oplogs applied to it on a regular basis to keep its data
synchronized with the deployment database. Snapshots are generated from
the data stored in the head database according to your 
:ref:`snapshot schedule <snapshot-frequency-and-retention>`.

Once the first full backup is completed, each active backup job follows
this process:

1. The Backup Agent tails the deployment's oplog.
2. The Backup Agent routinely batches new oplog entries in :term:`oplog
   slices <oplog slice>` and transfers them to |onprem|.
3. |onprem| stores the oplog entries in the Oplog Store.
4. |onprem| applies the new oplog entries from the oplog slices to the
   head database that stores the deployment backup.
5. |onprem| creates a new snapshot and stores it in the snapshot store
   as specified in your :ref:`snapshot schedule <snapshot-frequency-and-retention>`.
