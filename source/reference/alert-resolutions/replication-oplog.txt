.. _replication-oplog-alerts:

========================
Replication Oplog Alerts
========================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Replication Oplog alerts can be triggered when the amount of
:term:`oplog` data generated on a :term:`primary` cluster member is
larger than the cluster's configured oplog size.

Description
-----------

:alert:`Replication Oplog Window is (X)
<Replication Oplog Window is>` occurs if the approximate amount of
time available in the primary replication oplog meets or goes below
the specified threshold. This refers to the amount of time that the
primary can continue logging given the current rate at which oplog
data is generated.

:alert:`Oplog Data Per Hour is (X) <Oplog Data Per Hour is>` occurs
if the amount of data per hour being written to a primary's
replication oplog meets or exceeds the specified threshold.

Possible Observations
---------------------

These are a few common observations seen when these alerts are
triggered:

- The :guilabel:`Oplog GB / Hour` graph in the
  :doc:`metrics view </monitor-cluster-metrics/>` spikes upward.

- The :guilabel:`Replication Oplog Window` graph in the
  :doc:`metrics view </monitor-cluster-metrics/>` is low.

- The |service| :ref:`mongodb-logs` of :term:`secondary` or
  unhealthy nodes display the following message:

  .. code-block:: none
     :copyable: false

     We are too stale to use <node>:27017 as a sync source.

- An |service| node is reporting a state of :manual:`STARTUP2
  </reference/replica-states/index.html#replstate.STARTUP2>` and
  :manual:`RECOVERING </reference/replica-states/index.html#replstate.RECOVERING>`
  for an extended period of time.

  Typically, this indicates that the node has "fallen off the oplog"
  and is unable to keep up with the oplog data being generated by
  the primary node. In this case, the node will require an
  :ref:`initial sync <replica-set-initial-sync>` in order to recover
  and ensure that the data is consistent across all nodes. 
  You can check the state of a node using the :method:`rs.status()
  <rs.status>` shell method.

Common Triggers
---------------

These are a few common events which may lead to increased oplog
activity:

- Intensive write and update operations in a short period of time.

- The cluster's :ref:`configured oplog size
  <scale-cluster-more-configuration-options>` is smaller than the
  value in the :guilabel:`Oplog GB / Hour` graph observed in the
  cluster :doc:`metrics view </monitor-cluster-metrics/>`.

Possible Solutions
------------------

These are a few possible actions to consider to help resolve
Replication Oplog Alerts:

- Increase the oplog size by
  :ref:`editing your cluster's configuration
  <scale-cluster-more-configuration-options>` to ensure it is higher
  than the *peak* value from the :guilabel:`Oplog GB / Hour` graph
  in the cluster :doc:`metrics view </monitor-cluster-metrics/>`.

- Increase the oplog size if you foresee intense write and update
  operations occurring in a short time period.

  .. note::

     You may need to :doc:`increase your cluster's storage
     </scale-cluster>` to free enough space to resize the oplog.

- Ensure that all write operations specify a
  :manual:`write concern </reference/write-concern/>` of
  ``majority`` to ensure that writes are replicated to at least one
  node before moving on to the next write operation. This controls
  the rate of traffic from your application by preventing the
  primary from accepting writes more quickly than the secondaries can
  handle.

Refer to the following for more information on understanding ``oplog``
sizing requirements:

- :manual:`Workloads that Might Require a Larger Oplog Size
  </core/replica-set-oplog/#workloads-that-might-require-a-larger-oplog-size>`

- `How Large Should the Oplog Be?
  <https://support.mongodb.com/article/000018970>`__
