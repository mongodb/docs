title: Disable the Balancer.
level: 4
ref: 4.4-upgrade-disable-balancer
content: |

   Connect a ``mongo`` shell to a :binary:`~bin.mongos` instance in
   the sharded cluster, and run :method:`sh.stopBalancer()` to
   disable the balancer:

   .. code-block:: javascript

      sh.stopBalancer()

   .. note::

      If a migration is in progress, the system will complete the
      in-progress migration before stopping the balancer. You can run
      :method:`sh.isBalancerRunning()` to check the balancer's current
      state.

   To verify that the balancer is disabled, run
   :method:`sh.getBalancerState()`, which returns false if the balancer
   is disabled:

   .. code-block:: javascript

      sh.getBalancerState()

   For more information on disabling the balancer, see
   :ref:`sharding-balancing-disable-temporarily`.

---
title: "Upgrade the config servers."
level: 4
ref: 4.4-upgrade-config-servers
content: |-
   1. Upgrade the :ref:`secondary <replica-set-secondary-members>`
      members of the replica set one at a time:

      a. Shut down the secondary :binary:`~bin.mongod` instance and replace
         the |oldversion| binary with the |newversion| binary.

      #. Start the |newversion| binary with the :option:`--configsvr <mongod --configsvr>`,
         :option:`--replSet <mongod --replSet>`, and :option:`--port <mongod --port>`. 
         Include any other options as used by the deployment.

         .. code-block:: bash

            mongod --configsvr --replSet <replSetName> --port <port> --dbpath <path> --bind_ip localhost,<ip address>

         If using a :doc:`configuration file
         </reference/configuration-options>`, update the file to
         specify :setting:`sharding.clusterRole: configsvr
         <sharding.clusterRole>`, :setting:`replication.replSetName`,
         :setting:`net.port`, and :setting:`net.bindIp`,
         then start the |newversion| binary:
         
         .. code-block:: yaml

            sharding:
               clusterRole: configsvr
            replication:
               replSetName: <string>
            net:
               port: <port>
               bindIp: localhost,<ip address>
            storage:
               dbpath: <path>

         Include any other settings as appropriate for your deployment.

      #. Wait for the member to recover to ``SECONDARY`` state before
         upgrading the next secondary member. To check the member's state,
         issue :method:`rs.status()` in the ``mongo`` shell.

         Repeat for each secondary member.

   #. Step down the replica set primary.

      a. Connect a ``mongo`` shell to the primary and use
         :method:`rs.stepDown()` to step down the primary and force an
         election of a new primary:

         
         .. code-block:: javascript

            rs.stepDown()

      #. When :method:`rs.status()` shows that the primary has stepped
         down and another member has assumed ``PRIMARY`` state, shut down
         the stepped-down primary and replace the :binary:`~bin.mongod` binary
         with the |newversion| binary.

      #. Start the |newversion| binary with the :option:`--configsvr
         <mongod --configsvr>`, :option:`--replSet <mongod --replSet>`,
         :option:`--port <mongod --port>`, and :option:`--bind_ip
         <mongod --bind_ip>` options. Include any optional command line
         options used by the previous deployment:

         .. code-block:: bash

            mongod --configsvr --replSet <replSetName> --port <port> --dbpath <path> --bind_ip localhost,<ip address>

         If using a :doc:`configuration file
         </reference/configuration-options>`, update the file to
         specify :setting:`sharding.clusterRole: configsvr
         <sharding.clusterRole>`, :setting:`replication.replSetName`,
         :setting:`net.port`, and :setting:`net.bindIp`,
         then start the |newversion| binary:

         
         .. code-block:: yaml

            sharding:
               clusterRole: configsvr
            replication:
               replSetName: <string>
            net:
               port: <port>
               bindIp: localhost,<ip address>
            storage:
               dbpath: <path>

         Include any other configuration as appropriate for your deployment.

---
title: Upgrade the shards.
level: 4
ref: 4.4-upgrade-shards
content: |-
   Upgrade the shards one at a time.

   For each shard replica set:

   1. Upgrade the :ref:`secondary <replica-set-secondary-members>`
      members of the replica set one at a time:

      a. Shut down the :binary:`~bin.mongod` instance and replace the |oldversion|
         binary with the |newversion| binary.

      #. Start the |newversion| binary with the :option:`--shardsvr
         <mongod --shardsvr>`, :option:`--replSet <mongod --replSet>`,
         :option:`--port <mongod --port>`, and :option:`--bind_ip
         <mongod --bind_ip>` options. Include any additional command line
         options as appropriate for your deployment:

         .. code-block:: bash

            mongod --shardsvr --replSet <replSetName> --port <port> --dbpath <path> --bind_ip localhost,<ip address>


         If using a :doc:`configuration file
         </reference/configuration-options>`, update the file to
         include :setting:`sharding.clusterRole: shardsvr <sharding.clusterRole>`,
         :setting:`replication.replSetName`, :setting:`net.port`, and
         :setting:`net.bindIp`, then start the |newversion| binary:

         
         .. code-block:: yaml

            sharding:
               clusterRole: shardsvr
            replication:
               replSetName: <string>
            net:
               port: <port>
               bindIp: localhost,<ip address>
            storage:
               dbpath: <path>

         Include any other configuration as appropriate for your deployment.

      #. Wait for the member to recover to ``SECONDARY`` state before
         upgrading the next secondary member. To check the member's
         state, you can issue :method:`rs.status()` in the
         ``mongo`` shell.

         Repeat for each secondary member.

   #. Step down the replica set primary.

      Connect a ``mongo`` shell to the primary and use
      :method:`rs.stepDown()` to step down the primary and force an
      election of a new primary:

      .. code-block:: javascript

         rs.stepDown()

   #. When :method:`rs.status()`
      shows that the primary has stepped down and another member
      has assumed ``PRIMARY`` state, upgrade the stepped-down primary: 

      1. Shut down the stepped-down primary and replace the
         :binary:`~bin.mongod` binary with the |newversion| binary.

      #. Start the |newversion| binary with the :option:`--shardsvr
         <mongod --shardsvr>`, :option:`--replSet <mongod --replSet>`,
         :option:`--port <mongod --port>`, and :option:`--bind_ip
         <mongod --bind_ip>` options. Include any additional command line
         options as appropriate for your deployment:

         
         .. code-block:: bash

            mongod --shardsvr --replSet <replSetName> --port <port> --dbpath <path> --bind_ip localhost,<ip address>

         If using a :doc:`configuration file
         </reference/configuration-options>`, update the file to
         specify :setting:`sharding.clusterRole: shardsvr
         <sharding.clusterRole>`, :setting:`replication.replSetName`,
         :setting:`net.port`, and :setting:`net.bindIp`, then start the
         |newversion| binary:

         
         .. code-block:: yaml

            sharding:
               clusterRole: shardsvr
            replication:
               replSetName: <string>
            net:
               port: <port>
               bindIp: localhost,<ip address>
            storage:
               dbpath: <path>

         Include any other configuration as appropriate for your deployment.

---
title: "Upgrade the ``mongos`` instances."
level: 4
ref: 4.4-upgrade-mongos-instances
content: |-
   Replace each :binary:`~bin.mongos` instance with the |newversion| binary
   and restart. Include any other configuration as appropriate for your
   deployment.

   .. include:: /includes/fact-bind-ip-sharded-clusters.rst

   
   .. code-block:: bash

      mongos --configdb csReplSet/<rsconfigsver1:port1>,<rsconfigsver2:port2>,<rsconfigsver3:port3> --bind_ip localhost,<ip address>

---
title: "Re-enable the balancer."
level: 4
ref: 4.4-upgrade-reenable-balancer
content: |-

   Using a |newversion| ``mongo`` shell, connect to a
   :binary:`~bin.mongos` in the cluster and run
   :method:`sh.startBalancer()` to re-enable the balancer: 

   .. code-block:: javascript
   
      sh.startBalancer()

   .. include:: /includes/extracts/4.2-changes-start-balancer-autosplit.rst
   
   If you do not wish to enable auto-splitting while the balancer is
   enabled, you must also run :method:`sh.disableAutoSplit()`.
   
   For more information about re-enabling the balancer, see
   :ref:`sharding-balancing-enable`.
---
title: "Enable backwards-incompatible |newversion| features."
level: 5
ref: 4.4-upgrade-enable-features-mongos
content: |

   .. include:: /includes/upgrade-enable-features.rst


   .. tip::

      .. include:: /includes/featureCompatibility-caveat.rst


   On a :binary:`~bin.mongos` instance, run the
   :dbcommand:`setFeatureCompatibilityVersion` command in the ``admin``
   database:
   
   .. code-block:: javascript

      db.adminCommand( { setFeatureCompatibilityVersion: "4.4" } )

   Setting :ref:`featureCompatibilityVersion (FCV) : "4.4" <set-fcv>`
   implicitly performs a :dbcommand:`replSetReconfig` on each shard to
   add the :rsconf:`term` field to the shard replica configuration
   document.

   .. include:: /includes/FCV-propagation.rst

   This command must perform writes to an internal system collection.
   If for any reason the command does not complete successfully, you
   can safely retry the command on the :binary:`~bin.mongos` as the
   operation is idempotent.

   .. note::

      While :dbcommand:`setFeatureCompatibilityVersion` is running on
      the sharded cluster, chunk migrations, splits, and merges
      can fail with ``ConflictingOperationInProgress``.

   Any :term:`orphaned documents <orphaned document>` that exist on your
   shards will be cleaned up when you set the
   :dbcommand:`setFeatureCompatibilityVersion` to |newversion|. The
   cleanup process:

   - Does not block the upgrade from completing, and
   - Is rate limited. To mitigate the potential effect on performance
     during orphaned document cleanup, see
     :ref:`range-deletion-performance-tuning`.

   .. note:: Additional Consideration

      .. include:: /includes/fact-mongos-fcv.rst


...
