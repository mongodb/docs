.. _source-usage-example-copy-existing-data:

==================
Copy Existing Data
==================

.. facet::
   :name: genre
   :values: reference

.. meta:: 
   :keywords: code example, copy, filter, configuration setting
   :description: Copy data from a MongoDB collection to an Apache Kafka topic using the Kafka source connector, with options to filter specific documents.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

These usage examples demonstrate how to copy data from MongoDB to an
{+kafka+} topic using the {+source-connector+}.

Examples
--------

The following examples show how to configure your source connector to
copy existing data from a single collection or from multiple collections.

Copy and Filter Collection Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Suppose you want to copy a MongoDB collection to {+kafka+} and filter some data.

Your requirements and your solutions are as follows:

.. list-table::
   :header-rows: 1
   :widths: 50 50

   * - Requirement
     - Solution

   * - Copy the ``customers`` collection of the ``shopping`` database in your 
       MongoDB deployment onto an {+kafka+} topic.
     - | See the :ref:`<source-usage-example-copy-existing-data-copy-data>` section of this guide.

   * - Only copy documents that have the value "Mexico" in the ``country`` field.
     - | See the :ref:`<source-usage-example-copy-existing-data-mask-data>` section of this guide.

The ``customers`` collection contains the following documents:

.. _usage-example-copy-sample-document:

.. code-block:: json
   :copyable: false

   {
     "_id": 1,
     "country": "Mexico",
     "purchases": 2,
     "last_viewed": { "$date": "2021-10-31T20:30:00.245Z" }
   }
   {
     "_id": 2,
     "country": "Iceland",
     "purchases": 8,
     "last_viewed": { "$date": "2015-07-20T10:00:00.135Z" }
   }

.. _source-usage-example-copy-existing-data-copy-data:

Copy Data
`````````

Copy the contents of the ``customers`` collection of the ``shopping`` database by 
specifying the following configuration options in your source connector:

.. code-block:: properties

   database=shopping
   collection=customers
   startup.mode=copy_existing

Your source connector copies your collection by creating change event documents
that describe inserting each document into your collection. 

.. note:: Data Copy Can Produce Duplicate Events

   .. include:: /includes/copy-existing-admonition.rst

To learn more about change event documents, see the
:ref:`Change Streams <source-connector-fundamentals-change-event>` guide.

To learn more about the ``startup.mode`` option, see
:ref:`<source-configuration-startup>`.

.. _source-usage-example-copy-existing-data-mask-data:

Filter Data
```````````

You can filter data by specifying an aggregation pipeline in the 
``startup.mode.copy.existing.pipeline`` option of your source connector configuration. The
following configuration specifies an aggregation pipeline that matches all
documents with "Mexico" in the ``country`` field:

.. code-block:: properties

   startup.mode.copy.existing.pipeline=[{ "$match": { "country": "Mexico" } }]

To learn more about  the ``startup.mode.copy.existing.pipeline`` option, see
:ref:`<source-configuration-startup>`.

To learn more about aggregation pipelines, see the following resources:

- :ref:`<source-usage-example-custom-pipeline>` Usage Example
- :manual:`Aggregation </aggregation>` in the MongoDB manual.

.. _source-usage-example-copy-existing-data-config:

Specify the Configuration
`````````````````````````

Your final source connector configuration to copy the ``customers`` collection should
look like this:

.. literalinclude:: /includes/usage-examples/copy/source.properties
    :language: properties
    :emphasize-lines: 5,6

Once your connector copies your data, you see the following change event
document corresponding to the 
:ref:`preceding sample collection <usage-example-copy-sample-document>`
in the ``shopping.customers`` {+kafka+} topic:

.. literalinclude:: /includes/usage-examples/copy/payload.json
    :language: json
    :copyable: false

.. note:: Write the Data in your Topic into a Collection

   Use a change data capture handler to convert change event documents in an
   {+kafka+} topic into MongoDB write operations. To learn more, see the
   :ref:`Change Data Capture Handlers <sink-fundamentals-cdc-handler>` guide.

Copy Data From Multiple Sources
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Suppose you want to copy data from another collection in the ``shopping``
database named ``products``, which contains the following document:

.. code-block:: json
   :copyable: false

   {
     "_id": 1,
     "item_name": "lipstick",
     "department": "cosmetics",
     "quantity": 45
   }

You can copy from both the ``customers`` and ``products`` collections
by using the ``startup.mode.copy.existing.namespace.regex`` configuration
setting, as shown in the following code:

.. literalinclude:: /includes/usage-examples/copy/multisource.properties
    :language: properties
    :emphasize-lines: 5

In addition to the change event document in the ``shopping.customers`` {+kafka+} topic,
described in the :ref:`preceding section <source-usage-example-copy-existing-data-config>`,
you can see the following document in the ``shopping.products`` topic:

.. literalinclude:: /includes/usage-examples/copy/multisource.json
    :language: json
    :copyable: false

.. tip::

   To learn more about the ``startup.mode.copy.existing.namespace.regex`` setting,
   see the :ref:`Settings table <source-configuration-startup-table-start>` in
   the Startup Properties guide.