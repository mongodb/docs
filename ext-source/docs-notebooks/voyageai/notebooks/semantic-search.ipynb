{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search with Voyage AI Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [Semantic Search with Voyage AI](https://www.mongodb.com/docs/voyageai/tutorials/semantic-search/) tutorial. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "This guide describes how to perform semantic search with Voyage AI models. This page includes examples for basic and advanced semantic search use cases, including search with reranking, as well as multilingual, multimodal, contextualized chunk, and large corpus retrieval.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/voyageai/notebooks/semantic-search.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Your Environment\n",
    "\n",
    "Before you begin, install libraries and set your model API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  --upgrade voyageai numpy datasets pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your model API key\n",
    "os.environ[\"VOYAGE_API_KEY\"] = \"<your-model-api-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Semantic Search\n",
    "\n",
    "Find similar documents using simple vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Voyage AI client\n",
    "vo = voyageai.Client()\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The Mediterranean diet emphasizes fish, olive oil, and vegetables, believed to reduce chronic diseases.\",\n",
    "    \"Photosynthesis in plants converts light energy into glucose and produces essential oxygen.\",\n",
    "    \"20th-century innovations, from radios to smartphones, centered on electronic advancements.\",\n",
    "    \"Rivers provide water, irrigation, and habitat for aquatic species, vital for ecosystems.\",\n",
    "    \"Apple's conference call to discuss fourth fiscal quarter results and business updates is scheduled for Thursday, November 2, 2023 at 2:00 p.m. PT / 5:00 p.m. ET.\",\n",
    "    \"Shakespeare's works, like 'Hamlet' and 'A Midsummer Night's Dream,' endure in literature.\"\n",
    "]\n",
    "\n",
    "# Search query\n",
    "query = \"When is Apple's conference call scheduled?\"\n",
    "\n",
    "# Generate embeddings for documents\n",
    "doc_embeddings = vo.embed(\n",
    "    texts=documents,\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"document\"\n",
    ").embeddings\n",
    "\n",
    "# Generate embedding for query\n",
    "query_embedding = vo.embed(\n",
    "    texts=[query],\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"query\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "similarities = np.dot(doc_embeddings, query_embedding)\n",
    "\n",
    "# Sort documents by similarity (highest to lowest)\n",
    "ranked_indices = np.argsort(-similarities)\n",
    "\n",
    "# Display results\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "for rank, idx in enumerate(ranked_indices, 1):\n",
    "    print(f\"{rank}. {documents[idx]}\")\n",
    "    print(f\"   Similarity: {similarities[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search with Reranker\n",
    "\n",
    "Improve search accuracy with reranking models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Voyage AI client\n",
    "vo = voyageai.Client()\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The Mediterranean diet emphasizes fish, olive oil, and vegetables, believed to reduce chronic diseases.\",\n",
    "    \"Photosynthesis in plants converts light energy into glucose and produces essential oxygen.\",\n",
    "    \"20th-century innovations, from radios to smartphones, centered on electronic advancements.\",\n",
    "    \"Rivers provide water, irrigation, and habitat for aquatic species, vital for ecosystems.\",\n",
    "    \"Apple's conference call to discuss fourth fiscal quarter results and business updates is scheduled for Thursday, November 2, 2023 at 2:00 p.m. PT / 5:00 p.m. ET.\",\n",
    "    \"Shakespeare's works, like 'Hamlet' and 'A Midsummer Night's Dream,' endure in literature.\"\n",
    "]\n",
    "\n",
    "# Search query\n",
    "query = \"When is Apple's conference call scheduled?\"\n",
    "\n",
    "# Generate embeddings for documents\n",
    "doc_embeddings = vo.embed(\n",
    "    texts=documents,\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"document\"\n",
    ").embeddings\n",
    "\n",
    "# Generate embedding for query\n",
    "query_embedding = vo.embed(\n",
    "    texts=[query],\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"query\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "similarities = np.dot(doc_embeddings, query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "ranked_indices = np.argsort(-similarities)\n",
    "\n",
    "# Display results before reranking\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Before reranker (embedding similarity only):\")\n",
    "for rank, idx in enumerate(ranked_indices[:3], 1):\n",
    "    print(f\"{rank}. {documents[idx]}\")\n",
    "    print(f\"   Similarity Score: {similarities[idx]:.4f}\\n\")\n",
    "\n",
    "# Rerank documents for improved accuracy\n",
    "rerank_results = vo.rerank(\n",
    "    query=query,\n",
    "    documents=documents,\n",
    "    model=\"rerank-2.5\"\n",
    ")\n",
    "\n",
    "# Display results after reranking\n",
    "print(\"\\nAfter reranker:\")\n",
    "for rank, result in enumerate(rerank_results.results[:3], 1):\n",
    "    print(f\"{rank}. {documents[result.index]}\")\n",
    "    print(f\"   Relevance Score: {result.relevance_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual Semantic Search\n",
    "\n",
    "Search across documents in different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Voyage AI client\n",
    "vo = voyageai.Client()\n",
    "\n",
    "# English documents about technology companies\n",
    "english_docs = [\n",
    "    \"Apple announced record-breaking revenue in its latest quarterly earnings report.\",\n",
    "    \"The Mediterranean diet emphasizes fish, olive oil, and vegetables.\",\n",
    "    \"Microsoft is investing heavily in artificial intelligence and cloud computing.\",\n",
    "    \"Shakespeare's plays continue to influence modern literature and theater.\"\n",
    "]\n",
    "\n",
    "# Spanish documents about technology companies\n",
    "spanish_docs = [\n",
    "    \"Apple anunció ingresos récord en su último informe trimestral de ganancias.\",\n",
    "    \"La dieta mediterránea enfatiza el pescado, el aceite de oliva y las verduras.\",\n",
    "    \"Microsoft está invirtiendo fuertemente en inteligencia artificial y computación en la nube.\",\n",
    "    \"Las obras de Shakespeare continúan influenciando la literatura y el teatro modernos.\"\n",
    "]\n",
    "\n",
    "# Chinese documents about technology companies\n",
    "chinese_docs = [\n",
    "    \"苹果公司在最新季度财报中宣布创纪录的收入。\",\n",
    "    \"地中海饮食强调鱼类、橄榄油和蔬菜。\",\n",
    "    \"微软正在大力投资人工智能和云计算。\",\n",
    "    \"莎士比亚的作品继续影响现代文学和戏剧。\"\n",
    "]\n",
    "\n",
    "# Perform semantic search in English\n",
    "english_query = \"tech company earnings\"\n",
    "\n",
    "# Generate embeddings for English documents\n",
    "english_embeddings = vo.embed(\n",
    "    texts=english_docs,\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"document\"\n",
    ").embeddings\n",
    "\n",
    "# Generate embedding for English query\n",
    "english_query_embedding = vo.embed(\n",
    "    texts=[english_query],\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"query\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "english_similarities = np.dot(english_embeddings, english_query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "english_ranked = np.argsort(-english_similarities)\n",
    "\n",
    "print(f\"English Query: '{english_query}'\\n\")\n",
    "for rank, idx in enumerate(english_ranked[:2], 1):\n",
    "    print(f\"{rank}. {english_docs[idx]}\")\n",
    "    print(f\"   Similarity: {english_similarities[idx]:.4f}\\n\")\n",
    "\n",
    "# Perform semantic search in Spanish\n",
    "spanish_query = \"ganancias de empresas tecnológicas\"\n",
    "\n",
    "# Generate embeddings for Spanish documents\n",
    "spanish_embeddings = vo.embed(\n",
    "    texts=spanish_docs,\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"document\"\n",
    ").embeddings\n",
    "\n",
    "# Generate embedding for Spanish query\n",
    "spanish_query_embedding = vo.embed(\n",
    "    texts=[spanish_query],\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"query\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "spanish_similarities = np.dot(spanish_embeddings, spanish_query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "spanish_ranked = np.argsort(-spanish_similarities)\n",
    "\n",
    "print(f\"Spanish Query: '{spanish_query}'\\n\")\n",
    "for rank, idx in enumerate(spanish_ranked[:2], 1):\n",
    "    print(f\"{rank}. {spanish_docs[idx]}\")\n",
    "    print(f\"   Similarity: {spanish_similarities[idx]:.4f}\\n\")\n",
    "\n",
    "# Perform semantic search in Chinese\n",
    "chinese_query = \"科技公司收益\"\n",
    "\n",
    "# Generate embeddings for Chinese documents\n",
    "chinese_embeddings = vo.embed(\n",
    "    texts=chinese_docs,\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"document\"\n",
    ").embeddings\n",
    "\n",
    "# Generate embedding for Chinese query\n",
    "chinese_query_embedding = vo.embed(\n",
    "    texts=[chinese_query],\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"query\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "chinese_similarities = np.dot(chinese_embeddings, chinese_query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "chinese_ranked = np.argsort(-chinese_similarities)\n",
    "\n",
    "print(f\"Chinese Query: '{chinese_query}'\\n\")\n",
    "for rank, idx in enumerate(chinese_ranked[:2], 1):\n",
    "    print(f\"{rank}. {chinese_docs[idx]}\")\n",
    "    print(f\"   Similarity: {chinese_similarities[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Semantic Search\n",
    "\n",
    "Search text and image data.\n",
    "\n",
    "> **Note:** Search for sample images and save them in your project directory. The following code example assumes you have images of a cat, dog, and banana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize Voyage AI client\n",
    "vo = voyageai.Client()\n",
    "\n",
    "# Prepare interleaved text + image inputs\n",
    "interleaved_inputs = [\n",
    "    [\"An orange cat\", Image.open('cat.jpg')],\n",
    "    [\"A golden retriever\", Image.open('dog.jpg')],\n",
    "    [\"A banana\", Image.open('banana.jpg')],\n",
    "]\n",
    "\n",
    "# Prepare image-only inputs\n",
    "image_only_inputs = [\n",
    "    [Image.open('cat.jpg')],\n",
    "    [Image.open('dog.jpg')],\n",
    "    [Image.open('banana.jpg')],\n",
    "]\n",
    "\n",
    "# Labels for display\n",
    "labels = [\"cat.jpg\", \"dog.jpg\", \"banana.jpg\"]\n",
    "\n",
    "# Search query\n",
    "query = \"a cute pet\"\n",
    "\n",
    "# Generate embeddings for interleaved text + image inputs\n",
    "interleaved_embeddings = vo.multimodal_embed(\n",
    "    inputs=interleaved_inputs,\n",
    "    model=\"voyage-multimodal-3.5\"\n",
    ").embeddings\n",
    "\n",
    "# Generate embedding for query\n",
    "query_embedding = vo.multimodal_embed(\n",
    "    inputs=[[query]],\n",
    "    model=\"voyage-multimodal-3.5\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "interleaved_similarities = np.dot(interleaved_embeddings, query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "interleaved_ranked = np.argsort(-interleaved_similarities)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Search with interleaved text + image:\")\n",
    "for rank, idx in enumerate(interleaved_ranked, 1):\n",
    "    print(f\"{rank}. {interleaved_inputs[idx][0]}\")\n",
    "    print(f\"   Similarity: {interleaved_similarities[idx]:.4f}\\n\")\n",
    "\n",
    "# Generate embeddings for image-only inputs\n",
    "image_only_embeddings = vo.multimodal_embed(\n",
    "    inputs=image_only_inputs,\n",
    "    model=\"voyage-multimodal-3.5\"\n",
    ").embeddings\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "image_only_similarities = np.dot(image_only_embeddings, query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "image_only_ranked = np.argsort(-image_only_similarities)\n",
    "\n",
    "print(\"\\nSearch with image-only:\")\n",
    "for rank, idx in enumerate(image_only_ranked, 1):\n",
    "    print(f\"{rank}. {labels[idx]}\")\n",
    "    print(f\"   Similarity: {image_only_similarities[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with Contextualized Chunk Embeddings\n",
    "\n",
    "Generate embeddings with additional context for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Voyage AI client\n",
    "vo = voyageai.Client()\n",
    "\n",
    "# Sample documents (each document is a list of chunks that share context)\n",
    "documents = [\n",
    "    [\n",
    "        \"This is the SEC filing on Greenery Corp.'s Q2 2024 performance.\",\n",
    "        \"The company's revenue increased by 7% compared to the previous quarter.\"\n",
    "    ],\n",
    "    [\n",
    "        \"This is the SEC filing on Leafy Inc.'s Q2 2024 performance.\",\n",
    "        \"The company's revenue increased by 15% compared to the previous quarter.\"\n",
    "    ],\n",
    "    [\n",
    "        \"This is the SEC filing on Elephant Ltd.'s Q2 2024 performance.\",\n",
    "        \"The company's revenue decreased by 2% compared to the previous quarter.\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Search query\n",
    "query = \"What was the revenue growth for Leafy Inc. in Q2 2024?\"\n",
    "\n",
    "# Generate contextualized embeddings (preserves relationships between chunks)\n",
    "contextualized_result = vo.contextualized_embed(\n",
    "    inputs=documents,\n",
    "    model=\"voyage-context-3\",\n",
    "    input_type=\"document\"\n",
    ")\n",
    "\n",
    "# Flatten the embeddings and chunks for semantic search\n",
    "contextualized_embeddings = []\n",
    "all_chunks = []\n",
    "chunk_to_doc = []  # Maps chunk index to document index\n",
    "\n",
    "for doc_idx, result in enumerate(contextualized_result.results):\n",
    "    for emb, chunk in zip(result.embeddings, documents[doc_idx]):\n",
    "        contextualized_embeddings.append(emb)\n",
    "        all_chunks.append(chunk)\n",
    "        chunk_to_doc.append(doc_idx)\n",
    "\n",
    "# Generate contextualized query embedding\n",
    "query_embedding_ctx = vo.contextualized_embed(\n",
    "    inputs=[[query]],\n",
    "    model=\"voyage-context-3\",\n",
    "    input_type=\"query\"\n",
    ").results[0].embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "similarities_ctx = np.dot(contextualized_embeddings, query_embedding_ctx)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "ranked_indices_ctx = np.argsort(-similarities_ctx)\n",
    "\n",
    "# Display top 3 results\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "for rank, idx in enumerate(ranked_indices_ctx[:3], 1):\n",
    "    doc_idx = chunk_to_doc[idx]\n",
    "    print(f\"{rank}. {all_chunks[idx]}\")\n",
    "    print(f\"   (From document: {documents[doc_idx][0]})\")\n",
    "    print(f\"   Similarity: {similarities_ctx[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search with Large Corpus\n",
    "\n",
    "This example demonstrates semantic search using the [MTEB LegalBench Consumer Contracts QA](https://huggingface.co/datasets/mteb/legalbench_consumer_contracts_qa) benchmark dataset, which contains legal questions and contract clauses.\n",
    "\n",
    "The dataset includes human-annotated relevance scores indicating which documents are relevant to each query. In this example, you use semantic similarity to find documents, then cross-reference our results against these ground truth labels to evaluate search quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize Voyage AI client\n",
    "vo = voyageai.Client()\n",
    "\n",
    "# Load legal benchmark dataset\n",
    "corpus_ds = load_dataset(\"mteb/legalbench_consumer_contracts_qa\", \"corpus\")[\"corpus\"]\n",
    "queries_ds = load_dataset(\"mteb/legalbench_consumer_contracts_qa\", \"queries\")[\"queries\"]\n",
    "qrels_ds = load_dataset(\"mteb/legalbench_consumer_contracts_qa\")[\"test\"]\n",
    "\n",
    "# Extract corpus and query data\n",
    "corpus_ids = [row[\"_id\"] for row in corpus_ds]\n",
    "corpus_texts = [row[\"text\"] for row in corpus_ds]\n",
    "query_ids = [row[\"_id\"] for row in queries_ds]\n",
    "query_texts = [row[\"text\"] for row in queries_ds]\n",
    "\n",
    "# Build relevance mapping from dataset's ground truth (human-annotated) labels\n",
    "qrels = defaultdict(set)\n",
    "for row in qrels_ds:\n",
    "    if row[\"score\"] > 0:\n",
    "        qrels[row[\"query-id\"]].add(row[\"corpus-id\"])\n",
    "\n",
    "# Generate embeddings for the entire corpus\n",
    "print(f\"Generating embeddings for {len(corpus_texts)} documents...\")\n",
    "corpus_embeddings = vo.embed(\n",
    "    texts=corpus_texts,\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"document\"\n",
    ").embeddings\n",
    "\n",
    "# Select a sample query (change query_idx to explore other queries)\n",
    "# Query: 'Will Google come to a users assistance in the event of an alleged violation of such users IP rights?'\n",
    "query_idx = 1\n",
    "query = query_texts[query_idx]\n",
    "query_id = query_ids[query_idx]\n",
    "\n",
    "# Generate embedding for the query\n",
    "query_embedding = vo.embed(\n",
    "    texts=[query],\n",
    "    model=\"voyage-4-large\",\n",
    "    input_type=\"query\"\n",
    ").embeddings[0]\n",
    "\n",
    "# Calculate similarity scores using dot product\n",
    "similarities = np.dot(corpus_embeddings, query_embedding)\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "ranked_indices = np.argsort(-similarities)\n",
    "\n",
    "# Display top 5 results\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top 5 Results:\")\n",
    "for rank, idx in enumerate(ranked_indices[:5], 1):\n",
    "    doc_id = corpus_ids[idx]\n",
    "    is_relevant = \"✓\" if doc_id in qrels[query_id] else \"✗\"\n",
    "    print(f\"{rank}. [{is_relevant}] Document ID: {doc_id}\")\n",
    "    print(f\"   Similarity: {similarities[idx]:.4f}\")\n",
    "    print(f\"   Text: {corpus_texts[idx][:100]}...\\n\")\n",
    "\n",
    "# Show the ground truth most relevant document\n",
    "most_relevant_id = list(qrels[query_id])[0]\n",
    "most_relevant_idx = corpus_ids.index(most_relevant_id)\n",
    "print(f\"Ground truth most relevant document:\")\n",
    "print(f\"Document ID: {most_relevant_id}\")\n",
    "print(f\"Rank in results: {np.where(ranked_indices == most_relevant_idx)[0][0] + 1}\")\n",
    "print(f\"Similarity: {similarities[most_relevant_idx]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
