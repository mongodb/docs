:noprevnext:

.. _voyage-landing:

========================
{+voyage-full+}
========================

.. default-domain:: mongodb

.. meta::
   :keywords: Voyage AI, embedding models, rerankers, AI, machine learning, vector search, semantic search, retrieval-augmented generation, RAG, AI agents
   :description: Use Voyage AI's best-in-class embedding models and rerankers to power your AI search and retrieval applications.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

MongoDB provides an API for {+voyageai+}'s best-in-class 
embedding and reranking models. Use {+voyageai+} models 
with other parts of your AI stack, including vector databases 
and large language models (LLMs), to build production-ready 
applications with accurate AI search and retrieval.

.. image:: /images/voyage-flowchart.png
   :alt: Voyage flowchart
   :width: 1444px

Start Building
--------------

Use the following resources to get started:

.. card-group::
   :columns: 3
   :style: compact

   .. card::
      :cta: Quick Start
      :url: https://www.mongodb.com/docs/voyageai/quickstart/
      :icon: general_action_star
      :icon-alt: Quick Start icon

      Create an API key, generate your first embeddings, and build
      a RAG application.

   .. card::
      :cta: Manage API Keys
      :url: https://www.mongodb.com/docs/voyageai/management/api-keys/
      :icon: atlas_data_api
      :icon-alt: API Reference icon

      Learn how to manage your API keys in |service-full|.

   .. card::
      :cta: API Reference
      :url: https://www.mongodb.com/docs/api/doc/atlas-embedding-and-reranking-api/
      :icon: general_content_tutorial
      :icon-alt: API Reference icon

      Explore the API specification.

Voyage AI Models
----------------

{+voyageai+}'s embedding and reranking models are state-of-the-art
in retrieval accuracy. To learn more about the models, see :ref:`voyage-models`.

.. kicker:: Featured Models

.. card-group::
   :columns: 2
   :style: compact

   .. card::
      :headline: voyage-4-large
      :url: https://www.mongodb.com/docs/voyageai/models/text-embeddings/

      The best general-purpose and multilingual retrieval quality.
      All 4 series models share the same embedding space.

   .. card::
      :headline: voyage-context-3
      :url: https://www.mongodb.com/docs/voyageai/models/contextualized-chunk-embeddings/

      Contextualized chunk embeddings optimized for general-purpose and multilingual retrieval quality.

.. card-group::
   :columns: 2
   :style: compact

   .. card::
      :headline: voyage-multimodal-3.5
      :url: https://www.mongodb.com/docs/voyageai/models/multimodal-embeddings/

      Rich multimodal embedding model that can vectorize interleaved text and visual data, such as screenshots of PDFs, slides, tables, figures, videos, and more.

   .. card::
      :headline: rerank-2.5
      :url: https://www.mongodb.com/docs/voyageai/models/rerankers/

      Our generalist reranker optimized for quality with instruction-following and multilingual support.

Use Cases
---------

{+voyageai+} models support the following use cases:

.. card-group::
   :columns: 2
   :style: compact

   .. card::
      :cta: Semantic Search
      :url: https://www.mongodb.com/docs/voyageai/tutorials/semantic-search/
      :icon: mdb_vector_search
      :icon-alt: Semantic Search icon

      Use semantic search to retrieve contextually relevant information.

   .. card::
      :cta: Retrieval-Augmented Generation
      :url: https://www.mongodb.com/docs/voyageai/tutorials/rag/
      :icon: atlas_autocomplete
      :icon-alt: RAG icon

      Implement RAG to ground LLMs in your data and reduce hallucinations.

Better Together
---------------

Leverage {+voyageai+} with MongoDB Vector Search and AI integrations
to streamline your AI application development.

.. card-group::
   :columns: 2
   :style: compact

   .. card::
      :cta: MongoDB Vector Search
      :url: https://www.mongodb.com/docs/atlas/atlas-vector-search/
      :icon: atlas_diverse_search_parameters
      :icon-alt: Vector Search icon

      Combine {+voyageai+} models with MongoDB Vector Search to build production-ready AI applications.

   .. card::
      :cta: AI Integrations
      :url: https://www.mongodb.com/docs/atlas/ai-integrations/
      :icon: atlas_integration
      :icon-alt: AI Integrations icon

      Integrate with LangChain, LlamaIndex, and other popular AI frameworks.

.. _voyage-key-concepts:

Key Concepts
------------

.. glossary::

   embedding model
     Embedding models are algorithms that convert data into 
     :term:`vector embeddings` that capture your data's semantic, or underlying, meaning. 
     These vectors enable :term:`vector search` and serve as
     essential building blocks for :term:`retrieval-augmented generation (RAG) <RAG>`, 
     the predominant approach for building reliable AI applications.

   reranker
     :ref:`Rerankers <voyage-rerankers>` are algorithms that score relevance 
     between a search query and your search results. Rerankers help you refine 
     your initial results by reordering documents based on
     relevance scores, producing a more accurate subset of results.

   vector embeddings
      A vector embedding is an array of numbers, with each
      dimension representing a different feature or attribute of your data. Vectors can be
      used to represent any type of data, from text, images, and video to unstructured data.
      You create vector embeddings by passing your data through an embedding model, 
      and you can store these embeddings in a database that supports vector embeddings 
      like MongoDB.

   vector search
      :ref:`Vector search <avs-about-vector-search>` is the search method that powers 
      semantic search and RAG. By measuring the distance between vectors,
      you can determine semantic similarity between different data points. 
      This allows you to get relevant search results
      by comparing your vectorized query against 
      your vector embeddings. You can use {+voyageai+} models with any vector search 
      solution and vector database, but they integrate seamlessly with 
      :ref:`MongoDB Vector Search <avs-overview>`
      and `MongoDB Atlas <https://www.mongodb.com/docs/atlas/>`__.

   RAG
      Retrieval-augmented generation (RAG) is an architecture used
      to augment large language models (LLMs) with additional data
      so that they can generate more accurate responses. To learn more,
      see :ref:`RAG with Voyage AI <voyage-rag>`.

   tokens
      In the context of embedding models and LLMs, tokens are the fundamental units of text, 
      such as words, subwords, or characters, that the model processes 
      to create embeddings or generate text. Tokens are how you are 
      billed for usage of embedding models and LLMs. 

   rate limits
      Rate limits are restrictions imposed by API providers on the 
      number of requests a user can make within a specific time frame, 
      often measured in tokens per minute (TPM) or requests per minute (RPM). 
      These limits ensure fair usage, prevent abuse, and maintain the stability and 
      performance of the service for all users.

.. toctree::
   :titlesonly:
   :hidden:

   Quick Start </quickstart>
   Models Overview </models>
   Text Embeddings </models/text-embeddings>
   Contextualized Chunk Embeddings </models/contextualized-chunk-embeddings>
   Multimodal Embeddings </models/multimodal-embeddings>
   Rerankers </models/rerankers>
   Accessing Models </api-and-clients>
   API Reference </api-reference/overview>
   Model API Keys </management/api-keys>
   Organization and Project Access </management/organization-project-access>
   Monitor Usage </management/monitor-usage>
   Manage Rate Limits </management/rate-limits>
   Billing </management/billing>
   AWS Marketplace </management/aws-marketplace>
   Azure Marketplace </management/azure-marketplace>
   GCP Marketplace </management/gcp-marketplace>
   Semantic Search Tutorial </tutorials/semantic-search>
   RAG Tutorial </tutorials/rag>
   Dimensions and Quantization </tutorials/dimensions-and-quantization>
   Tokenization </tutorials/tokenization>
   