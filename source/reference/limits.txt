=============================
MongoDB Limits and Thresholds
=============================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

This document provides a collection of hard and soft limitations of
the MongoDB system.

BSON Documents
--------------

.. _limit-bson-document-size:
.. limit:: BSON Document Size

   .. include:: /includes/fact-document-max-size.rst

.. _limit-nested-depth:
.. limit:: Nested Depth for BSON Documents

   MongoDB supports no more than 100 levels of nesting for :term:`BSON
   documents <document>`.

.. _restrictions-on-db-names:
.. _restrictions-on-collection-names:
.. _faq-restrictions-on-collection-names:

Naming Restrictions
-------------------

.. limit:: Database Name Case Sensitivity

   Since database names are case *insensitive* in MongoDB, database
   names cannot differ only by the case of the characters.

.. limit:: Restrictions on Database Names for Windows

   For MongoDB deployments running on Windows, database names cannot
   contain any of the following characters:

   .. code-block:: none

      /\. "$*<>:|?

   Also database names cannot contain the null character.

.. limit:: Restrictions on Database Names for Unix and Linux Systems

   For MongoDB deployments running on Unix and Linux systems, database
   names cannot contain any of the following characters:

   .. code-block:: none

      /\. "$

   Also database names cannot contain the null character.

.. limit:: Length of Database Names

   Database names cannot be empty and must have fewer than 64 characters.

.. limit:: Restriction on Collection Names

   Collection names should begin with an underscore or a letter
   character, and *cannot*:

   - contain the ``$``.

   - be an empty string (e.g. ``""``).

   - contain the null character.

   - begin with the ``system.`` prefix. (Reserved for internal use.)

   If your collection name includes special characters, such as the
   underscore character, then to access the collection use the
   :method:`db.getCollection()` method in the :program:`mongo` shell or
   a :api:`similar method for your driver <>`.

   .. include:: /includes/fact-collection-namespace-limit.rst

.. _limit-restrictions-on-field-names:

.. limit:: Restrictions on Field Names

   Field names cannot contain dots (i.e. ``.``) or null characters, and they
   must not start with a dollar sign (i.e. ``$``). See
   :ref:`faq-dollar-sign-escaping` for an alternate approach.

.. _faq-dev-namespace:

Namespaces
----------

.. _limit-namespace-length:
.. limit:: Namespace Length

   .. include:: /includes/fact-collection-namespace-limit.rst

   .. seealso:: :ref:`faq-restrictions-on-collection-names`

.. _limit-number-of-namespaces:
.. limit:: Number of Namespaces

   .. versionchanged:: 3.0

   For the MMAPv1 the number of namespaces is limited to the size of
   the namespace file divided by 628.

   A 16 megabyte namespace file can support approximately 24,000
   namespaces. Each collection and index is a namespace.

   The WiredTiger storage engine is *not* subject to this limitation.

.. _limit-size-of-namespace-file:
.. limit:: Size of Namespace File

   .. versionchanged:: 3.0

   For the MMAPv1 storage engine, namespace files can be no larger
   than 2047 megabytes.

   By default namespace files are 16 megabytes. You can configure the
   size using the :setting:`~storage.mmapv1.nsSize` option.

   The WiredTiger storage engine is *not* subject to this limitation.

.. seealso:: :ref:`faq-restrictions-on-collection-names`

.. _index-limitations:

Indexes
-------

.. _limit-index-size:
.. limit:: Index Key Limit

   The *total size* of an index entry, which can include structural
   overhead depending on the BSON type, must be *less than* 1024 bytes.

   .. COMMENT refer to src/mongo/db/structure/btree/key.cpp (KeyV1Owned::KeyV1Owned)

   .. |limit| replace:: :limit:`index key limit <Index Key Limit>`

   .. versionchanged:: 2.6

      .. include:: /includes/list-index-field-limit-behaviors.rst

.. _limit-number-of-indexes-per-collection:
.. limit:: Number of Indexes per Collection

   A single collection can have *no more* than 64 indexes.

.. _limit-index-name-length:
.. limit:: Index Name Length

   Fully qualified index names, which includes the namespace and the dot
   separators (i.e. ``<database name>.<collection name>.$<index name>``),
   cannot be longer than 128 characters.

   By default, ``<index name>`` is the concatenation of the field names
   and index type. You can explicitly specify the ``<index name>`` to the
   :method:`~db.collection.createIndex()` method to ensure that the fully
   qualified index name does not exceed the limit.

.. limit:: Number of Indexed Fields in a Compound Index

   There can be no more than 31 fields in a compound index.

.. limit:: Queries cannot use both text and Geospatial Indexes

   .. |operation| replace:: :query:`$text` query

   .. include:: /includes/fact-special-indexes-and-text.rst

   .. TODO remove in the 2.6 version of the manual

.. limit:: Fields with 2dsphere Indexes can only hold Geometries

   .. include:: /includes/geo-data-limit-for-2dsphere.rst

.. seealso:: The unique indexes limit in :ref:`limits-sharding-operations`.

.. limit:: NaN values returned from Covered Queries by the WiredTiger Storage Engine are always of type double

   If the value of a field returned from a query that is :ref:`covered
   by an index <covered-queries>` is ``NaN``, the type of that ``NaN``
   value is *always* ``double``.

.. limit:: Multikey Index

   .. include:: /includes/fact-multikey-index-covered-query.rst

Data
----

.. limit:: Maximum Number of Documents in a Capped Collection

   .. versionchanged:: 2.4

   If you specify a maximum number of documents for a capped
   collection using the ``max`` parameter to
   :dbcommand:`create`, the limit must be less than 2\ :sup:`32`
   documents. If you do not specify a maximum number of documents when
   creating a capped collection, there is no limit on the number of
   documents.

.. _limit-database-size:
.. limit:: Database Size

   The MMAPv1 storage engine limits each database to no more than 16000 data
   files. This means that a single MMAPv1 database has a maximum size of 32TB.
   Setting the :setting:`storage.mmapv1.smallFiles` option reduces this limit to 8TB.

.. _limit-data-size:
.. limit:: Data Size

   .. versionchanged:: 3.0

   Using the MMAPv1 storage engine, a single :program:`mongod`
   instance cannot manage a data set that exceeds maximum virtual
   memory address space provided by the underlying operating system.

   .. list-table:: Virtual Memory Limitations
      :widths: 15 10 10
      :header-rows: 1

      * - Operating System
        - Journaled
        - Not Journaled
      * - Linux
        - 64 terabytes
        - 128 terabytes
      * - Windows Server 2012 R2 and Windows 8.1
        - 64 terabytes
        - 128 terabytes
      * - Windows (otherwise)
        - 4 terabytes
        - 8 terabytes

   The WiredTiger storage engine is *not* subject to this limitation.

.. limit:: Number of Collections in a Database

   .. versionchanged:: 3.0

   For the MMAPv1 storage engine, the maximum number of collections in
   a database is a function of the size of the namespace file and the
   number of indexes of collections in the database.

   The WiredTiger storage engine is *not* subject to this limitation.

   See :limit:`Number of Namespaces` for more information.

Replica Sets
------------

.. limit:: Number of Members of a Replica Set

   .. versionchanged:: 3.0.0

   Replica sets can have up to 50 members. See
   :ref:`3.0-replica-sets-max-members` for more information about
   specific driver compatibility with large replica sets.

.. limit:: Number of Voting Members of a Replica Set

   Replica sets can have up to 7 voting members. For replica sets with
   more than 7 total members, see :ref:`replica-set-non-voting-members`.

.. limit:: Maximum Size of Auto-Created Oplog

   .. versionchanged:: 2.6

   If you do not explicitly specify an oplog size (i.e. with
   :setting:`~replication.oplogSizeMB` or :option:`--oplogSize
   <mongod --oplogSize>`) MongoDB will create an oplog that is no
   larger than 50 gigabytes.

.. _limits-sharding:

Sharded Clusters
----------------

Sharded clusters have the restrictions and thresholds described here.

.. _limits-sharding-operations:

Sharding Operational Restrictions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. limit:: Operations Unavailable in Sharded Environments

   The :dbcommand:`group` does not work with sharding. Use
   :dbcommand:`mapReduce` or :dbcommand:`aggregate` instead.

   :method:`db.eval()` is incompatible with sharded collections. You may
   use :method:`db.eval()` with un-sharded collections in a shard
   cluster.

   :query:`$where` does not permit references to the ``db`` object
   from the :query:`$where` function. This is uncommon in
   un-sharded collections.

   The :update:`$isolated` update modifier does not work in sharded
   environments.

   :operator:`$snapshot` queries do not work in sharded environments.

   The :dbcommand:`geoSearch` command is not supported in sharded
   environments.

.. limit:: Covered Queries in Sharded Clusters

   .. include:: /includes/extracts/fact-covered-query-sharded-collection-covered-queries.rst

.. limit:: Sharding Existing Collection Data Size

   An existing collection can only be sharded if its size does not exceed
   specific limits. These limits can be estimated based on the average size of
   all :term:`shard key` values, and the configured :term:`chunk` size.
   
   .. important:: 
      
      These limits only apply for the initial sharding operation. Sharded
      collections can grow to *any* size after successfully enabling sharding.
   
   Use the following formulas to calculate the *theoretical* maximum
   collection size. 
   
   .. code-block:: javascript
   
      maxSplits = 16777216 (bytes) / <average size of shard key values in bytes>
      maxCollectionSize (MB) = maxSplits * (chunkSize / 2)
   
   .. note::
      
      The maximum :term:`BSON` document size is 16MB or ``16777216`` bytes.
      
      All conversions should use base-2 scale, e.g. 1024 kilobytes = 1
      megabyte.
   
   If ``maxCollectionSize`` is less than or nearly equal to the target
   collection, increase the chunk size to ensure sucessful initial sharding.
   If there is doubt as to whether the result of the calculation is too
   'close' to the target collection size, it is likely better to increase the
   chunk size.
   
   After successful initial sharding, you can reduce the chunk size as needed.
   If you later reduce the chunk size, it may take time for all chunks to
   split to the new size. See
   :doc:`/tutorial/modify-chunk-size-in-sharded-cluster` for instructions on
   modifying chunk size.
   
   This table illustrates the approximate maximum collection sizes
   using the formulas described above:

   .. list-table::
      :header-rows: 1
      :stub-columns: 1

      * - Average Size of Shard Key Values
        - 512 bytes
        - 256 bytes
        - 128 bytes
        - 64 bytes
      * - Maximum Number of Splits
        - 32,768
        - 65,536
        - 131,072
        - 262,144
      * - Max Collection Size (64 MB Chunk Size)
        - 1 TB
        - 2 TB
        - 4 TB
        - 8 TB
      * - Max Collection Size (128 MB Chunk Size)
        - 2 TB
        - 4 TB
        - 8 TB
        - 16 TB
      * - Max Collection Size (256 MB Chunk Size)
        - 4 TB
        - 8 TB
        - 16 TB
        - 32 TB

.. limit:: Single Document Modification Operations in Sharded Collections

   .. |single-modification-operation-names| replace:: :method:`~db.collection.update()` and :method:`~db.collection.remove()`
   .. |single-modification-operation-option| replace:: ``justOne`` or ``multi: false``

   .. include:: /includes/fact-single-modification-in-sharded-collections.rst

.. _limit-sharding-unique-indexes:

.. limit:: Unique Indexes in Sharded Collections

   MongoDB does not support unique indexes across shards, except when
   the unique index contains the full shard key as a prefix of the
   index. In these situations MongoDB will enforce uniqueness across
   the full key, not a single field.

   .. see:: :doc:`/tutorial/enforce-unique-keys-for-sharded-collections`
      for an alternate approach.

.. _limit-balancer-migration-document-limit:

.. limit:: Maximum Number of Documents Per Chunk to Migrate

   MongoDB cannot move a chunk if the number of documents in the chunk
   exceeds either 250000 documents or 1.3 times the number of average
   sized documents that the :ref:`maximum chunk size
   <sharding-chunk-size>` can hold.

.. _limits-shard-keys:

Shard Key Limitations
~~~~~~~~~~~~~~~~~~~~~

.. limit:: Shard Key Size

   A shard key cannot exceed 512 bytes.

.. limit:: Shard Key Index Type

   A :term:`shard key` index can be an ascending index on the shard
   key, a compound index that start with the shard key and specify
   ascending order for the shard key, or a :doc:`hashed index
   </core/index-hashed>`.

   A :term:`shard key` index cannot be an index that specifies a
   :doc:`multikey index </core/index-multikey>`, a :doc:`text index
   </core/index-text>` or a :ref:`geospatial index
   <index-feature-geospatial>` on the :term:`shard key` fields.

.. limit:: Shard Key is Immutable

   You cannot change a shard key after sharding the collection. If
   you must change a shard key:

   - Dump all data from MongoDB into an external format.

   - Drop the original sharded collection.

   - Configure sharding using the new shard key.

   - :doc:`Pre-split </tutorial/create-chunks-in-sharded-cluster>` the shard
     key range to ensure initial even distribution.

   - Restore the dumped data into MongoDB.

.. limit:: Shard Key Value in a Document is Immutable

   After you insert a document into a sharded collection, you cannot
   change the document's value for the field or fields that comprise
   the shard key. The :method:`~db.collection.update()` operation will
   not modify the value of a shard key in an existing document.

.. limit:: Monotonically Increasing Shard Keys Can Limit Insert Throughput

   For clusters with high insert volumes, a shard keys with
   monotonically increasing and decreasing keys can affect insert
   throughput. If your shard key is the ``_id`` field, be aware that
   the default values of the ``_id`` fields are :term:`ObjectIds
   <ObjectId>` which have generally increasing values.

   When inserting documents with monotonically increasing shard keys, all
   inserts belong to the same :term:`chunk` on a single
   :term:`shard`. The system will eventually divide the
   chunk range that receives all write operations
   and migrate its contents to distribute data more evenly. However, at any
   moment the cluster can direct insert operations only to a single
   shard, which creates an insert throughput bottleneck.

   If the operations on the cluster are predominately read operations
   and updates, this limitation may not affect the cluster.

   To avoid this constraint, use a :ref:`hashed shard key
   <sharding-hashed-sharding>` or select a field that does not
   increase or decrease monotonically.

   .. versionchanged:: 2.4
      :ref:`Hashed shard keys <sharding-hashed-sharding>` and
      :ref:`hashed indexes <index-type-hashed>` store hashes of keys
      with ascending values.

Operations
----------

.. _limit-sort:
.. limit:: Sort Operations

   If MongoDB cannot use an index to get documents in the requested
   sort order, the combined size of all documents in the sort
   operation, plus a small overhead, must be less than 32 megabytes.

.. _limit-agg-sort:

.. limit:: Aggregation Pipeline Operation

   .. include:: /includes/fact-agg-memory-limit.rst

.. limit:: 2d Geospatial queries cannot use the $or operator

   .. see:: :query:`$or` and :doc:`/core/geospatial-indexes`.

.. limit:: Area of GeoJSON Polygons

   .. |geo-operator-method| replace:: :query:`$geoIntersects` or :query:`$geoWithin`

   .. include:: /includes/fact-geometry-hemisphere-limitation.rst

.. limit:: Write Command Operation Limit Size

   :doc:`Write commands </reference/command/nav-crud>` can accept no
   more than 1000 operations. The :method:`Bulk()` operations in the
   :program:`mongo` shell and comparable methods in the drivers do not
   have this limit.
