.. _om-nw-lb-mesh:

=========================================
Networking, Load Balancing, Service Mesh
=========================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Consider the following additional requirements when deploying the |application|
in multiple |k8s| clusters:

- :ref:`om-networking-overview`
- :ref:`om-service-mesh`
- :ref:`om-networking-and-load-balancing`
- :ref:`diagram-om-mc-ext-lb`
- :ref:`diagram-om-mc-mesh-lb-proxy`

.. _om-networking-overview:

Networking Overview
-------------------

The following table describes:

- Origins of connections to the |application| instances
- The tasks that the |application| performs after it connects
- The URL to |onprem| that each type of connection uses and how to configure it.

.. list-table::
   :header-rows: 1
   :widths: 10 40 50

   * - Connection's origin
     - Purpose or action
     - URL to |onprem|

   * - The |k8s-op-short|
     - Configures the |onprem| instance and enables monitoring after the {+appdb+} is in the running state
     - Through a default |onprem| |fqdn| in the form: ``<om_resource_name>-svc.<namespace>.svc.cluster.local`` or the value of
       :opsmgrkube:`spec.opsManagerURL`

   * - The |k8s-op-short|
     - Configures a specific |k8s-mdbrsc| or |mongodb-multi| deployment
     - Through the project's ConfigMap, configured when you :ref:`create a project <create-k8s-project>`

   * - {+mdbagent+} in the {+appdb+} Pods
     - Receives the Automation configuration
     - Without having to connect to an |onprem| instance. The {+mdbagent+} is
       running in a headless mode.

   * - {+monitoring-agent+} in the {+appdb+} Pods
     - Sends monitoring data
     - Through a default |onprem| |fqdn| in the form: ``<om_resource_name>-svc.<namespace>.svc.cluster.local`` or the value of
       :opsmgrkube:`spec.opsManagerURL`

   * - {+mdbagent+} in the ``MongoDB`` or ``MongoDBMultiCluster`` resources Pods
     - Receives the Automation configuration, backup and restore processes
     - Through the project's ConfigMap, configured when you :ref:`create a project <create-k8s-project>`

   * - {+monitoring-agent+} in the ``MongoDB`` or ``MongoDBMultiCluster`` resources Pods
     - Sends monitoring data
     - Through the project's ConfigMap, configured when you :ref:`create a project <create-k8s-project>`

   * - User
     - Uses the |onprem| UI or API
     - Through a public, external domain of the externally exposed |onprem| instance, configured with :opsmgrkube:`spec.externalConnectivity`

.. _om-service-mesh:

Service Mesh
-------------

Add the nodes hosting the {+appdb+} instances  and the |application|
instances to the same service mesh to allow for:

- Network connectivity between deployed components.
- Cross-cluster DNS resolution.

To simplify the networking configuration between the |k8s-op-short| and
|onprem| instances, we recommend that you add the operator cluster, which
is the |k8s| cluster where you install the |k8s-op-short| to the same
service mesh, but it's not a strict requirement. If you include the operator
cluster into the same service mesh, you can then use it as a host for the
|application| and the {+appdb+} instances.

Configure a service mesh for the following |k8s| clusters and include them into the mesh configuration:

- The "operator cluster" on which you deploy the |k8s-op-short| itself.
- The "member |k8s| clusters" that will host the |application| instances.
- Additional member |k8s| clusters, or the same member clusters used for |onprem|,
  that will host the {+appdb+} instances.

Having the same service mesh configured for all |k8s| clusters ensures that each
|onprem| instance can establish a secure connection to any of the
{+appdb+} instances deployed in multiple |k8s| clusters.

After you deploy the {+appdb+} instances on member |k8s| clusters,
the API endpoint for each |onprem| instance that you deploy on member |k8s|
clusters must be able to directly connect to each of the {+appdb+}
instances. This allows the |k8s-op-short| to complete the stages needed
to deploy |onprem| instances on member clusters, such as creating admin
users, and configuring backups.

.. _om-networking-and-load-balancing:

Load Balancing
--------------

In most cases, you must provide an external access to the |application|
to enable user access to the |onprem| UI.

For multi-cluster deployments of the |application|, each cluster can
expose its Pods hosting the |application| individually using a |k8s-service|
of type ``LoadBalancer`` .

Create a ``LoadBalancer`` service using :opsmgrkube:`spec.externalConnectivity`
and point an external domain to that service's external IP address.
Even if you configure more than one instance of the |application|, the
|k8s| service sends traffic in a round-robin fashion to all available Pods
hosting the |application|.

Since the |k8s-op-short| doesn't support load balancing of the traffic to
all Pods across all |k8s| clusters, you must configure load balancing
outside of the |k8s-op-short| configuration.

The following examples and diagrams illustrate a few of the many ways in which
you can configure load balancing across multiple |k8s| clusters.

- :ref:`diagram-om-mc-ext-lb`
- :ref:`diagram-om-mc-mesh-lb-proxy`

.. _diagram-om-mc-ext-lb:

Diagram Example 1: External Load Balancer
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Configure an external network load balancer (a passthrough proxy) for all
|k8s| clusters hosting the |application| and the {+appdb+}.
The |application| is stateless. The load balancer can forward traffic to
each cluster's ``LoadBalancer`` service in a round-robin fashion, or to
one cluster at a time, if you configure the load balancer in a way where
while one cluster is active, the other cluster is passive. The following
diagram illustrates this approach.

.. figure:: /images/om-multicluster-external-lb.svg
   :alt: Diagram showing the high-level networking example of the Ops Manager application
         deployment on multiple Kubernetes clusters where the traffic
         is distributed by an external load balancer.
   :figwidth: 600px

In this diagram:

1. The |k8s-op-short| creates an external service of type ``LoadBalancer``,
   named ``<om_resource_name>-svc-ext``, with an assigned external IP address,
   on each member cluster. You can configure this service globally for all
   member clusters using :opsmgrkube:`spec.externalConnectivity`. Or, if
   this service is specific to each member cluster, you can configure it
   using :opsmgrkube:`spec.clusterSpecList.externalConnectivity`.

   Each service that the |k8s-op-short| creates for the |application| always
   contains all Pods hosting the |application| from the current cluster.

.. _diagram-om-mc-mesh-lb-proxy:

Diagram Example 2: Load Balancing by a Service Mesh, with a Proxy
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Use cross-cluster load balancing capabilities provided by a service mesh.

In each |k8s| cluster, the |k8s-op-short| creates a |k8s-service|, named
``<om_resource_name>-svc``, which you can use to distribute traffic across
all available Pods hosting the |application| instances in all member clusters.

You can deploy a proxy component, such as Nginx or HAProxy, in one of the
clusters, expose it externally over the Internet through your public |fqdn|,
and configure the proxy to forward all network traffic through the TCP
passthrough to the service named ``<om_resource_name>-svc.<namespace>.svc.cluster.local``.

The following diagram illustrates this approach.

.. figure:: /images/om-multicluster-lb-from-mesh-with-proxy.svg
   :alt: Diagram showing the high-level networking example of the Ops Manager application
         deployment on multiple Kubernetes clusters where the traffic
         is distributed by a load balancer within a service mesh, and a
         proxy service is used.
   :figwidth: 600px

In this diagram:

1. On each member cluster the |k8s-op-short| creates a |k8s-service| of
   type ``ClusterIP`` that you can access using
   ``<om_resource_name>-svc.<namespace>.svc.cluster.local``.
   It's a service that contains in its endpoints all Pods deployed in this
   member cluster.
2. The traffic between |k8s| clusters is handled by the service mesh.
   When the |k8s-op-short| creates services on each member cluster for the
   |application|, the |k8s-op-short| doesn't assign a cluster index suffix
   to the names of these services. Therefore, the service mesh can perform
   traffic load balancing  to all Pods hosting the |application| in all
   clusters.
3. In each member cluster, the |k8s-op-short| deploys a StatefulSet named
   ``<om_resource_name>-<cluster-index>``. For example, ``om-0`` is the
   name of the StatefulSet for the member cluster with the index 0.
4. Even though each cluster has an ``<om_resource_name>-svc`` ``ClusterIP``
   service deployed, this service doesn't handle the user traffic. When
   the user accesses the service in ``Member Cluster 1``, the service mesh
   handles the traffic.
5. Each Pod hosting the |application| is named after its StatefulSet name.
   For example, ``om-1-2`` is the name of the Pod number 2 in the cluster with
   the index 1.
