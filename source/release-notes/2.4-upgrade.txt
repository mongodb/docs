==========================
Upgrade MongoDB 2.2 to 2.4
==========================

.. default-domain:: mongodb

Only upgrade sharded clusters to 2.4 if all members of the cluster are
currently running instances of 2.2. The only supported upgrade path
for sharded clusters running 2.0 is via 2.2.

Rolling Upgrade Limitation for 2.2.0 Deployments Running with ``auth`` Enabled
------------------------------------------------------------------------------

MongoDB *cannot* support deployments that mix 2.2.0 and 2.4.0, or
greater, components. MongoDB version 2.2.1 and later processes *can*
exist in mixed deployments with 2.4-series processes. Therefore you
cannot perform a rolling upgrade from MongoDB 2.2.0 to MongoDB
2.4.0. To upgrade a cluster with 2.2.0 components, use one of the
following procedures.

1. Perform a rolling upgrade of all 2.2.0 processes to the latest
   2.2-series release (e.g. 2.2.3) so that there are no processes in
   the deployment that predate 2.2.1. When there are no 2.2.0
   processes in the deployment, perform a rolling upgrade to 2.4.0.

2. Stop all processes in the cluster. Upgrade all processes to a
   2.4-series release of MongoDB, and start all processes at the same
   time.

.. _2.4-upgrade-cluster:

Upgrade a Sharded Cluster from MongoDB 2.2 to MongoDB 2.4
---------------------------------------------------------

Upgrading a :term:`sharded cluster` from MongoDB version 2.2 to 2.4
(or 2.3) requires that you run a 2.4 :program:`mongos`
with the :option:`--upgrade <mongos --upgrade>` option, described in
this procedure. The upgrade process does not require downtime.

The upgrade to MongoDB 2.4 adds epochs to the metadata for all
collections and chunks in the existing cluster. MongoDB 2.2 processes
are capable of handling epochs, even though 2.2 did not require them.

This procedure applies only to upgrades from version 2.2. Earlier
versions of MongoDB do not correctly handle epochs.

While the upgrade is in progress, you cannot make changes to the
collection metadata. For example, you cannot perform operations that
add shards, drop databases, or drop collections, or modify the
metadata in any other way.

.. warning::

   Once you upgrade to 2.4 and complete the upgrade procedure **do
   not** use 2.0 :program:`mongod` and :program:`mongos` processes in
   your cluster. 2.0 process may re-introduce old metadata formats
   into cluster metadata.

.. note::

   The upgraded config database will require more storage space than
   before, though this storage increase represents a fraction of the
   current config database size. The additional storage requirement
   will be much less for deployments that have run with 2.2 for a
   non-trivial period of time, but, as always, pre-allocation of 
   data files could be triggered. See
   :ref:`faq-tools-for-measuring-storage-use` for more information.

.. _2.4-upgrade-meta-data:

Sharded Cluster Upgrade Procedure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Do not perform operations that modify metadata while performing this
procedure.

1. Turn off the :ref:`balancer <sharding-balancing-internals>` in the
   :term:`sharded cluster`, as described in
   :ref:`sharding-balancing-disable-temporally`.

   .. optional::

      For additional security during the upgrade, you can make a
      backup of the config database using :program:`mongodump` or
      other backup tools.

#. Ensure there are no version 2.0 :program:`mongod` or
   :program:`mongos` processes still active in the sharded
   cluster. The automated upgrade process checks for 2.0 processes,
   but network availability can prevent a definitive check. Wait 5
   minutes after stopping or upgrading version 2.0 :program:`mongos`
   processes to confirm that none are still active.

#. Start a single 2.4 :program:`mongos` process with
   :setting:`configdb` pointing to the sharded cluster's :ref:`config
   servers <sharding-config-server>` and with the :option:`--upgrade
   <mongos --upgrade>` option.  The upgrade process happens pre :option:`--fork`.
   
   You can upgrade an existing
   :program:`mongos` instance to 2.4 or you can start a new `mongos`
   instance that can reach all config servers if you need to avoid
   reconfiguring a production :program:`mongos`.

   Start the :program:`mongos` with a command that resembles the
   following:

   .. code-block:: sh

      mongos --configdb <config server> --upgrade

   Without the :option:`--upgrade <mongos --upgrade>` option 2.4
   :program:`mongos` processes will fail to start until the upgrade
   process is complete.

   The upgrade will prevent any chunk moves or splits from occurring
   during the upgrade process. If there are very many sharded
   collections or there are stale locks held by other failed processes,
   acquiring the locks for all collections can take
   seconds or minutes. See the log for progress updates.

#. When the :program:`mongos` process starts successfully, the upgrade is
   complete. If the :program:`mongos` process fails to start, check the
   log for more information.

   If the :program:`mongos` terminates or loses its connection to the
   config servers during the upgrade, you may always safely retry the
   upgrade.

   However, if the upgrade failed in the short critical section,
   the retry will end with a warning that manual intervention is required.
   To continue upgrading, you must follow the :ref:`upgrade-cluster-resync`
   procedure.

   .. optional::

      If the :program:`mongos` logs show the upgrade waiting for the upgrade
      lock, a previous upgrade process may still be active or may have ended
      abnormally.  After 15 minutes of no remote activity :program:`mongos`
      will force the upgrade lock. If you can verify that there are no running upgrade
      processes, you may connect to a 2.2 :program:`mongos` process
      and force the lock manually:

   .. code-block:: sh

      mongo <mongos.example.net>

   .. code-block:: javascript

      db.getMongo().getCollection("config.locks").findOne({ _id : "upgradeLock" })

      If the process specified in the ``process`` field of this document
      is *verifiably* offline, run the following operation to force the
      lock.

   .. code-block:: javascript

      db.getMongo().getCollection("config.locks").update({ _id : "upgradeLock" }, { $set : { state : 0 } })

      It is always more safe to wait for the :program:`mongos` to verify
      that the lock is inactive, if you have any doubts about the
      activity of another upgrade operation.  Note also that mongos may also
      have to wait for other collection locks, which should not be forced.

#. Upgrade and restart other :program:`mongos` processes in the
   sharded cluster, *without* the :option:`--upgrade <mongos --upgrade>`
   option.

   See :ref:`2.4 finalize-shard-cluster-upgrade` for more information.

#. :ref:`Re-enable the balancer
   <sharding-balancing-disable-temporally>`. You can now perform
   operations that modify cluster metadata.

Once you have upgraded, *do not* introduce version 2.0 MongoDB
processes into the sharded cluster. This can reintroduce old metadata
formats into the config servers. The metadata change made by this
upgrade process will help prevent errors caused by cross-version
incompatibilities in future versions of MongoDB.

.. _upgrade-cluster-resync:

Resync after a Critical Section Interruption
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

During the short critical section of the upgrade that applies changes
to the metadata, it is unlikely but possible that a network
interruption can prevent all three config servers from verifying or
modifying data. If this occurs, the :ref:`config servers
<sharding-config-server>` must be re-synced, and there may be problems
starting new :program:`mongos` processes. The :term:`sharded cluster`
will remain accessible, but avoid all cluster metadata changes until
you resync the config servers. Operations that change metadata include:
adding shards, dropping databases, and dropping collections.

.. note::

   Only perform the following procedure *if* something (e.g. network,
   power, etc.) interrupts the upgrade process during the short
   critical section of the upgrade. Remember, you may always safely
   attempt the :ref:`meta data upgrade procedure
   <2.4-upgrade-meta-data>`.

To resync the config servers:

1. Turn off the :ref:`balancer <sharding-balancing-internals>` in the
   sharded cluster and stop all metadata operations. If you are in the
   middle of an upgrade process (:ref:`2.4-upgrade-cluster`), you
   have already disabled the balancer.

#. Shut down two of the three config servers, preferably the last two listed
   in the :setting:`configdb` string. For example, if your :setting:`configdb`
   string is ``configA:27019,configB:27019,configC:27019``, shut down
   ``configB`` and ``configC``. Shutting down the last two config servers
   ensures that most :program:`mongos` instances will have
   uninterrupted access to cluster metadata.

#. :program:`mongodump` the data files of the active config server
   (``configA``).

#. Move the data files of the deactivated config servers (``configB``
   and ``configC``) to a backup location.

#. Create new, empty :term:`data directories <dbpath>`.

#. Restart the disabled config servers with :option:`--dbpath <mongod --dbpath>`
   pointing to the now-empty data directory and :option:`--port <mongod --port>`
   pointing to an alternate port (e.g. ``27020``).

#. Use :program:`mongorestore` to repopulate the data files on the
   disabled documents from the active
   config server (``configA``) to the restarted config servers on the new
   port (``configB:27020,configC:27020``). These config servers are now
   re-synced.

#. Restart the restored config servers on the old port, resetting the
   port back to the old settings (``configB:27019`` and ``configC:27019``).

#. In some cases connection pooling may cause spurious failures, as
   the :program:`mongos` disables old connections only after attempted
   use. 2.4 fixes this problem, but to avoid this issue in version
   2.2, you can restart all :program:`mongos` instances (one-by-one,
   to avoid downtime) and use the :method:`rs.stepDown()` method
   before restarting each of the shard :term:`replica set`
   :term:`primaries <primary>`.

#. The sharded cluster is now fully resynced; however before you
   attempt the upgrade process again, you must manually reset the
   upgrade state using a version 2.2 :program:`mongos`. Begin by
   connecting to the 2.2 :program:`mongos` with the :program:`mongo`
   shell:

   .. code-block:: sh

      mongo <mongos.example.net>

   Then, use the following operation to reset the upgrade process:

   .. code-block:: javascript

      db.getMongo().getCollection("config.version").update({ _id : 1 }, { $unset : { upgradeState : 1 } })

#. Finally retry the upgrade process, as in
   :ref:`2.4-upgrade-cluster`.

.. _2.4 finalize-shard-cluster-upgrade:

Complete Sharded Cluster Upgrade
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

After you have successfully completed the meta-data upgrade process
described in :ref:`2.4-upgrade-meta-data`, and the 2.4
:program:`mongos` instance starts, you can upgrade the other processes
in your MongoDB deployment.

While the balancer is still disabled, upgrade the components of your
sharded cluster in the following order:

- Upgrade all :program:`mongos` instances in the cluster, in any
  order.

- Upgrade all 3 :program:`mongod` config server instances, upgrading
  the *first* system in the :option:`mongos --configdb` argument
  *last*.

- Upgrade each shard, one at a time, upgrading the :program:`mongod`
  secondaries before running :dbcommand:`replSetStepDown` and
  upgrading the primary of each shard.

When this process is complete, you can now :ref:`re-enable the
balancer <sharding-balancing-disable-temporally>`.
