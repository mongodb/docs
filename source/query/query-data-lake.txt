.. _query-adl:

=======================
Querying Your Data Lake
=======================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol 

You can use the MongoDB Query Language (MQL) on {+adl+} to query and 
analyze data on your data store. {+adl+} supports most, but not all the 
standard server commands. To learn more about the supported and 
unsupported MongoDB server commands and aggregation pipleline stages, 
see :ref:`data-lake-mql-support`.

You can run up to 30 simultaneous queries on your {+dl+} against:

- Data in your |s3| bucket.
- Documents in your MongoDB |service| cluster.
- Data in files hosted at publicly accessible |url|\s.

.. see:: 

   - :doc:`How to Connect to Your Data Lake </tutorial/connect>`
   - :doc:`How to Run Queries Against Your Data Lake 
     </tutorial/run-queries>`

.. _query-s3:

Querying Data on S3 
-------------------

You can use {+adl+} to query and analyze data on your cloud object 
store using MongoDB Query Language (MQL). To query data on |s3|, your 
{+dl+} storage :ref:`configuration <datalake-configuration-file>` must 
contain settings that define:

- Your |s3| {+data-lake-store+}. 
- {+dl+} virtual databases and collections that map to your 
  {+data-lake-store+}.

.. example::

   .. code-block:: json

      {
        "stores" : [
          {
            "name" : "<store-name>",
            "provider" : "s3",
            "region" : "<aws-region>",
            "bucket" : "<s3-bucket-name>",
            "prefix" : "<file-path-prefix>",
            "delimiter" : "<path-separator>"
          }
        ],
        "databases" : [ 
          {
            "name" : "<database-name>", 
            "collections" : [
              {
                "name" : "<collection-name>",
                "dataSources" : [
                  {
                    "storeName" : "<store-name>",
                    "path" : "<path-to-file>"
                  }
                ]
              }
            ],
            "maxWildcardCollections" : <number-of-wildcard-collections>
          }
        ]
      }

To learn more about these settings, see 
:ref:`datalake-configuration-file`.

{+dl+} creates the virtual databases and collections you specified in 
your {+dl+} configuration for the data in your |s3| store. When you 
:doc:`connect </tutorial/connect>` to your {+dl+} and :doc:`run queries 
</tutorial/run-queries>`, {+dl+} processes your queries against the 
data and returns the query results.

When :doc:`deploying </tutorial/deploy>` your {+dl+}, if you specified 
an |s3| bucket with both read and write permissions or |aws| |s3| 
:aws:`s3:PutObject </AmazonS3/latest/dev/using-with-s3-actions.html#using-with-s3-actions-related-to-objects>` 
permission, you can also save your query results in your |s3| bucket 
using :ref:`adl-out-stage` to |s3|.

If you successfully create or update an object on your |s3| data store, 
{+dl+} returns the latest version of that object for any subsequent 
read requests and all list operations of the objects also reflect the 
changes. If your query contains multiple stages, each stage receives 
the most recent data available from the data store as that stage is 
processed.

.. include:: /includes/fact-doc-order-in-query-result.rst

.. include:: /includes/fact-partition-cost-benefit.rst

.. _query-atlas:

Querying Data in Your |service| Cluster 
---------------------------------------

You can use {+adl+} to query and analyze data in your |service| 
cluster. To query data in your |service| cluster, your {+dl+} storage 
:ref:`configuration <datalake-configuration-file>` must contain 
settings that define: 

- Your |service| {+data-lake-store+}.
- {+dl+} virtual databases and collections that map to your 
  {+data-lake-store+}.

.. example::

   .. code-block:: json

      {
        "stores" : [
          {
            "name" : "<store-name>",
            "provider": "atlas",
            "clusterName": "<atlas-cluster-name>", 
            "projectId": "<atlas-project-ID>"
          }
        ],
        "databases" : [
          {
            "name" : "<database-name>",
            "collections" : [
              {
                "name" : "<collection-name>",
                "dataSources" : [
                  {
                    "storeName" : "<store-name>",
                    "database" : "<atlas-database-name>",
                    "collection" : "<atlas-collection-name>" 
                  }
                ]
              }
            ]
          }
        ]
      }

To learn more about these settings, see 
:ref:`datalake-configuration-file`. 
You can create or update your {+dl+} storage configuration for an
|service| cluster data store using the :guilabel:`Visual Editor` or the
:guilabel:`JSON Editor`. For more information, see :ref:`deploy-atlas-datastore-datalake`.

{+dl+} automatically detects the file format and creates the virtual 
databases and collections you specified in your {+dl+} configuration. 
When you :doc:`connect </tutorial/connect>` to your {+dl+} and run 
queries, {+dl+} processes your queries against the data and returns the 
query results. 

If you query a collection in {+adl+} that is mapped to only one 
|service| collection, {+adl+} acts as a proxy and forwards your query 
to |service|. When acting as a proxy, {+adl+} doesn't scan data into 
its virtual collection to proces the query thus improving performance 
and reducing cost. This optimization is not available for queries on 
{+adl+} collections that are mapped to multiple |service| collections. 

.. example:: 

   Consider the following {+dl+} storage configuration: 

   .. code-block:: json

      {
        "stores" : [
          {
            "name" : "atlas-store",
            "provider": "atlas",
            "clusterName": "myCluster", 
            "projectId": "5e2211c17a3e5a48f5497de3"
          }
        ],
        "databases" : [
          {
            "name" : "atlas-db",
            "collections" : [
              {
                "name" : "foo",
                "dataSources" : [
                  {
                    "storeName" : "atlas-store",
                    "database" : "myFooData",
                    "collection" : "foo" 
                  }
                ]
              },
              {
                "name" : "barbaz",
                "dataSources" : [
                  {
                    "storeName" : "atlas-store",
                    "database" : "myBarData",
                    "collection" : "bar" 
                  },
                  {
                    "storeName" : "atlas-store",
                    "database" : "myBazData",
                    "collection" : "baz" 
                  }
                ]
              }
            ]
          }
        ]
      }

   For the above storage configuration, {+adl+} acts as a proxy for 
   queries on ``foo`` collection and forwards the queries to |service|. 
   This performance and cost optimization is not available for queries 
   on ``barbaz`` collection because ``barbaz`` is mapped to multiple 
   |service| collections.

You can also save your query results in your |service| cluster using 
:ref:`adl-out-stage` to |service|.

If you successfully create or update a document in your collection on 
the |service| cluster, {+dl+} returns the latest version of that 
document for any subsequent read requests and all list operations of 
the collection also reflect the changes. If your query contains 
multiple stages, each stage receives the most recent data available 
from the data store as that stage is processed.

.. _query-http:

Querying Data at a |http| or |https| |url| 
------------------------------------------

.. include:: /includes/extracts/fact-http-beta-message.rst

You can use {+adl+} to query and analyze data in files hosted at 
publicly accessible |url|\s. To query data in your publicly accessible 
|url|\s, your {+dl+} storage :ref:`configuration 
<datalake-configuration-file>` must contain settings that define: 

- Your |http| {+data-lake-store+}.
- {+dl+} virtual databases and collections that map to your 
  {+data-lake-store+}.

.. example::

   .. code-block:: json

      {
        "stores" : [
          {
            "name" : "<store-name>",
            "provider": "http",
            "urls": ["<url>"],
            "defaultFormat" : "<string>"
            "allowInsecure": <boolean>,
          }
        ],
        "databases" : [
          {
            "name" : "<database-name>",
            "collections" : [
              {
                "name" : "<collection-name>",
                "dataSources" : [
                  {
                    "storeName" : "<store-name>",
                    "urls" : ["<url>"],
                    "defaultFormat" : "<string>"
                    "allowInsecure" : <boolean>,
                  }
                ]
              }
            ]
          }
        ]
      }

To learn more about these settings, see 
:ref:`datalake-configuration-file`. 
You can create or update your {+dl+} storage configuration for an
|service| cluster data store using the :guilabel:`Visual Editor` or the
:guilabel:`JSON Editor`. For more information, see :ref:`deploy-http-datastore-datalake`.

{+dl+} creates the virtual databases and collections you specified in 
your {+dl+} configuration for the data in your |url|. {+dl+} also 
creates one partition for each |url| in your collection. When you 
:doc:`connect </tutorial/connect>` to your {+dl+} and run queries, 
{+dl+} processes your queries against the data and returns the query 
results.

.. _federated-queries:

Running Federated Queries 
-------------------------

You can use {+adl+} to query and analyze a unified view of data in your 
|service| cluster, |s3| bucket, and at your |http| URL. For federated 
queries, your {+dl+} storage :ref:`configuration 
<datalake-configuration-file>` must contain the settings that define: 

- Your |s3|, |service|, and |http| {+data-lake-stores+}.
- {+dl+} virtual databases and collections that map to your |s3|, 
  |service|, and |http| {+data-lake-store+}\s.

.. example:: 

   .. code-block:: json 

      {
        "stores" : [
          {
            "name" : "<atlas-store-name>",
            "provider": "atlas",
            "clusterName": "<atlas-cluster-name>", 
            "projectId": "<atlas-project-ID>"
          },
          {
            "name" : "<s3-store-name>",
            "provider" : "s3",
            "region" : "<aws-region>",
            "bucket" : "<s3-bucket-name>",
            "prefix" : "<file-path-prefix>",
            "delimiter" : "<path-separator>"
          },
          {
            "name" : "<store-name>",
            "provider": "http",
            "urls": ["<url>"],
            "defaultFormat" : "<string>"
            "allowInsecure": <boolean>,
          }
        ],
        "databases" : [
          {
            "name" : "<database-name>",
            "collections" : [
              {
                "name" : "<collection-name>",
                "dataSources" : [
                  {
                    "storeName" : "<atlas-store-name>",
                    "database" : "<atlas-database-name>",
                    "collection" : "<atlas-collection-name>" 
                  },
                  {
                    "storeName" : "<s3-store-name>",
                    "path" : "<path-to-file>"
                  },
                  {
                    "storeName" : "<store-name>",
                    "urls" : ["<url>"],
                    "defaultFormat" : "<string>"
                    "allowInsecure" : <boolean>,
                  }
                ]
              }
            ]
          }
        ]
      }

To learn more about these settings, see 
:ref:`datalake-configuration-file`.

When you :doc:`connect </tutorial/connect>` to your {+dl+} and run 
federated queries, {+dl+} combines data from your |service| cluster, 
|s3| bucket, and |http| store in virtual databases and collections and 
returns a union of data in the results. 

.. _query-troubleshooting:

Troubleshooting 
---------------

**Error:** We are currently experiencing increased query processing 
wait times for {+adl+}. Our Engineering team is investigating. Normal 
service will resume shortly, please try again.

{+adl+} returns this error only when {+adl+} can't execute queries 
because of resource contention. We recommend that you run your queries 
again.

.. toctree::
   :titlesonly:
   :hidden:

   /admin/optimize-query-performance
   /admin/determine-query-status
   /admin/terminate-running-query
   /query/view-query-history
   /query/download-query-logs
