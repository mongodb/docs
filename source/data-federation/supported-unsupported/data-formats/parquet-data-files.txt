.. _adf-parquet-data:

=======
Parquet 
=======

.. default-domain:: mongodb

.. meta::
   :keywords: $out to S3
   :description: Explore how Atlas Data Federation reads and writes Parquet data files, offering efficient storage and compatibility with analytics tools.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. _adf-parquet-data-format:

About Parquet Format 
--------------------

`Apache Parquet <https://parquet.apache.org/docs/>`_ is a free,
open-source file format that is popular for analytic workloads. Parquet
stores columns together, rather than rows. It's a fixed-schema format
with support for complex data structures like arrays and nested
documents. These features have the following advantages:

- **Performant queries**. Parquet is column-oriented, and therefore
  queries on Parquet data can be extremely performant. For example, a
  query that selects just one of thousands of columns can immediately
  extract that data from the Parquet file, rather than trying to find
  the desired value in each row.
- **Efficient storage**. Parquet stores columns contiguously, which
  enables very efficient compression. Parquet requires that the values
  in a given column must have the same type, and the values in a column
  are generally more similar than values in other columns. This enables
  a wider variety of encoding and compression schemes.
- **Compatibility with analytics tools**. Parquet files have a fixed
  schema, and therefore Parquet data is compatible with many analytics
  tools that require data in a tabular, fixed-schema format.

About Parquet for {+adf+} 
---------------------------------------

{+adf+} can read from and write to Parquet data files. 

- **Reading Parquet**. You can query Parquet data from |s3| with
  {+adf+}. These queries might be more performant than queries on other
  data formats. To learn more about why queries against Parquet data
  might be more performant than other data formats, see
  :ref:`adf-parquet-data-format`. 
- **Writing Parquet**. {+adf+} allows you to also write data to Parquet
  using the :ref:`$out to S3 <adf-out-stage>` stage. {+adf+}
  automatically infers what Parquet schema to use based on the MongoDB
  data that you are writing to Parquet. You can transform your data to
  Parquet data format if you want to query that data with another
  analytics tool such as a data warehouse.

  To learn more about how {+adf+} writes to Parquet file format during 
  :ref:`$out to S3 <adf-out-stage>` stage, see :ref:`Parquet File Format 
  <adf-out-stage-limitations>`.
