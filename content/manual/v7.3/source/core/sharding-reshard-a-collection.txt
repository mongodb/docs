.. _sharding-resharding:

====================
Reshard a Collection
====================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 3
   :class: singlecol

.. facet::
   :name: genre
   :values: tutorial

.. versionadded:: 5.0

The ideal shard key allows MongoDB to distribute documents evenly
throughout the cluster while facilitating common query patterns. A
suboptimal shard key can lead to performance or scaling issues due to
uneven data distribution. 

Starting in MongoDB 5.0, you can change the shard key for a collection to
change the distribution of your data across a cluster.

Starting in MongoDB 7.2, you can reshard a collection on the same shard key,
allowing you to redistribute data to include new shards or to different zones
without changing your shard key.

.. note::

   Before resharding your collection, read
   :ref:`shardkey-troubleshoot-shard-keys` for information on common
   performance and scaling issues and advice on how to fix them.

.. _resharding-limitations:

About this Task
---------------

- Only one collection can be resharded at a time.
- :rsconf:`writeConcernMajorityJournalDefault` must be ``true``.
- To reshard a collection that has a :ref:`uniqueness
  <index-type-unique>` constraint, the new shard key must satisfy
  the :ref:`unique index requirements <sharding-shard-key-unique>` for 
  any existing unique indexes.
- The following commands and corresponding shell methods are not
  supported on the collection that is being resharded while the
  resharding operation is in progress:

  - :dbcommand:`collMod`
  - :dbcommand:`convertToCapped`
  - :dbcommand:`createIndexes`
  - :method:`~db.collection.createIndex()`
  - :dbcommand:`drop`
  - :method:`~db.collection.drop()`
  - :dbcommand:`dropIndexes`
  - :method:`~db.collection.dropIndex()`
  - :dbcommand:`renameCollection`
  - :method:`~db.collection.renameCollection()`

- The following commands and methods are not supported on the cluster
  while the resharding operation is in progress:

  - :dbcommand:`addShard`
  - :dbcommand:`removeShard`
  - :method:`db.createCollection()`
  - :dbcommand:`dropDatabase`

  .. warning::

     Using any of the preceding commands during a resharding
     operation causes the resharding operation to fail.

- If the collection to be resharded uses :atlas:`Atlas Search
  </atlas-search>`, the search index will become unavailable when the
  resharding operation completes. You need to manually rebuild the
  search index once the resharding operation completes.

- You can't reshard a sharded :ref:`time series collection
  <manual-timeseries-collection>`.

.. _reshard-requirements:

Before you Begin
----------------

Before you reshard your collection, ensure that you meet the following
requirements:

- Your application can tolerate a period of **two seconds** where the
  collection that is being resharded blocks writes. During the time
  period where writes are blocked your application experiences an
  increase in latency. If your workload cannot tolerate this
  requirement, consider :ref:`refining your shard key
  <shard-key-refine>` instead.
- Your database meets these resource requirements:

  - Available storage space: Ensure that the available storage
    space on each shard the collection will be distributed
    across is at least twice the size of the collection
    that you want to reshard and its total index size, divided
    by the number of shards. 

    .. code-block:: none
       :copyable: false

       storage_req = ( ( collection_size + index_size ) * 2 ) / shard_count

    For example, consider a collection that contains 2 TB of
    data and has a 400 GB index distributed across four shards.
    To perform a resharding operation on this collection, each
    shard would require 1.2 TB of available storage.

    .. code-block:: none
       :copyable: false

       1.2 TB storage = ( ( 2 TB collection + 0.4 TB index ) * 2 ) / 4 shards

    To meet storage requirements, you may need to upgrade to
    the next tier of storage during the resharding operation.
    You can scale down once the operation completes.

  -  I/O: Ensure that your I/O capacity is below 50%.
  -  CPU load: Ensure that your CPU load is below 80%.

  .. important::

     These requirements are not enforced by the database. A failure to
     allocate enough resources can result in:

     - the database running out of space and shutting down
     - decreased performance
     - the resharding operation taking longer than expected

     If your application has time periods with less traffic, reshard your
     collection during that time if possible.

- You must rewrite your application's queries to use **both** the
  current shard key and the new shard key.

  .. tip::

     If your application can tolerate downtime, you can perform these
     steps to avoid rewriting your application's queries to use both the
     current and new shard keys:
     
     #. Stop your application.
     
     #. Rewrite your application to use the **new** shard key.

     #. Wait until resharding completes. To monitor the resharding
        process, use the :pipeline:`$currentOp` pipeline stage.
     
     #. Deploy your rewritten application.

  Before resharding completes, the following queries return an error if
  the query filter does not include either the current shard key or a
  unique field (like ``_id``):

  - :method:`~db.collection.deleteOne()`
  - :method:`~db.collection.findAndModify()`
  - :method:`~db.collection.findOneAndDelete()`
  - :method:`~db.collection.findOneAndReplace()`
  - :method:`~db.collection.findOneAndUpdate()`
  - :method:`~db.collection.replaceOne()`
  - :method:`~db.collection.updateOne()`

  For optimal performance, we recommend that you also rewrite other
  queries to include the new shard key.

  Once the resharding operation completes, you can remove the old shard
  key from the queries.

- No index builds are in progress. Use ``db.currentOp()`` to
  check for any running index builds:

  .. code-block:: javascript
     :copyable: false

     db.adminCommand(
        {
          currentOp: true,
          $or: [
            { op: "command", "command.createIndexes": { $exists: true }  },
            { op: "none", "msg" : /^Index Build/ }
          ]
        }
    )

  In the result document, if the ``inprog`` field value is an empty
  array, there are no index builds in progress:

  .. code-block:: javascript
     :copyable: false

     {
        inprog: [],
        ok: 1,
        '$clusterTime': { ... },
        operationTime: <timestamp>
     }

.. note::

    Resharding is a write-intensive process which can generate increased rates 
    of oplog. You may wish to:

    - set a fixed oplog size to prevent unbounded oplog growth.
    - increase the oplog size to minimize the chance that one or more
      secondary nodes becomes stale.
    
    See the :ref:`replica-set-oplog` documentation for more details.

.. _resharding_process:

Steps
-----

.. important::

   We strongly recommend that you check the
   :ref:`resharding-limitations` and read the :ref:`resharding_process`
   section in full before resharding your collection.

.. include:: /includes/reshard-collection-introduction.rst

.. include:: /includes/steps/reshard-a-collection.rst

Behavior
--------

Minimum Duration of a Resharding Operation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The minimum duration of a resharding operation is always 5 minutes.

Retryable Writes
~~~~~~~~~~~~~~~~

:ref:`Retryable writes <retryable-writes>` initiated before or during
resharding can be retried during and after the collection has been
resharded for up to 5 minutes. After 5 minutes you may be unable to find
the definitive result of the write and subsequent attempts to retry the
write fail with an ``IncompleteTransactionHistory`` error.

Error Case
----------

Duplicate ``_id`` Values
~~~~~~~~~~~~~~~~~~~~~~~~

The resharding operation fails if ``_id`` values are not globally unique
to avoid corrupting collection data. Duplicate ``_id`` values can also
prevent successful chunk migration. If you have documents with duplicate
``_id`` values, copy the data from each into a new document, and then
delete the duplicate documents.
