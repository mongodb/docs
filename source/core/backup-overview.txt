============
Backup Flows
============

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Introduction
------------

|mms| Backup's process for keeping a backup in sync with your
deployment is analogous to the process used by a secondary to replicate
data in a :term:`replica set`. Backup first performs an :term:`initial
sync` to catch up with your deployment and then tails the :term:`oplog`
to remain current. Backup takes scheduled snapshots to keep a history
of the data.

Blockstore Storage
~~~~~~~~~~~~~~~~~~

.. include:: /images/backup-flow-blockstore.rst

File System Storage
~~~~~~~~~~~~~~~~~~~

.. include:: /images/backup-flow-filesystem-storage.rst

File System storage gives you full control over your data, allowing you
to reduce the number of MongoDB instances you need to run and enabling
you to take advantage of existing storage infrastructure. With
filesystem storage, you can access the backed-up data files using
standard filesystem utilities, rather than having to retrieve them
through the |mms| interface.

With filesystem storage, you can select any mountable filesystem to
which |mms| writes the snapshots. 

If you use file system snapshot storage and use multiple |onprem|
instances (including those activated as Backup Daemons), all |onprem|
instances must have the same view of the file system snapshot storage.
You can achieve this through a Network File System (NFS) application or
something similar.

Operation Log Storage
~~~~~~~~~~~~~~~~~~~~~

With either a Blockstore or File System Store, you must create an
:term:`oplog store <Oplog Store Database>` database. It stores your
:term:`oplog` for processing. When you add either a blockstore or a
filesystem store, |mms| prompts you to specify the database for your
oplogs.

.. include:: /includes/important-multiple-instances-share-view-filesystem-snapshots.rst

.. TODO: link to the installation tutorial where it talks about
   picking the snapshot store.

.. _backup-initial-sync:

Initial Sync
------------

Transfer of Data and Oplog Entries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When you start a backup, the Backup Agent streams your deployment's
existing data to |mms| in batches of documents, totaling roughly 10 MB
each, called **slices**. Slices contain only the data as it existed
when you started the backup.

While transferring the data, the Backup Agent tails the :term:`oplog`
and streams the oplog updates to |mms|. |mms| then stores the oplog
entries in the oplog database for later processing offline.

Building the Backup
~~~~~~~~~~~~~~~~~~~

When |mms| has received all of the slices, it creates a local database
on its server and inserts the documents that were captured as slices
during the initial sync. |mms| then applies the oplog entries from
the oplog store.

|mms| then validates the data. If there are missing documents, |mms|
queries the deployment for the documents and inserts them. A missing
document could occur because of an update that caused a document to
move during the initial sync.

Once |mms| validates the accuracy of the data directory, it has
completed the initial sync process and proceeds to routine operation.

Initial Sync Phases
~~~~~~~~~~~~~~~~~~~

Backups go through a series of phases during backup. The first backup
is called the initial synchronization (``initialSync``). If you click
the :guilabel:`Backup` button, you are presented with the list of
backup jobs in progress. During ``initialSync``, they proceed through
these phases in the following order:

.. list-table::
   :widths: 20 50 30
   :header-rows: 1

   * - State

     - Description

     - Measure of Progress

   * - ``starting``

     - Waiting phase until |mms| receives sync slices.

     - None

   * - ``transferring``

     - Shows progress one namespace at a time. 

     - 
       * A ratio of ingested documents to total documents.

       * A percentage of documents ingested. 

   * - ``building``

     - |mms| has started building the deployment ``HEAD`` database. 

       .. note:: 
          As of Backup Agent 4.0 and |onprem| 2.0, this happens in the
          background during the ``transferring`` phase, but the UI
          shows the ``transferring`` phase until all slices are
          received.

     - The percentage of the entire ``HEAD`` database that has been
       built.

   * - ``applying oplogs``

     - |mms| has completed building the ``HEAD`` database. |mms| is
       applying the oplog entries to catch up with the customer's oplog
       at the point that the previous phase completed.

     - The percentage of slices currently applied. 

   * - ``fetching missing documents``

     - |mms| queries the customers deployment for documents missed
       during the ``building`` and ``applying oplogs`` phases.

     - The percentage of slices currently applied.

   * - ``creating indexes``

     - |mms| creates all the indexes of the customer's deployment.

     - 
       * The index currently being processed.
       * A percentage of total indexes processed so far.

   * - ``complete``

     - The backup ``initialSync`` job has completed.

     -


Routine Operation
-----------------

The Backup Agent tails the deployment's oplog and routinely batches and
transfers new oplog entries to the |http-service|, which stores them in
the oplog store. The Backup Daemon applies all
newly-received oplog entries in batches to its local replica of the
backed-up deployment.

Snapshots
---------

The Backup Daemon takes a snapshot of the data directory for the
backed-up deployment regularly, as specified by the :ref:`snapshot
schedule <snapshot-frequency-and-retention>`. The Backup daemon takes
the snapshot and transfers it to the snapshot storage.
For a sharded cluster, the daemon takes a snapshot of
each shard and of the config servers. The daemon can also use
:ref:`checkpoints <checkpoint>` to synchronize the shards and config
servers for custom snapshots. You must first :ref:`enable checkpoints
<enable-cluster-checkpoints>`.

When a user requests a snapshot, a Backup Daemon retrieves the data
from the snapshot storage and delivers it to the requested destination.

.. seealso::
   :doc:`/core/restore-overview` for an overview of the restore process.

Grooms
------

Groom jobs perform periodic "garbage collection" on the snapshot
storage to reclaim space from deleted snapshots. A scheduling process
determines when grooms are necessary.
