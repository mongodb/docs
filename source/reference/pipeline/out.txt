.. _adl-out-stage:

========
``$out``
========

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. |out| replace:: :manual:`$out </reference/operator/aggregation/out>`
.. |convert| replace:: :manual:`$convert </reference/operator/aggregation/convert>`


|out| takes documents returned by the aggregation pipeline and writes
them to a specified collection. The |out| operator must be the last
stage in the
:manual:`aggregation pipeline </reference/operator/aggregation-pipeline/>`.
In {+adl+}, |out| can be used to write to |s3| buckets with read and
write permissions or to an |service| cluster
:manual:`namespace </reference/limits/#faq-dev-namespace>`.

.. seealso::

   |out|

.. tabs::

   .. tab:: S3
      :tabid: s3

   .. tab:: Atlas Cluster
      :tabid: atlas


.. _adl-out-stage-perms:

Permissions Required
--------------------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      You must have:

      - A {+dl+} configured for |s3| bucket with read and write
        permissions or
        :aws:`s3::PutObject </AmazonS3/latest/dev/using-with-s3-actions.html#using-with-s3-actions-related-to-objects>`
        permissions.
      - A MongoDB user with :authrole:`readWriteAnyDatabase` role.

   .. tab:: Atlas Cluster
      :tabid: atlas

      You must be a database user with one of the following roles:

      - :authrole:`readWriteAnyDatabase`
      - :authrole:`readAnyDatabase`
      - :atlasrole:`atlasAdmin`
      - A custom role with the following privileges:

        - :manual:`insert </reference/privilege-actions/#insert>` and
        - :manual:`remove </reference/privilege-actions/#remove>`

.. _adl-out-stage-syntax:

Syntax
------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      .. code-block:: json
         :linenos:

         {
           "$out": {
             "s3": {
               "bucket": "<bucket-name>",
               "region": "<aws-region>",
               "filename": "<file-name>",
               "format": {
                 "name": "json|json.gz|bson|bson.gz",
                 "maxFileSize": "<file-size>"
               }
             }
           }
         }

   .. tab:: Atlas Cluster
      :tabid: atlas

      .. code-block:: json
         :linenos:

         {
           "$out": {
             "atlas": {
               "projectId": "<atlas-project-ID>",
               "clusterName": "<atlas-cluster-name>",
               "db": "<atlas-database-name>",
               "coll": "<atlas-collection-name>"
             }
           }
         }

.. _adl-out-stage-fields:

Fields
------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      .. list-table::
         :header-rows: 1
         :widths: 10 10 70 10

         * - Field
           - Type
           - Description
           - Necessity

         * - ``s3``
           - object
           - Location to write the documents from the aggregation
             pipeline.
           - Required

         * - ``s3.bucket``
           - string
           - Name of the |s3| bucket to write the documents from
             the aggregation pipeline to.

             .. important::

                The generated call to |s3| inserts a ``/`` between
                ``s3.bucket`` and ``s3.filename``. Don't append a
                ``/`` after the ``s3.bucket``.

                .. example::

                   If you set ``s3.bucket`` to ``myBucket`` and
                   ``s3.filename`` to ``myPath/myData``, {+adl+} writes
                   this out as ``s3://myBucket/myPath/myFile``

           - Required

         * - ``s3.region``
           - string
           - Name of the |aws| region in which the bucket is hosted.
           - Required

         * - ``s3.filename``
           - string
           - Name of the file to write the documents from the
             aggregation pipeline to. Filename can be constant or
             :ref:`created dynamically <adl-out-stage-egs>` from the
             fields in the documents that reach the |out| stage. Any
             filename expression you provide must evaluate to a
             ``string`` data type.

             .. important::

                The generated call to |s3| inserts a ``/`` between
                ``s3.bucket`` and ``s3.filename``. Don't prepend a
                ``/`` before the ``s3.filename``.

                .. example::

                   If you set ``s3.bucket`` to ``myBucket`` and
                   ``s3.filename`` to ``myPath/myData``, {+adl+} writes
                   this out as ``s3://myBucket/myPath/myFile``

           - Required

         * - ``s3.format``
           - object
           - Details of the file in |s3|.
           - Required

         * - | ``s3``
             | ``.format``
             | ``.name``
           - enum
           - Format of the file in |s3|. Value can be one of the
             following:

             - ``json``
             - ``json.gz``
             - ``bson``
             - ``bson.gz``

           - Required

         * - | ``s3``
             | ``.format``
             | ``.maxFileSize``
           - bytes
           - Maximum size of the file in |s3|. When the file size limit
             for the current file is reached, a new file is created in
             |s3|. The first file appends a ``1`` before the filename
             extension. For each subsequent file, the {+adl+} increments
             the appended number by one.

             .. example::

                ``<filename>.1.<fileformat>``

                ``<filename>.2.<fileformat>``

             If a document is larger than the ``maxFileSize``, {+dl+}
             writes the document to its own file. The following
             suffixes are supported:

             .. list-table::
                :widths: 30 70

                * - Base 10: scaling in multiples of 1000
                  - - ``B``
                    - ``KB``
                    - ``MB``
                    - ``GB``
                    - ``TB``
                    - ``PB``
                * - Base 2: scaling in multiples of 1024
                  - - ``KiB``
                    - ``MiB``
                    - ``GiB``
                    - ``TiB``
                    - ``PiB``

             If omitted, defaults to ``200MiB``.

           - Optional

   .. tab:: Atlas Cluster
      :tabid: atlas

      .. list-table::
         :header-rows: 1
         :widths: 10 10 70 10

         * - Field
           - Type
           - Description
           - Necessity

         * - ``atlas``
           - object
           - Location to write the documents from the aggregation
             pipeline.
           - Required

         * - ``clusterName``
           - string
           - Name of the |service| cluster.
           - Required

         * - ``coll``
           - string
           - Name of the collection on the |service| cluster.
           - Required

         * - ``db``
           - string
           - Name of the database on the |service| cluster that contains
             the collection.
           - Required

         * - ``projectId``
           - string
           - Unique identifier of the project that contains the
             |service| cluster. The project ID must be the ID of the
             project that contains your {+dl+}. If omitted, defaults to
             the ID of the project that contains your {+dl+}.
           - Optional

.. _adl-out-stage-egs:

Examples
--------

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      The following examples show |out| syntaxes for dynamically
      creating a filename from a constant string or from the fields of
      the same or different data types in the documents that reach the
      |out| stage.

      **Simple String Example**

      .. example::

         You want to write 1 GiB of data as a compressed |bson| file to
         an |s3| bucket named ``my-s3-bucket``.

         Using the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": "big_box_store/",
                  "format": {
                    "name": "bson.gz"
                  }
                }
              }
            }

         |out| writes five compressed |bson| files:

         1. The first 200 MiB of data to a file that |out| names
            ``big_box_store.bson.gz``.

            As you didn't change the maximum file size using
            ``s3.format.maxFileSize``, {+adl+} uses the default value
            of 200 MiB.

         2. The second 200 MiB of data to a new file that |out| names
            ``big_box_store/1.bson.gz``.

            The value of ``s3.filename`` serves as a constant in each
            filename.

            Your ``s3.filename`` included a delimiter, so {+adl+}
            includes it in the filename before incrementing the counter.

            If it didn't include a delimiter, {+adl+} would have added
            a ``.`` in its place, like ``big_box_store.1.bson.gz``

         3. Three more files that |out| names
            ``big_box_store/2.bson.gz`` through
            ``big_box_store/4.bson.gz``.

      **Single Field from Documents**

      .. example::

         You want to write 90 MiB of data as a |json| file to an |s3|
         bucket named ``my-s3-bucket``.

         Using the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {"$toString": "$sale-date"},
                  "format": {
                    "name": "json",
                    "maxFileSize": "100MiB"
                  }
                }
              }
            }

         |out| writes 90 MiB of data to a |json| file in the root
         of the bucket. |out| names each file using each document's
         ``sale-date`` value converted to a string.

      **Multiple Fields from Documents**

      .. example::

         You want to write 176 MiB of data as a compressed |bson| file
         to an |s3| bucket named ``my-s3-bucket``.

         Using the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {
                    "$concat": [
                      "persons/",
                      "$name", "/",
                      "$unique-id"
                    ]
                  },
                  "format": {
                    "name": "bson",
                    "maxFileSize": "200MiB"
                  }
                }
              }
            }

         |out| writes 176 MiB of data to a |bson| file. To name the
         file, |out| concatenates:

         - A constant string ``persons/`` and, from the documents:
           - The string value of the ``name`` field,
           - A forward slash (``/``), and
           - The string value of the ``unique-id`` field.

      **Multiple Types of Fields from Documents**

      .. example::

         You want to write 154 MiB of data as a compressed |json| file
         to an |s3| bucket named ``my-s3-bucket``.

         Consider the following |out| syntax:

         .. code-block:: json
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {
                    "$concat": [
                      "big-box-store/",
                      {
                        "$toString": "$store_number"
                      }, "/",
                      {
                        "$toString": "$sale-date"
                      }, "/",
                      "$part-id"
                    ]
                  },
                  "format": {
                    "name": "json.gz",
                    "maxFileSize": "200MiB"
                  }
                }
              }
            }

         |out| writes 154 MiB of data to a compressed |json| file.  To
         name the file, |out| concatenates:

         - A constant string value of ``big-box-store``,
         - A string value of a unique store number in the
           ``store-number`` field,
         - A string value of the date from the ``sale-date`` field, and
         - A string value of part ID from the ``part-id`` field.

   .. tab:: Atlas Cluster
      :tabid: atlas

      The following example shows the |out| syntax for sending the
      aggregated data to a ``sampleDB.mySampleData`` collection in the
      |service| cluster named ``myTestCluster``. In the following
      syntax, the project ID is not specified and therefore |out|
      uses the ID of the project that contains your {+dl+}.

      .. code-block:: json
         :linenos:

         {
           "$out": {
             "atlas": {
               "clusterName": "myTestCluster",
               "db": "sampleDB",
               "coll": "mySampleData"
             }
           }
         }

.. _adl-out-stage-limitations:

.. tabs::
   :hidden:

   .. tab:: S3
      :tabid: s3

      **Limitations**

      {+dl+} interprets empty strings (``""``) as null values when
      parsing filenames. If you want {+dl+} to generate filenames that
      it can parse correctly, you must wrap the field references that
      could have null values using |convert| with an empty
      string ``onNull`` value.

      .. example::

         This example shows how to handle null values in the ``$year``
         field when creating a filename from the field value.

         .. code-block:: json
            :copyable: false
            :linenos:

            {
              "$out": {
                "s3": {
                  "bucket": "my-s3-bucket",
                  "region": "us-east-1",
                  "filename": {
                    "$concat": [
                      "big-box-store/",
                      {
                        "$convert": {
                          "input": "$year",
                          "to": "string",
                          "onNull": ""
                        }
                      }
                    ]
                  },
                  "format": {
                    "name": "json.gz",
                    "maxFileSize": "200MiB"
                  }
                }
              }
            }

      **Errors**

      - If the filename is not of type string, {+dl+} writes documents
        to a special error file in your bucket.

      - If the documents cannot be written to a file with the specified
        filename, {+dl+} writes documents to ordinally-named files in
        the specified format and specified size.

        .. example::

          - ``s3://<bucket-name>/atlas-data-lake-{<CORRELATION_ID>}/$out-error-docs/1.json``
          - ``s3://<bucket-name>/atlas-data-lake-{<CORRELATION_ID>}/$out-error-docs/2.json``

        {+dl+} returns an error message that specifies the number of
        documents that had invalid filenames and the directory where
        these documents were written.

   .. tab:: Atlas Cluster
      :tabid: atlas
