ref: concurrent-operations-read-uncommitted
content: |
  In MongoDB, clients can see the results of writes before the writes
  are :term:`durable`:

  .. include:: /includes/list-visibility-of-data.rst

# The include file has the following content:
#
#  - Regardless of :doc:`write concern </reference/write-concern>`,
#    other clients can see the result of the write operations before
#    the write operation is acknowledged to the issuing client.
#
#  - Clients can read data which may be subsequently :doc:`rolled back
#    </core/replica-set-rollbacks>`.

---
ref: concurrent-operations-single-document-write
content: |
   Write operations are atomic with respect to a single document; i.e.
   if a write is updating multiple fields in the document, a reader
   will never see the document with only some of the fields updated.

   With a single :program:`mongod` instance, a set of read and write
   operations to a single document is serializable. With replica sets,
   *only* in the absence of a rollback, is a set of read and write
   operations to a single document serializable.
---
ref: concurrent-operations-multi-document-writes
content: |
   When a single write operation modifies multiple documents, the
   modification of each document is atomic, but the operation as a whole
   is not atomic and other operations may interleave. However, you can
   *isolate* a single write operation that affects multiple documents
   using the :update:`$isolated` operator. 
---
ref: concurrent-operations-multi-document-writes-no-isolation
content: |

   #. Non-point-in-time read operations. Suppose a read operation
      begins at time *t*\ :sub:`1` and starts reading documents. A
      write operation then commits an update to one of the documents at
      some later time *t*\ :sub:`2`. The reader may see the updated
      version of the document, and therefore does not see a
      point-in-time snapshot of the data.

   #. Non-serializable operations. Suppose a read operation reads a
      document *d*\ :sub:`1` at time *t*\ :sub:`1` and a write
      operation updates *d*\ :sub:`1` at some later time *t*\ :sub:`3`.
      This introduces a read-write dependency such that, if the
      operations were to be serialized, the read operation must precede
      the write operation. But also suppose that the write operation
      updates document *d*\ :sub:`2` at time *t*\ :sub:`2` and the read
      operation subsequently reads *d*\ :sub:`2` at some later time
      *t*\ :sub:`4`. This introduces a write-read dependency which
      would instead require the read operation to come *after* the
      write operation in a serializable schedule. There is a dependency
      cycle which makes serializability impossible.

   #. Dropped results for MMAPv1. For MMAPv1, reads may miss matching
      documents that are updated or deleted during the course of the
      read operation. However, data that has not been modified during
      the operation will always be visible.
---
ref: concurrent-operations-isolate-operator
content: |
   Using the :update:`$isolated` operator, a write operation that affects
   multiple documents can prevent other processes from interleaving once
   the write operation modifies the first document. This ensures that no
   client sees the changes until the write operation completes or errors
   out.

   :update:`$isolated` does **not** work with :term:`sharded clusters
   <sharded cluster>`.

   An isolated write operation does not provide "all-or-nothing" atomicity.
   That is, an error during the write operation does not roll back all
   its changes that preceded the error.

   .. note::

      :update:`$isolated` operator causes write operations to acquire
      an exclusive lock on the collection, *even for document-level
      locking storage engines* such as WiredTiger. That is,
      :update:`$isolated` operator will make WiredTiger single-threaded
      for the duration of the operation.
---
ref: monotonic-reads
content: |
   MongoDB provides monotonic reads from a standalone :program:`mongod`
   instance. Suppose an application performs a sequence of operations
   that consists of a read operation *R*\ :sub:`1` followed later in
   the sequence by another read operation *R*\ :sub:`2`. If the
   application performs the sequence on a standalone :program:`mongod`
   instance, the later read *R*\ :sub:`2` never returns results that
   reflect an earlier state than that returned from *R*\ :sub:`1`; i.e.
   *R*\ :sub:`2` returns data that is monotonically increasing in
   recency from *R*\ :sub:`1`.

   .. versionchanged:: 3.2

      For replica sets and sharded clusters, MongoDB provides monotonic
      reads if read operations specify :doc:`/reference/read-concern`
      ``"majority"`` and read preference :readmode:`primary`.

      In previous versions, MongoDB cannot make monotonic read
      guarantees from replica sets and sharded clusters.

---
ref: monotonic-writes
content: |
   MongoDB provides  monotonic write guarantees for standalone
   :program:`mongod` instances, replica sets, and sharded clusters.

   Suppose an application performs a sequence of operations that
   consists of a write operation *W*\ :sub:`1` followed later in the
   sequence by a write operation *W*\ :sub:`2`. MongoDB guarantees that
   *W*\ :sub:`1` operation precedes *W*\ :sub:`2`.
---
ref: replica-read-consistency-single-primary
content: |

  In MongoDB, in a replica set with one primary member
  [#edge-cases-2-primaries]_,

  - With :readconcern:`"local"` ``readConcern``, reads from the
    primary reflect the latest writes in absence of a failover; 

  - With :readconcern:`"majority"` ``readConcern``, read operations
    from the primary or the secondaries have :term:`eventual
    consistency`.
---
ref: isolate-cursor-snapshot
content: |

   MongoDB cursors can return the same document more than once in some
   situations. As a cursor returns documents other operations may
   interleave with the query. If some of these operations are
   :doc:`updates </core/write-operations>` that cause the document to
   move (in the case of MMAPv1, caused by document growth) or that
   change the indexed field on the index used by the query; then the
   cursor will return the same document more than once.

   In very specific cases, you can isolate the cursor from returning
   the same document more than once by using the
   :method:`cursor.snapshot()` method. For more information, see
   :ref:`faq-developers-isolate-cursors`.

---
ref: lock-general
content: |
    MongoDB uses multi-granularity locking [#mgl-ref]_ that allows
    operations to lock at the global, database or collection level, and
    allows for individual storage engines to implement their own
    concurrency control below the collection level (e.g., at the
    document-level in WiredTiger).

    MongoDB uses reader-writer locks that allow concurrent readers
    shared access to a resource, such as a database or collection, but
    in MMAPv1, give exclusive access to a single write operation.
---
ref: lock-sharding
content: |
   In a sharded cluster, locks apply to each individual shard, not to
   the whole cluster; i.e. each :program:`mongod` instance is
   independent of the others in the shard cluster and uses its own
   :ref:`locks <faq-concurrency-locking>`. The operations on one
   :program:`mongod` instance do not block the operations on any others.
---
ref: lock-replica-set-primary
content: |
   When writing to a :term:`replica set`, the lock's scope
   applies to the :term:`primary`.
...
