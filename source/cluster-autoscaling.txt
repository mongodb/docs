.. _cluster-autoscaling:

======================
Configure Auto-Scaling
======================

.. default-domain:: mongodb

.. facet::
   :name: genre
   :values: reference

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. include:: /includes/fact-auto-scaling-availability.rst

You can configure the {+cluster+} tier ranges that |service| uses to
automatically scale your {+cluster+} tier, storage capacity, or both in
response to {+cluster+} usage.

|service| auto-scaling adjusts {+cluster+} tier based on real-time resource
usage. The improved auto-scaling engine can now more accurately detect
sustained higher demand and short-term peak traffic for upscaling decisions.
Similarly, |service| makes downscaling choices more promptly, for more
optimized resource utilization and cost profile.

To help control costs, you can specify a range of maximum and minimum
{+cluster+} sizes that your {+cluster+} can automatically scale to.

Auto-scaling works on a rolling basis, and the process doesn't incur any 
downtime. {+service+} maintains a primary during this process but the 
nodes are upgraded one by one and will be unavailable while being 
upgraded. 

.. _howitworks-scale-cluster-tier:
.. _system-memory-calculation:

How |service| Scales {+Cluster+} Tier
-------------------------------------

.. note:: Tier Availability

   Automatic scaling works on {+cluster+} tiers in :guilabel:`General` and
   :guilabel:`Low-CPU` classes, but *not* on {+clusters+} in
   the :guilabel:`Local NVMe SSD` class.

|service| analyzes the following {+cluster+} metrics to
determine when to scale a {+cluster+}, and whether to scale the
{+cluster+} tier up or down:

- Normalized System CPU Utilization

- System Memory Utilization

|service| calculates system System Memory Utilization based on available node memory
and total memory as follows:

(``memoryTotal`` - (``memoryFree`` + ``memoryBuffers`` + ``memoryCached``)) / (``memoryTotal``) * 100

In the previous calculation, ``memoryFree``, ``memoryBuffers``, and ``memoryCached`` are
amounts of available memory that |service| can reclaim for other
purposes. To learn more, see :guilabel:`System Memory` in
:ref:`review-available-metrics`.

|service| won't scale your {+cluster+} tier if the new {+cluster+} 
tier would fall outside of your specified :guilabel:`Minimum` and 
:guilabel:`Maximum Cluster Size` range. 

|service| scales your {+cluster+} to another tier in the same class.
For example, |service| scales :guilabel:`General` {+clusters+}
to other :guilabel:`General` {+cluster+} classes, but doesn't scale 
:guilabel:`General` {+clusters+} to :guilabel:`Low-CPU` {+cluster+}
classes.

The exact auto-scaling criteria are subject to change in order to ensure
appropriate cluster resource utilization.

.. include:: /includes/fact-auto-scaling-and-migration.rst

If you deploy :term:`read-only nodes <read-only node>` and want your
{+cluster+} to scale faster, consider adjusting your :ref:`Replica
Set Scaling Mode <replica-set-scaling-mode>`.

Scaling Up a {+Cluster+} Tier
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To effectively manage dynamic workloads for your applications, |service|
scales up nodes in your {+cluster+} under the conditions described in this
section.

If the next {+cluster+} tier is within your :guilabel:`Maximum Cluster Size`
range, |service| scales :term:`operational nodes <operational node>` in your
{+cluster+} up to the next tier if at least *one* of the following criteria
is true for *any* {+cluster+} node of this type.

.. note::

  The following list groups together CPU-related criteria, followed by
  the memory-related criteria. Within each group, criteria appear in
  the order from most restrictive to least restrictive, and criteria for
  specific cloud providers appear first, if they exist.

- ``M10`` and ``M20`` {+clusters+}:

  - |aws|. The average normalized :term:`Relative System CPU Utilization <relative system CPU utilization>`
    has exceeded 90% for the past 20 minutes and the average non-normalized
    :term:`Absolute System CPU Utilization <absolute system CPU utilization>`
    for :term:`CPU steal` has exceeded 30% for the past 3 minutes.

  - |azure|. The average normalized :term:`Relative System CPU Utilization <relative system CPU utilization>`
    has exceeded 90% for the past 20 minutes and the average non-normalized
    :term:`Absolute System CPU Utilization <absolute system CPU utilization>`
    for :term:`softIRQ` has exceeded 10% for the past 3 minutes.

  - The average normalized :term:`Absolute System CPU Utilization <absolute system CPU utilization>`
    has exceeded 90% of resources available to the {+cluster+} for the past 20 minutes.

  - The average normalized :term:`Relative System CPU Utilization <relative system CPU utilization>`
    has exceeded 75% of resources available to the {+cluster+} for the past one hour.

  - The average :guilabel:`System Memory Utilization` has exceeded 90% of resources
    available to the {+cluster+} for the past 10 minutes. To learn how
    |service| calculates the amount of system memory utilization, see
    :ref:`system-memory-calculation`.

  - The average :guilabel:`System Memory Utilization` has exceeded 75% of
    resources available to the {+cluster+} for the past one hour.

- ``M30+`` {+clusters+}:

  - The average :guilabel:`System CPU Utilization` has exceeded 90% of
    resources available to the {+cluster+} for the past 10 minutes.

  - The average :guilabel:`System CPU Utilization` has exceeded 75% of
    resources available to the {+cluster+} for the past one hour.

  - The average :guilabel:`System Memory Utilization` has exceeded 90% of
    resources available to the {+cluster+} for the past 10 minutes.

  - The average :guilabel:`System Memory Utilization` has exceeded 75% of
    resources available to the {+cluster+} for the past one hour.

These thresholds ensure that your {+cluster+} scales up quickly in
response to high loads, and your application can handle spikes in
traffic or usage, maintaining its performance and reliability.

.. note::

   The conditions in this section describe operational nodes.
   For :term:`analytics nodes <analytics node>` on any cloud provider,
   |service| scales them up to the next tier if the average normalized
   :guilabel:`System CPU Utilization` or
   the :guilabel:`System Memory Utilization` has exceeded 75% of resources
   available to any {+cluster+} node for the past one hour.

To achieve optimal resource utilization and cost profile, |service| avoids
scaling up the {+cluster+} to the next tier if:

- The ``M10`` or ``M20`` {+cluster+} has been scaled up in the past 20 minutes
  or one hour, depending on thresholds.
- The ``M30+`` {+cluster+} has been scaled up in the past 10 minutes
  or one hour, depending on thresholds.

For example, if the cluster tier has not been changed since ``12:00``,
|service| will scale an ``M30+`` {+cluster+} at ``12:10``, if the
{+cluster+}\'s current normalized System CPU Utilization is greater than 90%.

.. important:: Sudden Workload Spikes

   Scaling up to a greater {+cluster+} tier requires enough time to
   prepare backing resources. Automatic scaling may not occur when a
   {+cluster+} receives a burst of activity, such as a bulk insert.
   To reduce the risk of running out of resources, plan to scale up
   {+clusters+} before bulk inserts and other workload spikes.

Scaling Down a {+Cluster+} Tier
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To optimize costs, |service| scales down nodes in your {+cluster+} under
the conditions described in this section.

If the next lowest {+cluster+} tier is within your
:guilabel:`Minimum Cluster Size` range, |service| scales the nodes in your
{+cluster+} down to the next lowest tier if *all* of the following criteria
are true for *all* nodes of the specified {+cluster+} type:

- :term:`Operational nodes <operational node>`:

  - The average normalized :guilabel:`System CPU Utilization` is below 45% of resources
    available to the {+cluster+} over at least the last 10 minutes **AND**
    the last 4 hours. |service| uses the "4 hours average" checkpoint as
    an indication that the CPU load has settled down on the observed level.
    |service| uses the "10 minutes average" checkpoint as an indication
    that no recent CPU spikes have occurred that |service| didn't capture
    with the "4 hour average" checkpoint.

  - The average :manual:`WiredTiger cache </reference/command/serverStatus/#serverstatus.wiredTiger.cache>`
    usage is below 90% of the maximum WiredTiger cache size for at least
    the last 10 minutes **AND** the last 4 hours at the **current** {+cluster+}
    tier size. This indicates to |service| that the current {+cluster+} isn't overloaded.

  - The **projected total System Memory Utilization** at the new lower {+cluster+}
    tier is below 60% for at least the last 10 minutes **AND** the last 4 hours.
    |service| calculates the **projected total memory usage** mentioned
    in the preceding statement as follows.

    |service| measures the current memory usage and replaces the current
    :manual:`WiredTiger cache </reference/command/serverStatus/#serverstatus.wiredTiger.cache>`
    usage size with 80% of the WiredTiger cache size on the **new** lower tier {+cluster+}.

    Next, |service| checks whether the **projected total memory usage**
    would be below 60% for at least the last 4 hours and at least the
    last 10 minutes on the new tier size.

    .. note::

       |service| includes the WiredTiger cache in its memory calculation
       to make it more likely that {+clusters+} with a full cache, but
       otherwise low traffic, will scale down. In other words,
       |service| examines the size of the WiredTiger cache to determine that it can
       safely down scale an otherwise idle {+cluster+} with low Normalized System CPU Utilization
       in cases where the {+cluster+}\'s WiredTiger caches might reach 90% of
       the {+cluster+}\'s maximum WiredTiger cache size.

  - The {+cluster+} hasn't been scaled down (manually or automatically) in
    the past 24 hours.

  These conditions ensure that |service| scales down operational nodes
  in your {+cluster+} to prevent high utilization states.

- :term:`Analytics nodes <analytics node>`:

  - The average :guilabel:`Normalized System CPU Utilization` and
    :guilabel:`System Memory Utilization` over the past 24 hours is below 50% of
    resources available to the {+cluster+}.

  - The {+cluster+} hasn't been scaled down (manually or automatically) in
    the past 24 hours.

  .. note::

     ``M10`` and ``M20`` {+clusters+} use lower thresholds to account for
     caps on CPU usage set by cloud providers after burst periods. These
     thresholds vary depending on your cloud provider and {+cluster+} tier.

.. _downward-scaling-considerations:

Considerations for Downward Auto-Scaling of Cluster Tier and Storage
````````````````````````````````````````````````````````````````````

- When |service| scales down the storage capacity of your {+cluster+},
  this can take longer than expanding storage capacity due to the 
  mechanics of the scaling process.
- Estimate your deployment's range of workloads and then set the
  :guilabel:`Minimum Cluster Size` value to the {+cluster+} tier that
  has enough capacity to handle your deployment's workload. Account for
  any possible spikes or dips in {+cluster+} activity.

- You can't scale to a {+cluster+} tier smaller than ``M10``.

- You can't select a minimum {+cluster+} tier that is below the current
  disk configuration of your {+cluster+}. If your storage increases
  beyond what is supported by your minimum {+cluster+} tier, |service|
  increases your {+cluster+}\s storage configuration beyond what your
  minimum {+cluster+} tier supports, then |service| automatically 
  adjusts your minimum {+cluster+} tier to a tier that
  supports the current storage requirements of your {+cluster+}.

  .. example::

     You have set your auto-scaling bounds to ``M20`` - ``M60`` and your
     current {+cluster+} tier is ``M40`` with a disk capacity of 200GB. 
     |service| triggers a disk auto-scaling event to increase capacity to 
     320GB because current disk usage exceeds 180GB, which is more than 
     90% of the 200GB capacity.

     |service|:
     
     1. Raises your minimum cluster tier to the next lowest tier, ``M30``,
        that can accommodate the new storage capacity. ``M20`` supports a 
        maximum storage capacity of 256GB, so it is no longer a 
        valid auto-scaling bound.
     2. |service| determines that the current instance size, ``M40``,
        supports the new disk configuration. The disk auto-scaling event 
        succeeds.

Scaling a Sharded {+Cluster+}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

|service| auto-scales the {+cluster+} tier for sharded {+clusters+}
using the same criteria as replica sets. |service| applies the 
following rules:

- If the operational or analytics nodes within a shard
  meet the criteria to auto-scale,
  only the operational/analytics nodes on that particular shard will change tier.
- The Config server replica set doesn't auto-scale.

.. _independently-scaling-shards:
  
New API for Independently Scaling Shards in {+Clusters+}
``````````````````````````````````````````````````````````

As of API resource version 2024-08-05 of the :ref:`Versioned Atlas Administration API <api-versioning-overview>`,
you can independently scale the {+cluster+} tier of each shard individually.
This API version is a significant change to the underlying scaling model of |service| {+clusters+}.

.. warning::

   The 2024-08-05 API version is a significant breaking change.
   If you send a request with the new API to describe the shards within the {+cluster+} asymmetrically,
   *the previous symmetrical-only API will no longer be available for that {+cluster+}*.
   To return to a previous API version,
   first reconfigure the cluster to have all shards operate on the same tier.

The new API is capable of describing asymmetric {+clusters+}.
The ``replicationSpec.numShards`` field is not present in the new API schema.
Instead, each shard is specified by a separate ``replicationSpec``,
even for symmetric {+clusters+} in which all shards are configured the same.

.. _howitworks-scale-cluster-storage:

How |service| Scales Cluster Storage
------------------------------------

|service| enables {+cluster+} storage auto-scaling by default.
|service| automatically increases {+cluster+} storage when disk space used
reaches 90% for *any* node in the {+cluster+}.

The following considerations apply:

- |service| automatically scales {+cluster+} storage up only. You can manually
  reduce your {+cluster+} storage from the :ref:`Edit Cluster <scale-cluster>` page.

- On :ref:`AWS <amazon-aws>`, :ref:`Azure <microsoft-azure>`, and
  :ref:`GCP <google-gcp>` {+clusters+}, |service| increases {+cluster+}
  storage capacity to achieve 70% disk space used. To learn more, see
  :ref:`change-storage-capacity-aws`, :ref:`change-storage-capacity-azure`,
  and :ref:`change-storage-capacity-gcp`.

- Avoid high-speed write activity if you plan to scale up {+clusters+}.
  Scaling up a {+cluster+} to greater storage capacity requires sufficient
  time to  prepare and copy data to new disks. If a {+cluster+} receives
  a burst of high-speed write activity, such as a bulk insert, automatic
  scaling might not occur due to a temporary spike in disk storage capacity.
  To reduce the risk of running out of disk  storage, plan to scale up
  {+clusters+} in advance of bulk inserts and other instances of high-speed
  write activity.

- |service| disables disk auto-scaling if you specify one cluster tier
  class for the base nodes and another, different cluster tier class for
  the analytics nodes. For example, if you specify a :guilabel:`General`
  cluster class for :term:`operational nodes <operational node>` in
  the :guilabel:`Base Tier`, and a :guilabel:`Low-CPU` cluster class for
  analytics nodes in the :guilabel:`Analytics Tier`, |service| disables
  disk auto-scaling with the following error message: ``Disk auto-scaling
  is not yet available for clusters with mixed instance classes``.

- |service| disables disk auto-scaling if you deploy the :guilabel:`Base Tier`
  and :guilabel:`Analytics Tier` nodes in different cloud provider regions.

{+Cluster+} Tier and {+Cluster+} Storage Might Scale in Parallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When |service| attempts to automatically scale your {+cluster+} storage
capacity, it might need to scale your storage outside of the bounds that
your current {+cluster+} tier supports. To help ensure that your {+cluster+}
doesn't experience any downtime, |service| scales your {+cluster+} tier
(in addition to {+cluster+} storage) to accommodate the new storage capacity.

On |azure|, if you enable auto-scaling on a {+cluster+} deployed in one of
the :ref:`regions that support extended storage <microsoft-azure-storage-supported-regions>`,
and the current |iops| is lower than the default |iops| for the auto-scaled
disk size, |service| increases the alloted number of |iops| in the
:guilabel:`IOPS` slider and notifies you in the UI. To learn more, see
:ref:`change-storage-capacity-azure`.

.. example::

   The maximum storage capacity for an ``M30`` {+cluster+} is 480 GB. If
   you have an ``M30`` {+cluster+} with the maximum storage allocated and
   your disk space used reaches 90%, a storage auto-scaling event requires
   raising your storage capacity to 600 GB. In this case, |service| scales
   your {+cluster+} tier up to ``M40`` because this is the lowest {+cluster+}
   tier that can support the new required storage capacity. On |azure|,
   if you deployed the {+cluster+} in one of the :ref:`regions that support extended storage <microsoft-azure-storage-supported-regions>`,
   |service| also automatically increases |iops| to match the |iops| level
   for that tier's {+cluster+}.

In the event that your specified maximum {+cluster+} tier can't support
the new storage capacity, |service|:

1. Raises your maximum {+cluster+} tier to the next lowest tier that can
   accommodate the new storage capacity.

#. Scales your {+cluster+} tier to that new maximum tier.

.. note::

   When |service| overrides your maximum {+cluster+} tier, it also disables
   your {+cluster+} from automatically scaling down. To re-enable downward
   auto-scaling, configure it in :ref:`Cluster Settings <scale-cluster>`.
   See also :ref:`downward-scaling-considerations`.

If |service| attempts to scale your {+cluster+} tier down and the target
tier can't support your current disk capacity, provisioned |iops|, or both,
|service| doesn't scale your {+cluster+} down. In this scenario, |service|
updates your auto-scaling settings based on the relationship between your
current {+cluster+} tier and the configured maximum {+cluster+} tier:

- If the {+cluster+} is currently at the configured maximum {+cluster+}
  tier, |service| disables the {+cluster+} from automatically scaling
  down because all smaller tiers wouldn't be able to accommodate
  the necessary storage settings. If you want to re-enable downward
  auto-scaling, you must do so manually from your :ref:`Cluster
  Settings <scale-cluster>`.

- If the {+cluster+} isn't currently at the configured maximum {+cluster+}
  tier, |service| raises the minimum {+cluster+} tier to the current {+cluster+}
  tier. In this case, |service| doesn't disable downward auto-scaling.

This auto-scaling logic reduces the downtime in cases when your storage
settings don't match your workload.

Oplog Considerations
~~~~~~~~~~~~~~~~~~~~

Depending on whether you choose to use storage auto-scaling, |service| manages
the oplog entries based on either the minimum oplog retention window, or
the oplog size. To learn more, see :ref:`Oplog Size Behavior <oplog-size-behavior>`.
|service| enables storage auto-scaling by default.

Configure Auto-Scaling Options
------------------------------

You can configure auto-scaling options when you
:ref:`create <create-new-cluster>` or :ref:`modify <scale-cluster>` a
{+cluster+}. For new clusters, |service| automatically enables
{+cluster+} tier auto-scaling and storage auto-scaling.

You can do one of the following:

- Review and adjust the upper and lower {+cluster+} tiers that |service|
  should use when auto-scaling your {+cluster+}, or
- :ref:`Opt out <opt-out-autoscaling>` of using auto-scaling.

|service| displays auto-scaling options in the :guilabel:`Auto-scale`
section of the {+cluster+} builder for :guilabel:`General` and
:guilabel:`Low-CPU` tier {+clusters+}.

.. _configure-cluster-autoscaling:

Auto-Scaling Enabled by Default
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When you create a new {+cluster+}, |service| enables auto-scaling for
{+cluster+} tier and {+cluster+} storage. You don't need
to explicitly enable auto-scaling. If you prefer, you can
:ref:`opt out <opt-out-autoscaling>` for {+cluster+} tier and cluster
storage.

.. note::

   |service| enables cluster tier auto-scaling by default when you
   create {+clusters+} in the {+atlas-ui+}. If you
   :oas-atlas-op:`create clusters with the API </createOneCluster>`,
   |service| disables {+cluster+} tier auto-scaling by default.

With auto-scaling enabled, your {+cluster+} can automatically:

- Scale up to increase capability with a higher {+cluster+} tier.
- Decrease the current {+cluster+} tier to a lower {+cluster+} tier.

In the :guilabel:`Cluster tier` section of the :guilabel:`Auto-scale`
options, you can specify the :guilabel:`Maximum Cluster Size` and
:guilabel:`Minimum Cluster Size` values that your {+cluster+} can
automatically scale to. |service| sets these values as follows:

- The :guilabel:`Maximum Cluster Size` is set to one tier above your
  current {+cluster+} tier.

- The :guilabel:`Minimum Cluster Size` is set to the current {+cluster+}
  tier.

Review the {+Cluster+} Tier Auto-Scaling Options
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To review the enabled auto-scaling options for {+cluster+} tier and storage:

1. In the selected :guilabel:`Auto-Scale` checkbox, review
   the :guilabel:`Maximum Cluster Size` and
   :guilabel:`Minimum Cluster Size` values, and adjust them if needed.

#. Review the :guilabel:`Allow cluster to be scaled down` option 
   that is checked by default when you create a new {+cluster+}.

#. Review the options under the :guilabel:`Storage Scaling` checkbox
   that is checked by default.

.. _opt-out-autoscaling:

Opt Out of {+Cluster+} Tier and Storage Auto-Scaling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To opt out of {+cluster+} auto-scaling (increasing the cluster tier),
when :ref:`creating a new cluster <create-new-cluster>`, navigate to the
:guilabel:`Cluster Tier` menu, and un-check the
:guilabel:`Cluster Tier Scaling` checkbox in the :guilabel:`Auto-scale`
section.

To opt out of {+cluster+} auto-scaling (decreasing the cluster tier),
when :ref:`creating a new cluster <create-new-cluster>`, navigate to
:guilabel:`Cluster Tier` menu, and un-check the
:guilabel:`Allow cluster to be scaled down` checkbox in the
:guilabel:`Auto-scale` section.

To opt out of cluster storage scaling, un-check the
:guilabel:`Storage Scaling` checkbox in the :guilabel:`Auto-scale`
section.

.. _activity-feed-auto-scaling-events:

Review Auto-scaling Activity Feed
----------------------------------

You can :ref:`view Activity Feed <view-activity-feed>` to review the events
for each |service| project. When an auto-scaling event occurs, |service| logs
the event in the project :guilabel:`Activity Feed`.

To view or download only auto-scaling events:

1. In the :guilabel:`Activity Feed`, click the :guilabel:`Filter by event(s)` menu and check :guilabel:`Atlas`.
2. In the search box above the list, start typing ``auto-scaling``.

   In the right-hand side of the menu, all auto-scaling events display.
   Deselect any that you don't want to see.
   The feed list automatically updates with each change you make.

.. _custom-alerts-auto-scaling-events:

Configure Alerts for Auto-scaling Events
-----------------------------------------

.. important::

   .. include:: /includes/opt-out-of-auto-autoscaling-emails.rst

Auto-scaling activities are a subset of :ref:`Atlas alerts <alert-conditions>`.

|service| automatically sets up default alerts for :ref:`auto-scaling events <alert-conditions-autoscaling>`.
You can opt out of or change alert configuration for some or all auto-scaling
events at a project level.

To modify an alert configuration, in the :guilabel:`Category` section,
select :guilabel:`Atlas Auto Scaling` and then select the :guilabel:`Condition/Metric`
from the list. You can then modify roles for alert recipients, change a
notification method, such as email or SMS, and add a notifier, such as Slack.
To learn more, see :ref:`configure-autoscaling-alert`.
